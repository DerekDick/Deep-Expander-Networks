Namespace(acc_type='class', augment=True, batch_size=128, bottleneck=True, cachemode=True, cardinality=8, criterion='crossentropy', cuda=True, data_dir='/ssd_scratch/cvit/Imagenet12', dataset='imagenet12', decayinterval=30, decaylevel=10, droprate=0, epochs=90, evaluate=False, expandConfig=None, expandSize=2, from_modelzoo=False, growth=48, layers=100, learningratescheduler='imagenetschedular', logdir='../logs/imagenet_densenetexpander169_expandsize2_nov12', lr=0.1, manualSeed=123, maxlr=0.1, minlr=1e-05, model_def='densenetexpander169', momentum=0.9, name='imagenet_densenetexpander169_expandsize2_nov12', nclasses=1000, nesterov=True, ngpus=2, optimType='sgd', pretrained=False, pretrained_file='', printfreq=200, reduce=0.5, resume='savedmodels/densenetexpander169_imagenet_densenetexpander169_expandsize2_nov12_best.pth.tar', start_epoch=0, store='', tenCrop=False, tensorboard=True, testOnly=False, verbose=True, weightDecay=0.0001, weight_init=False, widen_factor=4, workers=8)
DataParallel (
  (module): DenseNet (
    (features): Sequential (
      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      (relu0): ReLU (inplace)
      (pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))
      (denseblock1): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (transition1): _Transition (
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU (inplace)
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)
      )
      (denseblock2): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer7): _DenseLayer (
          (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer8): _DenseLayer (
          (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer9): _DenseLayer (
          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer10): _DenseLayer (
          (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer11): _DenseLayer (
          (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer12): _DenseLayer (
          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (transition2): _Transition (
        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU (inplace)
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)
      )
      (denseblock3): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer7): _DenseLayer (
          (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer8): _DenseLayer (
          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer9): _DenseLayer (
          (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer10): _DenseLayer (
          (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer11): _DenseLayer (
          (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer12): _DenseLayer (
          (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer13): _DenseLayer (
          (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer14): _DenseLayer (
          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer15): _DenseLayer (
          (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer16): _DenseLayer (
          (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer17): _DenseLayer (
          (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer18): _DenseLayer (
          (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer19): _DenseLayer (
          (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer20): _DenseLayer (
          (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer21): _DenseLayer (
          (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer22): _DenseLayer (
          (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer23): _DenseLayer (
          (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer24): _DenseLayer (
          (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer25): _DenseLayer (
          (norm.1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer26): _DenseLayer (
          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer27): _DenseLayer (
          (norm.1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer28): _DenseLayer (
          (norm.1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer29): _DenseLayer (
          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer30): _DenseLayer (
          (norm.1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer31): _DenseLayer (
          (norm.1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer32): _DenseLayer (
          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (transition3): _Transition (
        (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU (inplace)
        (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)
      )
      (denseblock4): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer7): _DenseLayer (
          (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer8): _DenseLayer (
          (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer9): _DenseLayer (
          (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer10): _DenseLayer (
          (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer11): _DenseLayer (
          (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer12): _DenseLayer (
          (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer13): _DenseLayer (
          (norm.1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer14): _DenseLayer (
          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer15): _DenseLayer (
          (norm.1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer16): _DenseLayer (
          (norm.1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer17): _DenseLayer (
          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer18): _DenseLayer (
          (norm.1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer19): _DenseLayer (
          (norm.1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer20): _DenseLayer (
          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer21): _DenseLayer (
          (norm.1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer22): _DenseLayer (
          (norm.1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer23): _DenseLayer (
          (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer24): _DenseLayer (
          (norm.1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer25): _DenseLayer (
          (norm.1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer26): _DenseLayer (
          (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer27): _DenseLayer (
          (norm.1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer28): _DenseLayer (
          (norm.1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer29): _DenseLayer (
          (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer30): _DenseLayer (
          (norm.1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer31): _DenseLayer (
          (norm.1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer32): _DenseLayer (
          (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True)
    )
    (classifier): Linear (1664 -> 1000)
  )
)
=> loading checkpoint 'savedmodels/densenetexpander169_imagenet_densenetexpander169_expandsize2_nov12_best.pth.tar'
=> loaded checkpoint 'savedmodels/densenetexpander169_imagenet_densenetexpander169_expandsize2_nov12_best.pth.tar' (epoch 32)
Starting epoch number: 32 Learning rate: 0.010000000000000002
Train: [32][0/10010]	Time 14.472 (14.472)	Data 1.144 (1.144)	Loss 1.898	Prec@1 53.1250	Prec@5 81.2500
Train: [32][200/10010]	Time 0.625 (125.609)	Data 0.007 (1.364)	Loss 1.797	Prec@1 58.9164	Prec@5 80.5698
Train: [32][400/10010]	Time 0.587 (235.447)	Data 0.004 (1.551)	Loss 1.795	Prec@1 59.1022	Prec@5 80.5837
Train: [32][600/10010]	Time 0.576 (346.378)	Data 0.003 (1.736)	Loss 1.802	Prec@1 58.9356	Prec@5 80.5428
Train: [32][800/10010]	Time 0.571 (457.208)	Data 0.002 (1.911)	Loss 1.805	Prec@1 58.8629	Prec@5 80.5097
Train: [32][1000/10010]	Time 0.568 (568.503)	Data 0.002 (2.099)	Loss 1.802	Prec@1 58.9028	Prec@5 80.4945
Train: [32][1200/10010]	Time 0.566 (679.374)	Data 0.002 (2.271)	Loss 1.800	Prec@1 58.9144	Prec@5 80.5819
Train: [32][1400/10010]	Time 0.565 (791.121)	Data 0.002 (2.445)	Loss 1.799	Prec@1 58.9768	Prec@5 80.5691
Train: [32][1600/10010]	Time 0.564 (902.562)	Data 0.002 (2.619)	Loss 1.802	Prec@1 58.9890	Prec@5 80.5673
Train: [32][1800/10010]	Time 0.563 (1013.915)	Data 0.002 (2.788)	Loss 1.802	Prec@1 58.9763	Prec@5 80.5789
Train: [32][2000/10010]	Time 0.562 (1125.456)	Data 0.001 (2.966)	Loss 1.802	Prec@1 58.9713	Prec@5 80.5824
Train: [32][2200/10010]	Time 0.562 (1237.203)	Data 0.001 (3.128)	Loss 1.802	Prec@1 58.9828	Prec@5 80.6026
Train: [32][2400/10010]	Time 0.562 (1348.695)	Data 0.001 (3.296)	Loss 1.803	Prec@1 58.9826	Prec@5 80.5729
Train: [32][2600/10010]	Time 0.561 (1459.913)	Data 0.001 (3.464)	Loss 1.803	Prec@1 58.9734	Prec@5 80.5970
Train: [32][2800/10010]	Time 0.561 (1570.869)	Data 0.001 (3.640)	Loss 1.803	Prec@1 58.9580	Prec@5 80.5982
Train: [32][3000/10010]	Time 0.561 (1682.208)	Data 0.001 (3.810)	Loss 1.803	Prec@1 58.9410	Prec@5 80.5750
Train: [32][3200/10010]	Time 0.560 (1793.192)	Data 0.001 (3.979)	Loss 1.804	Prec@1 58.9284	Prec@5 80.5344
Train: [32][3400/10010]	Time 0.560 (1904.248)	Data 0.001 (4.141)	Loss 1.805	Prec@1 58.9259	Prec@5 80.5351
Train: [32][3600/10010]	Time 0.560 (2015.705)	Data 0.001 (4.301)	Loss 1.806	Prec@1 58.8940	Prec@5 80.5260
Train: [32][3800/10010]	Time 0.560 (2127.205)	Data 0.001 (4.468)	Loss 1.805	Prec@1 58.9078	Prec@5 80.5487
Train: [32][4000/10010]	Time 0.559 (2238.303)	Data 0.001 (4.632)	Loss 1.805	Prec@1 58.9230	Prec@5 80.5568
Train: [32][4200/10010]	Time 0.559 (2350.109)	Data 0.001 (4.801)	Loss 1.806	Prec@1 58.9231	Prec@5 80.5428
Train: [32][4400/10010]	Time 0.559 (2461.841)	Data 0.001 (4.968)	Loss 1.806	Prec@1 58.9278	Prec@5 80.5532
Train: [32][4600/10010]	Time 0.559 (2572.817)	Data 0.001 (5.138)	Loss 1.806	Prec@1 58.9125	Prec@5 80.5452
Train: [32][4800/10010]	Time 0.559 (2684.063)	Data 0.001 (5.307)	Loss 1.806	Prec@1 58.9161	Prec@5 80.5545
Train: [32][5000/10010]	Time 0.559 (2795.095)	Data 0.001 (5.477)	Loss 1.807	Prec@1 58.9021	Prec@5 80.5339
Train: [32][5200/10010]	Time 0.559 (2906.675)	Data 0.001 (5.644)	Loss 1.806	Prec@1 58.9232	Prec@5 80.5491
Train: [32][5400/10010]	Time 0.559 (3018.179)	Data 0.001 (5.816)	Loss 1.806	Prec@1 58.9156	Prec@5 80.5483
Train: [32][5600/10010]	Time 0.559 (3129.150)	Data 0.001 (5.977)	Loss 1.805	Prec@1 58.9215	Prec@5 80.5625
Train: [32][5800/10010]	Time 0.559 (3240.149)	Data 0.001 (6.138)	Loss 1.805	Prec@1 58.9106	Prec@5 80.5632
Train: [32][6000/10010]	Time 0.558 (3351.345)	Data 0.001 (6.307)	Loss 1.805	Prec@1 58.9096	Prec@5 80.5638
Train: [32][6200/10010]	Time 0.558 (3462.414)	Data 0.001 (6.471)	Loss 1.806	Prec@1 58.8980	Prec@5 80.5490
Train: [32][6400/10010]	Time 0.558 (3573.629)	Data 0.001 (6.633)	Loss 1.806	Prec@1 58.8962	Prec@5 80.5570
Train: [32][6600/10010]	Time 0.558 (3684.631)	Data 0.001 (6.791)	Loss 1.806	Prec@1 58.8789	Prec@5 80.5533
Train: [32][6800/10010]	Time 0.558 (3796.244)	Data 0.001 (6.961)	Loss 1.806	Prec@1 58.8800	Prec@5 80.5531
Train: [32][7000/10010]	Time 0.558 (3907.608)	Data 0.001 (7.127)	Loss 1.806	Prec@1 58.8825	Prec@5 80.5553
Train: [32][7200/10010]	Time 0.558 (4019.112)	Data 0.001 (7.294)	Loss 1.806	Prec@1 58.8885	Prec@5 80.5534
Train: [32][7400/10010]	Time 0.558 (4130.476)	Data 0.001 (7.463)	Loss 1.806	Prec@1 58.8761	Prec@5 80.5491
Train: [32][7600/10010]	Time 0.558 (4241.446)	Data 0.001 (7.622)	Loss 1.806	Prec@1 58.8757	Prec@5 80.5332
Train: [32][7800/10010]	Time 0.558 (4353.103)	Data 0.001 (7.786)	Loss 1.806	Prec@1 58.8762	Prec@5 80.5402
Train: [32][8000/10010]	Time 0.558 (4464.031)	Data 0.001 (7.942)	Loss 1.806	Prec@1 58.8739	Prec@5 80.5389
Train: [32][8200/10010]	Time 0.558 (4575.433)	Data 0.001 (8.105)	Loss 1.807	Prec@1 58.8656	Prec@5 80.5336
Train: [32][8400/10010]	Time 0.558 (4686.877)	Data 0.001 (8.276)	Loss 1.807	Prec@1 58.8563	Prec@5 80.5308
Train: [32][8600/10010]	Time 0.558 (4798.193)	Data 0.001 (8.444)	Loss 1.807	Prec@1 58.8575	Prec@5 80.5407
Train: [32][8800/10010]	Time 0.558 (4909.745)	Data 0.001 (8.619)	Loss 1.807	Prec@1 58.8575	Prec@5 80.5462
Train: [32][9000/10010]	Time 0.558 (5021.267)	Data 0.001 (8.797)	Loss 1.807	Prec@1 58.8634	Prec@5 80.5420
Train: [32][9200/10010]	Time 0.558 (5132.777)	Data 0.001 (8.967)	Loss 1.807	Prec@1 58.8672	Prec@5 80.5411
Train: [32][9400/10010]	Time 0.558 (5244.232)	Data 0.001 (9.131)	Loss 1.807	Prec@1 58.8739	Prec@5 80.5425
Train: [32][9600/10010]	Time 0.558 (5355.455)	Data 0.001 (9.302)	Loss 1.807	Prec@1 58.8711	Prec@5 80.5403
Train: [32][9800/10010]	Time 0.558 (5466.540)	Data 0.001 (9.460)	Loss 1.807	Prec@1 58.8748	Prec@5 80.5437
Train: [32][10000/10010]	Time 0.558 (5577.460)	Data 0.001 (9.618)	Loss 1.807	Prec@1 58.8736	Prec@5 80.5425
Train: [32]	Time 5585.101	Data 9.621	Loss 1.807	Prec@1 58.8741	Prec@5 80.5428	
Val: [32]	Time 75.572	Data 1.731	Loss 1.511	Prec@1 63.5580	Prec@5 85.4840	
Best Prec@1: [63.558]	
Starting epoch number: 33 Learning rate: 0.010000000000000002
Train: [33][0/10010]	Time 3.262 (3.262)	Data 1.510 (1.510)	Loss 1.743	Prec@1 60.9375	Prec@5 81.2500
Train: [33][200/10010]	Time 0.570 (114.503)	Data 0.008 (1.688)	Loss 1.784	Prec@1 59.1651	Prec@5 80.7836
Train: [33][400/10010]	Time 0.562 (225.262)	Data 0.005 (1.867)	Loss 1.782	Prec@1 59.2133	Prec@5 80.8798
Train: [33][600/10010]	Time 0.559 (335.836)	Data 0.003 (2.045)	Loss 1.785	Prec@1 59.1787	Prec@5 80.8600
Train: [33][800/10010]	Time 0.557 (445.901)	Data 0.003 (2.221)	Loss 1.779	Prec@1 59.2677	Prec@5 80.9262
Train: [33][1000/10010]	Time 0.557 (557.222)	Data 0.002 (2.403)	Loss 1.776	Prec@1 59.3461	Prec@5 80.9651
Train: [33][1200/10010]	Time 0.556 (668.245)	Data 0.002 (2.580)	Loss 1.773	Prec@1 59.4674	Prec@5 81.0119
Train: [33][1400/10010]	Time 0.556 (779.194)	Data 0.002 (2.762)	Loss 1.774	Prec@1 59.4904	Prec@5 81.0102
Train: [33][1600/10010]	Time 0.556 (890.552)	Data 0.002 (2.944)	Loss 1.772	Prec@1 59.4902	Prec@5 81.0480
Train: [33][1800/10010]	Time 0.556 (1001.857)	Data 0.002 (3.125)	Loss 1.772	Prec@1 59.4960	Prec@5 81.0687
Train: [33][2000/10010]	Time 0.556 (1112.762)	Data 0.002 (3.301)	Loss 1.773	Prec@1 59.4831	Prec@5 81.0278
Train: [33][2200/10010]	Time 0.556 (1223.670)	Data 0.002 (3.479)	Loss 1.774	Prec@1 59.4613	Prec@5 81.0101
Train: [33][2400/10010]	Time 0.556 (1335.093)	Data 0.002 (3.658)	Loss 1.776	Prec@1 59.4215	Prec@5 80.9532
Train: [33][2600/10010]	Time 0.556 (1446.046)	Data 0.001 (3.836)	Loss 1.775	Prec@1 59.4351	Prec@5 80.9619
Train: [33][2800/10010]	Time 0.556 (1556.906)	Data 0.001 (4.015)	Loss 1.776	Prec@1 59.4319	Prec@5 80.9410
Train: [33][3000/10010]	Time 0.556 (1667.903)	Data 0.001 (4.189)	Loss 1.777	Prec@1 59.4034	Prec@5 80.9301
Train: [33][3200/10010]	Time 0.556 (1778.814)	Data 0.001 (4.367)	Loss 1.778	Prec@1 59.4197	Prec@5 80.9298
Train: [33][3400/10010]	Time 0.556 (1889.762)	Data 0.001 (4.545)	Loss 1.777	Prec@1 59.4428	Prec@5 80.9364
Train: [33][3600/10010]	Time 0.556 (2000.559)	Data 0.001 (4.719)	Loss 1.776	Prec@1 59.4594	Prec@5 80.9367
Train: [33][3800/10010]	Time 0.555 (2110.874)	Data 0.001 (4.897)	Loss 1.777	Prec@1 59.4587	Prec@5 80.9316
Train: [33][4000/10010]	Time 0.555 (2221.561)	Data 0.001 (5.071)	Loss 1.777	Prec@1 59.4502	Prec@5 80.9130
Train: [33][4200/10010]	Time 0.555 (2332.430)	Data 0.001 (5.258)	Loss 1.778	Prec@1 59.4362	Prec@5 80.9000
Train: [33][4400/10010]	Time 0.555 (2442.808)	Data 0.001 (5.431)	Loss 1.779	Prec@1 59.4107	Prec@5 80.8792
Train: [33][4600/10010]	Time 0.555 (2553.206)	Data 0.001 (5.610)	Loss 1.780	Prec@1 59.4054	Prec@5 80.8652
Train: [33][4800/10010]	Time 0.555 (2663.722)	Data 0.001 (5.782)	Loss 1.780	Prec@1 59.4002	Prec@5 80.8735
Train: [33][5000/10010]	Time 0.555 (2774.755)	Data 0.001 (5.929)	Loss 1.780	Prec@1 59.4031	Prec@5 80.8701
Train: [33][5200/10010]	Time 0.555 (2885.909)	Data 0.001 (6.078)	Loss 1.780	Prec@1 59.4193	Prec@5 80.8640
Train: [33][5400/10010]	Time 0.555 (2996.463)	Data 0.001 (6.221)	Loss 1.781	Prec@1 59.4025	Prec@5 80.8664
Train: [33][5600/10010]	Time 0.555 (3107.189)	Data 0.001 (6.367)	Loss 1.781	Prec@1 59.4033	Prec@5 80.8647
Train: [33][5800/10010]	Time 0.555 (3217.792)	Data 0.001 (6.512)	Loss 1.781	Prec@1 59.3936	Prec@5 80.8558
Train: [33][6000/10010]	Time 0.555 (3328.443)	Data 0.001 (6.656)	Loss 1.782	Prec@1 59.3820	Prec@5 80.8432
Train: [33][6200/10010]	Time 0.555 (3438.965)	Data 0.001 (6.796)	Loss 1.782	Prec@1 59.3687	Prec@5 80.8326
Train: [33][6400/10010]	Time 0.555 (3549.709)	Data 0.001 (6.939)	Loss 1.783	Prec@1 59.3615	Prec@5 80.8239
Train: [33][6600/10010]	Time 0.555 (3660.564)	Data 0.001 (7.085)	Loss 1.782	Prec@1 59.3717	Prec@5 80.8321
Train: [33][6800/10010]	Time 0.555 (3771.239)	Data 0.001 (7.225)	Loss 1.782	Prec@1 59.3840	Prec@5 80.8377
Train: [33][7000/10010]	Time 0.555 (3882.100)	Data 0.001 (7.376)	Loss 1.783	Prec@1 59.3770	Prec@5 80.8305
Train: [33][7200/10010]	Time 0.554 (3992.516)	Data 0.001 (7.519)	Loss 1.783	Prec@1 59.3715	Prec@5 80.8320
Train: [33][7400/10010]	Time 0.554 (4103.153)	Data 0.001 (7.665)	Loss 1.784	Prec@1 59.3465	Prec@5 80.8166
Train: [33][7600/10010]	Time 0.554 (4213.452)	Data 0.001 (7.805)	Loss 1.785	Prec@1 59.3346	Prec@5 80.8128
Train: [33][7800/10010]	Time 0.554 (4324.103)	Data 0.001 (7.954)	Loss 1.785	Prec@1 59.3216	Prec@5 80.7961
Train: [33][8000/10010]	Time 0.554 (4434.731)	Data 0.001 (8.100)	Loss 1.785	Prec@1 59.3334	Prec@5 80.8056
Train: [33][8200/10010]	Time 0.554 (4545.227)	Data 0.001 (8.243)	Loss 1.784	Prec@1 59.3394	Prec@5 80.8197
Train: [33][8400/10010]	Time 0.554 (4655.460)	Data 0.001 (8.382)	Loss 1.785	Prec@1 59.3419	Prec@5 80.8103
Train: [33][8600/10010]	Time 0.554 (4765.955)	Data 0.001 (8.524)	Loss 1.785	Prec@1 59.3315	Prec@5 80.8056
Train: [33][8800/10010]	Time 0.554 (4876.292)	Data 0.001 (8.665)	Loss 1.785	Prec@1 59.3350	Prec@5 80.8146
Train: [33][9000/10010]	Time 0.554 (4986.967)	Data 0.001 (8.805)	Loss 1.785	Prec@1 59.3219	Prec@5 80.8104
Train: [33][9200/10010]	Time 0.554 (5097.776)	Data 0.001 (8.944)	Loss 1.786	Prec@1 59.3044	Prec@5 80.7979
Train: [33][9400/10010]	Time 0.554 (5208.299)	Data 0.001 (9.084)	Loss 1.787	Prec@1 59.3057	Prec@5 80.7944
Train: [33][9600/10010]	Time 0.554 (5318.870)	Data 0.001 (9.225)	Loss 1.787	Prec@1 59.2966	Prec@5 80.7867
Train: [33][9800/10010]	Time 0.554 (5429.486)	Data 0.001 (9.368)	Loss 1.787	Prec@1 59.2989	Prec@5 80.7879
Train: [33][10000/10010]	Time 0.554 (5539.893)	Data 0.001 (9.508)	Loss 1.786	Prec@1 59.2989	Prec@5 80.7954
Train: [33]	Time 5544.426	Data 9.511	Loss 1.786	Prec@1 59.2992	Prec@5 80.7964	
Val: [33]	Time 71.909	Data 1.923	Loss 1.503	Prec@1 63.6100	Prec@5 85.5900	
Best Prec@1: [63.610]	
Starting epoch number: 34 Learning rate: 0.010000000000000002
Train: [34][0/10010]	Time 2.050 (2.050)	Data 1.437 (1.437)	Loss 1.766	Prec@1 57.8125	Prec@5 82.0312
Train: [34][200/10010]	Time 0.560 (112.554)	Data 0.008 (1.626)	Loss 1.787	Prec@1 59.3284	Prec@5 80.7253
Train: [34][400/10010]	Time 0.557 (223.488)	Data 0.005 (1.820)	Loss 1.774	Prec@1 59.5133	Prec@5 80.9753
Train: [34][600/10010]	Time 0.556 (333.996)	Data 0.003 (2.015)	Loss 1.765	Prec@1 59.5804	Prec@5 81.1590
Train: [34][800/10010]	Time 0.555 (444.863)	Data 0.003 (2.204)	Loss 1.768	Prec@1 59.6344	Prec@5 81.1047
Train: [34][1000/10010]	Time 0.555 (555.853)	Data 0.002 (2.387)	Loss 1.764	Prec@1 59.7067	Prec@5 81.1454
Train: [34][1200/10010]	Time 0.555 (666.515)	Data 0.002 (2.566)	Loss 1.762	Prec@1 59.7816	Prec@5 81.1693
Train: [34][1400/10010]	Time 0.555 (777.767)	Data 0.002 (2.758)	Loss 1.762	Prec@1 59.8166	Prec@5 81.1786
Train: [34][1600/10010]	Time 0.556 (889.453)	Data 0.002 (2.948)	Loss 1.764	Prec@1 59.8088	Prec@5 81.1749
Train: [34][1800/10010]	Time 0.556 (1000.549)	Data 0.002 (3.127)	Loss 1.762	Prec@1 59.8461	Prec@5 81.2110
Train: [34][2000/10010]	Time 0.556 (1111.587)	Data 0.002 (3.308)	Loss 1.764	Prec@1 59.8053	Prec@5 81.1793
Train: [34][2200/10010]	Time 0.555 (1222.135)	Data 0.002 (3.482)	Loss 1.762	Prec@1 59.7722	Prec@5 81.2106
Train: [34][2400/10010]	Time 0.555 (1332.941)	Data 0.002 (3.661)	Loss 1.761	Prec@1 59.8052	Prec@5 81.2041
Train: [34][2600/10010]	Time 0.555 (1443.946)	Data 0.001 (3.847)	Loss 1.762	Prec@1 59.8063	Prec@5 81.1902
Train: [34][2800/10010]	Time 0.555 (1554.117)	Data 0.001 (4.027)	Loss 1.761	Prec@1 59.8174	Prec@5 81.1808
Train: [34][3000/10010]	Time 0.555 (1664.347)	Data 0.001 (4.209)	Loss 1.762	Prec@1 59.7874	Prec@5 81.1808
Train: [34][3200/10010]	Time 0.555 (1775.118)	Data 0.001 (4.385)	Loss 1.761	Prec@1 59.7960	Prec@5 81.1992
Train: [34][3400/10010]	Time 0.555 (1885.937)	Data 0.001 (4.565)	Loss 1.762	Prec@1 59.7680	Prec@5 81.1882
Train: [34][3600/10010]	Time 0.554 (1996.627)	Data 0.001 (4.751)	Loss 1.761	Prec@1 59.7785	Prec@5 81.1986
Train: [34][3800/10010]	Time 0.555 (2108.034)	Data 0.001 (4.945)	Loss 1.763	Prec@1 59.7450	Prec@5 81.1663
Train: [34][4000/10010]	Time 0.555 (2219.270)	Data 0.001 (5.148)	Loss 1.765	Prec@1 59.6997	Prec@5 81.1336
Train: [34][4200/10010]	Time 0.555 (2330.315)	Data 0.001 (5.334)	Loss 1.766	Prec@1 59.6900	Prec@5 81.1405
Train: [34][4400/10010]	Time 0.555 (2441.379)	Data 0.001 (5.514)	Loss 1.767	Prec@1 59.6569	Prec@5 81.1185
Train: [34][4600/10010]	Time 0.555 (2552.127)	Data 0.001 (5.694)	Loss 1.767	Prec@1 59.6538	Prec@5 81.1162
Train: [34][4800/10010]	Time 0.555 (2663.339)	Data 0.001 (5.875)	Loss 1.767	Prec@1 59.6720	Prec@5 81.1162
Train: [34][5000/10010]	Time 0.555 (2773.923)	Data 0.001 (6.055)	Loss 1.767	Prec@1 59.6663	Prec@5 81.1147
Train: [34][5200/10010]	Time 0.555 (2885.314)	Data 0.001 (6.234)	Loss 1.768	Prec@1 59.6508	Prec@5 81.1014
Train: [34][5400/10010]	Time 0.555 (2996.098)	Data 0.001 (6.413)	Loss 1.769	Prec@1 59.6213	Prec@5 81.0699
Train: [34][5600/10010]	Time 0.555 (3106.522)	Data 0.001 (6.587)	Loss 1.769	Prec@1 59.6180	Prec@5 81.0720
Train: [34][5800/10010]	Time 0.555 (3217.632)	Data 0.001 (6.757)	Loss 1.770	Prec@1 59.6038	Prec@5 81.0563
Train: [34][6000/10010]	Time 0.555 (3328.179)	Data 0.001 (6.936)	Loss 1.770	Prec@1 59.5911	Prec@5 81.0568
Train: [34][6200/10010]	Time 0.555 (3439.025)	Data 0.001 (7.121)	Loss 1.770	Prec@1 59.5880	Prec@5 81.0463
Train: [34][6400/10010]	Time 0.555 (3549.910)	Data 0.001 (7.316)	Loss 1.771	Prec@1 59.5775	Prec@5 81.0419
Train: [34][6600/10010]	Time 0.555 (3660.823)	Data 0.001 (7.511)	Loss 1.771	Prec@1 59.5782	Prec@5 81.0457
Train: [34][6800/10010]	Time 0.555 (3771.501)	Data 0.001 (7.689)	Loss 1.772	Prec@1 59.5566	Prec@5 81.0348
Train: [34][7000/10010]	Time 0.555 (3882.484)	Data 0.001 (7.873)	Loss 1.772	Prec@1 59.5419	Prec@5 81.0229
Train: [34][7200/10010]	Time 0.555 (3993.659)	Data 0.001 (8.057)	Loss 1.773	Prec@1 59.5360	Prec@5 81.0200
Train: [34][7400/10010]	Time 0.555 (4105.154)	Data 0.001 (8.246)	Loss 1.773	Prec@1 59.5333	Prec@5 81.0070
Train: [34][7600/10010]	Time 0.555 (4216.623)	Data 0.001 (8.437)	Loss 1.774	Prec@1 59.5116	Prec@5 80.9968
Train: [34][7800/10010]	Time 0.555 (4328.036)	Data 0.001 (8.621)	Loss 1.774	Prec@1 59.5012	Prec@5 80.9807
Train: [34][8000/10010]	Time 0.555 (4439.371)	Data 0.001 (8.803)	Loss 1.774	Prec@1 59.5011	Prec@5 80.9837
Train: [34][8200/10010]	Time 0.555 (4550.575)	Data 0.001 (8.992)	Loss 1.774	Prec@1 59.4949	Prec@5 80.9844
Train: [34][8400/10010]	Time 0.555 (4661.387)	Data 0.001 (9.187)	Loss 1.774	Prec@1 59.5005	Prec@5 80.9850
Train: [34][8600/10010]	Time 0.555 (4771.968)	Data 0.001 (9.353)	Loss 1.775	Prec@1 59.4847	Prec@5 80.9777
Train: [34][8800/10010]	Time 0.555 (4882.704)	Data 0.001 (9.525)	Loss 1.776	Prec@1 59.4682	Prec@5 80.9580
Train: [34][9000/10010]	Time 0.555 (4993.260)	Data 0.001 (9.700)	Loss 1.776	Prec@1 59.4638	Prec@5 80.9580
Train: [34][9200/10010]	Time 0.555 (5103.454)	Data 0.001 (9.869)	Loss 1.776	Prec@1 59.4475	Prec@5 80.9528
Train: [34][9400/10010]	Time 0.555 (5214.082)	Data 0.001 (10.033)	Loss 1.777	Prec@1 59.4289	Prec@5 80.9480
Train: [34][9600/10010]	Time 0.555 (5324.350)	Data 0.001 (10.191)	Loss 1.777	Prec@1 59.4128	Prec@5 80.9359
Train: [34][9800/10010]	Time 0.555 (5434.851)	Data 0.001 (10.362)	Loss 1.778	Prec@1 59.4033	Prec@5 80.9329
Train: [34][10000/10010]	Time 0.554 (5545.418)	Data 0.001 (10.527)	Loss 1.778	Prec@1 59.4043	Prec@5 80.9324
Train: [34]	Time 5549.936	Data 10.531	Loss 1.778	Prec@1 59.4052	Prec@5 80.9331	
Val: [34]	Time 73.769	Data 1.753	Loss 1.552	Prec@1 62.6500	Prec@5 84.9380	
Best Prec@1: [63.610]	
Starting epoch number: 35 Learning rate: 0.010000000000000002
Train: [35][0/10010]	Time 2.080 (2.080)	Data 1.359 (1.359)	Loss 1.928	Prec@1 59.3750	Prec@5 76.5625
Train: [35][200/10010]	Time 0.561 (112.813)	Data 0.008 (1.548)	Loss 1.754	Prec@1 59.9891	Prec@5 81.3511
Train: [35][400/10010]	Time 0.559 (223.974)	Data 0.004 (1.731)	Loss 1.747	Prec@1 60.0140	Prec@5 81.3981
Train: [35][600/10010]	Time 0.558 (335.215)	Data 0.003 (1.915)	Loss 1.753	Prec@1 59.9886	Prec@5 81.2487
Train: [35][800/10010]	Time 0.557 (446.027)	Data 0.003 (2.094)	Loss 1.753	Prec@1 60.0782	Prec@5 81.2285
Train: [35][1000/10010]	Time 0.556 (556.771)	Data 0.002 (2.279)	Loss 1.756	Prec@1 59.9596	Prec@5 81.2391
Train: [35][1200/10010]	Time 0.556 (667.647)	Data 0.002 (2.460)	Loss 1.752	Prec@1 60.0105	Prec@5 81.3072
Train: [35][1400/10010]	Time 0.556 (778.566)	Data 0.002 (2.626)	Loss 1.753	Prec@1 59.9516	Prec@5 81.3191
Train: [35][1600/10010]	Time 0.555 (888.821)	Data 0.002 (2.791)	Loss 1.754	Prec@1 59.9264	Prec@5 81.3149
Train: [35][1800/10010]	Time 0.555 (999.286)	Data 0.002 (2.954)	Loss 1.755	Prec@1 59.8747	Prec@5 81.3303
Train: [35][2000/10010]	Time 0.554 (1109.377)	Data 0.002 (3.111)	Loss 1.755	Prec@1 59.8623	Prec@5 81.3027
Train: [35][2200/10010]	Time 0.554 (1219.843)	Data 0.001 (3.271)	Loss 1.754	Prec@1 59.8467	Prec@5 81.3245
Train: [35][2400/10010]	Time 0.554 (1330.519)	Data 0.001 (3.435)	Loss 1.757	Prec@1 59.7960	Prec@5 81.2777
Train: [35][2600/10010]	Time 0.554 (1440.914)	Data 0.001 (3.595)	Loss 1.757	Prec@1 59.7967	Prec@5 81.2479
Train: [35][2800/10010]	Time 0.554 (1551.703)	Data 0.001 (3.762)	Loss 1.758	Prec@1 59.7616	Prec@5 81.2316
Train: [35][3000/10010]	Time 0.554 (1662.172)	Data 0.001 (3.913)	Loss 1.758	Prec@1 59.7553	Prec@5 81.2305
Train: [35][3200/10010]	Time 0.554 (1772.422)	Data 0.001 (4.071)	Loss 1.760	Prec@1 59.7206	Prec@5 81.2053
Train: [35][3400/10010]	Time 0.554 (1882.759)	Data 0.001 (4.227)	Loss 1.761	Prec@1 59.6961	Prec@5 81.1832
Train: [35][3600/10010]	Time 0.554 (1993.165)	Data 0.001 (4.394)	Loss 1.763	Prec@1 59.6783	Prec@5 81.1474
Train: [35][3800/10010]	Time 0.553 (2103.807)	Data 0.001 (4.557)	Loss 1.762	Prec@1 59.6850	Prec@5 81.1828
Train: [35][4000/10010]	Time 0.554 (2214.823)	Data 0.001 (4.727)	Loss 1.762	Prec@1 59.6564	Prec@5 81.1797
Train: [35][4200/10010]	Time 0.554 (2325.370)	Data 0.001 (4.891)	Loss 1.763	Prec@1 59.6420	Prec@5 81.1589
Train: [35][4400/10010]	Time 0.553 (2435.917)	Data 0.001 (5.056)	Loss 1.764	Prec@1 59.6358	Prec@5 81.1451
Train: [35][4600/10010]	Time 0.553 (2546.478)	Data 0.001 (5.207)	Loss 1.765	Prec@1 59.6226	Prec@5 81.1203
Train: [35][4800/10010]	Time 0.553 (2656.981)	Data 0.001 (5.362)	Loss 1.767	Prec@1 59.5927	Prec@5 81.1042
Train: [35][5000/10010]	Time 0.553 (2767.882)	Data 0.001 (5.530)	Loss 1.768	Prec@1 59.5692	Prec@5 81.0986
Train: [35][5200/10010]	Time 0.553 (2878.708)	Data 0.001 (5.687)	Loss 1.768	Prec@1 59.5667	Prec@5 81.0996
Train: [35][5400/10010]	Time 0.553 (2989.377)	Data 0.001 (5.852)	Loss 1.768	Prec@1 59.5642	Prec@5 81.1023
Train: [35][5600/10010]	Time 0.554 (3100.271)	Data 0.001 (6.028)	Loss 1.768	Prec@1 59.5583	Prec@5 81.0927
Train: [35][5800/10010]	Time 0.554 (3211.006)	Data 0.001 (6.191)	Loss 1.768	Prec@1 59.5714	Prec@5 81.0997
Train: [35][6000/10010]	Time 0.554 (3321.865)	Data 0.001 (6.348)	Loss 1.767	Prec@1 59.5798	Prec@5 81.1000
Train: [35][6200/10010]	Time 0.554 (3432.666)	Data 0.001 (6.499)	Loss 1.768	Prec@1 59.5548	Prec@5 81.0924
Train: [35][6400/10010]	Time 0.554 (3543.317)	Data 0.001 (6.658)	Loss 1.769	Prec@1 59.5490	Prec@5 81.0882
Train: [35][6600/10010]	Time 0.554 (3654.534)	Data 0.001 (6.821)	Loss 1.769	Prec@1 59.5478	Prec@5 81.0844
Train: [35][6800/10010]	Time 0.554 (3765.647)	Data 0.001 (6.984)	Loss 1.770	Prec@1 59.5248	Prec@5 81.0718
Train: [35][7000/10010]	Time 0.554 (3876.960)	Data 0.001 (7.146)	Loss 1.771	Prec@1 59.5153	Prec@5 81.0606
Train: [35][7200/10010]	Time 0.554 (3987.960)	Data 0.001 (7.290)	Loss 1.770	Prec@1 59.5212	Prec@5 81.0651
Train: [35][7400/10010]	Time 0.554 (4099.447)	Data 0.001 (7.443)	Loss 1.771	Prec@1 59.5096	Prec@5 81.0548
Train: [35][7600/10010]	Time 0.554 (4210.272)	Data 0.001 (7.604)	Loss 1.772	Prec@1 59.4912	Prec@5 81.0419
Train: [35][7800/10010]	Time 0.554 (4321.284)	Data 0.001 (7.765)	Loss 1.772	Prec@1 59.4962	Prec@5 81.0481
Train: [35][8000/10010]	Time 0.554 (4432.063)	Data 0.001 (7.913)	Loss 1.772	Prec@1 59.4833	Prec@5 81.0453
Train: [35][8200/10010]	Time 0.554 (4543.081)	Data 0.001 (8.067)	Loss 1.772	Prec@1 59.4810	Prec@5 81.0465
Train: [35][8400/10010]	Time 0.554 (4654.435)	Data 0.001 (8.227)	Loss 1.772	Prec@1 59.4850	Prec@5 81.0442
Train: [35][8600/10010]	Time 0.554 (4765.296)	Data 0.001 (8.395)	Loss 1.772	Prec@1 59.4904	Prec@5 81.0466
Train: [35][8800/10010]	Time 0.554 (4875.904)	Data 0.001 (8.563)	Loss 1.773	Prec@1 59.4829	Prec@5 81.0365
Train: [35][9000/10010]	Time 0.554 (4986.898)	Data 0.001 (8.712)	Loss 1.773	Prec@1 59.4855	Prec@5 81.0419
Train: [35][9200/10010]	Time 0.554 (5097.695)	Data 0.001 (8.862)	Loss 1.773	Prec@1 59.4837	Prec@5 81.0350
Train: [35][9400/10010]	Time 0.554 (5208.435)	Data 0.001 (9.019)	Loss 1.773	Prec@1 59.4805	Prec@5 81.0314
Train: [35][9600/10010]	Time 0.554 (5318.756)	Data 0.001 (9.157)	Loss 1.774	Prec@1 59.4708	Prec@5 81.0218
Train: [35][9800/10010]	Time 0.554 (5429.360)	Data 0.001 (9.302)	Loss 1.774	Prec@1 59.4789	Prec@5 81.0200
Train: [35][10000/10010]	Time 0.554 (5540.211)	Data 0.001 (9.453)	Loss 1.774	Prec@1 59.4744	Prec@5 81.0064
Train: [35]	Time 5544.845	Data 9.457	Loss 1.774	Prec@1 59.4740	Prec@5 81.0067	
Val: [35]	Time 74.084	Data 1.769	Loss 1.486	Prec@1 63.9280	Prec@5 86.0000	
Best Prec@1: [63.928]	
Starting epoch number: 36 Learning rate: 0.010000000000000002
Train: [36][0/10010]	Time 2.025 (2.025)	Data 1.467 (1.467)	Loss 1.827	Prec@1 57.0312	Prec@5 79.6875
Train: [36][200/10010]	Time 0.562 (112.895)	Data 0.008 (1.654)	Loss 1.773	Prec@1 59.3361	Prec@5 80.8691
Train: [36][400/10010]	Time 0.559 (224.075)	Data 0.005 (1.836)	Loss 1.762	Prec@1 59.5464	Prec@5 81.1078
Train: [36][600/10010]	Time 0.559 (335.776)	Data 0.003 (2.013)	Loss 1.760	Prec@1 59.6480	Prec@5 81.2357
Train: [36][800/10010]	Time 0.558 (446.642)	Data 0.003 (2.190)	Loss 1.761	Prec@1 59.6744	Prec@5 81.1856
Train: [36][1000/10010]	Time 0.557 (557.872)	Data 0.002 (2.361)	Loss 1.759	Prec@1 59.6411	Prec@5 81.2375
Train: [36][1200/10010]	Time 0.557 (669.191)	Data 0.002 (2.533)	Loss 1.758	Prec@1 59.6228	Prec@5 81.2526
Train: [36][1400/10010]	Time 0.557 (780.250)	Data 0.002 (2.697)	Loss 1.759	Prec@1 59.6878	Prec@5 81.2260
Train: [36][1600/10010]	Time 0.557 (891.436)	Data 0.002 (2.870)	Loss 1.758	Prec@1 59.7151	Prec@5 81.2354
Train: [36][1800/10010]	Time 0.556 (1002.114)	Data 0.002 (3.039)	Loss 1.759	Prec@1 59.7311	Prec@5 81.2574
Train: [36][2000/10010]	Time 0.556 (1113.082)	Data 0.002 (3.214)	Loss 1.758	Prec@1 59.7404	Prec@5 81.2754
Train: [36][2200/10010]	Time 0.556 (1224.045)	Data 0.002 (3.386)	Loss 1.758	Prec@1 59.7619	Prec@5 81.3100
Train: [36][2400/10010]	Time 0.556 (1334.939)	Data 0.001 (3.550)	Loss 1.760	Prec@1 59.7079	Prec@5 81.2708
Train: [36][2600/10010]	Time 0.556 (1445.907)	Data 0.001 (3.727)	Loss 1.758	Prec@1 59.7493	Prec@5 81.2791
Train: [36][2800/10010]	Time 0.556 (1556.352)	Data 0.001 (3.877)	Loss 1.759	Prec@1 59.7409	Prec@5 81.2698
Train: [36][3000/10010]	Time 0.556 (1667.781)	Data 0.001 (4.036)	Loss 1.760	Prec@1 59.7343	Prec@5 81.2583
Train: [36][3200/10010]	Time 0.556 (1779.150)	Data 0.001 (4.195)	Loss 1.761	Prec@1 59.7111	Prec@5 81.2422
Train: [36][3400/10010]	Time 0.556 (1890.634)	Data 0.001 (4.351)	Loss 1.761	Prec@1 59.6998	Prec@5 81.2364
Train: [36][3600/10010]	Time 0.556 (2002.141)	Data 0.001 (4.518)	Loss 1.762	Prec@1 59.6998	Prec@5 81.2188
Train: [36][3800/10010]	Time 0.556 (2113.458)	Data 0.001 (4.666)	Loss 1.763	Prec@1 59.6911	Prec@5 81.2019
Train: [36][4000/10010]	Time 0.556 (2224.155)	Data 0.001 (4.840)	Loss 1.763	Prec@1 59.6880	Prec@5 81.2004
Train: [36][4200/10010]	Time 0.556 (2334.292)	Data 0.001 (5.011)	Loss 1.764	Prec@1 59.6603	Prec@5 81.1810
Train: [36][4400/10010]	Time 0.555 (2444.548)	Data 0.001 (5.185)	Loss 1.763	Prec@1 59.6766	Prec@5 81.1900
Train: [36][4600/10010]	Time 0.555 (2554.103)	Data 0.001 (5.359)	Loss 1.764	Prec@1 59.6761	Prec@5 81.1868
Train: [36][4800/10010]	Time 0.555 (2664.096)	Data 0.001 (5.529)	Loss 1.764	Prec@1 59.6692	Prec@5 81.1852
Train: [36][5000/10010]	Time 0.555 (2774.002)	Data 0.001 (5.698)	Loss 1.764	Prec@1 59.6585	Prec@5 81.1795
Train: [36][5200/10010]	Time 0.554 (2883.788)	Data 0.001 (5.868)	Loss 1.765	Prec@1 59.6421	Prec@5 81.1654
Train: [36][5400/10010]	Time 0.554 (2993.592)	Data 0.001 (6.037)	Loss 1.765	Prec@1 59.6209	Prec@5 81.1592
Train: [36][5600/10010]	Time 0.554 (3103.599)	Data 0.001 (6.210)	Loss 1.765	Prec@1 59.6190	Prec@5 81.1609
Train: [36][5800/10010]	Time 0.554 (3213.518)	Data 0.001 (6.381)	Loss 1.765	Prec@1 59.6190	Prec@5 81.1455
Train: [36][6000/10010]	Time 0.554 (3323.100)	Data 0.001 (6.544)	Loss 1.766	Prec@1 59.6096	Prec@5 81.1408
Train: [36][6200/10010]	Time 0.554 (3433.070)	Data 0.001 (6.714)	Loss 1.766	Prec@1 59.6072	Prec@5 81.1448
Train: [36][6400/10010]	Time 0.554 (3543.103)	Data 0.001 (6.886)	Loss 1.766	Prec@1 59.5993	Prec@5 81.1295
Train: [36][6600/10010]	Time 0.553 (3653.156)	Data 0.001 (7.056)	Loss 1.766	Prec@1 59.6024	Prec@5 81.1255
Train: [36][6800/10010]	Time 0.553 (3762.798)	Data 0.001 (7.225)	Loss 1.767	Prec@1 59.5745	Prec@5 81.1151
Train: [36][7000/10010]	Time 0.553 (3872.805)	Data 0.001 (7.396)	Loss 1.767	Prec@1 59.5638	Prec@5 81.1107
Train: [36][7200/10010]	Time 0.553 (3982.639)	Data 0.001 (7.566)	Loss 1.768	Prec@1 59.5595	Prec@5 81.0996
Train: [36][7400/10010]	Time 0.553 (4092.532)	Data 0.001 (7.735)	Loss 1.768	Prec@1 59.5592	Prec@5 81.1115
Train: [36][7600/10010]	Time 0.553 (4201.996)	Data 0.001 (7.902)	Loss 1.768	Prec@1 59.5549	Prec@5 81.1127
Train: [36][7800/10010]	Time 0.553 (4311.636)	Data 0.001 (8.073)	Loss 1.768	Prec@1 59.5436	Prec@5 81.1087
Train: [36][8000/10010]	Time 0.553 (4421.122)	Data 0.001 (8.242)	Loss 1.769	Prec@1 59.5386	Prec@5 81.0995
Train: [36][8200/10010]	Time 0.552 (4530.678)	Data 0.001 (8.411)	Loss 1.769	Prec@1 59.5371	Prec@5 81.0933
Train: [36][8400/10010]	Time 0.552 (4640.146)	Data 0.001 (8.574)	Loss 1.769	Prec@1 59.5355	Prec@5 81.0893
Train: [36][8600/10010]	Time 0.552 (4749.791)	Data 0.001 (8.743)	Loss 1.769	Prec@1 59.5286	Prec@5 81.0883
Train: [36][8800/10010]	Time 0.552 (4859.750)	Data 0.001 (8.915)	Loss 1.770	Prec@1 59.5207	Prec@5 81.0832
Train: [36][9000/10010]	Time 0.552 (4969.527)	Data 0.001 (9.081)	Loss 1.770	Prec@1 59.5197	Prec@5 81.0801
Train: [36][9200/10010]	Time 0.552 (5079.163)	Data 0.001 (9.248)	Loss 1.770	Prec@1 59.5155	Prec@5 81.0788
Train: [36][9400/10010]	Time 0.552 (5188.613)	Data 0.001 (9.416)	Loss 1.770	Prec@1 59.5099	Prec@5 81.0724
Train: [36][9600/10010]	Time 0.552 (5298.773)	Data 0.001 (9.588)	Loss 1.771	Prec@1 59.5026	Prec@5 81.0733
Train: [36][9800/10010]	Time 0.552 (5408.583)	Data 0.001 (9.754)	Loss 1.771	Prec@1 59.4952	Prec@5 81.0727
Train: [36][10000/10010]	Time 0.552 (5518.437)	Data 0.001 (9.919)	Loss 1.771	Prec@1 59.4948	Prec@5 81.0667
Train: [36]	Time 5522.892	Data 9.922	Loss 1.771	Prec@1 59.4927	Prec@5 81.0657	
Val: [36]	Time 71.159	Data 1.719	Loss 1.498	Prec@1 63.6040	Prec@5 85.7340	
Best Prec@1: [63.928]	
Starting epoch number: 37 Learning rate: 0.010000000000000002
Train: [37][0/10010]	Time 1.947 (1.947)	Data 1.344 (1.344)	Loss 1.966	Prec@1 56.2500	Prec@5 80.4688
Train: [37][200/10010]	Time 0.556 (111.672)	Data 0.008 (1.516)	Loss 1.751	Prec@1 59.9813	Prec@5 81.3161
Train: [37][400/10010]	Time 0.553 (221.602)	Data 0.004 (1.681)	Loss 1.761	Prec@1 59.6692	Prec@5 81.1896
Train: [37][600/10010]	Time 0.552 (331.478)	Data 0.003 (1.845)	Loss 1.758	Prec@1 59.8703	Prec@5 81.1759
Train: [37][800/10010]	Time 0.551 (441.439)	Data 0.003 (2.012)	Loss 1.756	Prec@1 59.8744	Prec@5 81.2129
Train: [37][1000/10010]	Time 0.551 (551.198)	Data 0.002 (2.175)	Loss 1.755	Prec@1 59.8261	Prec@5 81.2617
Train: [37][1200/10010]	Time 0.550 (660.740)	Data 0.002 (2.338)	Loss 1.756	Prec@1 59.8629	Prec@5 81.2565
Train: [37][1400/10010]	Time 0.550 (770.370)	Data 0.002 (2.504)	Loss 1.754	Prec@1 59.9064	Prec@5 81.3309
Train: [37][1600/10010]	Time 0.550 (880.156)	Data 0.002 (2.671)	Loss 1.754	Prec@1 59.8644	Prec@5 81.3300
Train: [37][1800/10010]	Time 0.550 (990.001)	Data 0.002 (2.840)	Loss 1.752	Prec@1 59.8890	Prec@5 81.3259
Train: [37][2000/10010]	Time 0.550 (1099.591)	Data 0.001 (2.999)	Loss 1.753	Prec@1 59.8826	Prec@5 81.2910
Train: [37][2200/10010]	Time 0.550 (1209.666)	Data 0.001 (3.164)	Loss 1.754	Prec@1 59.8684	Prec@5 81.2841
Train: [37][2400/10010]	Time 0.550 (1319.487)	Data 0.001 (3.329)	Loss 1.755	Prec@1 59.8523	Prec@5 81.2767
Train: [37][2600/10010]	Time 0.549 (1428.946)	Data 0.001 (3.488)	Loss 1.755	Prec@1 59.8538	Prec@5 81.2827
Train: [37][2800/10010]	Time 0.549 (1538.783)	Data 0.001 (3.650)	Loss 1.755	Prec@1 59.8402	Prec@5 81.2771
Train: [37][3000/10010]	Time 0.549 (1648.788)	Data 0.001 (3.817)	Loss 1.756	Prec@1 59.8259	Prec@5 81.2490
Train: [37][3200/10010]	Time 0.549 (1758.733)	Data 0.001 (3.983)	Loss 1.757	Prec@1 59.8089	Prec@5 81.2405
Train: [37][3400/10010]	Time 0.549 (1868.557)	Data 0.001 (4.150)	Loss 1.757	Prec@1 59.8220	Prec@5 81.2341
Train: [37][3600/10010]	Time 0.549 (1978.223)	Data 0.001 (4.314)	Loss 1.759	Prec@1 59.7735	Prec@5 81.2044
Train: [37][3800/10010]	Time 0.549 (2088.110)	Data 0.001 (4.478)	Loss 1.759	Prec@1 59.7713	Prec@5 81.1918
Train: [37][4000/10010]	Time 0.549 (2197.645)	Data 0.001 (4.641)	Loss 1.759	Prec@1 59.7745	Prec@5 81.2010
Train: [37][4200/10010]	Time 0.549 (2307.824)	Data 0.001 (4.806)	Loss 1.760	Prec@1 59.7735	Prec@5 81.1961
Train: [37][4400/10010]	Time 0.549 (2417.664)	Data 0.001 (4.969)	Loss 1.760	Prec@1 59.7796	Prec@5 81.1905
Train: [37][4600/10010]	Time 0.549 (2527.836)	Data 0.001 (5.135)	Loss 1.761	Prec@1 59.7525	Prec@5 81.1676
Train: [37][4800/10010]	Time 0.549 (2637.715)	Data 0.001 (5.294)	Loss 1.761	Prec@1 59.7502	Prec@5 81.1716
Train: [37][5000/10010]	Time 0.549 (2747.607)	Data 0.001 (5.457)	Loss 1.763	Prec@1 59.7332	Prec@5 81.1530
Train: [37][5200/10010]	Time 0.549 (2857.388)	Data 0.001 (5.624)	Loss 1.763	Prec@1 59.7226	Prec@5 81.1479
Train: [37][5400/10010]	Time 0.549 (2967.175)	Data 0.001 (5.791)	Loss 1.763	Prec@1 59.7292	Prec@5 81.1567
Train: [37][5600/10010]	Time 0.549 (3077.049)	Data 0.001 (5.960)	Loss 1.764	Prec@1 59.7156	Prec@5 81.1455
Train: [37][5800/10010]	Time 0.549 (3186.457)	Data 0.001 (6.120)	Loss 1.764	Prec@1 59.7090	Prec@5 81.1501
Train: [37][6000/10010]	Time 0.549 (3296.341)	Data 0.001 (6.289)	Loss 1.764	Prec@1 59.7018	Prec@5 81.1567
Train: [37][6200/10010]	Time 0.549 (3406.099)	Data 0.001 (6.454)	Loss 1.764	Prec@1 59.6966	Prec@5 81.1579
Train: [37][6400/10010]	Time 0.549 (3515.729)	Data 0.001 (6.615)	Loss 1.764	Prec@1 59.6966	Prec@5 81.1655
Train: [37][6600/10010]	Time 0.549 (3625.302)	Data 0.001 (6.778)	Loss 1.764	Prec@1 59.6785	Prec@5 81.1521
Train: [37][6800/10010]	Time 0.549 (3735.113)	Data 0.001 (6.942)	Loss 1.765	Prec@1 59.6693	Prec@5 81.1452
Train: [37][7000/10010]	Time 0.549 (3845.240)	Data 0.001 (7.107)	Loss 1.765	Prec@1 59.6538	Prec@5 81.1371
Train: [37][7200/10010]	Time 0.549 (3955.126)	Data 0.001 (7.275)	Loss 1.765	Prec@1 59.6671	Prec@5 81.1407
Train: [37][7400/10010]	Time 0.549 (4065.040)	Data 0.001 (7.438)	Loss 1.766	Prec@1 59.6603	Prec@5 81.1393
Train: [37][7600/10010]	Time 0.549 (4175.555)	Data 0.001 (7.604)	Loss 1.767	Prec@1 59.6320	Prec@5 81.1327
Train: [37][7800/10010]	Time 0.549 (4285.364)	Data 0.001 (7.769)	Loss 1.767	Prec@1 59.6176	Prec@5 81.1133
Train: [37][8000/10010]	Time 0.549 (4395.273)	Data 0.001 (7.933)	Loss 1.767	Prec@1 59.6099	Prec@5 81.1011
Train: [37][8200/10010]	Time 0.549 (4504.811)	Data 0.001 (8.095)	Loss 1.768	Prec@1 59.5956	Prec@5 81.0933
Train: [37][8400/10010]	Time 0.549 (4614.566)	Data 0.001 (8.262)	Loss 1.768	Prec@1 59.5932	Prec@5 81.0967
Train: [37][8600/10010]	Time 0.549 (4724.165)	Data 0.001 (8.430)	Loss 1.768	Prec@1 59.5931	Prec@5 81.0996
Train: [37][8800/10010]	Time 0.549 (4833.881)	Data 0.001 (8.593)	Loss 1.768	Prec@1 59.5870	Prec@5 81.0938
Train: [37][9000/10010]	Time 0.549 (4943.605)	Data 0.001 (8.757)	Loss 1.769	Prec@1 59.5719	Prec@5 81.0893
Train: [37][9200/10010]	Time 0.549 (5053.243)	Data 0.001 (8.918)	Loss 1.770	Prec@1 59.5502	Prec@5 81.0733
Train: [37][9400/10010]	Time 0.549 (5163.206)	Data 0.001 (9.083)	Loss 1.771	Prec@1 59.5349	Prec@5 81.0640
Train: [37][9600/10010]	Time 0.549 (5273.138)	Data 0.001 (9.251)	Loss 1.771	Prec@1 59.5250	Prec@5 81.0564
Train: [37][9800/10010]	Time 0.549 (5383.175)	Data 0.001 (9.415)	Loss 1.772	Prec@1 59.5041	Prec@5 81.0468
Train: [37][10000/10010]	Time 0.549 (5492.976)	Data 0.001 (9.574)	Loss 1.772	Prec@1 59.5069	Prec@5 81.0485
Train: [37]	Time 5497.460	Data 9.577	Loss 1.772	Prec@1 59.5061	Prec@5 81.0479	
Val: [37]	Time 70.639	Data 1.706	Loss 1.853	Prec@1 56.9180	Prec@5 80.6540	
Best Prec@1: [63.928]	
Starting epoch number: 38 Learning rate: 0.010000000000000002
Train: [38][0/10010]	Time 1.954 (1.954)	Data 1.370 (1.370)	Loss 1.689	Prec@1 57.8125	Prec@5 81.2500
Train: [38][200/10010]	Time 0.555 (111.631)	Data 0.008 (1.538)	Loss 1.778	Prec@1 59.1224	Prec@5 81.0868
Train: [38][400/10010]	Time 0.552 (221.181)	Data 0.004 (1.699)	Loss 1.770	Prec@1 59.3594	Prec@5 81.1000
Train: [38][600/10010]	Time 0.550 (330.746)	Data 0.003 (1.864)	Loss 1.776	Prec@1 59.3022	Prec@5 80.9198
Train: [38][800/10010]	Time 0.550 (440.586)	Data 0.003 (2.032)	Loss 1.773	Prec@1 59.3389	Prec@5 80.9779
Train: [38][1000/10010]	Time 0.550 (550.409)	Data 0.002 (2.197)	Loss 1.767	Prec@1 59.4601	Prec@5 81.1415
Train: [38][1200/10010]	Time 0.550 (660.084)	Data 0.002 (2.361)	Loss 1.768	Prec@1 59.4836	Prec@5 81.1173
Train: [38][1400/10010]	Time 0.549 (769.553)	Data 0.002 (2.518)	Loss 1.770	Prec@1 59.4860	Prec@5 81.1156
Train: [38][1600/10010]	Time 0.550 (879.780)	Data 0.002 (2.679)	Loss 1.767	Prec@1 59.4907	Prec@5 81.1778
Train: [38][1800/10010]	Time 0.549 (989.645)	Data 0.002 (2.843)	Loss 1.768	Prec@1 59.5017	Prec@5 81.1541
Train: [38][2000/10010]	Time 0.549 (1099.469)	Data 0.002 (3.007)	Loss 1.766	Prec@1 59.5526	Prec@5 81.1746
Train: [38][2200/10010]	Time 0.549 (1209.446)	Data 0.001 (3.168)	Loss 1.766	Prec@1 59.5663	Prec@5 81.1595
Train: [38][2400/10010]	Time 0.549 (1319.191)	Data 0.001 (3.327)	Loss 1.766	Prec@1 59.5904	Prec@5 81.1716
Train: [38][2600/10010]	Time 0.549 (1429.169)	Data 0.001 (3.493)	Loss 1.764	Prec@1 59.6060	Prec@5 81.1851
Train: [38][2800/10010]	Time 0.549 (1538.989)	Data 0.001 (3.657)	Loss 1.764	Prec@1 59.6118	Prec@5 81.1839
Train: [38][3000/10010]	Time 0.549 (1648.653)	Data 0.001 (3.820)	Loss 1.764	Prec@1 59.6046	Prec@5 81.1886
Train: [38][3200/10010]	Time 0.549 (1758.345)	Data 0.001 (3.989)	Loss 1.764	Prec@1 59.6313	Prec@5 81.1858
Train: [38][3400/10010]	Time 0.549 (1868.271)	Data 0.001 (4.155)	Loss 1.764	Prec@1 59.6320	Prec@5 81.2020
Train: [38][3600/10010]	Time 0.549 (1977.783)	Data 0.001 (4.320)	Loss 1.765	Prec@1 59.6202	Prec@5 81.1958
Train: [38][3800/10010]	Time 0.549 (2088.467)	Data 0.001 (4.487)	Loss 1.765	Prec@1 59.6029	Prec@5 81.1869
Train: [38][4000/10010]	Time 0.549 (2198.423)	Data 0.001 (4.651)	Loss 1.765	Prec@1 59.6062	Prec@5 81.2037
Train: [38][4200/10010]	Time 0.549 (2308.391)	Data 0.001 (4.815)	Loss 1.765	Prec@1 59.5890	Prec@5 81.1870
Train: [38][4400/10010]	Time 0.550 (2418.405)	Data 0.001 (4.979)	Loss 1.766	Prec@1 59.5667	Prec@5 81.1806
Train: [38][4600/10010]	Time 0.549 (2528.179)	Data 0.001 (5.143)	Loss 1.767	Prec@1 59.5462	Prec@5 81.1663
Train: [38][4800/10010]	Time 0.549 (2637.986)	Data 0.001 (5.304)	Loss 1.767	Prec@1 59.5501	Prec@5 81.1564
Train: [38][5000/10010]	Time 0.549 (2747.684)	Data 0.001 (5.470)	Loss 1.767	Prec@1 59.5418	Prec@5 81.1425
Train: [38][5200/10010]	Time 0.549 (2857.536)	Data 0.001 (5.635)	Loss 1.768	Prec@1 59.5357	Prec@5 81.1393
Train: [38][5400/10010]	Time 0.549 (2967.224)	Data 0.001 (5.800)	Loss 1.768	Prec@1 59.5238	Prec@5 81.1216
Train: [38][5600/10010]	Time 0.549 (3076.714)	Data 0.001 (5.961)	Loss 1.769	Prec@1 59.5116	Prec@5 81.1146
Train: [38][5800/10010]	Time 0.549 (3186.109)	Data 0.001 (6.120)	Loss 1.770	Prec@1 59.5099	Prec@5 81.1074
Train: [38][6000/10010]	Time 0.549 (3296.135)	Data 0.001 (6.285)	Loss 1.770	Prec@1 59.4966	Prec@5 81.0987
Train: [38][6200/10010]	Time 0.549 (3405.932)	Data 0.001 (6.449)	Loss 1.770	Prec@1 59.5103	Prec@5 81.1022
Train: [38][6400/10010]	Time 0.549 (3515.817)	Data 0.001 (6.612)	Loss 1.769	Prec@1 59.5274	Prec@5 81.1190
Train: [38][6600/10010]	Time 0.549 (3625.795)	Data 0.001 (6.776)	Loss 1.770	Prec@1 59.5074	Prec@5 81.1028
Train: [38][6800/10010]	Time 0.549 (3735.581)	Data 0.001 (6.939)	Loss 1.771	Prec@1 59.4981	Prec@5 81.0994
Train: [38][7000/10010]	Time 0.549 (3845.686)	Data 0.001 (7.105)	Loss 1.771	Prec@1 59.4905	Prec@5 81.0921
Train: [38][7200/10010]	Time 0.549 (3955.614)	Data 0.001 (7.273)	Loss 1.772	Prec@1 59.4748	Prec@5 81.0792
Train: [38][7400/10010]	Time 0.549 (4065.605)	Data 0.001 (7.447)	Loss 1.772	Prec@1 59.4727	Prec@5 81.0789
Train: [38][7600/10010]	Time 0.549 (4175.330)	Data 0.001 (7.613)	Loss 1.772	Prec@1 59.4718	Prec@5 81.0772
Train: [38][7800/10010]	Time 0.549 (4285.211)	Data 0.001 (7.781)	Loss 1.772	Prec@1 59.4656	Prec@5 81.0730
Train: [38][8000/10010]	Time 0.549 (4394.702)	Data 0.001 (7.940)	Loss 1.772	Prec@1 59.4605	Prec@5 81.0662
Train: [38][8200/10010]	Time 0.549 (4504.498)	Data 0.001 (8.108)	Loss 1.773	Prec@1 59.4468	Prec@5 81.0505
Train: [38][8400/10010]	Time 0.549 (4614.345)	Data 0.001 (8.274)	Loss 1.774	Prec@1 59.4348	Prec@5 81.0463
Train: [38][8600/10010]	Time 0.549 (4723.929)	Data 0.001 (8.441)	Loss 1.774	Prec@1 59.4284	Prec@5 81.0406
Train: [38][8800/10010]	Time 0.549 (4833.777)	Data 0.001 (8.607)	Loss 1.774	Prec@1 59.4136	Prec@5 81.0342
Train: [38][9000/10010]	Time 0.549 (4943.530)	Data 0.001 (8.769)	Loss 1.775	Prec@1 59.3943	Prec@5 81.0249
Train: [38][9200/10010]	Time 0.549 (5053.621)	Data 0.001 (8.934)	Loss 1.775	Prec@1 59.3986	Prec@5 81.0320
Train: [38][9400/10010]	Time 0.549 (5163.794)	Data 0.001 (9.103)	Loss 1.775	Prec@1 59.3919	Prec@5 81.0273
Train: [38][9600/10010]	Time 0.549 (5273.417)	Data 0.001 (9.264)	Loss 1.775	Prec@1 59.3925	Prec@5 81.0231
Train: [38][9800/10010]	Time 0.549 (5382.957)	Data 0.001 (9.429)	Loss 1.776	Prec@1 59.3831	Prec@5 81.0167
Train: [38][10000/10010]	Time 0.549 (5492.596)	Data 0.001 (9.596)	Loss 1.776	Prec@1 59.3825	Prec@5 81.0130
Train: [38]	Time 5497.176	Data 9.600	Loss 1.776	Prec@1 59.3815	Prec@5 81.0125	
Val: [38]	Time 70.535	Data 1.541	Loss 1.556	Prec@1 62.4340	Prec@5 84.9820	
Best Prec@1: [63.928]	
Starting epoch number: 39 Learning rate: 0.010000000000000002
Train: [39][0/10010]	Time 1.927 (1.927)	Data 1.325 (1.325)	Loss 1.567	Prec@1 67.1875	Prec@5 85.9375
Train: [39][200/10010]	Time 0.555 (111.524)	Data 0.007 (1.492)	Loss 1.788	Prec@1 58.9863	Prec@5 81.0051
Train: [39][400/10010]	Time 0.552 (221.321)	Data 0.004 (1.658)	Loss 1.758	Prec@1 59.6322	Prec@5 81.4273
Train: [39][600/10010]	Time 0.551 (330.952)	Data 0.003 (1.820)	Loss 1.758	Prec@1 59.6766	Prec@5 81.3800
Train: [39][800/10010]	Time 0.550 (440.580)	Data 0.002 (1.981)	Loss 1.757	Prec@1 59.6998	Prec@5 81.4402
Train: [39][1000/10010]	Time 0.550 (550.346)	Data 0.002 (2.143)	Loss 1.754	Prec@1 59.7691	Prec@5 81.4342
Train: [39][1200/10010]	Time 0.550 (660.170)	Data 0.002 (2.303)	Loss 1.752	Prec@1 59.8238	Prec@5 81.4367
Train: [39][1400/10010]	Time 0.550 (769.973)	Data 0.002 (2.468)	Loss 1.751	Prec@1 59.8194	Prec@5 81.4162
Train: [39][1600/10010]	Time 0.549 (879.622)	Data 0.002 (2.628)	Loss 1.754	Prec@1 59.8005	Prec@5 81.3905
Train: [39][1800/10010]	Time 0.549 (989.396)	Data 0.002 (2.788)	Loss 1.753	Prec@1 59.8088	Prec@5 81.3819
Train: [39][2000/10010]	Time 0.549 (1099.151)	Data 0.001 (2.951)	Loss 1.753	Prec@1 59.8115	Prec@5 81.3788
Train: [39][2200/10010]	Time 0.549 (1208.969)	Data 0.001 (3.110)	Loss 1.755	Prec@1 59.7346	Prec@5 81.3441
Train: [39][2400/10010]	Time 0.549 (1319.063)	Data 0.001 (3.278)	Loss 1.756	Prec@1 59.7463	Prec@5 81.3248
Train: [39][2600/10010]	Time 0.549 (1428.566)	Data 0.001 (3.440)	Loss 1.756	Prec@1 59.7216	Prec@5 81.3305
Train: [39][2800/10010]	Time 0.549 (1538.025)	Data 0.001 (3.605)	Loss 1.757	Prec@1 59.7320	Prec@5 81.3066
Train: [39][3000/10010]	Time 0.549 (1647.516)	Data 0.001 (3.770)	Loss 1.757	Prec@1 59.7337	Prec@5 81.3049
Train: [39][3200/10010]	Time 0.549 (1757.189)	Data 0.001 (3.936)	Loss 1.757	Prec@1 59.7211	Prec@5 81.2881
Train: [39][3400/10010]	Time 0.549 (1867.193)	Data 0.001 (4.106)	Loss 1.758	Prec@1 59.7085	Prec@5 81.2976
Train: [39][3600/10010]	Time 0.549 (1977.135)	Data 0.001 (4.271)	Loss 1.758	Prec@1 59.7265	Prec@5 81.2969
Train: [39][3800/10010]	Time 0.549 (2087.021)	Data 0.001 (4.437)	Loss 1.757	Prec@1 59.7265	Prec@5 81.3032
Train: [39][4000/10010]	Time 0.549 (2197.006)	Data 0.001 (4.601)	Loss 1.757	Prec@1 59.7394	Prec@5 81.3224
Train: [39][4200/10010]	Time 0.549 (2307.140)	Data 0.001 (4.767)	Loss 1.757	Prec@1 59.7246	Prec@5 81.3210
Train: [39][4400/10010]	Time 0.549 (2416.799)	Data 0.001 (4.930)	Loss 1.758	Prec@1 59.7117	Prec@5 81.2899
Train: [39][4600/10010]	Time 0.549 (2526.603)	Data 0.001 (5.090)	Loss 1.757	Prec@1 59.7419	Prec@5 81.3127
Train: [39][4800/10010]	Time 0.549 (2636.906)	Data 0.001 (5.256)	Loss 1.758	Prec@1 59.7219	Prec@5 81.2985
Train: [39][5000/10010]	Time 0.549 (2746.506)	Data 0.001 (5.418)	Loss 1.759	Prec@1 59.7009	Prec@5 81.2897
Train: [39][5200/10010]	Time 0.549 (2856.053)	Data 0.001 (5.580)	Loss 1.759	Prec@1 59.6835	Prec@5 81.2841
Train: [39][5400/10010]	Time 0.549 (2965.475)	Data 0.001 (5.744)	Loss 1.760	Prec@1 59.6714	Prec@5 81.2632
Train: [39][5600/10010]	Time 0.549 (3074.721)	Data 0.001 (5.903)	Loss 1.761	Prec@1 59.6647	Prec@5 81.2581
Train: [39][5800/10010]	Time 0.549 (3184.488)	Data 0.001 (6.067)	Loss 1.761	Prec@1 59.6616	Prec@5 81.2550
Train: [39][6000/10010]	Time 0.549 (3294.475)	Data 0.001 (6.236)	Loss 1.761	Prec@1 59.6522	Prec@5 81.2581
Train: [39][6200/10010]	Time 0.549 (3404.163)	Data 0.001 (6.403)	Loss 1.763	Prec@1 59.6224	Prec@5 81.2351
Train: [39][6400/10010]	Time 0.549 (3514.201)	Data 0.001 (6.569)	Loss 1.764	Prec@1 59.6109	Prec@5 81.2247
Train: [39][6600/10010]	Time 0.549 (3623.845)	Data 0.001 (6.736)	Loss 1.764	Prec@1 59.6053	Prec@5 81.2133
Train: [39][6800/10010]	Time 0.549 (3733.715)	Data 0.001 (6.900)	Loss 1.764	Prec@1 59.5921	Prec@5 81.2069
Train: [39][7000/10010]	Time 0.549 (3843.486)	Data 0.001 (7.068)	Loss 1.764	Prec@1 59.5810	Prec@5 81.2059
Train: [39][7200/10010]	Time 0.549 (3953.196)	Data 0.001 (7.234)	Loss 1.765	Prec@1 59.5700	Prec@5 81.1939
Train: [39][7400/10010]	Time 0.549 (4063.011)	Data 0.001 (7.397)	Loss 1.767	Prec@1 59.5370	Prec@5 81.1639
Train: [39][7600/10010]	Time 0.549 (4172.610)	Data 0.001 (7.563)	Loss 1.767	Prec@1 59.5279	Prec@5 81.1611
Train: [39][7800/10010]	Time 0.549 (4282.376)	Data 0.001 (7.728)	Loss 1.767	Prec@1 59.5330	Prec@5 81.1584
Train: [39][8000/10010]	Time 0.549 (4391.931)	Data 0.001 (7.896)	Loss 1.767	Prec@1 59.5263	Prec@5 81.1631
Train: [39][8200/10010]	Time 0.549 (4501.354)	Data 0.001 (8.060)	Loss 1.767	Prec@1 59.5214	Prec@5 81.1622
Train: [39][8400/10010]	Time 0.549 (4611.682)	Data 0.001 (8.224)	Loss 1.767	Prec@1 59.5236	Prec@5 81.1663
Train: [39][8600/10010]	Time 0.549 (4721.538)	Data 0.001 (8.389)	Loss 1.768	Prec@1 59.5215	Prec@5 81.1582
Train: [39][8800/10010]	Time 0.549 (4831.055)	Data 0.001 (8.551)	Loss 1.768	Prec@1 59.5032	Prec@5 81.1491
Train: [39][9000/10010]	Time 0.549 (4940.780)	Data 0.001 (8.710)	Loss 1.769	Prec@1 59.4956	Prec@5 81.1315
Train: [39][9200/10010]	Time 0.549 (5050.516)	Data 0.001 (8.876)	Loss 1.770	Prec@1 59.4775	Prec@5 81.1179
Train: [39][9400/10010]	Time 0.549 (5160.286)	Data 0.001 (9.039)	Loss 1.770	Prec@1 59.4755	Prec@5 81.1141
Train: [39][9600/10010]	Time 0.549 (5269.952)	Data 0.001 (9.206)	Loss 1.771	Prec@1 59.4655	Prec@5 81.1126
Train: [39][9800/10010]	Time 0.549 (5379.614)	Data 0.001 (9.374)	Loss 1.771	Prec@1 59.4617	Prec@5 81.1102
Train: [39][10000/10010]	Time 0.549 (5488.686)	Data 0.001 (9.532)	Loss 1.771	Prec@1 59.4585	Prec@5 81.1027
Train: [39]	Time 5493.110	Data 9.535	Loss 1.771	Prec@1 59.4570	Prec@5 81.1023	
Val: [39]	Time 70.622	Data 1.656	Loss 2.016	Prec@1 53.8680	Prec@5 78.1260	
Best Prec@1: [63.928]	
Starting epoch number: 40 Learning rate: 0.010000000000000002
Train: [40][0/10010]	Time 1.870 (1.870)	Data 1.250 (1.250)	Loss 1.896	Prec@1 57.0312	Prec@5 75.0000
Train: [40][200/10010]	Time 0.553 (111.097)	Data 0.007 (1.419)	Loss 1.792	Prec@1 58.7492	Prec@5 80.8652
Train: [40][400/10010]	Time 0.551 (220.783)	Data 0.004 (1.585)	Loss 1.768	Prec@1 59.3555	Prec@5 81.1701
Train: [40][600/10010]	Time 0.550 (330.575)	Data 0.003 (1.751)	Loss 1.763	Prec@1 59.5908	Prec@5 81.2916
Train: [40][800/10010]	Time 0.550 (440.340)	Data 0.002 (1.917)	Loss 1.756	Prec@1 59.6764	Prec@5 81.3388
Train: [40][1000/10010]	Time 0.549 (549.926)	Data 0.002 (2.078)	Loss 1.761	Prec@1 59.6201	Prec@5 81.2609
Train: [40][1200/10010]	Time 0.549 (659.620)	Data 0.002 (2.242)	Loss 1.759	Prec@1 59.6196	Prec@5 81.2585
Train: [40][1400/10010]	Time 0.549 (769.603)	Data 0.002 (2.405)	Loss 1.758	Prec@1 59.6823	Prec@5 81.2996
Train: [40][1600/10010]	Time 0.549 (879.343)	Data 0.002 (2.568)	Loss 1.754	Prec@1 59.7664	Prec@5 81.3349
Train: [40][1800/10010]	Time 0.549 (989.076)	Data 0.002 (2.730)	Loss 1.759	Prec@1 59.6500	Prec@5 81.2786
Train: [40][2000/10010]	Time 0.549 (1098.423)	Data 0.001 (2.888)	Loss 1.759	Prec@1 59.6620	Prec@5 81.2457
Train: [40][2200/10010]	Time 0.549 (1207.998)	Data 0.001 (3.051)	Loss 1.760	Prec@1 59.6348	Prec@5 81.2319
Train: [40][2400/10010]	Time 0.549 (1317.586)	Data 0.001 (3.220)	Loss 1.761	Prec@1 59.5946	Prec@5 81.2080
Train: [40][2600/10010]	Time 0.549 (1427.194)	Data 0.001 (3.385)	Loss 1.763	Prec@1 59.5702	Prec@5 81.1980
Train: [40][2800/10010]	Time 0.549 (1536.853)	Data 0.001 (3.549)	Loss 1.761	Prec@1 59.5822	Prec@5 81.2185
Train: [40][3000/10010]	Time 0.549 (1646.575)	Data 0.001 (3.714)	Loss 1.761	Prec@1 59.5773	Prec@5 81.2320
Train: [40][3200/10010]	Time 0.549 (1756.575)	Data 0.001 (3.882)	Loss 1.763	Prec@1 59.5761	Prec@5 81.2000
Train: [40][3400/10010]	Time 0.549 (1866.272)	Data 0.001 (4.050)	Loss 1.761	Prec@1 59.5987	Prec@5 81.2052
Train: [40][3600/10010]	Time 0.549 (1975.839)	Data 0.001 (4.212)	Loss 1.761	Prec@1 59.6087	Prec@5 81.2294
Train: [40][3800/10010]	Time 0.549 (2085.588)	Data 0.001 (4.377)	Loss 1.761	Prec@1 59.5992	Prec@5 81.2138
Train: [40][4000/10010]	Time 0.549 (2195.416)	Data 0.001 (4.541)	Loss 1.762	Prec@1 59.5845	Prec@5 81.2051
Train: [40][4200/10010]	Time 0.549 (2305.262)	Data 0.001 (4.708)	Loss 1.762	Prec@1 59.5846	Prec@5 81.2035
Train: [40][4400/10010]	Time 0.549 (2414.982)	Data 0.001 (4.868)	Loss 1.762	Prec@1 59.5891	Prec@5 81.2019
Train: [40][4600/10010]	Time 0.549 (2524.758)	Data 0.001 (5.036)	Loss 1.763	Prec@1 59.5725	Prec@5 81.1865
Train: [40][4800/10010]	Time 0.549 (2634.263)	Data 0.001 (5.199)	Loss 1.764	Prec@1 59.5644	Prec@5 81.1769
Train: [40][5000/10010]	Time 0.549 (2743.667)	Data 0.001 (5.363)	Loss 1.765	Prec@1 59.5550	Prec@5 81.1616
Train: [40][5200/10010]	Time 0.549 (2853.435)	Data 0.001 (5.529)	Loss 1.764	Prec@1 59.5556	Prec@5 81.1671
Train: [40][5400/10010]	Time 0.549 (2963.186)	Data 0.001 (5.687)	Loss 1.765	Prec@1 59.5620	Prec@5 81.1623
Train: [40][5600/10010]	Time 0.549 (3072.997)	Data 0.001 (5.852)	Loss 1.765	Prec@1 59.5534	Prec@5 81.1514
Train: [40][5800/10010]	Time 0.549 (3182.691)	Data 0.001 (6.016)	Loss 1.765	Prec@1 59.5466	Prec@5 81.1544
Train: [40][6000/10010]	Time 0.549 (3292.297)	Data 0.001 (6.181)	Loss 1.765	Prec@1 59.5280	Prec@5 81.1520
Train: [40][6200/10010]	Time 0.549 (3401.667)	Data 0.001 (6.345)	Loss 1.766	Prec@1 59.5159	Prec@5 81.1327
Train: [40][6400/10010]	Time 0.548 (3510.731)	Data 0.001 (6.514)	Loss 1.766	Prec@1 59.5222	Prec@5 81.1330
Train: [40][6600/10010]	Time 0.548 (3619.844)	Data 0.001 (6.683)	Loss 1.767	Prec@1 59.4993	Prec@5 81.1109
Train: [40][6800/10010]	Time 0.548 (3728.939)	Data 0.001 (6.853)	Loss 1.767	Prec@1 59.5123	Prec@5 81.1223
Train: [40][7000/10010]	Time 0.548 (3838.175)	Data 0.001 (7.022)	Loss 1.767	Prec@1 59.5165	Prec@5 81.1252
Train: [40][7200/10010]	Time 0.548 (3947.980)	Data 0.001 (7.190)	Loss 1.767	Prec@1 59.5147	Prec@5 81.1247
Train: [40][7400/10010]	Time 0.548 (4057.705)	Data 0.001 (7.357)	Loss 1.767	Prec@1 59.5047	Prec@5 81.1112
Train: [40][7600/10010]	Time 0.548 (4167.309)	Data 0.001 (7.525)	Loss 1.767	Prec@1 59.5046	Prec@5 81.1156
Train: [40][7800/10010]	Time 0.548 (4276.653)	Data 0.001 (7.686)	Loss 1.768	Prec@1 59.4914	Prec@5 81.1051
Train: [40][8000/10010]	Time 0.548 (4386.212)	Data 0.001 (7.852)	Loss 1.768	Prec@1 59.4840	Prec@5 81.0970
Train: [40][8200/10010]	Time 0.548 (4495.816)	Data 0.001 (8.018)	Loss 1.768	Prec@1 59.4768	Prec@5 81.0981
Train: [40][8400/10010]	Time 0.548 (4605.252)	Data 0.001 (8.178)	Loss 1.769	Prec@1 59.4736	Prec@5 81.0938
Train: [40][8600/10010]	Time 0.548 (4714.364)	Data 0.001 (8.340)	Loss 1.769	Prec@1 59.4766	Prec@5 81.0938
Train: [40][8800/10010]	Time 0.548 (4823.454)	Data 0.001 (8.495)	Loss 1.769	Prec@1 59.4734	Prec@5 81.0879
Train: [40][9000/10010]	Time 0.548 (4932.680)	Data 0.001 (8.660)	Loss 1.769	Prec@1 59.4785	Prec@5 81.0914
Train: [40][9200/10010]	Time 0.548 (5041.820)	Data 0.001 (8.825)	Loss 1.769	Prec@1 59.4721	Prec@5 81.0933
Train: [40][9400/10010]	Time 0.548 (5150.869)	Data 0.001 (8.992)	Loss 1.768	Prec@1 59.4830	Prec@5 81.0996
Train: [40][9600/10010]	Time 0.548 (5259.944)	Data 0.001 (9.164)	Loss 1.769	Prec@1 59.4646	Prec@5 81.0921
Train: [40][9800/10010]	Time 0.548 (5369.359)	Data 0.001 (9.331)	Loss 1.769	Prec@1 59.4579	Prec@5 81.0832
Train: [40][10000/10010]	Time 0.548 (5478.520)	Data 0.001 (9.493)	Loss 1.769	Prec@1 59.4515	Prec@5 81.0786
Train: [40]	Time 5483.009	Data 9.496	Loss 1.769	Prec@1 59.4529	Prec@5 81.0787	
Val: [40]	Time 70.229	Data 1.338	Loss 1.558	Prec@1 62.0180	Prec@5 85.3580	
Best Prec@1: [63.928]	
Starting epoch number: 41 Learning rate: 0.010000000000000002
Train: [41][0/10010]	Time 2.035 (2.035)	Data 1.294 (1.294)	Loss 1.904	Prec@1 57.8125	Prec@5 82.0312
Train: [41][200/10010]	Time 0.552 (111.038)	Data 0.007 (1.459)	Loss 1.789	Prec@1 59.1496	Prec@5 81.0285
Train: [41][400/10010]	Time 0.550 (220.360)	Data 0.004 (1.628)	Loss 1.761	Prec@1 59.5484	Prec@5 81.3688
Train: [41][600/10010]	Time 0.549 (330.132)	Data 0.003 (1.797)	Loss 1.751	Prec@1 59.7429	Prec@5 81.4840
Train: [41][800/10010]	Time 0.549 (439.605)	Data 0.002 (1.965)	Loss 1.747	Prec@1 59.7661	Prec@5 81.5582
Train: [41][1000/10010]	Time 0.549 (549.113)	Data 0.002 (2.125)	Loss 1.745	Prec@1 59.8355	Prec@5 81.5637
Train: [41][1200/10010]	Time 0.548 (658.600)	Data 0.002 (2.287)	Loss 1.743	Prec@1 59.9461	Prec@5 81.5785
Train: [41][1400/10010]	Time 0.548 (767.881)	Data 0.002 (2.452)	Loss 1.744	Prec@1 59.9226	Prec@5 81.5573
Train: [41][1600/10010]	Time 0.548 (877.195)	Data 0.002 (2.615)	Loss 1.745	Prec@1 59.9659	Prec@5 81.5199
Train: [41][1800/10010]	Time 0.548 (986.499)	Data 0.002 (2.781)	Loss 1.746	Prec@1 59.9298	Prec@5 81.4968
Train: [41][2000/10010]	Time 0.548 (1095.726)	Data 0.001 (2.943)	Loss 1.747	Prec@1 59.9200	Prec@5 81.4764
Train: [41][2200/10010]	Time 0.548 (1205.227)	Data 0.001 (3.109)	Loss 1.746	Prec@1 59.9411	Prec@5 81.4694
Train: [41][2400/10010]	Time 0.547 (1314.383)	Data 0.001 (3.273)	Loss 1.747	Prec@1 59.9177	Prec@5 81.4748
Train: [41][2600/10010]	Time 0.547 (1423.804)	Data 0.001 (3.438)	Loss 1.747	Prec@1 59.9334	Prec@5 81.4564
Train: [41][2800/10010]	Time 0.547 (1532.907)	Data 0.001 (3.605)	Loss 1.749	Prec@1 59.8762	Prec@5 81.4374
Train: [41][3000/10010]	Time 0.547 (1642.014)	Data 0.001 (3.772)	Loss 1.749	Prec@1 59.8743	Prec@5 81.4156
Train: [41][3200/10010]	Time 0.547 (1751.251)	Data 0.001 (3.936)	Loss 1.750	Prec@1 59.8778	Prec@5 81.3906
Train: [41][3400/10010]	Time 0.547 (1860.529)	Data 0.001 (4.105)	Loss 1.751	Prec@1 59.8480	Prec@5 81.3807
Train: [41][3600/10010]	Time 0.547 (1969.824)	Data 0.001 (4.270)	Loss 1.751	Prec@1 59.8362	Prec@5 81.3776
Train: [41][3800/10010]	Time 0.547 (2079.214)	Data 0.001 (4.439)	Loss 1.751	Prec@1 59.8498	Prec@5 81.3731
Train: [41][4000/10010]	Time 0.547 (2188.422)	Data 0.001 (4.603)	Loss 1.750	Prec@1 59.8612	Prec@5 81.3943
Train: [41][4200/10010]	Time 0.547 (2297.782)	Data 0.001 (4.767)	Loss 1.750	Prec@1 59.8682	Prec@5 81.3878
Train: [41][4400/10010]	Time 0.547 (2407.165)	Data 0.001 (4.930)	Loss 1.751	Prec@1 59.8456	Prec@5 81.3689
Train: [41][4600/10010]	Time 0.547 (2516.675)	Data 0.001 (5.096)	Loss 1.753	Prec@1 59.7993	Prec@5 81.3361
Train: [41][4800/10010]	Time 0.547 (2625.804)	Data 0.001 (5.260)	Loss 1.754	Prec@1 59.7865	Prec@5 81.3229
Train: [41][5000/10010]	Time 0.547 (2735.491)	Data 0.001 (5.428)	Loss 1.754	Prec@1 59.7710	Prec@5 81.3183
Train: [41][5200/10010]	Time 0.547 (2844.748)	Data 0.001 (5.594)	Loss 1.755	Prec@1 59.7631	Prec@5 81.3149
Train: [41][5400/10010]	Time 0.547 (2954.143)	Data 0.001 (5.759)	Loss 1.756	Prec@1 59.7414	Prec@5 81.2946
Train: [41][5600/10010]	Time 0.547 (3063.703)	Data 0.001 (5.926)	Loss 1.755	Prec@1 59.7526	Prec@5 81.3012
Train: [41][5800/10010]	Time 0.547 (3172.944)	Data 0.001 (6.091)	Loss 1.756	Prec@1 59.7301	Prec@5 81.2943
Train: [41][6000/10010]	Time 0.547 (3282.251)	Data 0.001 (6.257)	Loss 1.757	Prec@1 59.7143	Prec@5 81.2878
Train: [41][6200/10010]	Time 0.547 (3391.687)	Data 0.001 (6.423)	Loss 1.757	Prec@1 59.7006	Prec@5 81.2807
Train: [41][6400/10010]	Time 0.547 (3500.852)	Data 0.001 (6.589)	Loss 1.757	Prec@1 59.6862	Prec@5 81.2792
Train: [41][6600/10010]	Time 0.547 (3610.339)	Data 0.001 (6.755)	Loss 1.757	Prec@1 59.7059	Prec@5 81.2797
Train: [41][6800/10010]	Time 0.547 (3719.508)	Data 0.001 (6.924)	Loss 1.756	Prec@1 59.7141	Prec@5 81.2855
Train: [41][7000/10010]	Time 0.547 (3828.820)	Data 0.001 (7.093)	Loss 1.757	Prec@1 59.7055	Prec@5 81.2766
Train: [41][7200/10010]	Time 0.547 (3938.364)	Data 0.001 (7.261)	Loss 1.758	Prec@1 59.6762	Prec@5 81.2619
Train: [41][7400/10010]	Time 0.547 (4049.012)	Data 0.001 (7.429)	Loss 1.758	Prec@1 59.6676	Prec@5 81.2562
Train: [41][7600/10010]	Time 0.547 (4159.471)	Data 0.001 (7.598)	Loss 1.759	Prec@1 59.6488	Prec@5 81.2431
Train: [41][7800/10010]	Time 0.547 (4268.869)	Data 0.001 (7.763)	Loss 1.760	Prec@1 59.6293	Prec@5 81.2354
Train: [41][8000/10010]	Time 0.547 (4378.273)	Data 0.001 (7.930)	Loss 1.760	Prec@1 59.6368	Prec@5 81.2301
Train: [41][8200/10010]	Time 0.547 (4487.606)	Data 0.001 (8.093)	Loss 1.761	Prec@1 59.6221	Prec@5 81.2205
Train: [41][8400/10010]	Time 0.547 (4596.843)	Data 0.001 (8.258)	Loss 1.761	Prec@1 59.6111	Prec@5 81.2128
Train: [41][8600/10010]	Time 0.547 (4705.916)	Data 0.001 (8.412)	Loss 1.761	Prec@1 59.6160	Prec@5 81.2139
Train: [41][8800/10010]	Time 0.547 (4815.432)	Data 0.001 (8.579)	Loss 1.761	Prec@1 59.6178	Prec@5 81.2171
Train: [41][9000/10010]	Time 0.547 (4924.499)	Data 0.001 (8.739)	Loss 1.761	Prec@1 59.6065	Prec@5 81.2092
Train: [41][9200/10010]	Time 0.547 (5033.666)	Data 0.001 (8.908)	Loss 1.762	Prec@1 59.5988	Prec@5 81.2077
Train: [41][9400/10010]	Time 0.547 (5142.866)	Data 0.001 (9.073)	Loss 1.762	Prec@1 59.6028	Prec@5 81.2166
Train: [41][9600/10010]	Time 0.547 (5252.544)	Data 0.001 (9.240)	Loss 1.762	Prec@1 59.6015	Prec@5 81.2170
Train: [41][9800/10010]	Time 0.547 (5362.231)	Data 0.001 (9.408)	Loss 1.762	Prec@1 59.5999	Prec@5 81.2109
Train: [41][10000/10010]	Time 0.547 (5471.462)	Data 0.001 (9.568)	Loss 1.762	Prec@1 59.5976	Prec@5 81.2097
Train: [41]	Time 5475.913	Data 9.572	Loss 1.762	Prec@1 59.5974	Prec@5 81.2095	
Val: [41]	Time 70.534	Data 1.548	Loss 1.560	Prec@1 62.2560	Prec@5 85.0700	
Best Prec@1: [63.928]	
Starting epoch number: 42 Learning rate: 0.010000000000000002
Train: [42][0/10010]	Time 1.983 (1.983)	Data 1.419 (1.419)	Loss 1.796	Prec@1 58.5938	Prec@5 82.0312
Train: [42][200/10010]	Time 0.552 (110.909)	Data 0.008 (1.587)	Loss 1.738	Prec@1 59.6704	Prec@5 81.8097
Train: [42][400/10010]	Time 0.549 (220.252)	Data 0.004 (1.756)	Loss 1.733	Prec@1 60.0881	Prec@5 81.7663
Train: [42][600/10010]	Time 0.549 (329.925)	Data 0.003 (1.921)	Loss 1.732	Prec@1 60.1692	Prec@5 81.7167
Train: [42][800/10010]	Time 0.548 (439.078)	Data 0.003 (2.081)	Loss 1.732	Prec@1 60.1660	Prec@5 81.7250
Train: [42][1000/10010]	Time 0.548 (548.634)	Data 0.002 (2.247)	Loss 1.736	Prec@1 60.1344	Prec@5 81.6410
Train: [42][1200/10010]	Time 0.548 (657.991)	Data 0.002 (2.412)	Loss 1.735	Prec@1 60.2044	Prec@5 81.6312
Train: [42][1400/10010]	Time 0.548 (767.520)	Data 0.002 (2.577)	Loss 1.738	Prec@1 60.1390	Prec@5 81.6035
Train: [42][1600/10010]	Time 0.548 (877.171)	Data 0.002 (2.744)	Loss 1.743	Prec@1 60.0572	Prec@5 81.5306
Train: [42][1800/10010]	Time 0.548 (986.519)	Data 0.002 (2.903)	Loss 1.742	Prec@1 60.0639	Prec@5 81.5289
Train: [42][2000/10010]	Time 0.548 (1096.107)	Data 0.002 (3.070)	Loss 1.742	Prec@1 60.0797	Prec@5 81.5213
Train: [42][2200/10010]	Time 0.548 (1205.514)	Data 0.001 (3.234)	Loss 1.741	Prec@1 60.0668	Prec@5 81.5336
Train: [42][2400/10010]	Time 0.548 (1314.589)	Data 0.001 (3.398)	Loss 1.741	Prec@1 60.0603	Prec@5 81.5181
Train: [42][2600/10010]	Time 0.548 (1424.199)	Data 0.001 (3.564)	Loss 1.742	Prec@1 60.0220	Prec@5 81.5116
Train: [42][2800/10010]	Time 0.547 (1533.505)	Data 0.001 (3.734)	Loss 1.742	Prec@1 60.0240	Prec@5 81.5239
Train: [42][3000/10010]	Time 0.547 (1642.748)	Data 0.001 (3.903)	Loss 1.744	Prec@1 59.9969	Prec@5 81.4978
Train: [42][3200/10010]	Time 0.547 (1752.062)	Data 0.001 (4.070)	Loss 1.745	Prec@1 59.9881	Prec@5 81.4845
Train: [42][3400/10010]	Time 0.547 (1861.495)	Data 0.001 (4.236)	Loss 1.745	Prec@1 59.9406	Prec@5 81.4726
Train: [42][3600/10010]	Time 0.547 (1970.636)	Data 0.001 (4.399)	Loss 1.747	Prec@1 59.9100	Prec@5 81.4379
Train: [42][3800/10010]	Time 0.547 (2080.029)	Data 0.001 (4.566)	Loss 1.748	Prec@1 59.9147	Prec@5 81.4319
Train: [42][4000/10010]	Time 0.547 (2189.478)	Data 0.001 (4.731)	Loss 1.749	Prec@1 59.8819	Prec@5 81.4119
Train: [42][4200/10010]	Time 0.547 (2298.953)	Data 0.001 (4.893)	Loss 1.749	Prec@1 59.8836	Prec@5 81.4239
Train: [42][4400/10010]	Time 0.547 (2408.321)	Data 0.001 (5.058)	Loss 1.751	Prec@1 59.8483	Prec@5 81.3940
Train: [42][4600/10010]	Time 0.547 (2517.336)	Data 0.001 (5.220)	Loss 1.751	Prec@1 59.8428	Prec@5 81.3863
Train: [42][4800/10010]	Time 0.547 (2626.564)	Data 0.001 (5.385)	Loss 1.752	Prec@1 59.7991	Prec@5 81.3706
Train: [42][5000/10010]	Time 0.547 (2735.826)	Data 0.001 (5.550)	Loss 1.753	Prec@1 59.7905	Prec@5 81.3540
Train: [42][5200/10010]	Time 0.547 (2844.950)	Data 0.001 (5.713)	Loss 1.754	Prec@1 59.7725	Prec@5 81.3461
Train: [42][5400/10010]	Time 0.547 (2954.300)	Data 0.001 (5.880)	Loss 1.753	Prec@1 59.7755	Prec@5 81.3563
Train: [42][5600/10010]	Time 0.547 (3063.446)	Data 0.001 (6.039)	Loss 1.753	Prec@1 59.7770	Prec@5 81.3740
Train: [42][5800/10010]	Time 0.547 (3172.824)	Data 0.001 (6.209)	Loss 1.753	Prec@1 59.7676	Prec@5 81.3797
Train: [42][6000/10010]	Time 0.547 (3282.085)	Data 0.001 (6.377)	Loss 1.753	Prec@1 59.7706	Prec@5 81.3815
Train: [42][6200/10010]	Time 0.547 (3391.532)	Data 0.001 (6.545)	Loss 1.753	Prec@1 59.7648	Prec@5 81.3794
Train: [42][6400/10010]	Time 0.547 (3501.106)	Data 0.001 (6.713)	Loss 1.753	Prec@1 59.7602	Prec@5 81.3702
Train: [42][6600/10010]	Time 0.547 (3610.617)	Data 0.001 (6.878)	Loss 1.754	Prec@1 59.7591	Prec@5 81.3527
Train: [42][6800/10010]	Time 0.547 (3720.180)	Data 0.001 (7.047)	Loss 1.753	Prec@1 59.7621	Prec@5 81.3526
Train: [42][7000/10010]	Time 0.547 (3829.643)	Data 0.001 (7.213)	Loss 1.754	Prec@1 59.7494	Prec@5 81.3519
Train: [42][7200/10010]	Time 0.547 (3938.954)	Data 0.001 (7.380)	Loss 1.754	Prec@1 59.7463	Prec@5 81.3429
Train: [42][7400/10010]	Time 0.547 (4048.205)	Data 0.001 (7.550)	Loss 1.754	Prec@1 59.7483	Prec@5 81.3458
Train: [42][7600/10010]	Time 0.547 (4157.379)	Data 0.001 (7.711)	Loss 1.754	Prec@1 59.7441	Prec@5 81.3440
Train: [42][7800/10010]	Time 0.547 (4267.000)	Data 0.001 (7.879)	Loss 1.755	Prec@1 59.7385	Prec@5 81.3250
Train: [42][8000/10010]	Time 0.547 (4376.196)	Data 0.001 (8.044)	Loss 1.756	Prec@1 59.7179	Prec@5 81.3171
Train: [42][8200/10010]	Time 0.547 (4485.112)	Data 0.001 (8.207)	Loss 1.756	Prec@1 59.7172	Prec@5 81.3053
Train: [42][8400/10010]	Time 0.547 (4594.036)	Data 0.001 (8.368)	Loss 1.756	Prec@1 59.6996	Prec@5 81.2999
Train: [42][8600/10010]	Time 0.547 (4703.109)	Data 0.001 (8.531)	Loss 1.757	Prec@1 59.6958	Prec@5 81.2941
Train: [42][8800/10010]	Time 0.547 (4812.485)	Data 0.001 (8.697)	Loss 1.757	Prec@1 59.6790	Prec@5 81.2904
Train: [42][9000/10010]	Time 0.547 (4921.909)	Data 0.001 (8.863)	Loss 1.758	Prec@1 59.6705	Prec@5 81.2832
Train: [42][9200/10010]	Time 0.547 (5031.483)	Data 0.001 (9.030)	Loss 1.758	Prec@1 59.6794	Prec@5 81.2832
Train: [42][9400/10010]	Time 0.547 (5140.994)	Data 0.001 (9.198)	Loss 1.758	Prec@1 59.6764	Prec@5 81.2816
Train: [42][9600/10010]	Time 0.547 (5250.190)	Data 0.001 (9.367)	Loss 1.758	Prec@1 59.6732	Prec@5 81.2754
Train: [42][9800/10010]	Time 0.547 (5359.850)	Data 0.001 (9.537)	Loss 1.758	Prec@1 59.6698	Prec@5 81.2717
Train: [42][10000/10010]	Time 0.547 (5469.274)	Data 0.001 (9.703)	Loss 1.758	Prec@1 59.6729	Prec@5 81.2738
Train: [42]	Time 5473.729	Data 9.706	Loss 1.758	Prec@1 59.6737	Prec@5 81.2743	
Val: [42]	Time 71.078	Data 1.752	Loss 1.517	Prec@1 63.1560	Prec@5 85.4700	
Best Prec@1: [63.928]	
Starting epoch number: 43 Learning rate: 0.010000000000000002
Train: [43][0/10010]	Time 1.842 (1.842)	Data 1.225 (1.225)	Loss 1.772	Prec@1 61.7188	Prec@5 78.9062
Train: [43][200/10010]	Time 0.554 (111.367)	Data 0.007 (1.396)	Loss 1.749	Prec@1 59.5616	Prec@5 81.4210
Train: [43][400/10010]	Time 0.549 (220.293)	Data 0.004 (1.558)	Loss 1.745	Prec@1 59.9030	Prec@5 81.4059
Train: [43][600/10010]	Time 0.548 (329.398)	Data 0.003 (1.726)	Loss 1.738	Prec@1 60.0510	Prec@5 81.6400
Train: [43][800/10010]	Time 0.548 (438.565)	Data 0.002 (1.886)	Loss 1.738	Prec@1 60.1709	Prec@5 81.6197
Train: [43][1000/10010]	Time 0.547 (547.925)	Data 0.002 (2.052)	Loss 1.738	Prec@1 60.0930	Prec@5 81.6566
Train: [43][1200/10010]	Time 0.547 (657.292)	Data 0.002 (2.213)	Loss 1.738	Prec@1 60.0548	Prec@5 81.6416
Train: [43][1400/10010]	Time 0.547 (766.576)	Data 0.002 (2.375)	Loss 1.736	Prec@1 60.1273	Prec@5 81.6409
Train: [43][1600/10010]	Time 0.547 (876.109)	Data 0.002 (2.543)	Loss 1.735	Prec@1 60.1850	Prec@5 81.6331
Train: [43][1800/10010]	Time 0.547 (985.494)	Data 0.002 (2.703)	Loss 1.738	Prec@1 60.1142	Prec@5 81.5823
Train: [43][2000/10010]	Time 0.547 (1095.106)	Data 0.001 (2.869)	Loss 1.737	Prec@1 60.1262	Prec@5 81.5936
Train: [43][2200/10010]	Time 0.547 (1204.555)	Data 0.001 (3.035)	Loss 1.739	Prec@1 60.1282	Prec@5 81.5815
Train: [43][2400/10010]	Time 0.547 (1313.700)	Data 0.001 (3.199)	Loss 1.740	Prec@1 60.1149	Prec@5 81.5607
Train: [43][2600/10010]	Time 0.547 (1423.230)	Data 0.001 (3.366)	Loss 1.741	Prec@1 60.0619	Prec@5 81.5374
Train: [43][2800/10010]	Time 0.547 (1532.704)	Data 0.001 (3.534)	Loss 1.741	Prec@1 60.0927	Prec@5 81.5423
Train: [43][3000/10010]	Time 0.547 (1641.906)	Data 0.001 (3.704)	Loss 1.741	Prec@1 60.0985	Prec@5 81.5356
Train: [43][3200/10010]	Time 0.547 (1750.956)	Data 0.001 (3.870)	Loss 1.742	Prec@1 60.0694	Prec@5 81.4992
Train: [43][3400/10010]	Time 0.547 (1860.049)	Data 0.001 (4.039)	Loss 1.743	Prec@1 60.0531	Prec@5 81.4887
Train: [43][3600/10010]	Time 0.547 (1969.363)	Data 0.001 (4.206)	Loss 1.744	Prec@1 60.0371	Prec@5 81.4854
Train: [43][3800/10010]	Time 0.547 (2078.811)	Data 0.001 (4.373)	Loss 1.743	Prec@1 60.0514	Prec@5 81.5016
Train: [43][4000/10010]	Time 0.547 (2188.428)	Data 0.001 (4.539)	Loss 1.742	Prec@1 60.0461	Prec@5 81.4988
Train: [43][4200/10010]	Time 0.547 (2297.979)	Data 0.001 (4.704)	Loss 1.743	Prec@1 60.0099	Prec@5 81.4912
Train: [43][4400/10010]	Time 0.547 (2407.117)	Data 0.001 (4.868)	Loss 1.743	Prec@1 60.0039	Prec@5 81.4964
Train: [43][4600/10010]	Time 0.547 (2516.404)	Data 0.001 (5.030)	Loss 1.744	Prec@1 59.9591	Prec@5 81.4864
Train: [43][4800/10010]	Time 0.547 (2625.740)	Data 0.001 (5.195)	Loss 1.744	Prec@1 59.9600	Prec@5 81.4749
Train: [43][5000/10010]	Time 0.547 (2735.040)	Data 0.001 (5.359)	Loss 1.745	Prec@1 59.9450	Prec@5 81.4634
Train: [43][5200/10010]	Time 0.547 (2846.741)	Data 0.001 (5.527)	Loss 1.745	Prec@1 59.9369	Prec@5 81.4693
Train: [43][5400/10010]	Time 0.548 (2959.102)	Data 0.001 (5.694)	Loss 1.746	Prec@1 59.9338	Prec@5 81.4649
Train: [43][5600/10010]	Time 0.548 (3071.365)	Data 0.001 (5.861)	Loss 1.746	Prec@1 59.9338	Prec@5 81.4656
Train: [43][5800/10010]	Time 0.549 (3183.326)	Data 0.001 (6.036)	Loss 1.746	Prec@1 59.9343	Prec@5 81.4589
Train: [43][6000/10010]	Time 0.549 (3295.267)	Data 0.001 (6.208)	Loss 1.746	Prec@1 59.9240	Prec@5 81.4509
Train: [43][6200/10010]	Time 0.549 (3407.248)	Data 0.001 (6.369)	Loss 1.747	Prec@1 59.9111	Prec@5 81.4362
Train: [43][6400/10010]	Time 0.550 (3519.478)	Data 0.001 (6.528)	Loss 1.747	Prec@1 59.9184	Prec@5 81.4332
Train: [43][6600/10010]	Time 0.550 (3631.938)	Data 0.001 (6.694)	Loss 1.747	Prec@1 59.9155	Prec@5 81.4338
Train: [43][6800/10010]	Time 0.551 (3744.002)	Data 0.001 (6.858)	Loss 1.748	Prec@1 59.9002	Prec@5 81.4213
Train: [43][7000/10010]	Time 0.551 (3855.563)	Data 0.001 (7.014)	Loss 1.749	Prec@1 59.8807	Prec@5 81.3957
Train: [43][7200/10010]	Time 0.551 (3967.489)	Data 0.001 (7.181)	Loss 1.749	Prec@1 59.8852	Prec@5 81.3949
Train: [43][7400/10010]	Time 0.551 (4079.261)	Data 0.001 (7.344)	Loss 1.749	Prec@1 59.8699	Prec@5 81.3898
Train: [43][7600/10010]	Time 0.551 (4191.219)	Data 0.001 (7.511)	Loss 1.750	Prec@1 59.8697	Prec@5 81.3789
Train: [43][7800/10010]	Time 0.552 (4303.551)	Data 0.001 (7.678)	Loss 1.750	Prec@1 59.8533	Prec@5 81.3691
Train: [43][8000/10010]	Time 0.552 (4415.182)	Data 0.001 (7.837)	Loss 1.751	Prec@1 59.8311	Prec@5 81.3575
Train: [43][8200/10010]	Time 0.552 (4527.430)	Data 0.001 (8.000)	Loss 1.752	Prec@1 59.8145	Prec@5 81.3511
Train: [43][8400/10010]	Time 0.552 (4638.914)	Data 0.001 (8.176)	Loss 1.752	Prec@1 59.8176	Prec@5 81.3539
Train: [43][8600/10010]	Time 0.552 (4750.826)	Data 0.001 (8.340)	Loss 1.753	Prec@1 59.8010	Prec@5 81.3497
Train: [43][8800/10010]	Time 0.553 (4863.247)	Data 0.001 (8.506)	Loss 1.753	Prec@1 59.7973	Prec@5 81.3405
Train: [43][9000/10010]	Time 0.553 (4975.651)	Data 0.001 (8.685)	Loss 1.753	Prec@1 59.7898	Prec@5 81.3414
Train: [43][9200/10010]	Time 0.553 (5087.834)	Data 0.001 (8.842)	Loss 1.753	Prec@1 59.7886	Prec@5 81.3357
Train: [43][9400/10010]	Time 0.553 (5200.198)	Data 0.001 (9.005)	Loss 1.754	Prec@1 59.7915	Prec@5 81.3279
Train: [43][9600/10010]	Time 0.553 (5312.810)	Data 0.001 (9.168)	Loss 1.754	Prec@1 59.7828	Prec@5 81.3217
Train: [43][9800/10010]	Time 0.554 (5425.084)	Data 0.001 (9.328)	Loss 1.754	Prec@1 59.7775	Prec@5 81.3146
Train: [43][10000/10010]	Time 0.554 (5537.252)	Data 0.001 (9.484)	Loss 1.755	Prec@1 59.7643	Prec@5 81.3062
Train: [43]	Time 5541.843	Data 9.488	Loss 1.755	Prec@1 59.7659	Prec@5 81.3056	
Val: [43]	Time 78.024	Data 1.904	Loss 1.735	Prec@1 58.8400	Prec@5 82.4580	
Best Prec@1: [63.928]	
Starting epoch number: 44 Learning rate: 0.010000000000000002
Train: [44][0/10010]	Time 1.992 (1.992)	Data 1.378 (1.378)	Loss 1.595	Prec@1 63.2812	Prec@5 82.8125
Train: [44][200/10010]	Time 0.560 (112.637)	Data 0.008 (1.547)	Loss 1.735	Prec@1 60.2767	Prec@5 81.8486
Train: [44][400/10010]	Time 0.557 (223.225)	Data 0.004 (1.713)	Loss 1.721	Prec@1 60.5810	Prec@5 81.9533
Train: [44][600/10010]	Time 0.555 (333.796)	Data 0.003 (1.883)	Loss 1.718	Prec@1 60.6398	Prec@5 81.9702
Train: [44][800/10010]	Time 0.555 (444.209)	Data 0.003 (2.052)	Loss 1.719	Prec@1 60.6069	Prec@5 81.9191
Train: [44][1000/10010]	Time 0.554 (554.822)	Data 0.002 (2.224)	Loss 1.716	Prec@1 60.6776	Prec@5 81.9516
Train: [44][1200/10010]	Time 0.554 (665.532)	Data 0.002 (2.395)	Loss 1.721	Prec@1 60.6253	Prec@5 81.8582
Train: [44][1400/10010]	Time 0.554 (776.086)	Data 0.002 (2.567)	Loss 1.722	Prec@1 60.5393	Prec@5 81.8522
Train: [44][1600/10010]	Time 0.554 (886.481)	Data 0.002 (2.736)	Loss 1.724	Prec@1 60.4764	Prec@5 81.8336
Train: [44][1800/10010]	Time 0.554 (997.142)	Data 0.002 (2.903)	Loss 1.727	Prec@1 60.4191	Prec@5 81.7922
Train: [44][2000/10010]	Time 0.554 (1107.838)	Data 0.002 (3.074)	Loss 1.727	Prec@1 60.3804	Prec@5 81.7935
Train: [44][2200/10010]	Time 0.554 (1218.355)	Data 0.001 (3.244)	Loss 1.728	Prec@1 60.3628	Prec@5 81.7508
Train: [44][2400/10010]	Time 0.554 (1329.173)	Data 0.001 (3.415)	Loss 1.729	Prec@1 60.3525	Prec@5 81.7238
Train: [44][2600/10010]	Time 0.554 (1439.816)	Data 0.001 (3.586)	Loss 1.731	Prec@1 60.3103	Prec@5 81.6957
Train: [44][2800/10010]	Time 0.554 (1550.609)	Data 0.001 (3.757)	Loss 1.731	Prec@1 60.3113	Prec@5 81.6985
Train: [44][3000/10010]	Time 0.554 (1661.104)	Data 0.001 (3.928)	Loss 1.731	Prec@1 60.3031	Prec@5 81.6866
Train: [44][3200/10010]	Time 0.553 (1771.497)	Data 0.001 (4.100)	Loss 1.731	Prec@1 60.3129	Prec@5 81.6883
Train: [44][3400/10010]	Time 0.553 (1881.693)	Data 0.001 (4.271)	Loss 1.731	Prec@1 60.3033	Prec@5 81.6793
Train: [44][3600/10010]	Time 0.553 (1991.903)	Data 0.001 (4.443)	Loss 1.731	Prec@1 60.2715	Prec@5 81.6715
Train: [44][3800/10010]	Time 0.553 (2102.069)	Data 0.001 (4.616)	Loss 1.733	Prec@1 60.2475	Prec@5 81.6537
Train: [44][4000/10010]	Time 0.553 (2212.043)	Data 0.001 (4.786)	Loss 1.734	Prec@1 60.2103	Prec@5 81.6364
Train: [44][4200/10010]	Time 0.553 (2322.353)	Data 0.001 (4.961)	Loss 1.735	Prec@1 60.1739	Prec@5 81.6076
Train: [44][4400/10010]	Time 0.553 (2432.420)	Data 0.001 (5.129)	Loss 1.736	Prec@1 60.1394	Prec@5 81.5841
Train: [44][4600/10010]	Time 0.552 (2541.999)	Data 0.001 (5.294)	Loss 1.738	Prec@1 60.1157	Prec@5 81.5619
Train: [44][4800/10010]	Time 0.552 (2651.168)	Data 0.001 (5.461)	Loss 1.738	Prec@1 60.1118	Prec@5 81.5483
Train: [44][5000/10010]	Time 0.552 (2760.248)	Data 0.001 (5.624)	Loss 1.739	Prec@1 60.0953	Prec@5 81.5332
Train: [44][5200/10010]	Time 0.552 (2869.516)	Data 0.001 (5.789)	Loss 1.739	Prec@1 60.0888	Prec@5 81.5310
Train: [44][5400/10010]	Time 0.552 (2978.795)	Data 0.001 (5.954)	Loss 1.739	Prec@1 60.0724	Prec@5 81.5225
Train: [44][5600/10010]	Time 0.551 (3087.947)	Data 0.001 (6.121)	Loss 1.740	Prec@1 60.0528	Prec@5 81.5094
Train: [44][5800/10010]	Time 0.551 (3197.048)	Data 0.001 (6.288)	Loss 1.741	Prec@1 60.0453	Prec@5 81.5025
Train: [44][6000/10010]	Time 0.551 (3306.328)	Data 0.001 (6.455)	Loss 1.741	Prec@1 60.0421	Prec@5 81.5135
Train: [44][6200/10010]	Time 0.551 (3415.550)	Data 0.001 (6.619)	Loss 1.741	Prec@1 60.0339	Prec@5 81.5157
Train: [44][6400/10010]	Time 0.551 (3525.218)	Data 0.001 (6.787)	Loss 1.741	Prec@1 60.0324	Prec@5 81.5142
Train: [44][6600/10010]	Time 0.551 (3634.607)	Data 0.001 (6.954)	Loss 1.742	Prec@1 60.0143	Prec@5 81.4924
Train: [44][6800/10010]	Time 0.551 (3743.990)	Data 0.001 (7.117)	Loss 1.743	Prec@1 60.0076	Prec@5 81.4882
Train: [44][7000/10010]	Time 0.550 (3853.250)	Data 0.001 (7.284)	Loss 1.743	Prec@1 60.0031	Prec@5 81.4886
Train: [44][7200/10010]	Time 0.550 (3962.913)	Data 0.001 (7.449)	Loss 1.743	Prec@1 59.9910	Prec@5 81.4834
Train: [44][7400/10010]	Time 0.550 (4072.358)	Data 0.001 (7.617)	Loss 1.744	Prec@1 59.9715	Prec@5 81.4755
Train: [44][7600/10010]	Time 0.550 (4181.542)	Data 0.001 (7.783)	Loss 1.745	Prec@1 59.9588	Prec@5 81.4728
Train: [44][7800/10010]	Time 0.550 (4290.609)	Data 0.001 (7.944)	Loss 1.745	Prec@1 59.9632	Prec@5 81.4775
Train: [44][8000/10010]	Time 0.550 (4399.798)	Data 0.001 (8.112)	Loss 1.745	Prec@1 59.9518	Prec@5 81.4617
Train: [44][8200/10010]	Time 0.550 (4508.883)	Data 0.001 (8.272)	Loss 1.745	Prec@1 59.9479	Prec@5 81.4579
Train: [44][8400/10010]	Time 0.550 (4616.412)	Data 0.001 (8.395)	Loss 1.746	Prec@1 59.9403	Prec@5 81.4465
Train: [44][8600/10010]	Time 0.549 (4723.918)	Data 0.001 (8.521)	Loss 1.747	Prec@1 59.9303	Prec@5 81.4389
Train: [44][8800/10010]	Time 0.549 (4831.517)	Data 0.001 (8.648)	Loss 1.747	Prec@1 59.9216	Prec@5 81.4324
Train: [44][9000/10010]	Time 0.549 (4939.288)	Data 0.001 (8.773)	Loss 1.747	Prec@1 59.9065	Prec@5 81.4296
Train: [44][9200/10010]	Time 0.549 (5047.710)	Data 0.001 (8.896)	Loss 1.748	Prec@1 59.8976	Prec@5 81.4199
Train: [44][9400/10010]	Time 0.548 (5155.308)	Data 0.001 (9.021)	Loss 1.748	Prec@1 59.8892	Prec@5 81.4151
Train: [44][9600/10010]	Time 0.548 (5263.194)	Data 0.001 (9.144)	Loss 1.748	Prec@1 59.8791	Prec@5 81.4092
Train: [44][9800/10010]	Time 0.548 (5371.114)	Data 0.001 (9.272)	Loss 1.749	Prec@1 59.8654	Prec@5 81.3979
Train: [44][10000/10010]	Time 0.548 (5478.944)	Data 0.001 (9.401)	Loss 1.750	Prec@1 59.8557	Prec@5 81.3985
Train: [44]	Time 5483.283	Data 9.403	Loss 1.749	Prec@1 59.8562	Prec@5 81.3998	
Val: [44]	Time 68.218	Data 1.636	Loss 1.536	Prec@1 62.9980	Prec@5 85.4500	
Best Prec@1: [63.928]	
Starting epoch number: 45 Learning rate: 0.010000000000000002
Train: [45][0/10010]	Time 1.781 (1.781)	Data 1.218 (1.218)	Loss 1.902	Prec@1 55.4688	Prec@5 75.0000
Train: [45][200/10010]	Time 0.543 (109.230)	Data 0.007 (1.350)	Loss 1.721	Prec@1 60.2534	Prec@5 82.0157
Train: [45][400/10010]	Time 0.540 (216.702)	Data 0.004 (1.476)	Loss 1.727	Prec@1 60.1231	Prec@5 81.7624
Train: [45][600/10010]	Time 0.540 (324.463)	Data 0.003 (1.603)	Loss 1.721	Prec@1 60.2264	Prec@5 81.9117
Train: [45][800/10010]	Time 0.540 (432.325)	Data 0.002 (1.731)	Loss 1.725	Prec@1 60.2499	Prec@5 81.7757
Train: [45][1000/10010]	Time 0.539 (539.987)	Data 0.002 (1.859)	Loss 1.721	Prec@1 60.3763	Prec@5 81.8096
Train: [45][1200/10010]	Time 0.539 (647.697)	Data 0.002 (1.990)	Loss 1.724	Prec@1 60.3481	Prec@5 81.8075
Train: [45][1400/10010]	Time 0.542 (759.708)	Data 0.002 (2.182)	Loss 1.725	Prec@1 60.3408	Prec@5 81.7413
Train: [45][1600/10010]	Time 0.544 (870.828)	Data 0.001 (2.365)	Loss 1.727	Prec@1 60.2685	Prec@5 81.7170
Train: [45][1800/10010]	Time 0.546 (982.548)	Data 0.001 (2.545)	Loss 1.727	Prec@1 60.2933	Prec@5 81.7155
Train: [45][2000/10010]	Time 0.547 (1094.145)	Data 0.001 (2.732)	Loss 1.727	Prec@1 60.2652	Prec@5 81.7255
Train: [45][2200/10010]	Time 0.548 (1205.319)	Data 0.001 (2.917)	Loss 1.729	Prec@1 60.2287	Prec@5 81.7224
Train: [45][2400/10010]	Time 0.548 (1315.941)	Data 0.001 (3.094)	Loss 1.730	Prec@1 60.1963	Prec@5 81.6883
Train: [45][2600/10010]	Time 0.548 (1426.601)	Data 0.001 (3.273)	Loss 1.731	Prec@1 60.2001	Prec@5 81.6810
Train: [45][2800/10010]	Time 0.549 (1537.258)	Data 0.001 (3.453)	Loss 1.729	Prec@1 60.2318	Prec@5 81.6871
Train: [45][3000/10010]	Time 0.549 (1648.908)	Data 0.001 (3.640)	Loss 1.729	Prec@1 60.2338	Prec@5 81.6834
Train: [45][3200/10010]	Time 0.550 (1759.561)	Data 0.001 (3.812)	Loss 1.730	Prec@1 60.2202	Prec@5 81.6683
Train: [45][3400/10010]	Time 0.550 (1869.649)	Data 0.001 (3.981)	Loss 1.732	Prec@1 60.1643	Prec@5 81.6417
Train: [45][3600/10010]	Time 0.550 (1980.679)	Data 0.001 (4.166)	Loss 1.732	Prec@1 60.1671	Prec@5 81.6329
Train: [45][3800/10010]	Time 0.550 (2091.675)	Data 0.001 (4.354)	Loss 1.734	Prec@1 60.1449	Prec@5 81.5844
Train: [45][4000/10010]	Time 0.550 (2202.429)	Data 0.001 (4.541)	Loss 1.735	Prec@1 60.1342	Prec@5 81.5780
Train: [45][4200/10010]	Time 0.551 (2313.595)	Data 0.001 (4.723)	Loss 1.736	Prec@1 60.1068	Prec@5 81.5634
Train: [45][4400/10010]	Time 0.551 (2425.515)	Data 0.001 (4.911)	Loss 1.736	Prec@1 60.0860	Prec@5 81.5576
Train: [45][4600/10010]	Time 0.551 (2536.768)	Data 0.001 (5.095)	Loss 1.736	Prec@1 60.0870	Prec@5 81.5584
Train: [45][4800/10010]	Time 0.552 (2648.269)	Data 0.001 (5.280)	Loss 1.736	Prec@1 60.0742	Prec@5 81.5675
Train: [45][5000/10010]	Time 0.552 (2759.703)	Data 0.001 (5.465)	Loss 1.737	Prec@1 60.0485	Prec@5 81.5546
Train: [45][5200/10010]	Time 0.552 (2870.981)	Data 0.001 (5.649)	Loss 1.736	Prec@1 60.0481	Prec@5 81.5713
Train: [45][5400/10010]	Time 0.552 (2981.371)	Data 0.001 (5.828)	Loss 1.737	Prec@1 60.0394	Prec@5 81.5598
Train: [45][5600/10010]	Time 0.552 (3092.668)	Data 0.001 (6.012)	Loss 1.738	Prec@1 60.0258	Prec@5 81.5524
Train: [45][5800/10010]	Time 0.552 (3204.413)	Data 0.001 (6.199)	Loss 1.737	Prec@1 60.0299	Prec@5 81.5672
Train: [45][6000/10010]	Time 0.553 (3315.981)	Data 0.001 (6.386)	Loss 1.737	Prec@1 60.0340	Prec@5 81.5623
Train: [45][6200/10010]	Time 0.553 (3427.314)	Data 0.001 (6.570)	Loss 1.737	Prec@1 60.0340	Prec@5 81.5604
Train: [45][6400/10010]	Time 0.553 (3538.055)	Data 0.001 (6.748)	Loss 1.738	Prec@1 60.0194	Prec@5 81.5474
Train: [45][6600/10010]	Time 0.553 (3648.016)	Data 0.001 (6.916)	Loss 1.738	Prec@1 60.0107	Prec@5 81.5436
Train: [45][6800/10010]	Time 0.553 (3759.057)	Data 0.001 (7.100)	Loss 1.739	Prec@1 60.0026	Prec@5 81.5365
Train: [45][7000/10010]	Time 0.553 (3870.584)	Data 0.001 (7.286)	Loss 1.739	Prec@1 59.9889	Prec@5 81.5233
Train: [45][7200/10010]	Time 0.553 (3982.491)	Data 0.001 (7.473)	Loss 1.740	Prec@1 59.9754	Prec@5 81.5118
Train: [45][7400/10010]	Time 0.553 (4094.130)	Data 0.001 (7.657)	Loss 1.740	Prec@1 59.9711	Prec@5 81.5022
Train: [45][7600/10010]	Time 0.553 (4204.567)	Data 0.001 (7.820)	Loss 1.741	Prec@1 59.9645	Prec@5 81.4985
Train: [45][7800/10010]	Time 0.553 (4315.822)	Data 0.001 (7.999)	Loss 1.742	Prec@1 59.9502	Prec@5 81.4869
Train: [45][8000/10010]	Time 0.553 (4427.752)	Data 0.001 (8.181)	Loss 1.742	Prec@1 59.9367	Prec@5 81.4790
Train: [45][8200/10010]	Time 0.554 (4539.955)	Data 0.001 (8.376)	Loss 1.742	Prec@1 59.9266	Prec@5 81.4813
Train: [45][8400/10010]	Time 0.554 (4652.248)	Data 0.001 (8.561)	Loss 1.743	Prec@1 59.9121	Prec@5 81.4701
Train: [45][8600/10010]	Time 0.554 (4763.248)	Data 0.001 (8.734)	Loss 1.743	Prec@1 59.9120	Prec@5 81.4772
Train: [45][8800/10010]	Time 0.554 (4874.343)	Data 0.001 (8.908)	Loss 1.743	Prec@1 59.9122	Prec@5 81.4737
Train: [45][9000/10010]	Time 0.554 (4986.148)	Data 0.001 (9.094)	Loss 1.743	Prec@1 59.9016	Prec@5 81.4659
Train: [45][9200/10010]	Time 0.554 (5098.173)	Data 0.001 (9.283)	Loss 1.744	Prec@1 59.8962	Prec@5 81.4615
Train: [45][9400/10010]	Time 0.554 (5209.833)	Data 0.001 (9.464)	Loss 1.744	Prec@1 59.8853	Prec@5 81.4583
Train: [45][9600/10010]	Time 0.554 (5321.081)	Data 0.001 (9.646)	Loss 1.744	Prec@1 59.8832	Prec@5 81.4630
Train: [45][9800/10010]	Time 0.554 (5432.002)	Data 0.001 (9.825)	Loss 1.744	Prec@1 59.8804	Prec@5 81.4558
Train: [45][10000/10010]	Time 0.554 (5543.639)	Data 0.001 (10.003)	Loss 1.744	Prec@1 59.8789	Prec@5 81.4581
Train: [45]	Time 5548.272	Data 10.007	Loss 1.744	Prec@1 59.8779	Prec@5 81.4584	
Val: [45]	Time 73.706	Data 1.870	Loss 1.484	Prec@1 63.8120	Prec@5 86.0660	
Best Prec@1: [63.928]	
Starting epoch number: 46 Learning rate: 0.010000000000000002
Train: [46][0/10010]	Time 2.036 (2.036)	Data 1.449 (1.449)	Loss 1.741	Prec@1 54.6875	Prec@5 83.5938
Train: [46][200/10010]	Time 0.565 (113.638)	Data 0.008 (1.637)	Loss 1.720	Prec@1 60.2923	Prec@5 81.8058
Train: [46][400/10010]	Time 0.562 (225.445)	Data 0.005 (1.824)	Loss 1.711	Prec@1 60.5186	Prec@5 81.9709
Train: [46][600/10010]	Time 0.559 (335.828)	Data 0.003 (2.000)	Loss 1.717	Prec@1 60.4149	Prec@5 81.9572
Train: [46][800/10010]	Time 0.558 (446.738)	Data 0.003 (2.184)	Loss 1.718	Prec@1 60.4391	Prec@5 81.8947
Train: [46][1000/10010]	Time 0.558 (558.945)	Data 0.002 (2.374)	Loss 1.722	Prec@1 60.4279	Prec@5 81.8416
Train: [46][1200/10010]	Time 0.559 (670.989)	Data 0.002 (2.564)	Loss 1.721	Prec@1 60.4080	Prec@5 81.8211
Train: [46][1400/10010]	Time 0.559 (783.489)	Data 0.002 (2.750)	Loss 1.721	Prec@1 60.4011	Prec@5 81.8149
Train: [46][1600/10010]	Time 0.559 (894.794)	Data 0.002 (2.930)	Loss 1.720	Prec@1 60.4076	Prec@5 81.8312
Train: [46][1800/10010]	Time 0.558 (1004.787)	Data 0.002 (3.100)	Loss 1.720	Prec@1 60.4495	Prec@5 81.8217
Train: [46][2000/10010]	Time 0.558 (1116.014)	Data 0.002 (3.289)	Loss 1.717	Prec@1 60.5115	Prec@5 81.8493
Train: [46][2200/10010]	Time 0.558 (1227.393)	Data 0.002 (3.476)	Loss 1.720	Prec@1 60.4608	Prec@5 81.7998
Train: [46][2400/10010]	Time 0.557 (1338.473)	Data 0.002 (3.665)	Loss 1.721	Prec@1 60.4081	Prec@5 81.8022
Train: [46][2600/10010]	Time 0.557 (1449.552)	Data 0.001 (3.849)	Loss 1.723	Prec@1 60.3707	Prec@5 81.7708
Train: [46][2800/10010]	Time 0.557 (1560.148)	Data 0.001 (4.036)	Loss 1.724	Prec@1 60.3395	Prec@5 81.7409
Train: [46][3000/10010]	Time 0.557 (1671.387)	Data 0.001 (4.224)	Loss 1.723	Prec@1 60.3479	Prec@5 81.7337
Train: [46][3200/10010]	Time 0.557 (1782.510)	Data 0.001 (4.410)	Loss 1.723	Prec@1 60.3779	Prec@5 81.7467
Train: [46][3400/10010]	Time 0.557 (1893.731)	Data 0.001 (4.592)	Loss 1.724	Prec@1 60.3515	Prec@5 81.7230
Train: [46][3600/10010]	Time 0.557 (2005.115)	Data 0.001 (4.781)	Loss 1.725	Prec@1 60.3307	Prec@5 81.7141
Train: [46][3800/10010]	Time 0.557 (2116.157)	Data 0.001 (4.968)	Loss 1.726	Prec@1 60.3092	Prec@5 81.7018
Train: [46][4000/10010]	Time 0.557 (2227.322)	Data 0.001 (5.157)	Loss 1.727	Prec@1 60.2996	Prec@5 81.6677
Train: [46][4200/10010]	Time 0.557 (2338.787)	Data 0.001 (5.342)	Loss 1.728	Prec@1 60.2546	Prec@5 81.6470
Train: [46][4400/10010]	Time 0.557 (2450.455)	Data 0.001 (5.529)	Loss 1.729	Prec@1 60.2477	Prec@5 81.6523
Train: [46][4600/10010]	Time 0.557 (2561.963)	Data 0.001 (5.718)	Loss 1.728	Prec@1 60.2529	Prec@5 81.6567
Train: [46][4800/10010]	Time 0.557 (2673.305)	Data 0.001 (5.893)	Loss 1.729	Prec@1 60.2378	Prec@5 81.6542
Train: [46][5000/10010]	Time 0.557 (2784.744)	Data 0.001 (6.074)	Loss 1.730	Prec@1 60.2395	Prec@5 81.6468
Train: [46][5200/10010]	Time 0.557 (2895.949)	Data 0.001 (6.264)	Loss 1.730	Prec@1 60.2314	Prec@5 81.6422
Train: [46][5400/10010]	Time 0.557 (3006.967)	Data 0.001 (6.454)	Loss 1.731	Prec@1 60.2148	Prec@5 81.6340
Train: [46][5600/10010]	Time 0.557 (3118.187)	Data 0.001 (6.638)	Loss 1.732	Prec@1 60.1971	Prec@5 81.6101
Train: [46][5800/10010]	Time 0.557 (3229.511)	Data 0.001 (6.821)	Loss 1.733	Prec@1 60.1798	Prec@5 81.5993
Train: [46][6000/10010]	Time 0.557 (3340.302)	Data 0.001 (7.003)	Loss 1.733	Prec@1 60.1629	Prec@5 81.5951
Train: [46][6200/10010]	Time 0.557 (3451.450)	Data 0.001 (7.190)	Loss 1.734	Prec@1 60.1360	Prec@5 81.5805
Train: [46][6400/10010]	Time 0.557 (3563.240)	Data 0.001 (7.381)	Loss 1.736	Prec@1 60.1132	Prec@5 81.5653
Train: [46][6600/10010]	Time 0.557 (3675.130)	Data 0.001 (7.570)	Loss 1.736	Prec@1 60.1077	Prec@5 81.5544
Train: [46][6800/10010]	Time 0.557 (3786.740)	Data 0.001 (7.759)	Loss 1.736	Prec@1 60.1057	Prec@5 81.5589
Train: [46][7000/10010]	Time 0.557 (3897.385)	Data 0.001 (7.942)	Loss 1.736	Prec@1 60.1084	Prec@5 81.5627
Train: [46][7200/10010]	Time 0.557 (4007.824)	Data 0.001 (8.132)	Loss 1.737	Prec@1 60.0992	Prec@5 81.5589
Train: [46][7400/10010]	Time 0.556 (4118.633)	Data 0.001 (8.310)	Loss 1.737	Prec@1 60.0925	Prec@5 81.5504
Train: [46][7600/10010]	Time 0.556 (4229.285)	Data 0.001 (8.486)	Loss 1.737	Prec@1 60.0828	Prec@5 81.5449
Train: [46][7800/10010]	Time 0.556 (4339.869)	Data 0.001 (8.667)	Loss 1.738	Prec@1 60.0715	Prec@5 81.5451
Train: [46][8000/10010]	Time 0.556 (4450.593)	Data 0.001 (8.847)	Loss 1.738	Prec@1 60.0625	Prec@5 81.5417
Train: [46][8200/10010]	Time 0.556 (4560.994)	Data 0.001 (9.026)	Loss 1.738	Prec@1 60.0556	Prec@5 81.5469
Train: [46][8400/10010]	Time 0.556 (4672.113)	Data 0.001 (9.213)	Loss 1.738	Prec@1 60.0500	Prec@5 81.5502
Train: [46][8600/10010]	Time 0.556 (4783.419)	Data 0.001 (9.395)	Loss 1.739	Prec@1 60.0415	Prec@5 81.5343
Train: [46][8800/10010]	Time 0.556 (4894.821)	Data 0.001 (9.582)	Loss 1.739	Prec@1 60.0425	Prec@5 81.5327
Train: [46][9000/10010]	Time 0.556 (5006.185)	Data 0.001 (9.771)	Loss 1.739	Prec@1 60.0436	Prec@5 81.5277
Train: [46][9200/10010]	Time 0.556 (5117.726)	Data 0.001 (9.956)	Loss 1.739	Prec@1 60.0361	Prec@5 81.5254
Train: [46][9400/10010]	Time 0.556 (5229.873)	Data 0.001 (10.151)	Loss 1.741	Prec@1 60.0138	Prec@5 81.5104
Train: [46][9600/10010]	Time 0.556 (5341.986)	Data 0.001 (10.337)	Loss 1.741	Prec@1 60.0098	Prec@5 81.5100
Train: [46][9800/10010]	Time 0.557 (5454.301)	Data 0.001 (10.526)	Loss 1.741	Prec@1 60.0114	Prec@5 81.5139
Train: [46][10000/10010]	Time 0.557 (5566.308)	Data 0.001 (10.713)	Loss 1.741	Prec@1 60.0031	Prec@5 81.5066
Train: [46]	Time 5571.076	Data 10.717	Loss 1.741	Prec@1 60.0042	Prec@5 81.5073	
Val: [46]	Time 73.028	Data 1.702	Loss 1.503	Prec@1 63.5760	Prec@5 85.8160	
Best Prec@1: [63.928]	
Starting epoch number: 47 Learning rate: 0.010000000000000002
Train: [47][0/10010]	Time 1.806 (1.806)	Data 1.233 (1.233)	Loss 1.550	Prec@1 60.9375	Prec@5 82.8125
Train: [47][200/10010]	Time 0.557 (111.928)	Data 0.007 (1.410)	Loss 1.729	Prec@1 60.0202	Prec@5 81.6853
Train: [47][400/10010]	Time 0.558 (223.631)	Data 0.004 (1.598)	Loss 1.711	Prec@1 60.3608	Prec@5 81.8929
Train: [47][600/10010]	Time 0.559 (335.767)	Data 0.003 (1.783)	Loss 1.711	Prec@1 60.4201	Prec@5 81.9195
Train: [47][800/10010]	Time 0.559 (447.711)	Data 0.002 (1.970)	Loss 1.710	Prec@1 60.4654	Prec@5 81.9522
Train: [47][1000/10010]	Time 0.559 (559.469)	Data 0.002 (2.153)	Loss 1.712	Prec@1 60.4817	Prec@5 81.9907
Train: [47][1200/10010]	Time 0.557 (669.432)	Data 0.002 (2.327)	Loss 1.716	Prec@1 60.3631	Prec@5 81.9343
Train: [47][1400/10010]	Time 0.557 (779.968)	Data 0.002 (2.505)	Loss 1.715	Prec@1 60.3877	Prec@5 81.9019
Train: [47][1600/10010]	Time 0.557 (891.322)	Data 0.002 (2.691)	Loss 1.714	Prec@1 60.3866	Prec@5 81.8951
Train: [47][1800/10010]	Time 0.557 (1002.712)	Data 0.002 (2.876)	Loss 1.717	Prec@1 60.3315	Prec@5 81.8495
Train: [47][2000/10010]	Time 0.557 (1113.986)	Data 0.002 (3.059)	Loss 1.717	Prec@1 60.3601	Prec@5 81.8185
Train: [47][2200/10010]	Time 0.557 (1225.204)	Data 0.001 (3.241)	Loss 1.719	Prec@1 60.3280	Prec@5 81.7909
Train: [47][2400/10010]	Time 0.557 (1336.424)	Data 0.001 (3.429)	Loss 1.719	Prec@1 60.3336	Prec@5 81.8250
Train: [47][2600/10010]	Time 0.557 (1448.369)	Data 0.001 (3.620)	Loss 1.721	Prec@1 60.2788	Prec@5 81.8093
Train: [47][2800/10010]	Time 0.557 (1560.258)	Data 0.001 (3.805)	Loss 1.720	Prec@1 60.3152	Prec@5 81.8354
Train: [47][3000/10010]	Time 0.557 (1672.492)	Data 0.001 (3.990)	Loss 1.721	Prec@1 60.2859	Prec@5 81.8175
Train: [47][3200/10010]	Time 0.557 (1783.959)	Data 0.001 (4.174)	Loss 1.723	Prec@1 60.2646	Prec@5 81.7828
Train: [47][3400/10010]	Time 0.557 (1894.806)	Data 0.001 (4.356)	Loss 1.724	Prec@1 60.2667	Prec@5 81.7726
Train: [47][3600/10010]	Time 0.557 (2005.770)	Data 0.001 (4.542)	Loss 1.726	Prec@1 60.2469	Prec@5 81.7477
Train: [47][3800/10010]	Time 0.557 (2116.575)	Data 0.001 (4.723)	Loss 1.726	Prec@1 60.2508	Prec@5 81.7556
Train: [47][4000/10010]	Time 0.557 (2227.544)	Data 0.001 (4.905)	Loss 1.726	Prec@1 60.2469	Prec@5 81.7507
Train: [47][4200/10010]	Time 0.557 (2338.096)	Data 0.001 (5.086)	Loss 1.726	Prec@1 60.2570	Prec@5 81.7463
Train: [47][4400/10010]	Time 0.556 (2448.560)	Data 0.001 (5.264)	Loss 1.726	Prec@1 60.2580	Prec@5 81.7371
Train: [47][4600/10010]	Time 0.556 (2559.638)	Data 0.001 (5.449)	Loss 1.728	Prec@1 60.2417	Prec@5 81.7192
Train: [47][4800/10010]	Time 0.556 (2670.460)	Data 0.001 (5.629)	Loss 1.728	Prec@1 60.2396	Prec@5 81.7217
Train: [47][5000/10010]	Time 0.556 (2781.756)	Data 0.001 (5.811)	Loss 1.729	Prec@1 60.2209	Prec@5 81.7160
Train: [47][5200/10010]	Time 0.556 (2893.000)	Data 0.001 (5.994)	Loss 1.729	Prec@1 60.2270	Prec@5 81.7020
Train: [47][5400/10010]	Time 0.556 (3003.667)	Data 0.001 (6.170)	Loss 1.728	Prec@1 60.2341	Prec@5 81.7139
Train: [47][5600/10010]	Time 0.556 (3114.434)	Data 0.001 (6.352)	Loss 1.729	Prec@1 60.2212	Prec@5 81.6977
Train: [47][5800/10010]	Time 0.556 (3226.213)	Data 0.001 (6.541)	Loss 1.729	Prec@1 60.2205	Prec@5 81.7028
Train: [47][6000/10010]	Time 0.556 (3338.446)	Data 0.001 (6.730)	Loss 1.729	Prec@1 60.2319	Prec@5 81.7054
Train: [47][6200/10010]	Time 0.556 (3450.109)	Data 0.001 (6.914)	Loss 1.729	Prec@1 60.2137	Prec@5 81.6920
Train: [47][6400/10010]	Time 0.556 (3562.089)	Data 0.001 (7.103)	Loss 1.730	Prec@1 60.2164	Prec@5 81.6884
Train: [47][6600/10010]	Time 0.556 (3673.230)	Data 0.001 (7.287)	Loss 1.730	Prec@1 60.1897	Prec@5 81.6846
Train: [47][6800/10010]	Time 0.557 (3785.205)	Data 0.001 (7.475)	Loss 1.730	Prec@1 60.1818	Prec@5 81.6841
Train: [47][7000/10010]	Time 0.556 (3893.929)	Data 0.001 (7.611)	Loss 1.731	Prec@1 60.1712	Prec@5 81.6763
Train: [47][7200/10010]	Time 0.556 (4001.726)	Data 0.001 (7.734)	Loss 1.731	Prec@1 60.1691	Prec@5 81.6727
Train: [47][7400/10010]	Time 0.555 (4109.214)	Data 0.001 (7.854)	Loss 1.731	Prec@1 60.1703	Prec@5 81.6704
Train: [47][7600/10010]	Time 0.555 (4216.573)	Data 0.001 (7.975)	Loss 1.732	Prec@1 60.1557	Prec@5 81.6586
Train: [47][7800/10010]	Time 0.554 (4324.172)	Data 0.001 (8.098)	Loss 1.732	Prec@1 60.1529	Prec@5 81.6552
Train: [47][8000/10010]	Time 0.554 (4433.358)	Data 0.001 (8.244)	Loss 1.732	Prec@1 60.1474	Prec@5 81.6570
Train: [47][8200/10010]	Time 0.554 (4546.026)	Data 0.001 (8.438)	Loss 1.733	Prec@1 60.1310	Prec@5 81.6408
Train: [47][8400/10010]	Time 0.555 (4658.692)	Data 0.001 (8.633)	Loss 1.733	Prec@1 60.1273	Prec@5 81.6378
Train: [47][8600/10010]	Time 0.555 (4771.543)	Data 0.001 (8.823)	Loss 1.733	Prec@1 60.1225	Prec@5 81.6331
Train: [47][8800/10010]	Time 0.555 (4883.270)	Data 0.001 (9.010)	Loss 1.734	Prec@1 60.1059	Prec@5 81.6198
Train: [47][9000/10010]	Time 0.555 (4994.187)	Data 0.001 (9.193)	Loss 1.734	Prec@1 60.1058	Prec@5 81.6168
Train: [47][9200/10010]	Time 0.555 (5104.740)	Data 0.001 (9.370)	Loss 1.734	Prec@1 60.1076	Prec@5 81.6133
Train: [47][9400/10010]	Time 0.555 (5215.715)	Data 0.001 (9.547)	Loss 1.735	Prec@1 60.0980	Prec@5 81.6073
Train: [47][9600/10010]	Time 0.555 (5326.786)	Data 0.001 (9.730)	Loss 1.735	Prec@1 60.0890	Prec@5 81.5993
Train: [47][9800/10010]	Time 0.555 (5437.054)	Data 0.001 (9.893)	Loss 1.736	Prec@1 60.0807	Prec@5 81.5850
Train: [47][10000/10010]	Time 0.555 (5547.887)	Data 0.001 (10.068)	Loss 1.736	Prec@1 60.0678	Prec@5 81.5827
Train: [47]	Time 5552.453	Data 10.072	Loss 1.736	Prec@1 60.0671	Prec@5 81.5821	
Val: [47]	Time 72.172	Data 1.750	Loss 1.502	Prec@1 63.3840	Prec@5 85.9160	
Best Prec@1: [63.928]	
Starting epoch number: 48 Learning rate: 0.010000000000000002
Train: [48][0/10010]	Time 1.788 (1.788)	Data 1.241 (1.241)	Loss 1.638	Prec@1 65.6250	Prec@5 82.0312
Train: [48][200/10010]	Time 0.564 (113.371)	Data 0.007 (1.432)	Loss 1.728	Prec@1 60.1796	Prec@5 81.8136
Train: [48][400/10010]	Time 0.562 (225.480)	Data 0.004 (1.618)	Loss 1.713	Prec@1 60.4719	Prec@5 81.9903
Train: [48][600/10010]	Time 0.561 (337.094)	Data 0.003 (1.805)	Loss 1.713	Prec@1 60.5280	Prec@5 81.9754
Train: [48][800/10010]	Time 0.559 (447.825)	Data 0.002 (1.976)	Loss 1.714	Prec@1 60.5132	Prec@5 81.9444
Train: [48][1000/10010]	Time 0.558 (558.556)	Data 0.002 (2.155)	Loss 1.718	Prec@1 60.4372	Prec@5 81.8915
Train: [48][1200/10010]	Time 0.557 (668.604)	Data 0.002 (2.337)	Loss 1.720	Prec@1 60.3937	Prec@5 81.8413
Train: [48][1400/10010]	Time 0.556 (779.184)	Data 0.002 (2.516)	Loss 1.720	Prec@1 60.4100	Prec@5 81.8221
Train: [48][1600/10010]	Time 0.556 (890.121)	Data 0.002 (2.697)	Loss 1.720	Prec@1 60.4432	Prec@5 81.8361
Train: [48][1800/10010]	Time 0.556 (1000.745)	Data 0.002 (2.873)	Loss 1.719	Prec@1 60.4352	Prec@5 81.8460
Train: [48][2000/10010]	Time 0.556 (1111.957)	Data 0.002 (3.053)	Loss 1.718	Prec@1 60.4432	Prec@5 81.8587
Train: [48][2200/10010]	Time 0.556 (1222.697)	Data 0.001 (3.232)	Loss 1.719	Prec@1 60.4537	Prec@5 81.8467
Train: [48][2400/10010]	Time 0.556 (1334.655)	Data 0.001 (3.420)	Loss 1.719	Prec@1 60.4715	Prec@5 81.8230
Train: [48][2600/10010]	Time 0.556 (1446.756)	Data 0.001 (3.609)	Loss 1.719	Prec@1 60.4323	Prec@5 81.8276
Train: [48][2800/10010]	Time 0.556 (1558.683)	Data 0.001 (3.799)	Loss 1.720	Prec@1 60.4142	Prec@5 81.8246
Train: [48][3000/10010]	Time 0.557 (1670.537)	Data 0.001 (3.989)	Loss 1.720	Prec@1 60.4247	Prec@5 81.8298
Train: [48][3200/10010]	Time 0.556 (1780.235)	Data 0.001 (4.156)	Loss 1.721	Prec@1 60.4037	Prec@5 81.8018
Train: [48][3400/10010]	Time 0.556 (1891.421)	Data 0.001 (4.337)	Loss 1.721	Prec@1 60.3963	Prec@5 81.8077
Train: [48][3600/10010]	Time 0.556 (2003.796)	Data 0.001 (4.525)	Loss 1.722	Prec@1 60.3600	Prec@5 81.7933
Train: [48][3800/10010]	Time 0.557 (2116.276)	Data 0.001 (4.712)	Loss 1.724	Prec@1 60.3285	Prec@5 81.7768
Train: [48][4000/10010]	Time 0.557 (2229.303)	Data 0.001 (4.900)	Loss 1.723	Prec@1 60.3419	Prec@5 81.7727
Train: [48][4200/10010]	Time 0.557 (2341.769)	Data 0.001 (5.086)	Loss 1.724	Prec@1 60.3420	Prec@5 81.7612
Train: [48][4400/10010]	Time 0.557 (2453.518)	Data 0.001 (5.267)	Loss 1.726	Prec@1 60.2995	Prec@5 81.7320
Train: [48][4600/10010]	Time 0.557 (2565.012)	Data 0.001 (5.448)	Loss 1.726	Prec@1 60.2965	Prec@5 81.7404
Train: [48][4800/10010]	Time 0.557 (2676.400)	Data 0.001 (5.634)	Loss 1.727	Prec@1 60.2912	Prec@5 81.7234
Train: [48][5000/10010]	Time 0.557 (2787.685)	Data 0.001 (5.825)	Loss 1.727	Prec@1 60.2984	Prec@5 81.7129
Train: [48][5200/10010]	Time 0.557 (2899.074)	Data 0.001 (6.011)	Loss 1.727	Prec@1 60.2901	Prec@5 81.7193
Train: [48][5400/10010]	Time 0.557 (3009.829)	Data 0.001 (6.191)	Loss 1.727	Prec@1 60.2840	Prec@5 81.7223
Train: [48][5600/10010]	Time 0.557 (3121.685)	Data 0.001 (6.378)	Loss 1.727	Prec@1 60.2888	Prec@5 81.7235
Train: [48][5800/10010]	Time 0.557 (3233.645)	Data 0.001 (6.561)	Loss 1.727	Prec@1 60.2925	Prec@5 81.7226
Train: [48][6000/10010]	Time 0.558 (3345.957)	Data 0.001 (6.749)	Loss 1.727	Prec@1 60.2870	Prec@5 81.7122
Train: [48][6200/10010]	Time 0.558 (3457.608)	Data 0.001 (6.928)	Loss 1.729	Prec@1 60.2734	Prec@5 81.6968
Train: [48][6400/10010]	Time 0.558 (3569.465)	Data 0.001 (7.111)	Loss 1.729	Prec@1 60.2606	Prec@5 81.6937
Train: [48][6600/10010]	Time 0.558 (3681.223)	Data 0.001 (7.292)	Loss 1.729	Prec@1 60.2583	Prec@5 81.6912
Train: [48][6800/10010]	Time 0.558 (3793.700)	Data 0.001 (7.479)	Loss 1.729	Prec@1 60.2469	Prec@5 81.6818
Train: [48][7000/10010]	Time 0.558 (3906.076)	Data 0.001 (7.661)	Loss 1.729	Prec@1 60.2483	Prec@5 81.6802
Train: [48][7200/10010]	Time 0.558 (4018.941)	Data 0.001 (7.848)	Loss 1.730	Prec@1 60.2377	Prec@5 81.6638
Train: [48][7400/10010]	Time 0.558 (4131.404)	Data 0.001 (8.034)	Loss 1.730	Prec@1 60.2326	Prec@5 81.6657
Train: [48][7600/10010]	Time 0.558 (4242.861)	Data 0.001 (8.213)	Loss 1.730	Prec@1 60.2215	Prec@5 81.6615
Train: [48][7800/10010]	Time 0.558 (4353.597)	Data 0.001 (8.391)	Loss 1.730	Prec@1 60.2373	Prec@5 81.6598
Train: [48][8000/10010]	Time 0.558 (4464.574)	Data 0.001 (8.572)	Loss 1.731	Prec@1 60.2243	Prec@5 81.6549
Train: [48][8200/10010]	Time 0.558 (4576.015)	Data 0.001 (8.758)	Loss 1.731	Prec@1 60.2192	Prec@5 81.6459
Train: [48][8400/10010]	Time 0.558 (4687.031)	Data 0.001 (8.940)	Loss 1.732	Prec@1 60.2090	Prec@5 81.6415
Train: [48][8600/10010]	Time 0.558 (4798.468)	Data 0.001 (9.119)	Loss 1.732	Prec@1 60.2034	Prec@5 81.6376
Train: [48][8800/10010]	Time 0.558 (4910.619)	Data 0.001 (9.303)	Loss 1.732	Prec@1 60.1948	Prec@5 81.6383
Train: [48][9000/10010]	Time 0.558 (5022.486)	Data 0.001 (9.479)	Loss 1.733	Prec@1 60.1937	Prec@5 81.6298
Train: [48][9200/10010]	Time 0.558 (5134.875)	Data 0.001 (9.659)	Loss 1.733	Prec@1 60.1818	Prec@5 81.6215
Train: [48][9400/10010]	Time 0.558 (5247.360)	Data 0.001 (9.841)	Loss 1.734	Prec@1 60.1704	Prec@5 81.6166
Train: [48][9600/10010]	Time 0.558 (5359.110)	Data 0.001 (10.023)	Loss 1.734	Prec@1 60.1707	Prec@5 81.6186
Train: [48][9800/10010]	Time 0.558 (5470.746)	Data 0.001 (10.198)	Loss 1.734	Prec@1 60.1627	Prec@5 81.6092
Train: [48][10000/10010]	Time 0.558 (5582.357)	Data 0.001 (10.389)	Loss 1.735	Prec@1 60.1498	Prec@5 81.6008
Train: [48]	Time 5586.960	Data 10.393	Loss 1.735	Prec@1 60.1503	Prec@5 81.6012	
Val: [48]	Time 73.707	Data 1.742	Loss 1.486	Prec@1 63.6780	Prec@5 86.0340	
Best Prec@1: [63.928]	
Starting epoch number: 49 Learning rate: 0.010000000000000002
Train: [49][0/10010]	Time 1.898 (1.898)	Data 1.274 (1.274)	Loss 1.824	Prec@1 61.7188	Prec@5 80.4688
Train: [49][200/10010]	Time 0.561 (112.687)	Data 0.007 (1.453)	Loss 1.733	Prec@1 60.4555	Prec@5 81.5415
Train: [49][400/10010]	Time 0.557 (223.448)	Data 0.004 (1.637)	Loss 1.728	Prec@1 60.4660	Prec@5 81.5559
Train: [49][600/10010]	Time 0.556 (334.022)	Data 0.003 (1.815)	Loss 1.719	Prec@1 60.5943	Prec@5 81.7856
Train: [49][800/10010]	Time 0.556 (445.608)	Data 0.002 (1.997)	Loss 1.717	Prec@1 60.6625	Prec@5 81.8411
Train: [49][1000/10010]	Time 0.556 (556.589)	Data 0.002 (2.179)	Loss 1.720	Prec@1 60.5598	Prec@5 81.8002
Train: [49][1200/10010]	Time 0.556 (667.586)	Data 0.002 (2.359)	Loss 1.719	Prec@1 60.5544	Prec@5 81.7795
Train: [49][1400/10010]	Time 0.556 (778.472)	Data 0.002 (2.541)	Loss 1.721	Prec@1 60.5109	Prec@5 81.7686
Train: [49][1600/10010]	Time 0.556 (889.853)	Data 0.002 (2.725)	Loss 1.720	Prec@1 60.5242	Prec@5 81.8063
Train: [49][1800/10010]	Time 0.556 (1000.693)	Data 0.002 (2.908)	Loss 1.718	Prec@1 60.5402	Prec@5 81.8642
Train: [49][2000/10010]	Time 0.556 (1111.792)	Data 0.002 (3.090)	Loss 1.717	Prec@1 60.5510	Prec@5 81.8665
Train: [49][2200/10010]	Time 0.556 (1223.340)	Data 0.001 (3.276)	Loss 1.716	Prec@1 60.5510	Prec@5 81.8662
Train: [49][2400/10010]	Time 0.556 (1335.252)	Data 0.001 (3.464)	Loss 1.716	Prec@1 60.5503	Prec@5 81.8715
Train: [49][2600/10010]	Time 0.556 (1447.354)	Data 0.001 (3.652)	Loss 1.715	Prec@1 60.5473	Prec@5 81.8871
Train: [49][2800/10010]	Time 0.556 (1558.097)	Data 0.001 (3.826)	Loss 1.715	Prec@1 60.5495	Prec@5 81.8781
Train: [49][3000/10010]	Time 0.556 (1668.819)	Data 0.001 (4.004)	Loss 1.717	Prec@1 60.5473	Prec@5 81.8480
Train: [49][3200/10010]	Time 0.557 (1781.767)	Data 0.001 (4.194)	Loss 1.717	Prec@1 60.5204	Prec@5 81.8477
Train: [49][3400/10010]	Time 0.557 (1894.568)	Data 0.001 (4.383)	Loss 1.717	Prec@1 60.5183	Prec@5 81.8498
Train: [49][3600/10010]	Time 0.557 (2007.117)	Data 0.001 (4.573)	Loss 1.719	Prec@1 60.4706	Prec@5 81.8273
Train: [49][3800/10010]	Time 0.558 (2119.815)	Data 0.001 (4.758)	Loss 1.718	Prec@1 60.4687	Prec@5 81.8335
Train: [49][4000/10010]	Time 0.558 (2231.812)	Data 0.001 (4.946)	Loss 1.720	Prec@1 60.4474	Prec@5 81.8081
Train: [49][4200/10010]	Time 0.558 (2343.984)	Data 0.001 (5.126)	Loss 1.721	Prec@1 60.4226	Prec@5 81.7947
Train: [49][4400/10010]	Time 0.558 (2456.811)	Data 0.001 (5.313)	Loss 1.721	Prec@1 60.4424	Prec@5 81.8017
Train: [49][4600/10010]	Time 0.558 (2569.311)	Data 0.001 (5.498)	Loss 1.721	Prec@1 60.4351	Prec@5 81.7927
Train: [49][4800/10010]	Time 0.559 (2682.121)	Data 0.001 (5.693)	Loss 1.722	Prec@1 60.4151	Prec@5 81.7868
Train: [49][5000/10010]	Time 0.559 (2794.389)	Data 0.001 (5.888)	Loss 1.721	Prec@1 60.4339	Prec@5 81.7850
Train: [49][5200/10010]	Time 0.559 (2905.809)	Data 0.001 (6.072)	Loss 1.722	Prec@1 60.4088	Prec@5 81.7741
Train: [49][5400/10010]	Time 0.559 (3018.208)	Data 0.001 (6.258)	Loss 1.722	Prec@1 60.3881	Prec@5 81.7697
Train: [49][5600/10010]	Time 0.559 (3130.487)	Data 0.001 (6.442)	Loss 1.723	Prec@1 60.3875	Prec@5 81.7685
Train: [49][5800/10010]	Time 0.559 (3242.568)	Data 0.001 (6.620)	Loss 1.723	Prec@1 60.3798	Prec@5 81.7663
Train: [49][6000/10010]	Time 0.558 (3350.643)	Data 0.001 (6.741)	Loss 1.724	Prec@1 60.3597	Prec@5 81.7588
Train: [49][6200/10010]	Time 0.558 (3458.497)	Data 0.001 (6.862)	Loss 1.724	Prec@1 60.3538	Prec@5 81.7572
Train: [49][6400/10010]	Time 0.557 (3566.250)	Data 0.001 (6.983)	Loss 1.724	Prec@1 60.3448	Prec@5 81.7511
Train: [49][6600/10010]	Time 0.557 (3673.959)	Data 0.001 (7.103)	Loss 1.725	Prec@1 60.3477	Prec@5 81.7458
Train: [49][6800/10010]	Time 0.556 (3781.526)	Data 0.001 (7.225)	Loss 1.725	Prec@1 60.3344	Prec@5 81.7356
Train: [49][7000/10010]	Time 0.555 (3888.987)	Data 0.001 (7.345)	Loss 1.726	Prec@1 60.3234	Prec@5 81.7265
Train: [49][7200/10010]	Time 0.555 (3996.489)	Data 0.001 (7.468)	Loss 1.726	Prec@1 60.3239	Prec@5 81.7217
Train: [49][7400/10010]	Time 0.555 (4104.163)	Data 0.001 (7.595)	Loss 1.727	Prec@1 60.3077	Prec@5 81.7033
Train: [49][7600/10010]	Time 0.554 (4211.932)	Data 0.001 (7.722)	Loss 1.727	Prec@1 60.3066	Prec@5 81.6973
Train: [49][7800/10010]	Time 0.554 (4319.661)	Data 0.001 (7.847)	Loss 1.727	Prec@1 60.3095	Prec@5 81.7023
Train: [49][8000/10010]	Time 0.554 (4429.849)	Data 0.001 (8.022)	Loss 1.728	Prec@1 60.2930	Prec@5 81.6864
Train: [49][8200/10010]	Time 0.554 (4540.863)	Data 0.001 (8.204)	Loss 1.729	Prec@1 60.2757	Prec@5 81.6693
Train: [49][8400/10010]	Time 0.554 (4651.482)	Data 0.001 (8.378)	Loss 1.729	Prec@1 60.2595	Prec@5 81.6651
Train: [49][8600/10010]	Time 0.554 (4762.398)	Data 0.001 (8.547)	Loss 1.730	Prec@1 60.2484	Prec@5 81.6522
Train: [49][8800/10010]	Time 0.554 (4872.625)	Data 0.001 (8.710)	Loss 1.730	Prec@1 60.2369	Prec@5 81.6453
Train: [49][9000/10010]	Time 0.554 (4984.285)	Data 0.001 (8.885)	Loss 1.731	Prec@1 60.2312	Prec@5 81.6506
Train: [49][9200/10010]	Time 0.554 (5096.583)	Data 0.001 (9.068)	Loss 1.731	Prec@1 60.2256	Prec@5 81.6474
Train: [49][9400/10010]	Time 0.554 (5209.078)	Data 0.001 (9.250)	Loss 1.730	Prec@1 60.2292	Prec@5 81.6559
Train: [49][9600/10010]	Time 0.554 (5321.330)	Data 0.001 (9.431)	Loss 1.731	Prec@1 60.2136	Prec@5 81.6476
Train: [49][9800/10010]	Time 0.554 (5432.777)	Data 0.001 (9.612)	Loss 1.731	Prec@1 60.2060	Prec@5 81.6474
Train: [49][10000/10010]	Time 0.554 (5544.027)	Data 0.001 (9.791)	Loss 1.731	Prec@1 60.2098	Prec@5 81.6466
Train: [49]	Time 5548.647	Data 9.795	Loss 1.731	Prec@1 60.2085	Prec@5 81.6462	
Val: [49]	Time 74.248	Data 1.752	Loss 1.503	Prec@1 63.5560	Prec@5 85.8460	
Best Prec@1: [63.928]	
Starting epoch number: 50 Learning rate: 0.010000000000000002
Train: [50][0/10010]	Time 1.960 (1.960)	Data 1.291 (1.291)	Loss 1.836	Prec@1 59.3750	Prec@5 79.6875
Train: [50][200/10010]	Time 0.566 (113.739)	Data 0.007 (1.476)	Loss 1.704	Prec@1 60.5255	Prec@5 82.1673
Train: [50][400/10010]	Time 0.563 (225.583)	Data 0.004 (1.670)	Loss 1.703	Prec@1 60.8284	Prec@5 82.0624
Train: [50][600/10010]	Time 0.561 (337.197)	Data 0.003 (1.859)	Loss 1.701	Prec@1 60.8881	Prec@5 82.0312
Train: [50][800/10010]	Time 0.559 (447.718)	Data 0.003 (2.042)	Loss 1.705	Prec@1 60.8458	Prec@5 81.9903
Train: [50][1000/10010]	Time 0.559 (559.231)	Data 0.002 (2.226)	Loss 1.704	Prec@1 60.8275	Prec@5 82.0336
Train: [50][1200/10010]	Time 0.559 (671.166)	Data 0.002 (2.416)	Loss 1.700	Prec@1 60.9206	Prec@5 82.0826
Train: [50][1400/10010]	Time 0.559 (783.005)	Data 0.002 (2.605)	Loss 1.699	Prec@1 60.9447	Prec@5 82.0625
Train: [50][1600/10010]	Time 0.559 (894.752)	Data 0.002 (2.791)	Loss 1.702	Prec@1 60.8643	Prec@5 81.9981
Train: [50][1800/10010]	Time 0.558 (1005.374)	Data 0.002 (2.965)	Loss 1.705	Prec@1 60.8126	Prec@5 81.9614
Train: [50][2000/10010]	Time 0.558 (1115.656)	Data 0.002 (3.141)	Loss 1.705	Prec@1 60.8059	Prec@5 81.9629
Train: [50][2200/10010]	Time 0.558 (1227.777)	Data 0.002 (3.330)	Loss 1.708	Prec@1 60.7689	Prec@5 81.9425
Train: [50][2400/10010]	Time 0.558 (1340.004)	Data 0.001 (3.525)	Loss 1.710	Prec@1 60.7263	Prec@5 81.9213
Train: [50][2600/10010]	Time 0.558 (1452.013)	Data 0.001 (3.710)	Loss 1.711	Prec@1 60.7032	Prec@5 81.9036
Train: [50][2800/10010]	Time 0.558 (1563.491)	Data 0.001 (3.899)	Loss 1.711	Prec@1 60.6976	Prec@5 81.8971
Train: [50][3000/10010]	Time 0.558 (1674.118)	Data 0.001 (4.081)	Loss 1.710	Prec@1 60.7178	Prec@5 81.9125
Train: [50][3200/10010]	Time 0.558 (1785.676)	Data 0.001 (4.262)	Loss 1.710	Prec@1 60.7076	Prec@5 81.9102
Train: [50][3400/10010]	Time 0.558 (1897.348)	Data 0.001 (4.453)	Loss 1.711	Prec@1 60.6938	Prec@5 81.9058
Train: [50][3600/10010]	Time 0.558 (2009.531)	Data 0.001 (4.644)	Loss 1.711	Prec@1 60.6542	Prec@5 81.9134
Train: [50][3800/10010]	Time 0.558 (2120.983)	Data 0.001 (4.830)	Loss 1.713	Prec@1 60.6366	Prec@5 81.8956
Train: [50][4000/10010]	Time 0.558 (2231.173)	Data 0.001 (5.006)	Loss 1.713	Prec@1 60.6307	Prec@5 81.8963
Train: [50][4200/10010]	Time 0.558 (2342.424)	Data 0.001 (5.187)	Loss 1.713	Prec@1 60.6420	Prec@5 81.8899
Train: [50][4400/10010]	Time 0.558 (2454.219)	Data 0.001 (5.376)	Loss 1.713	Prec@1 60.6224	Prec@5 81.8850
Train: [50][4600/10010]	Time 0.558 (2566.171)	Data 0.001 (5.569)	Loss 1.714	Prec@1 60.5979	Prec@5 81.8761
Train: [50][4800/10010]	Time 0.558 (2677.891)	Data 0.001 (5.755)	Loss 1.715	Prec@1 60.5714	Prec@5 81.8812
Train: [50][5000/10010]	Time 0.558 (2789.359)	Data 0.001 (5.943)	Loss 1.715	Prec@1 60.5721	Prec@5 81.8777
Train: [50][5200/10010]	Time 0.558 (2900.922)	Data 0.001 (6.129)	Loss 1.716	Prec@1 60.5515	Prec@5 81.8722
Train: [50][5400/10010]	Time 0.558 (3011.876)	Data 0.001 (6.311)	Loss 1.716	Prec@1 60.5663	Prec@5 81.8705
Train: [50][5600/10010]	Time 0.558 (3123.100)	Data 0.001 (6.493)	Loss 1.716	Prec@1 60.5493	Prec@5 81.8633
Train: [50][5800/10010]	Time 0.558 (3234.092)	Data 0.001 (6.674)	Loss 1.716	Prec@1 60.5385	Prec@5 81.8601
Train: [50][6000/10010]	Time 0.557 (3344.552)	Data 0.001 (6.853)	Loss 1.717	Prec@1 60.5426	Prec@5 81.8573
Train: [50][6200/10010]	Time 0.557 (3454.518)	Data 0.001 (7.028)	Loss 1.718	Prec@1 60.5355	Prec@5 81.8472
Train: [50][6400/10010]	Time 0.557 (3566.402)	Data 0.001 (7.213)	Loss 1.718	Prec@1 60.5071	Prec@5 81.8415
Train: [50][6600/10010]	Time 0.557 (3678.509)	Data 0.001 (7.401)	Loss 1.719	Prec@1 60.4816	Prec@5 81.8282
Train: [50][6800/10010]	Time 0.557 (3790.194)	Data 0.001 (7.589)	Loss 1.720	Prec@1 60.4600	Prec@5 81.8197
Train: [50][7000/10010]	Time 0.557 (3901.744)	Data 0.001 (7.776)	Loss 1.721	Prec@1 60.4549	Prec@5 81.8087
Train: [50][7200/10010]	Time 0.557 (4012.495)	Data 0.001 (7.960)	Loss 1.721	Prec@1 60.4428	Prec@5 81.8032
Train: [50][7400/10010]	Time 0.557 (4123.477)	Data 0.001 (8.140)	Loss 1.721	Prec@1 60.4381	Prec@5 81.8011
Train: [50][7600/10010]	Time 0.557 (4234.266)	Data 0.001 (8.319)	Loss 1.722	Prec@1 60.4322	Prec@5 81.7946
Train: [50][7800/10010]	Time 0.557 (4345.340)	Data 0.001 (8.502)	Loss 1.722	Prec@1 60.4185	Prec@5 81.7909
Train: [50][8000/10010]	Time 0.557 (4456.351)	Data 0.001 (8.682)	Loss 1.722	Prec@1 60.4205	Prec@5 81.7880
Train: [50][8200/10010]	Time 0.557 (4567.494)	Data 0.001 (8.865)	Loss 1.724	Prec@1 60.3883	Prec@5 81.7650
Train: [50][8400/10010]	Time 0.557 (4678.463)	Data 0.001 (9.050)	Loss 1.724	Prec@1 60.3812	Prec@5 81.7618
Train: [50][8600/10010]	Time 0.557 (4790.986)	Data 0.001 (9.244)	Loss 1.725	Prec@1 60.3600	Prec@5 81.7554
Train: [50][8800/10010]	Time 0.557 (4903.707)	Data 0.001 (9.435)	Loss 1.725	Prec@1 60.3584	Prec@5 81.7491
Train: [50][9000/10010]	Time 0.557 (5016.420)	Data 0.001 (9.626)	Loss 1.725	Prec@1 60.3549	Prec@5 81.7498
Train: [50][9200/10010]	Time 0.557 (5128.801)	Data 0.001 (9.817)	Loss 1.725	Prec@1 60.3541	Prec@5 81.7478
Train: [50][9400/10010]	Time 0.557 (5239.465)	Data 0.001 (9.997)	Loss 1.725	Prec@1 60.3545	Prec@5 81.7422
Train: [50][9600/10010]	Time 0.557 (5350.475)	Data 0.001 (10.183)	Loss 1.725	Prec@1 60.3451	Prec@5 81.7355
Train: [50][9800/10010]	Time 0.557 (5462.827)	Data 0.001 (10.374)	Loss 1.726	Prec@1 60.3431	Prec@5 81.7315
Train: [50][10000/10010]	Time 0.557 (5574.746)	Data 0.001 (10.558)	Loss 1.726	Prec@1 60.3384	Prec@5 81.7283
Train: [50]	Time 5579.376	Data 10.562	Loss 1.726	Prec@1 60.3371	Prec@5 81.7280	
Val: [50]	Time 74.102	Data 1.722	Loss 2.421	Prec@1 47.8500	Prec@5 72.9620	
Best Prec@1: [63.928]	
Starting epoch number: 51 Learning rate: 0.010000000000000002
Train: [51][0/10010]	Time 1.957 (1.957)	Data 1.385 (1.385)	Loss 1.663	Prec@1 58.5938	Prec@5 81.2500
Train: [51][200/10010]	Time 0.560 (112.632)	Data 0.008 (1.573)	Loss 1.766	Prec@1 59.5655	Prec@5 81.3472
Train: [51][400/10010]	Time 0.556 (222.860)	Data 0.004 (1.756)	Loss 1.731	Prec@1 60.1718	Prec@5 81.8033
Train: [51][600/10010]	Time 0.555 (333.426)	Data 0.003 (1.940)	Loss 1.723	Prec@1 60.3512	Prec@5 81.9156
Train: [51][800/10010]	Time 0.555 (444.392)	Data 0.003 (2.130)	Loss 1.711	Prec@1 60.5649	Prec@5 82.0907
Train: [51][1000/10010]	Time 0.555 (555.642)	Data 0.002 (2.319)	Loss 1.713	Prec@1 60.5457	Prec@5 82.0195
Train: [51][1200/10010]	Time 0.555 (666.888)	Data 0.002 (2.508)	Loss 1.714	Prec@1 60.5290	Prec@5 81.9727
Train: [51][1400/10010]	Time 0.555 (776.883)	Data 0.002 (2.684)	Loss 1.715	Prec@1 60.5154	Prec@5 81.9487
Train: [51][1600/10010]	Time 0.554 (887.226)	Data 0.002 (2.860)	Loss 1.714	Prec@1 60.5276	Prec@5 81.9629
Train: [51][1800/10010]	Time 0.555 (998.830)	Data 0.002 (3.048)	Loss 1.715	Prec@1 60.4482	Prec@5 81.9454
Train: [51][2000/10010]	Time 0.555 (1110.128)	Data 0.002 (3.232)	Loss 1.712	Prec@1 60.4748	Prec@5 81.9551
Train: [51][2200/10010]	Time 0.555 (1221.614)	Data 0.002 (3.422)	Loss 1.714	Prec@1 60.4814	Prec@5 81.9113
Train: [51][2400/10010]	Time 0.555 (1333.273)	Data 0.002 (3.604)	Loss 1.716	Prec@1 60.4413	Prec@5 81.8917
Train: [51][2600/10010]	Time 0.555 (1444.757)	Data 0.001 (3.786)	Loss 1.718	Prec@1 60.4293	Prec@5 81.8760
Train: [51][2800/10010]	Time 0.556 (1557.409)	Data 0.001 (3.973)	Loss 1.717	Prec@1 60.4533	Prec@5 81.8912
Train: [51][3000/10010]	Time 0.556 (1669.406)	Data 0.001 (4.158)	Loss 1.718	Prec@1 60.4273	Prec@5 81.8813
Train: [51][3200/10010]	Time 0.557 (1781.796)	Data 0.001 (4.348)	Loss 1.719	Prec@1 60.4247	Prec@5 81.8545
Train: [51][3400/10010]	Time 0.557 (1893.260)	Data 0.001 (4.530)	Loss 1.719	Prec@1 60.4574	Prec@5 81.8486
Train: [51][3600/10010]	Time 0.556 (2003.197)	Data 0.001 (4.709)	Loss 1.719	Prec@1 60.4658	Prec@5 81.8505
Train: [51][3800/10010]	Time 0.556 (2113.800)	Data 0.001 (4.889)	Loss 1.719	Prec@1 60.4590	Prec@5 81.8475
Train: [51][4000/10010]	Time 0.556 (2224.817)	Data 0.001 (5.070)	Loss 1.720	Prec@1 60.4445	Prec@5 81.8317
Train: [51][4200/10010]	Time 0.556 (2335.817)	Data 0.001 (5.255)	Loss 1.720	Prec@1 60.4359	Prec@5 81.8226
Train: [51][4400/10010]	Time 0.556 (2447.025)	Data 0.001 (5.439)	Loss 1.720	Prec@1 60.4225	Prec@5 81.8227
Train: [51][4600/10010]	Time 0.556 (2557.661)	Data 0.001 (5.615)	Loss 1.720	Prec@1 60.4128	Prec@5 81.8061
Train: [51][4800/10010]	Time 0.556 (2668.795)	Data 0.001 (5.797)	Loss 1.721	Prec@1 60.4067	Prec@5 81.8034
Train: [51][5000/10010]	Time 0.556 (2778.875)	Data 0.001 (5.953)	Loss 1.720	Prec@1 60.4159	Prec@5 81.8164
Train: [51][5200/10010]	Time 0.555 (2886.693)	Data 0.001 (6.078)	Loss 1.721	Prec@1 60.4045	Prec@5 81.8073
Train: [51][5400/10010]	Time 0.554 (2994.590)	Data 0.001 (6.206)	Loss 1.721	Prec@1 60.3987	Prec@5 81.8068
Train: [51][5600/10010]	Time 0.554 (3104.859)	Data 0.001 (6.381)	Loss 1.721	Prec@1 60.3962	Prec@5 81.8131
Train: [51][5800/10010]	Time 0.554 (3215.520)	Data 0.001 (6.564)	Loss 1.721	Prec@1 60.3945	Prec@5 81.8059
Train: [51][6000/10010]	Time 0.554 (3326.573)	Data 0.001 (6.743)	Loss 1.721	Prec@1 60.3785	Prec@5 81.8009
Train: [51][6200/10010]	Time 0.554 (3437.625)	Data 0.001 (6.921)	Loss 1.722	Prec@1 60.3509	Prec@5 81.7819
Train: [51][6400/10010]	Time 0.554 (3548.787)	Data 0.001 (7.105)	Loss 1.723	Prec@1 60.3333	Prec@5 81.7697
Train: [51][6600/10010]	Time 0.554 (3660.248)	Data 0.001 (7.294)	Loss 1.723	Prec@1 60.3321	Prec@5 81.7756
Train: [51][6800/10010]	Time 0.555 (3771.529)	Data 0.001 (7.477)	Loss 1.723	Prec@1 60.3214	Prec@5 81.7700
Train: [51][7000/10010]	Time 0.555 (3883.267)	Data 0.001 (7.662)	Loss 1.723	Prec@1 60.3211	Prec@5 81.7681
Train: [51][7200/10010]	Time 0.555 (3994.816)	Data 0.001 (7.849)	Loss 1.723	Prec@1 60.3250	Prec@5 81.7761
Train: [51][7400/10010]	Time 0.555 (4105.946)	Data 0.001 (8.032)	Loss 1.724	Prec@1 60.3066	Prec@5 81.7672
Train: [51][7600/10010]	Time 0.555 (4215.908)	Data 0.001 (8.205)	Loss 1.725	Prec@1 60.2971	Prec@5 81.7610
Train: [51][7800/10010]	Time 0.555 (4326.813)	Data 0.001 (8.384)	Loss 1.725	Prec@1 60.2934	Prec@5 81.7536
Train: [51][8000/10010]	Time 0.555 (4438.638)	Data 0.001 (8.574)	Loss 1.726	Prec@1 60.2863	Prec@5 81.7435
Train: [51][8200/10010]	Time 0.555 (4550.588)	Data 0.001 (8.765)	Loss 1.727	Prec@1 60.2684	Prec@5 81.7247
Train: [51][8400/10010]	Time 0.555 (4662.285)	Data 0.001 (8.951)	Loss 1.727	Prec@1 60.2679	Prec@5 81.7198
Train: [51][8600/10010]	Time 0.555 (4772.477)	Data 0.001 (9.125)	Loss 1.727	Prec@1 60.2700	Prec@5 81.7162
Train: [51][8800/10010]	Time 0.555 (4883.526)	Data 0.001 (9.303)	Loss 1.727	Prec@1 60.2721	Prec@5 81.7117
Train: [51][9000/10010]	Time 0.555 (4995.491)	Data 0.001 (9.484)	Loss 1.728	Prec@1 60.2650	Prec@5 81.7092
Train: [51][9200/10010]	Time 0.555 (5107.388)	Data 0.001 (9.662)	Loss 1.728	Prec@1 60.2572	Prec@5 81.7087
Train: [51][9400/10010]	Time 0.555 (5219.900)	Data 0.001 (9.846)	Loss 1.728	Prec@1 60.2560	Prec@5 81.6980
Train: [51][9600/10010]	Time 0.555 (5331.821)	Data 0.001 (10.028)	Loss 1.729	Prec@1 60.2474	Prec@5 81.6896
Train: [51][9800/10010]	Time 0.555 (5442.799)	Data 0.001 (10.208)	Loss 1.729	Prec@1 60.2449	Prec@5 81.6846
Train: [51][10000/10010]	Time 0.555 (5553.793)	Data 0.001 (10.388)	Loss 1.729	Prec@1 60.2465	Prec@5 81.6884
Train: [51]	Time 5558.403	Data 10.392	Loss 1.729	Prec@1 60.2452	Prec@5 81.6876	
Val: [51]	Time 72.529	Data 1.641	Loss 1.511	Prec@1 63.4340	Prec@5 85.8280	
Best Prec@1: [63.928]	
Starting epoch number: 52 Learning rate: 0.010000000000000002
Train: [52][0/10010]	Time 1.943 (1.943)	Data 1.365 (1.365)	Loss 2.082	Prec@1 52.3438	Prec@5 72.6562
Train: [52][200/10010]	Time 0.559 (112.378)	Data 0.008 (1.548)	Loss 1.732	Prec@1 60.4128	Prec@5 81.6270
Train: [52][400/10010]	Time 0.557 (223.352)	Data 0.004 (1.730)	Loss 1.710	Prec@1 60.8401	Prec@5 81.9397
Train: [52][600/10010]	Time 0.556 (333.945)	Data 0.003 (1.905)	Loss 1.709	Prec@1 60.7490	Prec@5 81.9403
Train: [52][800/10010]	Time 0.555 (444.784)	Data 0.003 (2.084)	Loss 1.703	Prec@1 60.8565	Prec@5 82.0410
Train: [52][1000/10010]	Time 0.555 (556.011)	Data 0.002 (2.269)	Loss 1.703	Prec@1 60.8548	Prec@5 82.0570
Train: [52][1200/10010]	Time 0.556 (667.309)	Data 0.002 (2.454)	Loss 1.706	Prec@1 60.8041	Prec@5 81.9935
Train: [52][1400/10010]	Time 0.556 (778.863)	Data 0.002 (2.642)	Loss 1.707	Prec@1 60.7524	Prec@5 81.9917
Train: [52][1600/10010]	Time 0.556 (889.569)	Data 0.002 (2.820)	Loss 1.707	Prec@1 60.7243	Prec@5 82.0000
Train: [52][1800/10010]	Time 0.555 (1000.185)	Data 0.002 (3.001)	Loss 1.706	Prec@1 60.7128	Prec@5 82.0187
Train: [52][2000/10010]	Time 0.556 (1111.627)	Data 0.002 (3.189)	Loss 1.706	Prec@1 60.7224	Prec@5 82.0324
Train: [52][2200/10010]	Time 0.555 (1222.529)	Data 0.002 (3.376)	Loss 1.706	Prec@1 60.7100	Prec@5 82.0199
Train: [52][2400/10010]	Time 0.556 (1334.262)	Data 0.001 (3.571)	Loss 1.708	Prec@1 60.6700	Prec@5 81.9984
Train: [52][2600/10010]	Time 0.556 (1445.518)	Data 0.001 (3.753)	Loss 1.708	Prec@1 60.6579	Prec@5 81.9943
Train: [52][2800/10010]	Time 0.556 (1556.992)	Data 0.001 (3.939)	Loss 1.708	Prec@1 60.6848	Prec@5 82.0028
Train: [52][3000/10010]	Time 0.556 (1668.990)	Data 0.001 (4.129)	Loss 1.708	Prec@1 60.6582	Prec@5 82.0050
Train: [52][3200/10010]	Time 0.556 (1781.011)	Data 0.001 (4.321)	Loss 1.707	Prec@1 60.6778	Prec@5 82.0032
Train: [52][3400/10010]	Time 0.557 (1893.368)	Data 0.001 (4.510)	Loss 1.709	Prec@1 60.6370	Prec@5 81.9800
Train: [52][3600/10010]	Time 0.557 (2005.305)	Data 0.001 (4.698)	Loss 1.708	Prec@1 60.6435	Prec@5 81.9781
Train: [52][3800/10010]	Time 0.557 (2117.414)	Data 0.001 (4.888)	Loss 1.709	Prec@1 60.6210	Prec@5 81.9490
Train: [52][4000/10010]	Time 0.557 (2229.225)	Data 0.001 (5.081)	Loss 1.710	Prec@1 60.6128	Prec@5 81.9358
Train: [52][4200/10010]	Time 0.557 (2340.514)	Data 0.001 (5.269)	Loss 1.712	Prec@1 60.5968	Prec@5 81.9160
Train: [52][4400/10010]	Time 0.557 (2452.127)	Data 0.001 (5.466)	Loss 1.711	Prec@1 60.5947	Prec@5 81.9198
Train: [52][4600/10010]	Time 0.557 (2563.546)	Data 0.001 (5.652)	Loss 1.712	Prec@1 60.5881	Prec@5 81.9137
Train: [52][4800/10010]	Time 0.557 (2675.458)	Data 0.001 (5.842)	Loss 1.712	Prec@1 60.5784	Prec@5 81.9195
Train: [52][5000/10010]	Time 0.557 (2786.998)	Data 0.001 (6.025)	Loss 1.712	Prec@1 60.5863	Prec@5 81.9091
Train: [52][5200/10010]	Time 0.557 (2898.170)	Data 0.001 (6.210)	Loss 1.712	Prec@1 60.5938	Prec@5 81.9060
Train: [52][5400/10010]	Time 0.557 (3009.790)	Data 0.001 (6.399)	Loss 1.712	Prec@1 60.6054	Prec@5 81.8944
Train: [52][5600/10010]	Time 0.557 (3120.931)	Data 0.001 (6.581)	Loss 1.712	Prec@1 60.6012	Prec@5 81.8966
Train: [52][5800/10010]	Time 0.557 (3232.286)	Data 0.001 (6.764)	Loss 1.713	Prec@1 60.5782	Prec@5 81.8773
Train: [52][6000/10010]	Time 0.557 (3343.647)	Data 0.001 (6.950)	Loss 1.715	Prec@1 60.5356	Prec@5 81.8610
Train: [52][6200/10010]	Time 0.557 (3455.585)	Data 0.001 (7.139)	Loss 1.716	Prec@1 60.5273	Prec@5 81.8609
Train: [52][6400/10010]	Time 0.557 (3568.018)	Data 0.001 (7.331)	Loss 1.716	Prec@1 60.5248	Prec@5 81.8616
Train: [52][6600/10010]	Time 0.558 (3680.303)	Data 0.001 (7.522)	Loss 1.716	Prec@1 60.5136	Prec@5 81.8688
Train: [52][6800/10010]	Time 0.558 (3792.859)	Data 0.001 (7.713)	Loss 1.717	Prec@1 60.5017	Prec@5 81.8609
Train: [52][7000/10010]	Time 0.558 (3903.413)	Data 0.001 (7.891)	Loss 1.717	Prec@1 60.5084	Prec@5 81.8626
Train: [52][7200/10010]	Time 0.557 (4013.992)	Data 0.001 (8.068)	Loss 1.718	Prec@1 60.4914	Prec@5 81.8547
Train: [52][7400/10010]	Time 0.557 (4125.479)	Data 0.001 (8.257)	Loss 1.718	Prec@1 60.4862	Prec@5 81.8399
Train: [52][7600/10010]	Time 0.557 (4236.589)	Data 0.001 (8.441)	Loss 1.719	Prec@1 60.4812	Prec@5 81.8293
Train: [52][7800/10010]	Time 0.557 (4347.811)	Data 0.001 (8.629)	Loss 1.719	Prec@1 60.4877	Prec@5 81.8381
Train: [52][8000/10010]	Time 0.557 (4458.798)	Data 0.001 (8.812)	Loss 1.719	Prec@1 60.4852	Prec@5 81.8386
Train: [52][8200/10010]	Time 0.557 (4569.954)	Data 0.001 (8.997)	Loss 1.719	Prec@1 60.4921	Prec@5 81.8453
Train: [52][8400/10010]	Time 0.557 (4681.255)	Data 0.001 (9.182)	Loss 1.719	Prec@1 60.4822	Prec@5 81.8390
Train: [52][8600/10010]	Time 0.557 (4792.731)	Data 0.001 (9.366)	Loss 1.720	Prec@1 60.4537	Prec@5 81.8268
Train: [52][8800/10010]	Time 0.557 (4904.194)	Data 0.001 (9.552)	Loss 1.721	Prec@1 60.4354	Prec@5 81.8113
Train: [52][9000/10010]	Time 0.557 (5015.523)	Data 0.001 (9.734)	Loss 1.721	Prec@1 60.4374	Prec@5 81.8104
Train: [52][9200/10010]	Time 0.557 (5125.726)	Data 0.001 (9.904)	Loss 1.721	Prec@1 60.4342	Prec@5 81.8106
Train: [52][9400/10010]	Time 0.557 (5236.479)	Data 0.001 (10.082)	Loss 1.721	Prec@1 60.4229	Prec@5 81.8182
Train: [52][9600/10010]	Time 0.557 (5347.743)	Data 0.001 (10.269)	Loss 1.722	Prec@1 60.4042	Prec@5 81.8015
Train: [52][9800/10010]	Time 0.557 (5459.218)	Data 0.001 (10.461)	Loss 1.723	Prec@1 60.3986	Prec@5 81.7918
Train: [52][10000/10010]	Time 0.557 (5570.591)	Data 0.001 (10.643)	Loss 1.723	Prec@1 60.3919	Prec@5 81.7899
Train: [52]	Time 5575.163	Data 10.648	Loss 1.723	Prec@1 60.3917	Prec@5 81.7891	
Val: [52]	Time 70.978	Data 1.448	Loss 1.521	Prec@1 63.2280	Prec@5 85.6660	
Best Prec@1: [63.928]	
Starting epoch number: 53 Learning rate: 0.010000000000000002
Train: [53][0/10010]	Time 2.145 (2.145)	Data 1.589 (1.589)	Loss 1.793	Prec@1 64.0625	Prec@5 82.8125
Train: [53][200/10010]	Time 0.556 (111.709)	Data 0.009 (1.765)	Loss 1.730	Prec@1 60.3856	Prec@5 81.8330
Train: [53][400/10010]	Time 0.558 (223.598)	Data 0.005 (1.956)	Loss 1.713	Prec@1 60.6336	Prec@5 82.0040
Train: [53][600/10010]	Time 0.559 (335.800)	Data 0.004 (2.139)	Loss 1.710	Prec@1 60.7282	Prec@5 82.0559
Train: [53][800/10010]	Time 0.559 (447.844)	Data 0.003 (2.327)	Loss 1.709	Prec@1 60.7376	Prec@5 81.9952
Train: [53][1000/10010]	Time 0.559 (559.933)	Data 0.003 (2.521)	Loss 1.708	Prec@1 60.8657	Prec@5 81.9961
Train: [53][1200/10010]	Time 0.559 (671.218)	Data 0.002 (2.709)	Loss 1.705	Prec@1 60.9147	Prec@5 82.0163
Train: [53][1400/10010]	Time 0.558 (781.828)	Data 0.002 (2.889)	Loss 1.706	Prec@1 60.9130	Prec@5 82.0156
Train: [53][1600/10010]	Time 0.557 (892.489)	Data 0.002 (3.066)	Loss 1.706	Prec@1 60.8746	Prec@5 82.0117
Train: [53][1800/10010]	Time 0.557 (1003.358)	Data 0.002 (3.247)	Loss 1.706	Prec@1 60.8729	Prec@5 82.0195
Train: [53][2000/10010]	Time 0.557 (1114.109)	Data 0.002 (3.427)	Loss 1.705	Prec@1 60.8762	Prec@5 82.0516
Train: [53][2200/10010]	Time 0.556 (1224.609)	Data 0.002 (3.608)	Loss 1.706	Prec@1 60.8683	Prec@5 82.0181
Train: [53][2400/10010]	Time 0.556 (1335.120)	Data 0.002 (3.786)	Loss 1.705	Prec@1 60.8718	Prec@5 82.0179
Train: [53][2600/10010]	Time 0.556 (1446.720)	Data 0.002 (3.978)	Loss 1.706	Prec@1 60.8498	Prec@5 82.0141
Train: [53][2800/10010]	Time 0.557 (1558.904)	Data 0.001 (4.172)	Loss 1.707	Prec@1 60.8363	Prec@5 81.9827
Train: [53][3000/10010]	Time 0.557 (1670.927)	Data 0.001 (4.362)	Loss 1.706	Prec@1 60.8302	Prec@5 81.9906
Train: [53][3200/10010]	Time 0.557 (1783.138)	Data 0.001 (4.546)	Loss 1.706	Prec@1 60.8360	Prec@5 82.0012
Train: [53][3400/10010]	Time 0.557 (1894.443)	Data 0.001 (4.729)	Loss 1.707	Prec@1 60.8015	Prec@5 81.9929
Train: [53][3600/10010]	Time 0.557 (2006.007)	Data 0.001 (4.913)	Loss 1.707	Prec@1 60.7887	Prec@5 81.9922
Train: [53][3800/10010]	Time 0.557 (2118.470)	Data 0.001 (5.101)	Loss 1.708	Prec@1 60.7926	Prec@5 81.9924
Train: [53][4000/10010]	Time 0.558 (2230.599)	Data 0.001 (5.288)	Loss 1.709	Prec@1 60.7612	Prec@5 81.9885
Train: [53][4200/10010]	Time 0.558 (2342.875)	Data 0.001 (5.482)	Loss 1.709	Prec@1 60.7567	Prec@5 81.9894
Train: [53][4400/10010]	Time 0.558 (2454.386)	Data 0.001 (5.670)	Loss 1.709	Prec@1 60.7486	Prec@5 81.9970
Train: [53][4600/10010]	Time 0.558 (2565.603)	Data 0.001 (5.853)	Loss 1.710	Prec@1 60.7163	Prec@5 81.9767
Train: [53][4800/10010]	Time 0.558 (2677.253)	Data 0.001 (6.043)	Loss 1.710	Prec@1 60.6934	Prec@5 81.9632
Train: [53][5000/10010]	Time 0.558 (2789.019)	Data 0.001 (6.227)	Loss 1.711	Prec@1 60.6871	Prec@5 81.9563
Train: [53][5200/10010]	Time 0.558 (2900.979)	Data 0.001 (6.420)	Loss 1.711	Prec@1 60.6862	Prec@5 81.9570
Train: [53][5400/10010]	Time 0.558 (3012.193)	Data 0.001 (6.606)	Loss 1.711	Prec@1 60.6660	Prec@5 81.9644
Train: [53][5600/10010]	Time 0.558 (3122.668)	Data 0.001 (6.787)	Loss 1.711	Prec@1 60.6569	Prec@5 81.9565
Train: [53][5800/10010]	Time 0.557 (3233.899)	Data 0.001 (6.971)	Loss 1.711	Prec@1 60.6525	Prec@5 81.9488
Train: [53][6000/10010]	Time 0.557 (3345.337)	Data 0.001 (7.159)	Loss 1.711	Prec@1 60.6532	Prec@5 81.9442
Train: [53][6200/10010]	Time 0.557 (3456.580)	Data 0.001 (7.342)	Loss 1.712	Prec@1 60.6326	Prec@5 81.9331
Train: [53][6400/10010]	Time 0.557 (3567.667)	Data 0.001 (7.524)	Loss 1.713	Prec@1 60.6276	Prec@5 81.9336
Train: [53][6600/10010]	Time 0.557 (3678.132)	Data 0.001 (7.704)	Loss 1.714	Prec@1 60.6094	Prec@5 81.9188
Train: [53][6800/10010]	Time 0.557 (3789.641)	Data 0.001 (7.892)	Loss 1.714	Prec@1 60.5984	Prec@5 81.9174
Train: [53][7000/10010]	Time 0.557 (3901.603)	Data 0.001 (8.081)	Loss 1.714	Prec@1 60.5905	Prec@5 81.9130
Train: [53][7200/10010]	Time 0.557 (4013.627)	Data 0.001 (8.271)	Loss 1.715	Prec@1 60.5673	Prec@5 81.9087
Train: [53][7400/10010]	Time 0.557 (4125.331)	Data 0.001 (8.463)	Loss 1.715	Prec@1 60.5650	Prec@5 81.9023
Train: [53][7600/10010]	Time 0.557 (4236.700)	Data 0.001 (8.649)	Loss 1.716	Prec@1 60.5506	Prec@5 81.8886
Train: [53][7800/10010]	Time 0.557 (4347.910)	Data 0.001 (8.835)	Loss 1.716	Prec@1 60.5362	Prec@5 81.8803
Train: [53][8000/10010]	Time 0.557 (4459.764)	Data 0.001 (9.025)	Loss 1.717	Prec@1 60.5174	Prec@5 81.8684
Train: [53][8200/10010]	Time 0.557 (4571.756)	Data 0.001 (9.218)	Loss 1.717	Prec@1 60.5003	Prec@5 81.8644
Train: [53][8400/10010]	Time 0.557 (4683.449)	Data 0.001 (9.408)	Loss 1.717	Prec@1 60.4993	Prec@5 81.8663
Train: [53][8600/10010]	Time 0.557 (4793.927)	Data 0.001 (9.588)	Loss 1.718	Prec@1 60.4931	Prec@5 81.8618
Train: [53][8800/10010]	Time 0.557 (4903.692)	Data 0.001 (9.768)	Loss 1.718	Prec@1 60.4982	Prec@5 81.8630
Train: [53][9000/10010]	Time 0.557 (5014.095)	Data 0.001 (9.952)	Loss 1.718	Prec@1 60.4951	Prec@5 81.8610
Train: [53][9200/10010]	Time 0.557 (5124.747)	Data 0.001 (10.134)	Loss 1.718	Prec@1 60.4839	Prec@5 81.8540
Train: [53][9400/10010]	Time 0.557 (5235.389)	Data 0.001 (10.315)	Loss 1.719	Prec@1 60.4686	Prec@5 81.8434
Train: [53][9600/10010]	Time 0.557 (5346.390)	Data 0.001 (10.496)	Loss 1.719	Prec@1 60.4619	Prec@5 81.8318
Train: [53][9800/10010]	Time 0.557 (5457.736)	Data 0.001 (10.680)	Loss 1.719	Prec@1 60.4668	Prec@5 81.8383
Train: [53][10000/10010]	Time 0.557 (5569.675)	Data 0.001 (10.860)	Loss 1.719	Prec@1 60.4619	Prec@5 81.8312
Train: [53]	Time 5574.348	Data 10.865	Loss 1.719	Prec@1 60.4609	Prec@5 81.8293	
Val: [53]	Time 74.064	Data 1.716	Loss 1.474	Prec@1 64.2040	Prec@5 86.1960	
Best Prec@1: [64.204]	
Starting epoch number: 54 Learning rate: 0.010000000000000002
Train: [54][0/10010]	Time 2.140 (2.140)	Data 1.447 (1.447)	Loss 1.519	Prec@1 64.8438	Prec@5 89.8438
Train: [54][200/10010]	Time 0.566 (113.750)	Data 0.008 (1.639)	Loss 1.707	Prec@1 60.7937	Prec@5 82.1556
Train: [54][400/10010]	Time 0.564 (226.162)	Data 0.005 (1.826)	Loss 1.688	Prec@1 61.1070	Prec@5 82.3722
Train: [54][600/10010]	Time 0.561 (337.315)	Data 0.003 (2.009)	Loss 1.683	Prec@1 61.1182	Prec@5 82.4602
Train: [54][800/10010]	Time 0.560 (448.302)	Data 0.003 (2.189)	Loss 1.688	Prec@1 61.0097	Prec@5 82.3248
Train: [54][1000/10010]	Time 0.559 (559.160)	Data 0.002 (2.372)	Loss 1.688	Prec@1 61.0265	Prec@5 82.3325
Train: [54][1200/10010]	Time 0.558 (670.404)	Data 0.002 (2.558)	Loss 1.687	Prec@1 61.0383	Prec@5 82.3331
Train: [54][1400/10010]	Time 0.558 (781.555)	Data 0.002 (2.751)	Loss 1.687	Prec@1 61.0468	Prec@5 82.3318
Train: [54][1600/10010]	Time 0.558 (892.706)	Data 0.002 (2.933)	Loss 1.691	Prec@1 60.9346	Prec@5 82.2840
Train: [54][1800/10010]	Time 0.557 (1002.401)	Data 0.002 (3.098)	Loss 1.693	Prec@1 60.9045	Prec@5 82.2577
Train: [54][2000/10010]	Time 0.557 (1113.586)	Data 0.002 (3.281)	Loss 1.694	Prec@1 60.8895	Prec@5 82.2397
Train: [54][2200/10010]	Time 0.556 (1224.752)	Data 0.002 (3.464)	Loss 1.695	Prec@1 60.8583	Prec@5 82.2243
Train: [54][2400/10010]	Time 0.557 (1336.206)	Data 0.002 (3.655)	Loss 1.696	Prec@1 60.8396	Prec@5 82.2027
Train: [54][2600/10010]	Time 0.556 (1447.181)	Data 0.001 (3.834)	Loss 1.698	Prec@1 60.8005	Prec@5 82.1676
Train: [54][2800/10010]	Time 0.556 (1556.930)	Data 0.001 (4.011)	Loss 1.700	Prec@1 60.7732	Prec@5 82.1568
Train: [54][3000/10010]	Time 0.556 (1667.528)	Data 0.001 (4.190)	Loss 1.701	Prec@1 60.7475	Prec@5 82.1276
Train: [54][3200/10010]	Time 0.556 (1778.477)	Data 0.001 (4.376)	Loss 1.702	Prec@1 60.7144	Prec@5 82.0925
Train: [54][3400/10010]	Time 0.556 (1889.528)	Data 0.001 (4.560)	Loss 1.702	Prec@1 60.7117	Prec@5 82.0894
Train: [54][3600/10010]	Time 0.556 (2000.782)	Data 0.001 (4.749)	Loss 1.703	Prec@1 60.7045	Prec@5 82.0720
Train: [54][3800/10010]	Time 0.556 (2111.712)	Data 0.001 (4.936)	Loss 1.704	Prec@1 60.6865	Prec@5 82.0526
Train: [54][4000/10010]	Time 0.556 (2222.682)	Data 0.001 (5.123)	Loss 1.705	Prec@1 60.6874	Prec@5 82.0383
Train: [54][4200/10010]	Time 0.555 (2333.452)	Data 0.001 (5.308)	Loss 1.706	Prec@1 60.6502	Prec@5 82.0149
Train: [54][4400/10010]	Time 0.555 (2444.096)	Data 0.001 (5.489)	Loss 1.707	Prec@1 60.6187	Prec@5 81.9886
Train: [54][4600/10010]	Time 0.555 (2555.176)	Data 0.001 (5.673)	Loss 1.707	Prec@1 60.6414	Prec@5 81.9880
Train: [54][4800/10010]	Time 0.555 (2665.478)	Data 0.001 (5.848)	Loss 1.708	Prec@1 60.6324	Prec@5 81.9756
Train: [54][5000/10010]	Time 0.555 (2775.575)	Data 0.001 (6.019)	Loss 1.708	Prec@1 60.6532	Prec@5 81.9880
Train: [54][5200/10010]	Time 0.555 (2887.913)	Data 0.001 (6.209)	Loss 1.708	Prec@1 60.6477	Prec@5 81.9920
Train: [54][5400/10010]	Time 0.556 (3000.263)	Data 0.001 (6.399)	Loss 1.708	Prec@1 60.6188	Prec@5 81.9876
Train: [54][5600/10010]	Time 0.556 (3113.089)	Data 0.001 (6.594)	Loss 1.709	Prec@1 60.6080	Prec@5 81.9696
Train: [54][5800/10010]	Time 0.556 (3225.833)	Data 0.001 (6.786)	Loss 1.710	Prec@1 60.5807	Prec@5 81.9541
Train: [54][6000/10010]	Time 0.556 (3337.553)	Data 0.001 (6.973)	Loss 1.710	Prec@1 60.5810	Prec@5 81.9471
Train: [54][6200/10010]	Time 0.556 (3449.440)	Data 0.001 (7.164)	Loss 1.711	Prec@1 60.5709	Prec@5 81.9398
Train: [54][6400/10010]	Time 0.556 (3561.097)	Data 0.001 (7.349)	Loss 1.711	Prec@1 60.5796	Prec@5 81.9442
Train: [54][6600/10010]	Time 0.556 (3672.439)	Data 0.001 (7.530)	Loss 1.711	Prec@1 60.5737	Prec@5 81.9312
Train: [54][6800/10010]	Time 0.556 (3783.767)	Data 0.001 (7.718)	Loss 1.712	Prec@1 60.5599	Prec@5 81.9271
Train: [54][7000/10010]	Time 0.556 (3894.285)	Data 0.001 (7.897)	Loss 1.712	Prec@1 60.5484	Prec@5 81.9191
Train: [54][7200/10010]	Time 0.556 (4004.485)	Data 0.001 (8.074)	Loss 1.713	Prec@1 60.5284	Prec@5 81.9064
Train: [54][7400/10010]	Time 0.556 (4115.918)	Data 0.001 (8.263)	Loss 1.713	Prec@1 60.5192	Prec@5 81.8971
Train: [54][7600/10010]	Time 0.556 (4226.995)	Data 0.001 (8.449)	Loss 1.714	Prec@1 60.5041	Prec@5 81.8911
Train: [54][7800/10010]	Time 0.556 (4338.136)	Data 0.001 (8.635)	Loss 1.714	Prec@1 60.5016	Prec@5 81.8860
Train: [54][8000/10010]	Time 0.556 (4449.092)	Data 0.001 (8.817)	Loss 1.714	Prec@1 60.4970	Prec@5 81.8880
Train: [54][8200/10010]	Time 0.556 (4559.131)	Data 0.001 (8.993)	Loss 1.715	Prec@1 60.4839	Prec@5 81.8764
Train: [54][8400/10010]	Time 0.556 (4670.225)	Data 0.001 (9.175)	Loss 1.715	Prec@1 60.4806	Prec@5 81.8739
Train: [54][8600/10010]	Time 0.556 (4781.987)	Data 0.001 (9.362)	Loss 1.716	Prec@1 60.4602	Prec@5 81.8585
Train: [54][8800/10010]	Time 0.556 (4893.674)	Data 0.001 (9.547)	Loss 1.716	Prec@1 60.4629	Prec@5 81.8597
Train: [54][9000/10010]	Time 0.556 (5004.914)	Data 0.001 (9.727)	Loss 1.716	Prec@1 60.4517	Prec@5 81.8559
Train: [54][9200/10010]	Time 0.556 (5115.132)	Data 0.001 (9.901)	Loss 1.717	Prec@1 60.4463	Prec@5 81.8470
Train: [54][9400/10010]	Time 0.556 (5226.714)	Data 0.001 (10.083)	Loss 1.717	Prec@1 60.4399	Prec@5 81.8389
Train: [54][9600/10010]	Time 0.556 (5338.561)	Data 0.001 (10.260)	Loss 1.718	Prec@1 60.4258	Prec@5 81.8307
Train: [54][9800/10010]	Time 0.556 (5450.754)	Data 0.001 (10.442)	Loss 1.718	Prec@1 60.4228	Prec@5 81.8273
Train: [54][10000/10010]	Time 0.556 (5562.750)	Data 0.001 (10.619)	Loss 1.718	Prec@1 60.4147	Prec@5 81.8255
Train: [54]	Time 5567.348	Data 10.623	Loss 1.718	Prec@1 60.4127	Prec@5 81.8257	
Val: [54]	Time 72.676	Data 1.719	Loss 1.444	Prec@1 64.6980	Prec@5 86.5860	
Best Prec@1: [64.698]	
Starting epoch number: 55 Learning rate: 0.010000000000000002
Train: [55][0/10010]	Time 1.890 (1.890)	Data 1.319 (1.319)	Loss 1.826	Prec@1 63.2812	Prec@5 78.9062
Train: [55][200/10010]	Time 0.556 (111.788)	Data 0.007 (1.492)	Loss 1.727	Prec@1 60.4400	Prec@5 81.8525
Train: [55][400/10010]	Time 0.554 (222.168)	Data 0.004 (1.671)	Loss 1.702	Prec@1 60.8479	Prec@5 82.1404
Train: [55][600/10010]	Time 0.554 (333.200)	Data 0.003 (1.856)	Loss 1.691	Prec@1 61.0623	Prec@5 82.3029
Train: [55][800/10010]	Time 0.555 (444.699)	Data 0.003 (2.040)	Loss 1.691	Prec@1 60.9804	Prec@5 82.3190
Train: [55][1000/10010]	Time 0.555 (555.765)	Data 0.002 (2.217)	Loss 1.689	Prec@1 60.9648	Prec@5 82.3653
Train: [55][1200/10010]	Time 0.555 (666.456)	Data 0.002 (2.399)	Loss 1.691	Prec@1 60.9759	Prec@5 82.2804
Train: [55][1400/10010]	Time 0.555 (777.423)	Data 0.002 (2.577)	Loss 1.692	Prec@1 60.9420	Prec@5 82.2498
Train: [55][1600/10010]	Time 0.556 (889.882)	Data 0.002 (2.765)	Loss 1.692	Prec@1 60.9624	Prec@5 82.2469
Train: [55][1800/10010]	Time 0.557 (1002.576)	Data 0.002 (2.956)	Loss 1.692	Prec@1 60.9358	Prec@5 82.2638
Train: [55][2000/10010]	Time 0.557 (1114.388)	Data 0.002 (3.141)	Loss 1.694	Prec@1 60.9141	Prec@5 82.2241
Train: [55][2200/10010]	Time 0.557 (1225.165)	Data 0.002 (3.324)	Loss 1.695	Prec@1 60.9027	Prec@5 82.2052
Train: [55][2400/10010]	Time 0.557 (1336.373)	Data 0.001 (3.507)	Loss 1.695	Prec@1 60.8985	Prec@5 82.2135
Train: [55][2600/10010]	Time 0.557 (1447.815)	Data 0.001 (3.690)	Loss 1.696	Prec@1 60.8936	Prec@5 82.1934
Train: [55][2800/10010]	Time 0.557 (1559.390)	Data 0.001 (3.877)	Loss 1.696	Prec@1 60.8653	Prec@5 82.1819
Train: [55][3000/10010]	Time 0.557 (1671.021)	Data 0.001 (4.069)	Loss 1.697	Prec@1 60.8479	Prec@5 82.1843
Train: [55][3200/10010]	Time 0.557 (1782.336)	Data 0.001 (4.255)	Loss 1.698	Prec@1 60.8360	Prec@5 82.1711
Train: [55][3400/10010]	Time 0.557 (1893.338)	Data 0.001 (4.441)	Loss 1.697	Prec@1 60.8557	Prec@5 82.1806
Train: [55][3600/10010]	Time 0.557 (2005.624)	Data 0.001 (4.630)	Loss 1.696	Prec@1 60.8813	Prec@5 82.1773
Train: [55][3800/10010]	Time 0.557 (2117.903)	Data 0.001 (4.819)	Loss 1.698	Prec@1 60.8530	Prec@5 82.1581
Train: [55][4000/10010]	Time 0.557 (2229.478)	Data 0.001 (5.002)	Loss 1.698	Prec@1 60.8354	Prec@5 82.1343
Train: [55][4200/10010]	Time 0.557 (2341.249)	Data 0.001 (5.189)	Loss 1.699	Prec@1 60.8291	Prec@5 82.1235
Train: [55][4400/10010]	Time 0.557 (2452.563)	Data 0.001 (5.374)	Loss 1.699	Prec@1 60.8104	Prec@5 82.1149
Train: [55][4600/10010]	Time 0.557 (2563.272)	Data 0.001 (5.553)	Loss 1.701	Prec@1 60.7899	Prec@5 82.0920
Train: [55][4800/10010]	Time 0.557 (2674.126)	Data 0.001 (5.736)	Loss 1.701	Prec@1 60.7827	Prec@5 82.0978
Train: [55][5000/10010]	Time 0.557 (2785.089)	Data 0.001 (5.915)	Loss 1.702	Prec@1 60.7499	Prec@5 82.0861
Train: [55][5200/10010]	Time 0.557 (2895.871)	Data 0.001 (6.088)	Loss 1.703	Prec@1 60.7319	Prec@5 82.0659
Train: [55][5400/10010]	Time 0.557 (3006.094)	Data 0.001 (6.255)	Loss 1.704	Prec@1 60.7139	Prec@5 82.0551
Train: [55][5600/10010]	Time 0.557 (3117.504)	Data 0.001 (6.440)	Loss 1.704	Prec@1 60.7069	Prec@5 82.0499
Train: [55][5800/10010]	Time 0.557 (3229.216)	Data 0.001 (6.625)	Loss 1.705	Prec@1 60.6970	Prec@5 82.0339
Train: [55][6000/10010]	Time 0.557 (3340.906)	Data 0.001 (6.809)	Loss 1.706	Prec@1 60.6861	Prec@5 82.0130
Train: [55][6200/10010]	Time 0.557 (3452.443)	Data 0.001 (6.991)	Loss 1.706	Prec@1 60.6809	Prec@5 82.0071
Train: [55][6400/10010]	Time 0.557 (3562.904)	Data 0.001 (7.160)	Loss 1.706	Prec@1 60.6791	Prec@5 81.9995
Train: [55][6600/10010]	Time 0.557 (3674.359)	Data 0.001 (7.337)	Loss 1.707	Prec@1 60.6693	Prec@5 81.9917
Train: [55][6800/10010]	Time 0.557 (3786.704)	Data 0.001 (7.523)	Loss 1.708	Prec@1 60.6647	Prec@5 81.9859
Train: [55][7000/10010]	Time 0.557 (3898.903)	Data 0.001 (7.708)	Loss 1.708	Prec@1 60.6596	Prec@5 81.9792
Train: [55][7200/10010]	Time 0.557 (4011.088)	Data 0.001 (7.895)	Loss 1.709	Prec@1 60.6394	Prec@5 81.9756
Train: [55][7400/10010]	Time 0.557 (4122.278)	Data 0.001 (8.075)	Loss 1.709	Prec@1 60.6258	Prec@5 81.9693
Train: [55][7600/10010]	Time 0.557 (4233.167)	Data 0.001 (8.261)	Loss 1.710	Prec@1 60.6182	Prec@5 81.9704
Train: [55][7800/10010]	Time 0.557 (4344.842)	Data 0.001 (8.448)	Loss 1.710	Prec@1 60.6151	Prec@5 81.9679
Train: [55][8000/10010]	Time 0.557 (4456.387)	Data 0.001 (8.634)	Loss 1.711	Prec@1 60.6039	Prec@5 81.9572
Train: [55][8200/10010]	Time 0.557 (4568.091)	Data 0.001 (8.818)	Loss 1.711	Prec@1 60.6027	Prec@5 81.9494
Train: [55][8400/10010]	Time 0.557 (4679.963)	Data 0.001 (9.005)	Loss 1.711	Prec@1 60.5989	Prec@5 81.9424
Train: [55][8600/10010]	Time 0.557 (4791.283)	Data 0.001 (9.190)	Loss 1.712	Prec@1 60.5890	Prec@5 81.9398
Train: [55][8800/10010]	Time 0.557 (4902.558)	Data 0.001 (9.369)	Loss 1.711	Prec@1 60.5970	Prec@5 81.9430
Train: [55][9000/10010]	Time 0.557 (5013.719)	Data 0.001 (9.552)	Loss 1.712	Prec@1 60.5834	Prec@5 81.9392
Train: [55][9200/10010]	Time 0.557 (5125.173)	Data 0.001 (9.735)	Loss 1.713	Prec@1 60.5701	Prec@5 81.9389
Train: [55][9400/10010]	Time 0.557 (5236.174)	Data 0.001 (9.913)	Loss 1.713	Prec@1 60.5693	Prec@5 81.9319
Train: [55][9600/10010]	Time 0.557 (5346.720)	Data 0.001 (10.093)	Loss 1.713	Prec@1 60.5629	Prec@5 81.9313
Train: [55][9800/10010]	Time 0.557 (5458.029)	Data 0.001 (10.275)	Loss 1.714	Prec@1 60.5575	Prec@5 81.9255
Train: [55][10000/10010]	Time 0.557 (5569.024)	Data 0.001 (10.458)	Loss 1.714	Prec@1 60.5505	Prec@5 81.9225
Train: [55]	Time 5573.506	Data 10.461	Loss 1.714	Prec@1 60.5487	Prec@5 81.9207	
Val: [55]	Time 72.805	Data 1.901	Loss 1.654	Prec@1 60.2320	Prec@5 83.5060	
Best Prec@1: [64.698]	
Starting epoch number: 56 Learning rate: 0.010000000000000002
Train: [56][0/10010]	Time 1.930 (1.930)	Data 1.383 (1.383)	Loss 1.791	Prec@1 58.5938	Prec@5 82.0312
Train: [56][200/10010]	Time 0.561 (112.708)	Data 0.008 (1.569)	Loss 1.724	Prec@1 60.5877	Prec@5 81.7397
Train: [56][400/10010]	Time 0.558 (223.795)	Data 0.004 (1.756)	Loss 1.706	Prec@1 60.7212	Prec@5 81.9825
Train: [56][600/10010]	Time 0.557 (334.701)	Data 0.003 (1.939)	Loss 1.695	Prec@1 60.9336	Prec@5 82.1625
Train: [56][800/10010]	Time 0.556 (445.729)	Data 0.003 (2.119)	Loss 1.700	Prec@1 60.7814	Prec@5 82.0800
Train: [56][1000/10010]	Time 0.556 (556.645)	Data 0.002 (2.305)	Loss 1.699	Prec@1 60.8821	Prec@5 82.1046
Train: [56][1200/10010]	Time 0.556 (667.284)	Data 0.002 (2.485)	Loss 1.699	Prec@1 60.9089	Prec@5 82.1145
Train: [56][1400/10010]	Time 0.556 (778.279)	Data 0.002 (2.667)	Loss 1.697	Prec@1 60.9949	Prec@5 82.1729
Train: [56][1600/10010]	Time 0.555 (888.842)	Data 0.002 (2.841)	Loss 1.698	Prec@1 60.9521	Prec@5 82.1513
Train: [56][1800/10010]	Time 0.555 (998.951)	Data 0.002 (3.018)	Loss 1.700	Prec@1 60.8607	Prec@5 82.0950
Train: [56][2000/10010]	Time 0.555 (1109.968)	Data 0.002 (3.202)	Loss 1.701	Prec@1 60.8087	Prec@5 82.0543
Train: [56][2200/10010]	Time 0.555 (1221.254)	Data 0.002 (3.393)	Loss 1.702	Prec@1 60.8303	Prec@5 82.0359
Train: [56][2400/10010]	Time 0.555 (1332.871)	Data 0.001 (3.580)	Loss 1.702	Prec@1 60.8204	Prec@5 82.0560
Train: [56][2600/10010]	Time 0.555 (1444.532)	Data 0.001 (3.772)	Loss 1.702	Prec@1 60.8077	Prec@5 82.0505
Train: [56][2800/10010]	Time 0.555 (1554.737)	Data 0.001 (3.951)	Loss 1.702	Prec@1 60.8019	Prec@5 82.0399
Train: [56][3000/10010]	Time 0.555 (1665.368)	Data 0.001 (4.130)	Loss 1.701	Prec@1 60.8433	Prec@5 82.0601
Train: [56][3200/10010]	Time 0.555 (1777.653)	Data 0.001 (4.316)	Loss 1.702	Prec@1 60.8030	Prec@5 82.0530
Train: [56][3400/10010]	Time 0.556 (1889.791)	Data 0.001 (4.500)	Loss 1.701	Prec@1 60.8155	Prec@5 82.0590
Train: [56][3600/10010]	Time 0.556 (2002.211)	Data 0.001 (4.691)	Loss 1.701	Prec@1 60.8188	Prec@5 82.0662
Train: [56][3800/10010]	Time 0.556 (2113.875)	Data 0.001 (4.870)	Loss 1.701	Prec@1 60.8058	Prec@5 82.0851
Train: [56][4000/10010]	Time 0.556 (2224.588)	Data 0.001 (5.052)	Loss 1.700	Prec@1 60.8164	Prec@5 82.1068
Train: [56][4200/10010]	Time 0.556 (2335.165)	Data 0.001 (5.231)	Loss 1.700	Prec@1 60.8025	Prec@5 82.1002
Train: [56][4400/10010]	Time 0.556 (2445.878)	Data 0.001 (5.417)	Loss 1.701	Prec@1 60.8010	Prec@5 82.0794
Train: [56][4600/10010]	Time 0.556 (2556.480)	Data 0.001 (5.599)	Loss 1.701	Prec@1 60.7996	Prec@5 82.0858
Train: [56][4800/10010]	Time 0.555 (2666.843)	Data 0.001 (5.773)	Loss 1.701	Prec@1 60.7896	Prec@5 82.0936
Train: [56][5000/10010]	Time 0.556 (2778.056)	Data 0.001 (5.957)	Loss 1.702	Prec@1 60.7597	Prec@5 82.0750
Train: [56][5200/10010]	Time 0.555 (2888.697)	Data 0.001 (6.140)	Loss 1.702	Prec@1 60.7500	Prec@5 82.0832
Train: [56][5400/10010]	Time 0.555 (2999.487)	Data 0.001 (6.323)	Loss 1.703	Prec@1 60.7237	Prec@5 82.0691
Train: [56][5600/10010]	Time 0.555 (3110.524)	Data 0.001 (6.508)	Loss 1.703	Prec@1 60.7273	Prec@5 82.0727
Train: [56][5800/10010]	Time 0.555 (3221.185)	Data 0.001 (6.683)	Loss 1.703	Prec@1 60.7173	Prec@5 82.0748
Train: [56][6000/10010]	Time 0.555 (3331.769)	Data 0.001 (6.857)	Loss 1.703	Prec@1 60.7042	Prec@5 82.0756
Train: [56][6200/10010]	Time 0.555 (3442.172)	Data 0.001 (7.038)	Loss 1.703	Prec@1 60.7120	Prec@5 82.0770
Train: [56][6400/10010]	Time 0.555 (3554.027)	Data 0.001 (7.229)	Loss 1.704	Prec@1 60.6934	Prec@5 82.0607
Train: [56][6600/10010]	Time 0.555 (3666.210)	Data 0.001 (7.418)	Loss 1.705	Prec@1 60.6731	Prec@5 82.0437
Train: [56][6800/10010]	Time 0.556 (3778.454)	Data 0.001 (7.605)	Loss 1.706	Prec@1 60.6600	Prec@5 82.0326
Train: [56][7000/10010]	Time 0.556 (3890.350)	Data 0.001 (7.791)	Loss 1.706	Prec@1 60.6469	Prec@5 82.0319
Train: [56][7200/10010]	Time 0.556 (4001.570)	Data 0.001 (7.979)	Loss 1.707	Prec@1 60.6440	Prec@5 82.0216
Train: [56][7400/10010]	Time 0.556 (4113.182)	Data 0.001 (8.167)	Loss 1.707	Prec@1 60.6249	Prec@5 82.0160
Train: [56][7600/10010]	Time 0.556 (4225.179)	Data 0.001 (8.355)	Loss 1.708	Prec@1 60.6031	Prec@5 82.0105
Train: [56][7800/10010]	Time 0.556 (4337.209)	Data 0.001 (8.544)	Loss 1.708	Prec@1 60.6058	Prec@5 82.0074
Train: [56][8000/10010]	Time 0.556 (4448.904)	Data 0.001 (8.726)	Loss 1.708	Prec@1 60.6073	Prec@5 82.0103
Train: [56][8200/10010]	Time 0.556 (4560.574)	Data 0.001 (8.913)	Loss 1.708	Prec@1 60.6022	Prec@5 82.0133
Train: [56][8400/10010]	Time 0.556 (4671.929)	Data 0.001 (9.096)	Loss 1.709	Prec@1 60.5799	Prec@5 82.0004
Train: [56][8600/10010]	Time 0.556 (4782.860)	Data 0.001 (9.282)	Loss 1.710	Prec@1 60.5762	Prec@5 82.0015
Train: [56][8800/10010]	Time 0.556 (4893.753)	Data 0.001 (9.467)	Loss 1.710	Prec@1 60.5643	Prec@5 81.9919
Train: [56][9000/10010]	Time 0.556 (5004.933)	Data 0.001 (9.651)	Loss 1.710	Prec@1 60.5683	Prec@5 81.9938
Train: [56][9200/10010]	Time 0.556 (5115.499)	Data 0.001 (9.831)	Loss 1.711	Prec@1 60.5607	Prec@5 81.9925
Train: [56][9400/10010]	Time 0.556 (5226.122)	Data 0.001 (10.019)	Loss 1.711	Prec@1 60.5454	Prec@5 81.9788
Train: [56][9600/10010]	Time 0.556 (5338.566)	Data 0.001 (10.211)	Loss 1.712	Prec@1 60.5252	Prec@5 81.9653
Train: [56][9800/10010]	Time 0.556 (5451.064)	Data 0.001 (10.390)	Loss 1.712	Prec@1 60.5263	Prec@5 81.9637
Train: [56][10000/10010]	Time 0.556 (5563.757)	Data 0.001 (10.567)	Loss 1.712	Prec@1 60.5164	Prec@5 81.9658
Train: [56]	Time 5568.354	Data 10.571	Loss 1.712	Prec@1 60.5157	Prec@5 81.9659	
Val: [56]	Time 72.770	Data 1.782	Loss 1.489	Prec@1 63.8540	Prec@5 86.3760	
Best Prec@1: [64.698]	
Starting epoch number: 57 Learning rate: 0.010000000000000002
Train: [57][0/10010]	Time 1.915 (1.915)	Data 1.304 (1.304)	Loss 1.929	Prec@1 57.0312	Prec@5 78.1250
Train: [57][200/10010]	Time 0.559 (112.320)	Data 0.007 (1.479)	Loss 1.728	Prec@1 60.4827	Prec@5 81.8019
Train: [57][400/10010]	Time 0.558 (223.679)	Data 0.004 (1.657)	Loss 1.715	Prec@1 60.6141	Prec@5 81.9981
Train: [57][600/10010]	Time 0.557 (334.857)	Data 0.003 (1.831)	Loss 1.704	Prec@1 60.7841	Prec@5 82.0663
Train: [57][800/10010]	Time 0.554 (443.967)	Data 0.002 (1.974)	Loss 1.704	Prec@1 60.7541	Prec@5 82.0498
Train: [57][1000/10010]	Time 0.553 (553.107)	Data 0.002 (2.126)	Loss 1.700	Prec@1 60.8462	Prec@5 82.0906
Train: [57][1200/10010]	Time 0.552 (662.695)	Data 0.002 (2.285)	Loss 1.704	Prec@1 60.7671	Prec@5 82.0299
Train: [57][1400/10010]	Time 0.551 (771.727)	Data 0.002 (2.436)	Loss 1.703	Prec@1 60.8081	Prec@5 82.0452
Train: [57][1600/10010]	Time 0.550 (880.547)	Data 0.002 (2.581)	Loss 1.702	Prec@1 60.8560	Prec@5 82.0303
Train: [57][1800/10010]	Time 0.549 (989.583)	Data 0.002 (2.732)	Loss 1.701	Prec@1 60.8950	Prec@5 82.0404
Train: [57][2000/10010]	Time 0.549 (1098.496)	Data 0.001 (2.878)	Loss 1.701	Prec@1 60.9020	Prec@5 82.0434
Train: [57][2200/10010]	Time 0.549 (1207.877)	Data 0.001 (3.032)	Loss 1.700	Prec@1 60.8662	Prec@5 82.0678
Train: [57][2400/10010]	Time 0.548 (1316.861)	Data 0.001 (3.175)	Loss 1.701	Prec@1 60.8392	Prec@5 82.0553
Train: [57][2600/10010]	Time 0.548 (1425.719)	Data 0.001 (3.326)	Loss 1.702	Prec@1 60.8306	Prec@5 82.0535
Train: [57][2800/10010]	Time 0.548 (1534.815)	Data 0.001 (3.468)	Loss 1.701	Prec@1 60.8296	Prec@5 82.0653
Train: [57][3000/10010]	Time 0.547 (1642.593)	Data 0.001 (3.595)	Loss 1.702	Prec@1 60.8151	Prec@5 82.0586
Train: [57][3200/10010]	Time 0.547 (1750.454)	Data 0.001 (3.723)	Loss 1.702	Prec@1 60.8025	Prec@5 82.0635
Train: [57][3400/10010]	Time 0.546 (1858.185)	Data 0.001 (3.845)	Loss 1.701	Prec@1 60.8254	Prec@5 82.0675
Train: [57][3600/10010]	Time 0.546 (1966.136)	Data 0.001 (3.972)	Loss 1.699	Prec@1 60.8531	Prec@5 82.0924
Train: [57][3800/10010]	Time 0.546 (2074.049)	Data 0.001 (4.095)	Loss 1.700	Prec@1 60.8335	Prec@5 82.0826
Train: [57][4000/10010]	Time 0.545 (2182.079)	Data 0.001 (4.218)	Loss 1.700	Prec@1 60.8239	Prec@5 82.0890
Train: [57][4200/10010]	Time 0.545 (2290.090)	Data 0.001 (4.344)	Loss 1.700	Prec@1 60.8192	Prec@5 82.0809
Train: [57][4400/10010]	Time 0.545 (2398.028)	Data 0.001 (4.468)	Loss 1.700	Prec@1 60.8262	Prec@5 82.0749
Train: [57][4600/10010]	Time 0.545 (2505.844)	Data 0.001 (4.589)	Loss 1.701	Prec@1 60.8193	Prec@5 82.0817
Train: [57][4800/10010]	Time 0.544 (2613.470)	Data 0.001 (4.710)	Loss 1.701	Prec@1 60.8076	Prec@5 82.0731
Train: [57][5000/10010]	Time 0.544 (2721.411)	Data 0.001 (4.837)	Loss 1.701	Prec@1 60.8152	Prec@5 82.0825
Train: [57][5200/10010]	Time 0.544 (2829.135)	Data 0.001 (4.963)	Loss 1.700	Prec@1 60.8233	Prec@5 82.0837
Train: [57][5400/10010]	Time 0.544 (2936.817)	Data 0.001 (5.087)	Loss 1.701	Prec@1 60.8098	Prec@5 82.0736
Train: [57][5600/10010]	Time 0.544 (3044.355)	Data 0.001 (5.205)	Loss 1.703	Prec@1 60.7821	Prec@5 82.0604
Train: [57][5800/10010]	Time 0.543 (3151.710)	Data 0.001 (5.320)	Loss 1.703	Prec@1 60.7670	Prec@5 82.0519
Train: [57][6000/10010]	Time 0.543 (3259.351)	Data 0.001 (5.436)	Loss 1.703	Prec@1 60.7699	Prec@5 82.0536
Train: [57][6200/10010]	Time 0.543 (3367.183)	Data 0.001 (5.556)	Loss 1.703	Prec@1 60.7742	Prec@5 82.0577
Train: [57][6400/10010]	Time 0.543 (3474.844)	Data 0.001 (5.678)	Loss 1.703	Prec@1 60.7874	Prec@5 82.0514
Train: [57][6600/10010]	Time 0.543 (3582.465)	Data 0.001 (5.797)	Loss 1.702	Prec@1 60.7891	Prec@5 82.0594
Train: [57][6800/10010]	Time 0.543 (3689.951)	Data 0.001 (5.915)	Loss 1.703	Prec@1 60.7908	Prec@5 82.0600
Train: [57][7000/10010]	Time 0.542 (3797.491)	Data 0.001 (6.036)	Loss 1.703	Prec@1 60.7848	Prec@5 82.0593
Train: [57][7200/10010]	Time 0.542 (3905.212)	Data 0.001 (6.161)	Loss 1.703	Prec@1 60.7844	Prec@5 82.0617
Train: [57][7400/10010]	Time 0.542 (4013.008)	Data 0.001 (6.284)	Loss 1.703	Prec@1 60.7751	Prec@5 82.0583
Train: [57][7600/10010]	Time 0.542 (4120.914)	Data 0.001 (6.405)	Loss 1.703	Prec@1 60.7781	Prec@5 82.0614
Train: [57][7800/10010]	Time 0.542 (4228.798)	Data 0.001 (6.524)	Loss 1.704	Prec@1 60.7617	Prec@5 82.0502
Train: [57][8000/10010]	Time 0.542 (4336.786)	Data 0.001 (6.648)	Loss 1.704	Prec@1 60.7537	Prec@5 82.0421
Train: [57][8200/10010]	Time 0.542 (4444.675)	Data 0.001 (6.774)	Loss 1.704	Prec@1 60.7527	Prec@5 82.0456
Train: [57][8400/10010]	Time 0.542 (4552.579)	Data 0.001 (6.897)	Loss 1.705	Prec@1 60.7550	Prec@5 82.0457
Train: [57][8600/10010]	Time 0.542 (4660.098)	Data 0.001 (7.017)	Loss 1.705	Prec@1 60.7445	Prec@5 82.0349
Train: [57][8800/10010]	Time 0.542 (4767.766)	Data 0.001 (7.138)	Loss 1.706	Prec@1 60.7392	Prec@5 82.0283
Train: [57][9000/10010]	Time 0.542 (4876.262)	Data 0.001 (7.275)	Loss 1.706	Prec@1 60.7372	Prec@5 82.0274
Train: [57][9200/10010]	Time 0.542 (4984.943)	Data 0.001 (7.415)	Loss 1.706	Prec@1 60.7321	Prec@5 82.0225
Train: [57][9400/10010]	Time 0.542 (5093.137)	Data 0.001 (7.542)	Loss 1.707	Prec@1 60.7186	Prec@5 82.0131
Train: [57][9600/10010]	Time 0.542 (5201.256)	Data 0.001 (7.667)	Loss 1.707	Prec@1 60.7100	Prec@5 82.0125
Train: [57][9800/10010]	Time 0.542 (5309.151)	Data 0.001 (7.790)	Loss 1.708	Prec@1 60.6842	Prec@5 81.9955
Train: [57][10000/10010]	Time 0.542 (5416.941)	Data 0.001 (7.907)	Loss 1.709	Prec@1 60.6669	Prec@5 81.9863
Train: [57]	Time 5421.344	Data 7.909	Loss 1.709	Prec@1 60.6655	Prec@5 81.9869	
Val: [57]	Time 68.347	Data 1.578	Loss 1.571	Prec@1 62.3280	Prec@5 84.7840	
Best Prec@1: [64.698]	
Starting epoch number: 58 Learning rate: 0.010000000000000002
Train: [58][0/10010]	Time 1.763 (1.763)	Data 1.196 (1.196)	Loss 1.723	Prec@1 57.8125	Prec@5 85.9375
Train: [58][200/10010]	Time 0.544 (109.408)	Data 0.007 (1.322)	Loss 1.726	Prec@1 59.8686	Prec@5 82.1168
Train: [58][400/10010]	Time 0.542 (217.278)	Data 0.004 (1.442)	Loss 1.707	Prec@1 60.6043	Prec@5 82.2319
Train: [58][600/10010]	Time 0.541 (325.065)	Data 0.003 (1.563)	Loss 1.694	Prec@1 60.8491	Prec@5 82.3601
Train: [58][800/10010]	Time 0.541 (433.390)	Data 0.002 (1.686)	Loss 1.693	Prec@1 60.8614	Prec@5 82.3278
Train: [58][1000/10010]	Time 0.541 (541.436)	Data 0.002 (1.813)	Loss 1.693	Prec@1 60.8095	Prec@5 82.2779
Train: [58][1200/10010]	Time 0.541 (649.297)	Data 0.002 (1.939)	Loss 1.693	Prec@1 60.8120	Prec@5 82.2401
Train: [58][1400/10010]	Time 0.541 (757.419)	Data 0.001 (2.068)	Loss 1.694	Prec@1 60.8165	Prec@5 82.2309
Train: [58][1600/10010]	Time 0.540 (865.234)	Data 0.001 (2.193)	Loss 1.691	Prec@1 60.9194	Prec@5 82.2840
Train: [58][1800/10010]	Time 0.540 (973.203)	Data 0.001 (2.316)	Loss 1.693	Prec@1 60.8902	Prec@5 82.2425
Train: [58][2000/10010]	Time 0.540 (1081.046)	Data 0.001 (2.439)	Loss 1.693	Prec@1 60.8887	Prec@5 82.2499
Train: [58][2200/10010]	Time 0.540 (1189.088)	Data 0.001 (2.562)	Loss 1.692	Prec@1 60.8942	Prec@5 82.2495
Train: [58][2400/10010]	Time 0.540 (1297.144)	Data 0.001 (2.686)	Loss 1.694	Prec@1 60.8851	Prec@5 82.2115
Train: [58][2600/10010]	Time 0.540 (1405.488)	Data 0.001 (2.813)	Loss 1.694	Prec@1 60.8885	Prec@5 82.2184
Train: [58][2800/10010]	Time 0.541 (1514.693)	Data 0.001 (2.938)	Loss 1.695	Prec@1 60.8706	Prec@5 82.1919
Train: [58][3000/10010]	Time 0.541 (1623.240)	Data 0.001 (3.061)	Loss 1.696	Prec@1 60.8282	Prec@5 82.1619
Train: [58][3200/10010]	Time 0.541 (1731.233)	Data 0.001 (3.187)	Loss 1.696	Prec@1 60.8243	Prec@5 82.1784
Train: [58][3400/10010]	Time 0.541 (1839.286)	Data 0.001 (3.314)	Loss 1.695	Prec@1 60.8256	Prec@5 82.1927
Train: [58][3600/10010]	Time 0.541 (1947.123)	Data 0.001 (3.438)	Loss 1.697	Prec@1 60.8160	Prec@5 82.1686
Train: [58][3800/10010]	Time 0.541 (2054.942)	Data 0.001 (3.560)	Loss 1.697	Prec@1 60.7990	Prec@5 82.1589
Train: [58][4000/10010]	Time 0.541 (2162.812)	Data 0.001 (3.681)	Loss 1.698	Prec@1 60.8026	Prec@5 82.1572
Train: [58][4200/10010]	Time 0.541 (2271.088)	Data 0.001 (3.809)	Loss 1.699	Prec@1 60.7566	Prec@5 82.1345
Train: [58][4400/10010]	Time 0.541 (2379.242)	Data 0.001 (3.938)	Loss 1.699	Prec@1 60.7639	Prec@5 82.1353
Train: [58][4600/10010]	Time 0.541 (2487.426)	Data 0.001 (4.064)	Loss 1.700	Prec@1 60.7643	Prec@5 82.1246
Train: [58][4800/10010]	Time 0.541 (2595.439)	Data 0.001 (4.192)	Loss 1.700	Prec@1 60.7469	Prec@5 82.1090
Train: [58][5000/10010]	Time 0.541 (2703.506)	Data 0.001 (4.318)	Loss 1.701	Prec@1 60.7283	Prec@5 82.1048
Train: [58][5200/10010]	Time 0.541 (2811.504)	Data 0.001 (4.447)	Loss 1.702	Prec@1 60.7084	Prec@5 82.0744
Train: [58][5400/10010]	Time 0.541 (2919.540)	Data 0.001 (4.574)	Loss 1.702	Prec@1 60.7175	Prec@5 82.0833
Train: [58][5600/10010]	Time 0.541 (3027.638)	Data 0.001 (4.703)	Loss 1.702	Prec@1 60.7182	Prec@5 82.0732
Train: [58][5800/10010]	Time 0.541 (3135.853)	Data 0.001 (4.832)	Loss 1.703	Prec@1 60.7161	Prec@5 82.0648
Train: [58][6000/10010]	Time 0.541 (3243.992)	Data 0.001 (4.950)	Loss 1.703	Prec@1 60.7243	Prec@5 82.0673
Train: [58][6200/10010]	Time 0.541 (3352.037)	Data 0.001 (5.073)	Loss 1.704	Prec@1 60.7108	Prec@5 82.0335
Train: [58][6400/10010]	Time 0.541 (3460.079)	Data 0.001 (5.201)	Loss 1.706	Prec@1 60.6819	Prec@5 82.0179
Train: [58][6600/10010]	Time 0.541 (3567.982)	Data 0.001 (5.324)	Loss 1.706	Prec@1 60.6873	Prec@5 82.0249
Train: [58][6800/10010]	Time 0.541 (3676.080)	Data 0.001 (5.450)	Loss 1.706	Prec@1 60.6795	Prec@5 82.0279
Train: [58][7000/10010]	Time 0.540 (3783.996)	Data 0.001 (5.575)	Loss 1.706	Prec@1 60.6720	Prec@5 82.0281
Train: [58][7200/10010]	Time 0.540 (3891.944)	Data 0.001 (5.701)	Loss 1.706	Prec@1 60.6588	Prec@5 82.0182
Train: [58][7400/10010]	Time 0.540 (3999.980)	Data 0.001 (5.831)	Loss 1.706	Prec@1 60.6466	Prec@5 82.0081
Train: [58][7600/10010]	Time 0.540 (4108.048)	Data 0.001 (5.960)	Loss 1.706	Prec@1 60.6392	Prec@5 82.0071
Train: [58][7800/10010]	Time 0.540 (4216.217)	Data 0.001 (6.089)	Loss 1.707	Prec@1 60.6307	Prec@5 81.9928
Train: [58][8000/10010]	Time 0.541 (4324.791)	Data 0.001 (6.226)	Loss 1.707	Prec@1 60.6243	Prec@5 81.9982
Train: [58][8200/10010]	Time 0.541 (4433.560)	Data 0.001 (6.367)	Loss 1.708	Prec@1 60.6174	Prec@5 81.9871
Train: [58][8400/10010]	Time 0.541 (4541.550)	Data 0.001 (6.495)	Loss 1.708	Prec@1 60.6119	Prec@5 81.9809
Train: [58][8600/10010]	Time 0.541 (4649.688)	Data 0.001 (6.617)	Loss 1.707	Prec@1 60.6174	Prec@5 81.9901
Train: [58][8800/10010]	Time 0.541 (4757.893)	Data 0.001 (6.748)	Loss 1.707	Prec@1 60.6270	Prec@5 81.9917
Train: [58][9000/10010]	Time 0.541 (4865.927)	Data 0.001 (6.876)	Loss 1.707	Prec@1 60.6245	Prec@5 81.9924
Train: [58][9200/10010]	Time 0.541 (4973.783)	Data 0.001 (7.001)	Loss 1.708	Prec@1 60.6134	Prec@5 81.9828
Train: [58][9400/10010]	Time 0.541 (5081.759)	Data 0.001 (7.128)	Loss 1.708	Prec@1 60.6252	Prec@5 81.9814
Train: [58][9600/10010]	Time 0.541 (5189.639)	Data 0.001 (7.257)	Loss 1.708	Prec@1 60.6285	Prec@5 81.9779
Train: [58][9800/10010]	Time 0.540 (5297.308)	Data 0.001 (7.379)	Loss 1.708	Prec@1 60.6328	Prec@5 81.9696
Train: [58][10000/10010]	Time 0.540 (5404.774)	Data 0.001 (7.493)	Loss 1.709	Prec@1 60.6300	Prec@5 81.9658
Train: [58]	Time 5409.136	Data 7.495	Loss 1.708	Prec@1 60.6302	Prec@5 81.9660	
Val: [58]	Time 68.294	Data 1.640	Loss 1.863	Prec@1 56.7340	Prec@5 80.4720	
Best Prec@1: [64.698]	
Starting epoch number: 59 Learning rate: 0.010000000000000002
Train: [59][0/10010]	Time 1.760 (1.760)	Data 1.197 (1.197)	Loss 1.742	Prec@1 60.9375	Prec@5 83.5938
Train: [59][200/10010]	Time 0.546 (109.763)	Data 0.007 (1.323)	Loss 1.748	Prec@1 59.9114	Prec@5 81.5882
Train: [59][400/10010]	Time 0.542 (217.490)	Data 0.004 (1.446)	Loss 1.726	Prec@1 60.4173	Prec@5 81.8306
Train: [59][600/10010]	Time 0.543 (326.148)	Data 0.003 (1.555)	Loss 1.716	Prec@1 60.6528	Prec@5 81.9871
Train: [59][800/10010]	Time 0.542 (434.541)	Data 0.002 (1.683)	Loss 1.710	Prec@1 60.7483	Prec@5 82.0664
Train: [59][1000/10010]	Time 0.542 (542.328)	Data 0.002 (1.805)	Loss 1.707	Prec@1 60.7783	Prec@5 82.1062
Train: [59][1200/10010]	Time 0.541 (650.026)	Data 0.002 (1.924)	Loss 1.704	Prec@1 60.8633	Prec@5 82.1191
Train: [59][1400/10010]	Time 0.541 (757.606)	Data 0.001 (2.042)	Loss 1.702	Prec@1 60.8455	Prec@5 82.1762
Train: [59][1600/10010]	Time 0.540 (865.273)	Data 0.001 (2.162)	Loss 1.702	Prec@1 60.8404	Prec@5 82.1396
Train: [59][1800/10010]	Time 0.540 (972.997)	Data 0.001 (2.282)	Loss 1.700	Prec@1 60.8625	Prec@5 82.1679
Train: [59][2000/10010]	Time 0.540 (1080.530)	Data 0.001 (2.404)	Loss 1.696	Prec@1 60.8930	Prec@5 82.1933
Train: [59][2200/10010]	Time 0.540 (1188.387)	Data 0.001 (2.529)	Loss 1.694	Prec@1 60.9446	Prec@5 82.2116
Train: [59][2400/10010]	Time 0.540 (1296.305)	Data 0.001 (2.654)	Loss 1.694	Prec@1 60.9603	Prec@5 82.2148
Train: [59][2600/10010]	Time 0.540 (1404.740)	Data 0.001 (2.786)	Loss 1.695	Prec@1 60.9366	Prec@5 82.1838
Train: [59][2800/10010]	Time 0.541 (1513.941)	Data 0.001 (2.928)	Loss 1.694	Prec@1 60.9456	Prec@5 82.1958
Train: [59][3000/10010]	Time 0.541 (1622.639)	Data 0.001 (3.067)	Loss 1.695	Prec@1 60.9385	Prec@5 82.1783
Train: [59][3200/10010]	Time 0.541 (1730.857)	Data 0.001 (3.191)	Loss 1.694	Prec@1 60.9385	Prec@5 82.2043
Train: [59][3400/10010]	Time 0.540 (1838.233)	Data 0.001 (3.307)	Loss 1.694	Prec@1 60.9194	Prec@5 82.2005
Train: [59][3600/10010]	Time 0.540 (1945.895)	Data 0.001 (3.430)	Loss 1.696	Prec@1 60.8971	Prec@5 82.1558
Train: [59][3800/10010]	Time 0.540 (2053.652)	Data 0.001 (3.549)	Loss 1.696	Prec@1 60.8762	Prec@5 82.1519
Train: [59][4000/10010]	Time 0.540 (2161.371)	Data 0.001 (3.669)	Loss 1.697	Prec@1 60.8612	Prec@5 82.1513
Train: [59][4200/10010]	Time 0.540 (2269.147)	Data 0.001 (3.788)	Loss 1.697	Prec@1 60.8717	Prec@5 82.1674
Train: [59][4400/10010]	Time 0.540 (2376.720)	Data 0.001 (3.904)	Loss 1.697	Prec@1 60.8558	Prec@5 82.1546
Train: [59][4600/10010]	Time 0.540 (2484.502)	Data 0.001 (4.022)	Loss 1.698	Prec@1 60.8480	Prec@5 82.1387
Train: [59][4800/10010]	Time 0.540 (2592.255)	Data 0.001 (4.143)	Loss 1.698	Prec@1 60.8524	Prec@5 82.1359
Train: [59][5000/10010]	Time 0.540 (2700.071)	Data 0.001 (4.263)	Loss 1.699	Prec@1 60.8314	Prec@5 82.1089
Train: [59][5200/10010]	Time 0.540 (2807.670)	Data 0.001 (4.380)	Loss 1.699	Prec@1 60.8221	Prec@5 82.1061
Train: [59][5400/10010]	Time 0.540 (2915.432)	Data 0.001 (4.499)	Loss 1.700	Prec@1 60.7953	Prec@5 82.0825
Train: [59][5600/10010]	Time 0.540 (3022.850)	Data 0.001 (4.617)	Loss 1.700	Prec@1 60.7991	Prec@5 82.0883
Train: [59][5800/10010]	Time 0.540 (3130.483)	Data 0.001 (4.737)	Loss 1.700	Prec@1 60.7907	Prec@5 82.0842
Train: [59][6000/10010]	Time 0.540 (3237.877)	Data 0.001 (4.857)	Loss 1.701	Prec@1 60.7754	Prec@5 82.0827
Train: [59][6200/10010]	Time 0.540 (3345.792)	Data 0.001 (4.982)	Loss 1.701	Prec@1 60.7771	Prec@5 82.0795
Train: [59][6400/10010]	Time 0.540 (3453.694)	Data 0.001 (5.103)	Loss 1.702	Prec@1 60.7627	Prec@5 82.0691
Train: [59][6600/10010]	Time 0.540 (3561.471)	Data 0.001 (5.223)	Loss 1.702	Prec@1 60.7670	Prec@5 82.0695
Train: [59][6800/10010]	Time 0.540 (3669.339)	Data 0.001 (5.346)	Loss 1.702	Prec@1 60.7569	Prec@5 82.0672
Train: [59][7000/10010]	Time 0.539 (3776.972)	Data 0.001 (5.468)	Loss 1.702	Prec@1 60.7527	Prec@5 82.0603
Train: [59][7200/10010]	Time 0.539 (3884.861)	Data 0.001 (5.593)	Loss 1.704	Prec@1 60.7117	Prec@5 82.0398
Train: [59][7400/10010]	Time 0.539 (3992.506)	Data 0.001 (5.715)	Loss 1.704	Prec@1 60.7121	Prec@5 82.0418
Train: [59][7600/10010]	Time 0.539 (4099.942)	Data 0.001 (5.835)	Loss 1.704	Prec@1 60.7095	Prec@5 82.0436
Train: [59][7800/10010]	Time 0.539 (4207.732)	Data 0.001 (5.957)	Loss 1.705	Prec@1 60.7008	Prec@5 82.0377
Train: [59][8000/10010]	Time 0.539 (4315.519)	Data 0.001 (6.077)	Loss 1.705	Prec@1 60.7007	Prec@5 82.0400
Train: [59][8200/10010]	Time 0.539 (4423.215)	Data 0.001 (6.196)	Loss 1.705	Prec@1 60.6834	Prec@5 82.0340
Train: [59][8400/10010]	Time 0.539 (4530.998)	Data 0.001 (6.317)	Loss 1.706	Prec@1 60.6708	Prec@5 82.0326
Train: [59][8600/10010]	Time 0.539 (4638.799)	Data 0.001 (6.436)	Loss 1.706	Prec@1 60.6544	Prec@5 82.0280
Train: [59][8800/10010]	Time 0.539 (4746.391)	Data 0.001 (6.556)	Loss 1.706	Prec@1 60.6483	Prec@5 82.0241
Train: [59][9000/10010]	Time 0.539 (4854.040)	Data 0.001 (6.673)	Loss 1.707	Prec@1 60.6334	Prec@5 82.0112
Train: [59][9200/10010]	Time 0.539 (4961.799)	Data 0.001 (6.796)	Loss 1.708	Prec@1 60.6109	Prec@5 81.9947
Train: [59][9400/10010]	Time 0.539 (5069.698)	Data 0.001 (6.920)	Loss 1.708	Prec@1 60.6134	Prec@5 82.0038
Train: [59][9600/10010]	Time 0.539 (5177.650)	Data 0.001 (7.044)	Loss 1.708	Prec@1 60.6105	Prec@5 81.9995
Train: [59][9800/10010]	Time 0.539 (5285.564)	Data 0.001 (7.167)	Loss 1.708	Prec@1 60.6022	Prec@5 81.9937
Train: [59][10000/10010]	Time 0.539 (5393.243)	Data 0.001 (7.282)	Loss 1.709	Prec@1 60.5928	Prec@5 81.9872
Train: [59]	Time 5397.644	Data 7.284	Loss 1.709	Prec@1 60.5939	Prec@5 81.9872	
Val: [59]	Time 68.002	Data 1.575	Loss 1.448	Prec@1 64.8040	Prec@5 86.8700	
Best Prec@1: [64.804]	
Starting epoch number: 60 Learning rate: 0.0010000000000000002
Train: [60][0/10010]	Time 1.850 (1.850)	Data 1.294 (1.294)	Loss 1.957	Prec@1 54.6875	Prec@5 78.9062
Train: [60][200/10010]	Time 0.546 (109.805)	Data 0.007 (1.424)	Loss 1.644	Prec@1 62.0491	Prec@5 83.1390
Train: [60][400/10010]	Time 0.544 (218.029)	Data 0.004 (1.553)	Loss 1.604	Prec@1 63.0981	Prec@5 83.5256
Train: [60][600/10010]	Time 0.543 (326.252)	Data 0.003 (1.676)	Loss 1.584	Prec@1 63.4008	Prec@5 83.7822
Train: [60][800/10010]	Time 0.542 (434.029)	Data 0.002 (1.799)	Loss 1.574	Prec@1 63.5709	Prec@5 83.8971
Train: [60][1000/10010]	Time 0.542 (542.470)	Data 0.002 (1.932)	Loss 1.562	Prec@1 63.8783	Prec@5 84.0605
Train: [60][1200/10010]	Time 0.542 (650.916)	Data 0.002 (2.071)	Loss 1.554	Prec@1 64.0222	Prec@5 84.1766
Train: [60][1400/10010]	Time 0.542 (759.077)	Data 0.002 (2.201)	Loss 1.547	Prec@1 64.1757	Prec@5 84.2674
Train: [60][1600/10010]	Time 0.542 (866.985)	Data 0.001 (2.327)	Loss 1.541	Prec@1 64.2704	Prec@5 84.3477
Train: [60][1800/10010]	Time 0.541 (974.970)	Data 0.001 (2.448)	Loss 1.537	Prec@1 64.3557	Prec@5 84.3919
Train: [60][2000/10010]	Time 0.541 (1083.299)	Data 0.001 (2.576)	Loss 1.533	Prec@1 64.4225	Prec@5 84.4539
Train: [60][2200/10010]	Time 0.541 (1191.337)	Data 0.001 (2.706)	Loss 1.532	Prec@1 64.4302	Prec@5 84.4740
Train: [60][2400/10010]	Time 0.541 (1299.956)	Data 0.001 (2.849)	Loss 1.527	Prec@1 64.5724	Prec@5 84.5517
Train: [60][2600/10010]	Time 0.541 (1407.822)	Data 0.001 (2.971)	Loss 1.525	Prec@1 64.6347	Prec@5 84.5675
Train: [60][2800/10010]	Time 0.541 (1515.370)	Data 0.001 (3.086)	Loss 1.520	Prec@1 64.7263	Prec@5 84.6308
Train: [60][3000/10010]	Time 0.541 (1622.903)	Data 0.001 (3.201)	Loss 1.518	Prec@1 64.7709	Prec@5 84.6590
Train: [60][3200/10010]	Time 0.541 (1730.475)	Data 0.001 (3.320)	Loss 1.516	Prec@1 64.8201	Prec@5 84.7050
Train: [60][3400/10010]	Time 0.540 (1837.738)	Data 0.001 (3.438)	Loss 1.513	Prec@1 64.8516	Prec@5 84.7439
Train: [60][3600/10010]	Time 0.540 (1944.925)	Data 0.001 (3.557)	Loss 1.511	Prec@1 64.9017	Prec@5 84.7705
Train: [60][3800/10010]	Time 0.540 (2051.961)	Data 0.001 (3.677)	Loss 1.508	Prec@1 64.9730	Prec@5 84.8083
Train: [60][4000/10010]	Time 0.540 (2159.034)	Data 0.001 (3.795)	Loss 1.507	Prec@1 65.0248	Prec@5 84.8229
Train: [60][4200/10010]	Time 0.539 (2266.025)	Data 0.001 (3.911)	Loss 1.505	Prec@1 65.0610	Prec@5 84.8472
Train: [60][4400/10010]	Time 0.539 (2373.323)	Data 0.001 (4.028)	Loss 1.502	Prec@1 65.1143	Prec@5 84.8799
Train: [60][4600/10010]	Time 0.539 (2480.661)	Data 0.001 (4.148)	Loss 1.501	Prec@1 65.1377	Prec@5 84.8909
Train: [60][4800/10010]	Time 0.539 (2587.938)	Data 0.001 (4.262)	Loss 1.500	Prec@1 65.1655	Prec@5 84.9188
Train: [60][5000/10010]	Time 0.539 (2695.069)	Data 0.001 (4.377)	Loss 1.498	Prec@1 65.1966	Prec@5 84.9321
Train: [60][5200/10010]	Time 0.539 (2802.110)	Data 0.001 (4.495)	Loss 1.497	Prec@1 65.2214	Prec@5 84.9503
Train: [60][5400/10010]	Time 0.539 (2909.487)	Data 0.001 (4.613)	Loss 1.495	Prec@1 65.2576	Prec@5 84.9720
Train: [60][5600/10010]	Time 0.539 (3017.080)	Data 0.001 (4.735)	Loss 1.494	Prec@1 65.2808	Prec@5 84.9925
Train: [60][5800/10010]	Time 0.539 (3124.621)	Data 0.001 (4.863)	Loss 1.493	Prec@1 65.2926	Prec@5 85.0019
Train: [60][6000/10010]	Time 0.539 (3232.420)	Data 0.001 (4.993)	Loss 1.491	Prec@1 65.3148	Prec@5 85.0228
Train: [60][6200/10010]	Time 0.539 (3339.683)	Data 0.001 (5.116)	Loss 1.490	Prec@1 65.3520	Prec@5 85.0442
Train: [60][6400/10010]	Time 0.539 (3447.278)	Data 0.001 (5.240)	Loss 1.488	Prec@1 65.3893	Prec@5 85.0674
Train: [60][6600/10010]	Time 0.539 (3554.685)	Data 0.001 (5.362)	Loss 1.487	Prec@1 65.4234	Prec@5 85.0804
Train: [60][6800/10010]	Time 0.538 (3662.317)	Data 0.001 (5.486)	Loss 1.485	Prec@1 65.4537	Prec@5 85.0938
Train: [60][7000/10010]	Time 0.539 (3770.227)	Data 0.001 (5.615)	Loss 1.484	Prec@1 65.4910	Prec@5 85.1112
Train: [60][7200/10010]	Time 0.539 (3878.120)	Data 0.001 (5.742)	Loss 1.484	Prec@1 65.4927	Prec@5 85.1087
Train: [60][7400/10010]	Time 0.538 (3985.376)	Data 0.001 (5.863)	Loss 1.483	Prec@1 65.5053	Prec@5 85.1155
Train: [60][7600/10010]	Time 0.538 (4092.638)	Data 0.001 (5.987)	Loss 1.482	Prec@1 65.5305	Prec@5 85.1277
Train: [60][7800/10010]	Time 0.538 (4199.840)	Data 0.001 (6.106)	Loss 1.482	Prec@1 65.5354	Prec@5 85.1329
Train: [60][8000/10010]	Time 0.538 (4307.168)	Data 0.001 (6.228)	Loss 1.480	Prec@1 65.5711	Prec@5 85.1623
Train: [60][8200/10010]	Time 0.538 (4414.415)	Data 0.001 (6.349)	Loss 1.479	Prec@1 65.5920	Prec@5 85.1688
Train: [60][8400/10010]	Time 0.538 (4521.830)	Data 0.001 (6.476)	Loss 1.478	Prec@1 65.6219	Prec@5 85.1842
Train: [60][8600/10010]	Time 0.538 (4629.343)	Data 0.001 (6.606)	Loss 1.478	Prec@1 65.6339	Prec@5 85.1875
Train: [60][8800/10010]	Time 0.538 (4736.712)	Data 0.001 (6.727)	Loss 1.477	Prec@1 65.6549	Prec@5 85.1984
Train: [60][9000/10010]	Time 0.538 (4844.043)	Data 0.001 (6.849)	Loss 1.476	Prec@1 65.6763	Prec@5 85.2146
Train: [60][9200/10010]	Time 0.538 (4951.497)	Data 0.001 (6.973)	Loss 1.475	Prec@1 65.6948	Prec@5 85.2275
Train: [60][9400/10010]	Time 0.538 (5059.106)	Data 0.001 (7.096)	Loss 1.474	Prec@1 65.7059	Prec@5 85.2363
Train: [60][9600/10010]	Time 0.538 (5166.588)	Data 0.001 (7.216)	Loss 1.473	Prec@1 65.7137	Prec@5 85.2460
Train: [60][9800/10010]	Time 0.538 (5274.490)	Data 0.001 (7.341)	Loss 1.473	Prec@1 65.7284	Prec@5 85.2546
Train: [60][10000/10010]	Time 0.538 (5382.243)	Data 0.001 (7.469)	Loss 1.472	Prec@1 65.7439	Prec@5 85.2680
Train: [60]	Time 5386.627	Data 7.471	Loss 1.472	Prec@1 65.7444	Prec@5 85.2679	
Val: [60]	Time 68.136	Data 1.329	Loss 1.224	Prec@1 69.7160	Prec@5 89.3880	
Best Prec@1: [69.716]	
Starting epoch number: 61 Learning rate: 0.0010000000000000002
Train: [61][0/10010]	Time 1.837 (1.837)	Data 1.236 (1.236)	Loss 1.334	Prec@1 66.4062	Prec@5 87.5000
Train: [61][200/10010]	Time 0.543 (109.221)	Data 0.007 (1.362)	Loss 1.423	Prec@1 66.6317	Prec@5 85.9958
Train: [61][400/10010]	Time 0.540 (216.518)	Data 0.004 (1.486)	Loss 1.426	Prec@1 66.7647	Prec@5 85.9414
Train: [61][600/10010]	Time 0.539 (323.903)	Data 0.003 (1.609)	Loss 1.422	Prec@1 66.8547	Prec@5 85.9908
Train: [61][800/10010]	Time 0.538 (431.089)	Data 0.002 (1.732)	Loss 1.419	Prec@1 66.8881	Prec@5 86.0389
Train: [61][1000/10010]	Time 0.538 (538.114)	Data 0.002 (1.852)	Loss 1.417	Prec@1 66.9565	Prec@5 86.1139
Train: [61][1200/10010]	Time 0.538 (645.606)	Data 0.002 (1.974)	Loss 1.416	Prec@1 67.0054	Prec@5 86.1235
Train: [61][1400/10010]	Time 0.538 (753.446)	Data 0.001 (2.099)	Loss 1.416	Prec@1 67.0146	Prec@5 86.1159
Train: [61][1600/10010]	Time 0.538 (861.058)	Data 0.001 (2.225)	Loss 1.419	Prec@1 66.9840	Prec@5 86.0536
Train: [61][1800/10010]	Time 0.538 (968.737)	Data 0.001 (2.354)	Loss 1.419	Prec@1 66.9797	Prec@5 86.0390
Train: [61][2000/10010]	Time 0.538 (1076.553)	Data 0.001 (2.483)	Loss 1.418	Prec@1 67.0071	Prec@5 86.0523
Train: [61][2200/10010]	Time 0.538 (1184.075)	Data 0.001 (2.604)	Loss 1.418	Prec@1 66.9770	Prec@5 86.0436
Train: [61][2400/10010]	Time 0.538 (1291.561)	Data 0.001 (2.724)	Loss 1.419	Prec@1 66.9627	Prec@5 86.0146
Train: [61][2600/10010]	Time 0.538 (1399.105)	Data 0.001 (2.852)	Loss 1.421	Prec@1 66.9070	Prec@5 85.9844
Train: [61][2800/10010]	Time 0.538 (1507.330)	Data 0.001 (2.988)	Loss 1.421	Prec@1 66.8918	Prec@5 85.9916
Train: [61][3000/10010]	Time 0.538 (1615.765)	Data 0.001 (3.127)	Loss 1.422	Prec@1 66.8790	Prec@5 85.9719
Train: [61][3200/10010]	Time 0.539 (1724.232)	Data 0.001 (3.267)	Loss 1.421	Prec@1 66.8985	Prec@5 85.9724
Train: [61][3400/10010]	Time 0.539 (1832.603)	Data 0.001 (3.407)	Loss 1.420	Prec@1 66.9146	Prec@5 85.9697
Train: [61][3600/10010]	Time 0.539 (1940.589)	Data 0.001 (3.541)	Loss 1.422	Prec@1 66.8818	Prec@5 85.9507
Train: [61][3800/10010]	Time 0.539 (2048.487)	Data 0.001 (3.670)	Loss 1.422	Prec@1 66.8765	Prec@5 85.9476
Train: [61][4000/10010]	Time 0.539 (2156.316)	Data 0.001 (3.796)	Loss 1.423	Prec@1 66.8487	Prec@5 85.9389
Train: [61][4200/10010]	Time 0.539 (2264.024)	Data 0.001 (3.920)	Loss 1.422	Prec@1 66.8595	Prec@5 85.9539
Train: [61][4400/10010]	Time 0.539 (2371.365)	Data 0.001 (4.041)	Loss 1.423	Prec@1 66.8465	Prec@5 85.9403
Train: [61][4600/10010]	Time 0.539 (2478.841)	Data 0.001 (4.161)	Loss 1.423	Prec@1 66.8212	Prec@5 85.9346
Train: [61][4800/10010]	Time 0.539 (2586.338)	Data 0.001 (4.281)	Loss 1.423	Prec@1 66.8136	Prec@5 85.9390
Train: [61][5000/10010]	Time 0.539 (2693.611)	Data 0.001 (4.405)	Loss 1.422	Prec@1 66.8237	Prec@5 85.9441
Train: [61][5200/10010]	Time 0.539 (2801.064)	Data 0.001 (4.529)	Loss 1.421	Prec@1 66.8386	Prec@5 85.9533
Train: [61][5400/10010]	Time 0.538 (2908.184)	Data 0.001 (4.650)	Loss 1.421	Prec@1 66.8487	Prec@5 85.9518
Train: [61][5600/10010]	Time 0.538 (3016.080)	Data 0.001 (4.778)	Loss 1.420	Prec@1 66.8679	Prec@5 85.9650
Train: [61][5800/10010]	Time 0.538 (3123.392)	Data 0.001 (4.900)	Loss 1.420	Prec@1 66.8514	Prec@5 85.9631
Train: [61][6000/10010]	Time 0.538 (3230.713)	Data 0.001 (5.027)	Loss 1.420	Prec@1 66.8445	Prec@5 85.9621
Train: [61][6200/10010]	Time 0.538 (3338.003)	Data 0.001 (5.152)	Loss 1.420	Prec@1 66.8400	Prec@5 85.9526
Train: [61][6400/10010]	Time 0.538 (3445.437)	Data 0.001 (5.278)	Loss 1.420	Prec@1 66.8534	Prec@5 85.9525
Train: [61][6600/10010]	Time 0.538 (3552.997)	Data 0.001 (5.402)	Loss 1.420	Prec@1 66.8550	Prec@5 85.9554
Train: [61][6800/10010]	Time 0.538 (3660.618)	Data 0.001 (5.530)	Loss 1.420	Prec@1 66.8595	Prec@5 85.9571
Train: [61][7000/10010]	Time 0.538 (3768.275)	Data 0.001 (5.654)	Loss 1.420	Prec@1 66.8710	Prec@5 85.9595
Train: [61][7200/10010]	Time 0.538 (3875.868)	Data 0.001 (5.778)	Loss 1.419	Prec@1 66.8821	Prec@5 85.9592
Train: [61][7400/10010]	Time 0.538 (3983.626)	Data 0.001 (5.904)	Loss 1.419	Prec@1 66.8922	Prec@5 85.9716
Train: [61][7600/10010]	Time 0.538 (4091.371)	Data 0.001 (6.029)	Loss 1.419	Prec@1 66.8815	Prec@5 85.9626
Train: [61][7800/10010]	Time 0.538 (4198.974)	Data 0.001 (6.159)	Loss 1.419	Prec@1 66.8842	Prec@5 85.9643
Train: [61][8000/10010]	Time 0.538 (4306.510)	Data 0.001 (6.285)	Loss 1.419	Prec@1 66.8837	Prec@5 85.9608
Train: [61][8200/10010]	Time 0.538 (4413.906)	Data 0.001 (6.407)	Loss 1.419	Prec@1 66.8827	Prec@5 85.9655
Train: [61][8400/10010]	Time 0.538 (4521.496)	Data 0.001 (6.529)	Loss 1.419	Prec@1 66.8984	Prec@5 85.9740
Train: [61][8600/10010]	Time 0.538 (4628.852)	Data 0.001 (6.653)	Loss 1.418	Prec@1 66.9083	Prec@5 85.9780
Train: [61][8800/10010]	Time 0.538 (4736.082)	Data 0.001 (6.774)	Loss 1.418	Prec@1 66.9231	Prec@5 85.9832
Train: [61][9000/10010]	Time 0.538 (4843.214)	Data 0.001 (6.893)	Loss 1.418	Prec@1 66.9284	Prec@5 85.9805
Train: [61][9200/10010]	Time 0.538 (4950.562)	Data 0.001 (7.016)	Loss 1.418	Prec@1 66.9327	Prec@5 85.9727
Train: [61][9400/10010]	Time 0.538 (5058.195)	Data 0.001 (7.143)	Loss 1.418	Prec@1 66.9377	Prec@5 85.9759
Train: [61][9600/10010]	Time 0.538 (5165.929)	Data 0.001 (7.269)	Loss 1.418	Prec@1 66.9429	Prec@5 85.9716
Train: [61][9800/10010]	Time 0.538 (5273.496)	Data 0.001 (7.394)	Loss 1.417	Prec@1 66.9510	Prec@5 85.9734
Train: [61][10000/10010]	Time 0.538 (5381.238)	Data 0.001 (7.517)	Loss 1.417	Prec@1 66.9544	Prec@5 85.9818
Train: [61]	Time 5385.564	Data 7.519	Loss 1.417	Prec@1 66.9563	Prec@5 85.9825	
Val: [61]	Time 68.294	Data 1.580	Loss 1.205	Prec@1 70.0540	Prec@5 89.6060	
Best Prec@1: [70.054]	
Starting epoch number: 62 Learning rate: 0.0010000000000000002
Train: [62][0/10010]	Time 1.868 (1.868)	Data 1.317 (1.317)	Loss 0.988	Prec@1 75.7812	Prec@5 94.5312
Train: [62][200/10010]	Time 0.546 (109.831)	Data 0.007 (1.448)	Loss 1.378	Prec@1 67.8444	Prec@5 86.4350
Train: [62][400/10010]	Time 0.543 (217.624)	Data 0.004 (1.575)	Loss 1.384	Prec@1 67.6979	Prec@5 86.4382
Train: [62][600/10010]	Time 0.541 (325.250)	Data 0.003 (1.698)	Loss 1.385	Prec@1 67.5762	Prec@5 86.3639
Train: [62][800/10010]	Time 0.540 (432.827)	Data 0.002 (1.819)	Loss 1.389	Prec@1 67.5025	Prec@5 86.3140
Train: [62][1000/10010]	Time 0.540 (540.198)	Data 0.002 (1.939)	Loss 1.389	Prec@1 67.4490	Prec@5 86.3387
Train: [62][1200/10010]	Time 0.539 (647.862)	Data 0.002 (2.066)	Loss 1.388	Prec@1 67.5290	Prec@5 86.3805
Train: [62][1400/10010]	Time 0.539 (755.523)	Data 0.002 (2.190)	Loss 1.388	Prec@1 67.5171	Prec@5 86.3831
Train: [62][1600/10010]	Time 0.539 (862.982)	Data 0.001 (2.314)	Loss 1.389	Prec@1 67.4944	Prec@5 86.3820
Train: [62][1800/10010]	Time 0.539 (970.553)	Data 0.001 (2.440)	Loss 1.388	Prec@1 67.4825	Prec@5 86.3882
Train: [62][2000/10010]	Time 0.539 (1079.008)	Data 0.001 (2.590)	Loss 1.388	Prec@1 67.4995	Prec@5 86.3982
Train: [62][2200/10010]	Time 0.539 (1187.133)	Data 0.001 (2.727)	Loss 1.389	Prec@1 67.4789	Prec@5 86.3808
Train: [62][2400/10010]	Time 0.540 (1296.101)	Data 0.001 (2.887)	Loss 1.389	Prec@1 67.4634	Prec@5 86.3647
Train: [62][2600/10010]	Time 0.540 (1405.112)	Data 0.001 (3.046)	Loss 1.390	Prec@1 67.4443	Prec@5 86.3502
Train: [62][2800/10010]	Time 0.540 (1513.791)	Data 0.001 (3.193)	Loss 1.390	Prec@1 67.4346	Prec@5 86.3517
Train: [62][3000/10010]	Time 0.541 (1622.500)	Data 0.001 (3.339)	Loss 1.392	Prec@1 67.4122	Prec@5 86.3181
Train: [62][3200/10010]	Time 0.541 (1731.005)	Data 0.001 (3.478)	Loss 1.393	Prec@1 67.3847	Prec@5 86.2885
Train: [62][3400/10010]	Time 0.541 (1838.546)	Data 0.001 (3.600)	Loss 1.392	Prec@1 67.3903	Prec@5 86.3163
Train: [62][3600/10010]	Time 0.540 (1946.089)	Data 0.001 (3.720)	Loss 1.392	Prec@1 67.3886	Prec@5 86.3137
Train: [62][3800/10010]	Time 0.541 (2054.872)	Data 0.001 (3.837)	Loss 1.391	Prec@1 67.3754	Prec@5 86.3204
Train: [62][4000/10010]	Time 0.540 (2162.534)	Data 0.001 (3.959)	Loss 1.391	Prec@1 67.3941	Prec@5 86.3444
Train: [62][4200/10010]	Time 0.540 (2270.036)	Data 0.001 (4.079)	Loss 1.391	Prec@1 67.3783	Prec@5 86.3288
Train: [62][4400/10010]	Time 0.540 (2377.419)	Data 0.001 (4.198)	Loss 1.391	Prec@1 67.3845	Prec@5 86.3199
Train: [62][4600/10010]	Time 0.540 (2484.888)	Data 0.001 (4.319)	Loss 1.392	Prec@1 67.4003	Prec@5 86.3165
Train: [62][4800/10010]	Time 0.540 (2592.410)	Data 0.001 (4.440)	Loss 1.391	Prec@1 67.4082	Prec@5 86.3075
Train: [62][5000/10010]	Time 0.540 (2699.918)	Data 0.001 (4.562)	Loss 1.392	Prec@1 67.3862	Prec@5 86.3143
Train: [62][5200/10010]	Time 0.540 (2807.410)	Data 0.001 (4.688)	Loss 1.392	Prec@1 67.3805	Prec@5 86.3054
Train: [62][5400/10010]	Time 0.540 (2914.928)	Data 0.001 (4.811)	Loss 1.392	Prec@1 67.3877	Prec@5 86.3090
Train: [62][5600/10010]	Time 0.540 (3022.871)	Data 0.001 (4.949)	Loss 1.391	Prec@1 67.3951	Prec@5 86.3258
Train: [62][5800/10010]	Time 0.540 (3130.166)	Data 0.001 (5.066)	Loss 1.392	Prec@1 67.4050	Prec@5 86.3275
Train: [62][6000/10010]	Time 0.539 (3237.378)	Data 0.001 (5.185)	Loss 1.392	Prec@1 67.3918	Prec@5 86.3258
Train: [62][6200/10010]	Time 0.539 (3344.757)	Data 0.001 (5.302)	Loss 1.392	Prec@1 67.3921	Prec@5 86.3253
Train: [62][6400/10010]	Time 0.539 (3451.972)	Data 0.001 (5.417)	Loss 1.393	Prec@1 67.4002	Prec@5 86.3229
Train: [62][6600/10010]	Time 0.539 (3559.537)	Data 0.001 (5.540)	Loss 1.392	Prec@1 67.4130	Prec@5 86.3240
Train: [62][6800/10010]	Time 0.539 (3666.981)	Data 0.001 (5.663)	Loss 1.392	Prec@1 67.4124	Prec@5 86.3258
Train: [62][7000/10010]	Time 0.539 (3774.646)	Data 0.001 (5.785)	Loss 1.392	Prec@1 67.4080	Prec@5 86.3216
Train: [62][7200/10010]	Time 0.539 (3882.503)	Data 0.001 (5.911)	Loss 1.393	Prec@1 67.4023	Prec@5 86.3151
Train: [62][7400/10010]	Time 0.539 (3990.156)	Data 0.001 (6.033)	Loss 1.393	Prec@1 67.4057	Prec@5 86.3173
Train: [62][7600/10010]	Time 0.539 (4097.920)	Data 0.001 (6.154)	Loss 1.393	Prec@1 67.4128	Prec@5 86.3232
Train: [62][7800/10010]	Time 0.539 (4205.556)	Data 0.001 (6.271)	Loss 1.393	Prec@1 67.4038	Prec@5 86.3170
Train: [62][8000/10010]	Time 0.539 (4313.115)	Data 0.001 (6.388)	Loss 1.393	Prec@1 67.3916	Prec@5 86.3101
Train: [62][8200/10010]	Time 0.539 (4420.773)	Data 0.001 (6.507)	Loss 1.393	Prec@1 67.3975	Prec@5 86.3083
Train: [62][8400/10010]	Time 0.539 (4528.221)	Data 0.001 (6.625)	Loss 1.393	Prec@1 67.4027	Prec@5 86.3108
Train: [62][8600/10010]	Time 0.539 (4635.779)	Data 0.001 (6.749)	Loss 1.393	Prec@1 67.4065	Prec@5 86.3064
Train: [62][8800/10010]	Time 0.539 (4743.407)	Data 0.001 (6.872)	Loss 1.393	Prec@1 67.4057	Prec@5 86.3038
Train: [62][9000/10010]	Time 0.539 (4851.054)	Data 0.001 (6.995)	Loss 1.393	Prec@1 67.4043	Prec@5 86.3055
Train: [62][9200/10010]	Time 0.539 (4958.519)	Data 0.001 (7.116)	Loss 1.393	Prec@1 67.3996	Prec@5 86.3042
Train: [62][9400/10010]	Time 0.539 (5065.708)	Data 0.001 (7.236)	Loss 1.394	Prec@1 67.4028	Prec@5 86.2963
Train: [62][9600/10010]	Time 0.539 (5172.943)	Data 0.001 (7.354)	Loss 1.393	Prec@1 67.4133	Prec@5 86.3010
Train: [62][9800/10010]	Time 0.539 (5280.338)	Data 0.001 (7.472)	Loss 1.394	Prec@1 67.4078	Prec@5 86.2980
Train: [62][10000/10010]	Time 0.539 (5387.443)	Data 0.001 (7.586)	Loss 1.393	Prec@1 67.4135	Prec@5 86.3054
Train: [62]	Time 5391.967	Data 7.588	Loss 1.393	Prec@1 67.4144	Prec@5 86.3069	
Val: [62]	Time 67.919	Data 1.431	Loss 1.182	Prec@1 70.6160	Prec@5 90.0400	
Best Prec@1: [70.616]	
Starting epoch number: 63 Learning rate: 0.0010000000000000002
Train: [63][0/10010]	Time 1.796 (1.796)	Data 1.224 (1.224)	Loss 1.205	Prec@1 75.0000	Prec@5 89.0625
Train: [63][200/10010]	Time 0.542 (109.026)	Data 0.007 (1.351)	Loss 1.387	Prec@1 67.5023	Prec@5 86.3223
Train: [63][400/10010]	Time 0.539 (216.269)	Data 0.004 (1.471)	Loss 1.383	Prec@1 67.7057	Prec@5 86.4363
Train: [63][600/10010]	Time 0.539 (323.671)	Data 0.003 (1.591)	Loss 1.375	Prec@1 67.8453	Prec@5 86.5511
Train: [63][800/10010]	Time 0.538 (431.154)	Data 0.002 (1.713)	Loss 1.376	Prec@1 67.7971	Prec@5 86.5383
Train: [63][1000/10010]	Time 0.538 (538.484)	Data 0.002 (1.831)	Loss 1.379	Prec@1 67.7112	Prec@5 86.4534
Train: [63][1200/10010]	Time 0.538 (645.815)	Data 0.002 (1.950)	Loss 1.377	Prec@1 67.7190	Prec@5 86.4930
Train: [63][1400/10010]	Time 0.538 (753.387)	Data 0.001 (2.074)	Loss 1.379	Prec@1 67.6888	Prec@5 86.4728
Train: [63][1600/10010]	Time 0.538 (860.771)	Data 0.001 (2.194)	Loss 1.380	Prec@1 67.6608	Prec@5 86.4660
Train: [63][1800/10010]	Time 0.538 (968.229)	Data 0.001 (2.311)	Loss 1.378	Prec@1 67.7293	Prec@5 86.4789
Train: [63][2000/10010]	Time 0.537 (1075.501)	Data 0.001 (2.424)	Loss 1.381	Prec@1 67.7228	Prec@5 86.4259
Train: [63][2200/10010]	Time 0.537 (1182.823)	Data 0.001 (2.539)	Loss 1.379	Prec@1 67.7054	Prec@5 86.4341
Train: [63][2400/10010]	Time 0.537 (1290.012)	Data 0.001 (2.653)	Loss 1.379	Prec@1 67.6964	Prec@5 86.4282
Train: [63][2600/10010]	Time 0.537 (1397.095)	Data 0.001 (2.769)	Loss 1.379	Prec@1 67.7065	Prec@5 86.4346
Train: [63][2800/10010]	Time 0.537 (1504.165)	Data 0.001 (2.882)	Loss 1.379	Prec@1 67.7272	Prec@5 86.4309
Train: [63][3000/10010]	Time 0.537 (1611.429)	Data 0.001 (3.000)	Loss 1.378	Prec@1 67.7436	Prec@5 86.4511
Train: [63][3200/10010]	Time 0.537 (1718.358)	Data 0.001 (3.115)	Loss 1.378	Prec@1 67.7459	Prec@5 86.4510
Train: [63][3400/10010]	Time 0.537 (1825.385)	Data 0.001 (3.231)	Loss 1.378	Prec@1 67.7452	Prec@5 86.4516
Train: [63][3600/10010]	Time 0.537 (1932.715)	Data 0.001 (3.352)	Loss 1.378	Prec@1 67.7611	Prec@5 86.4521
Train: [63][3800/10010]	Time 0.537 (2040.271)	Data 0.001 (3.477)	Loss 1.378	Prec@1 67.7677	Prec@5 86.4600
Train: [63][4000/10010]	Time 0.537 (2147.685)	Data 0.001 (3.599)	Loss 1.378	Prec@1 67.7645	Prec@5 86.4590
Train: [63][4200/10010]	Time 0.537 (2254.941)	Data 0.001 (3.718)	Loss 1.378	Prec@1 67.7603	Prec@5 86.4630
Train: [63][4400/10010]	Time 0.537 (2362.353)	Data 0.001 (3.837)	Loss 1.379	Prec@1 67.7470	Prec@5 86.4573
Train: [63][4600/10010]	Time 0.537 (2470.026)	Data 0.001 (3.962)	Loss 1.379	Prec@1 67.7465	Prec@5 86.4590
Train: [63][4800/10010]	Time 0.537 (2577.546)	Data 0.001 (4.081)	Loss 1.378	Prec@1 67.7603	Prec@5 86.4651
Train: [63][5000/10010]	Time 0.537 (2685.095)	Data 0.001 (4.203)	Loss 1.378	Prec@1 67.7480	Prec@5 86.4533
Train: [63][5200/10010]	Time 0.537 (2792.697)	Data 0.001 (4.325)	Loss 1.378	Prec@1 67.7454	Prec@5 86.4619
Train: [63][5400/10010]	Time 0.537 (2900.474)	Data 0.001 (4.447)	Loss 1.378	Prec@1 67.7547	Prec@5 86.4713
Train: [63][5600/10010]	Time 0.537 (3008.183)	Data 0.001 (4.572)	Loss 1.378	Prec@1 67.7591	Prec@5 86.4703
Train: [63][5800/10010]	Time 0.537 (3115.932)	Data 0.001 (4.694)	Loss 1.378	Prec@1 67.7569	Prec@5 86.4615
Train: [63][6000/10010]	Time 0.537 (3223.749)	Data 0.001 (4.819)	Loss 1.378	Prec@1 67.7698	Prec@5 86.4681
Train: [63][6200/10010]	Time 0.537 (3331.498)	Data 0.001 (4.945)	Loss 1.378	Prec@1 67.7620	Prec@5 86.4675
Train: [63][6400/10010]	Time 0.537 (3439.459)	Data 0.001 (5.071)	Loss 1.378	Prec@1 67.7697	Prec@5 86.4701
Train: [63][6600/10010]	Time 0.537 (3547.006)	Data 0.001 (5.197)	Loss 1.377	Prec@1 67.7773	Prec@5 86.4849
Train: [63][6800/10010]	Time 0.537 (3654.413)	Data 0.001 (5.319)	Loss 1.377	Prec@1 67.7730	Prec@5 86.4899
Train: [63][7000/10010]	Time 0.537 (3761.969)	Data 0.001 (5.442)	Loss 1.378	Prec@1 67.7786	Prec@5 86.4879
Train: [63][7200/10010]	Time 0.537 (3869.315)	Data 0.001 (5.564)	Loss 1.378	Prec@1 67.7672	Prec@5 86.4805
Train: [63][7400/10010]	Time 0.537 (3976.624)	Data 0.001 (5.684)	Loss 1.378	Prec@1 67.7604	Prec@5 86.4799
Train: [63][7600/10010]	Time 0.537 (4083.944)	Data 0.001 (5.806)	Loss 1.378	Prec@1 67.7476	Prec@5 86.4852
Train: [63][7800/10010]	Time 0.537 (4191.209)	Data 0.001 (5.931)	Loss 1.378	Prec@1 67.7458	Prec@5 86.4897
Train: [63][8000/10010]	Time 0.537 (4298.650)	Data 0.001 (6.053)	Loss 1.377	Prec@1 67.7528	Prec@5 86.4982
Train: [63][8200/10010]	Time 0.537 (4406.177)	Data 0.001 (6.178)	Loss 1.378	Prec@1 67.7475	Prec@5 86.4930
Train: [63][8400/10010]	Time 0.537 (4513.738)	Data 0.001 (6.302)	Loss 1.378	Prec@1 67.7405	Prec@5 86.4880
Train: [63][8600/10010]	Time 0.537 (4621.188)	Data 0.001 (6.427)	Loss 1.378	Prec@1 67.7367	Prec@5 86.4909
Train: [63][8800/10010]	Time 0.537 (4728.970)	Data 0.001 (6.553)	Loss 1.378	Prec@1 67.7388	Prec@5 86.4947
Train: [63][9000/10010]	Time 0.537 (4836.716)	Data 0.001 (6.681)	Loss 1.378	Prec@1 67.7352	Prec@5 86.5019
Train: [63][9200/10010]	Time 0.537 (4944.627)	Data 0.001 (6.810)	Loss 1.378	Prec@1 67.7225	Prec@5 86.4975
Train: [63][9400/10010]	Time 0.537 (5052.387)	Data 0.001 (6.942)	Loss 1.378	Prec@1 67.7184	Prec@5 86.4926
Train: [63][9600/10010]	Time 0.537 (5159.715)	Data 0.001 (7.061)	Loss 1.378	Prec@1 67.7119	Prec@5 86.4931
Train: [63][9800/10010]	Time 0.537 (5267.017)	Data 0.001 (7.178)	Loss 1.378	Prec@1 67.7259	Prec@5 86.5024
Train: [63][10000/10010]	Time 0.537 (5374.492)	Data 0.001 (7.296)	Loss 1.378	Prec@1 67.7242	Prec@5 86.5032
Train: [63]	Time 5378.814	Data 7.298	Loss 1.378	Prec@1 67.7218	Prec@5 86.5013	
Val: [63]	Time 68.077	Data 1.429	Loss 1.184	Prec@1 70.6040	Prec@5 89.8920	
Best Prec@1: [70.616]	
Starting epoch number: 64 Learning rate: 0.0010000000000000002
Train: [64][0/10010]	Time 1.852 (1.852)	Data 1.292 (1.292)	Loss 0.912	Prec@1 73.4375	Prec@5 92.9688
Train: [64][200/10010]	Time 0.543 (109.160)	Data 0.007 (1.418)	Loss 1.345	Prec@1 68.6762	Prec@5 86.7537
Train: [64][400/10010]	Time 0.540 (216.497)	Data 0.004 (1.538)	Loss 1.354	Prec@1 68.3292	Prec@5 86.7188
Train: [64][600/10010]	Time 0.539 (323.775)	Data 0.003 (1.655)	Loss 1.353	Prec@1 68.3535	Prec@5 86.8045
Train: [64][800/10010]	Time 0.538 (431.314)	Data 0.002 (1.776)	Loss 1.352	Prec@1 68.3072	Prec@5 86.8338
Train: [64][1000/10010]	Time 0.538 (538.738)	Data 0.002 (1.893)	Loss 1.352	Prec@1 68.3223	Prec@5 86.8077
Train: [64][1200/10010]	Time 0.538 (646.144)	Data 0.002 (2.012)	Loss 1.355	Prec@1 68.2888	Prec@5 86.7545
Train: [64][1400/10010]	Time 0.538 (753.522)	Data 0.002 (2.130)	Loss 1.354	Prec@1 68.3262	Prec@5 86.7316
Train: [64][1600/10010]	Time 0.538 (861.011)	Data 0.001 (2.246)	Loss 1.356	Prec@1 68.2406	Prec@5 86.6968
Train: [64][1800/10010]	Time 0.538 (968.642)	Data 0.001 (2.365)	Loss 1.356	Prec@1 68.1943	Prec@5 86.7279
Train: [64][2000/10010]	Time 0.538 (1076.226)	Data 0.001 (2.488)	Loss 1.358	Prec@1 68.1573	Prec@5 86.7086
Train: [64][2200/10010]	Time 0.538 (1183.779)	Data 0.001 (2.613)	Loss 1.360	Prec@1 68.1157	Prec@5 86.6676
Train: [64][2400/10010]	Time 0.538 (1291.205)	Data 0.001 (2.736)	Loss 1.360	Prec@1 68.1168	Prec@5 86.6641
Train: [64][2600/10010]	Time 0.538 (1398.605)	Data 0.001 (2.858)	Loss 1.361	Prec@1 68.0967	Prec@5 86.6578
Train: [64][2800/10010]	Time 0.538 (1506.082)	Data 0.001 (2.980)	Loss 1.360	Prec@1 68.1107	Prec@5 86.6655
Train: [64][3000/10010]	Time 0.538 (1613.437)	Data 0.001 (3.103)	Loss 1.361	Prec@1 68.0968	Prec@5 86.6654
Train: [64][3200/10010]	Time 0.538 (1720.833)	Data 0.001 (3.227)	Loss 1.362	Prec@1 68.0891	Prec@5 86.6487
Train: [64][3400/10010]	Time 0.538 (1828.209)	Data 0.001 (3.349)	Loss 1.362	Prec@1 68.1031	Prec@5 86.6342
Train: [64][3600/10010]	Time 0.538 (1935.632)	Data 0.001 (3.468)	Loss 1.362	Prec@1 68.0994	Prec@5 86.6326
Train: [64][3800/10010]	Time 0.538 (2043.145)	Data 0.001 (3.589)	Loss 1.362	Prec@1 68.1028	Prec@5 86.6404
Train: [64][4000/10010]	Time 0.538 (2150.628)	Data 0.001 (3.712)	Loss 1.363	Prec@1 68.0556	Prec@5 86.6207
Train: [64][4200/10010]	Time 0.538 (2258.049)	Data 0.001 (3.834)	Loss 1.363	Prec@1 68.0645	Prec@5 86.6325
Train: [64][4400/10010]	Time 0.538 (2365.656)	Data 0.001 (3.958)	Loss 1.364	Prec@1 68.0586	Prec@5 86.6252
Train: [64][4600/10010]	Time 0.538 (2473.672)	Data 0.001 (4.091)	Loss 1.364	Prec@1 68.0516	Prec@5 86.6230
Train: [64][4800/10010]	Time 0.538 (2581.294)	Data 0.001 (4.217)	Loss 1.364	Prec@1 68.0597	Prec@5 86.6164
Train: [64][5000/10010]	Time 0.538 (2688.738)	Data 0.001 (4.341)	Loss 1.364	Prec@1 68.0469	Prec@5 86.6231
Train: [64][5200/10010]	Time 0.538 (2796.714)	Data 0.001 (4.477)	Loss 1.364	Prec@1 68.0351	Prec@5 86.6298
Train: [64][5400/10010]	Time 0.538 (2904.445)	Data 0.001 (4.605)	Loss 1.364	Prec@1 68.0461	Prec@5 86.6364
Train: [64][5600/10010]	Time 0.538 (3012.566)	Data 0.001 (4.732)	Loss 1.364	Prec@1 68.0561	Prec@5 86.6292
Train: [64][5800/10010]	Time 0.538 (3120.269)	Data 0.001 (4.856)	Loss 1.364	Prec@1 68.0563	Prec@5 86.6371
Train: [64][6000/10010]	Time 0.538 (3227.961)	Data 0.001 (4.979)	Loss 1.365	Prec@1 68.0491	Prec@5 86.6195
Train: [64][6200/10010]	Time 0.538 (3335.648)	Data 0.001 (5.102)	Loss 1.365	Prec@1 68.0471	Prec@5 86.6196
Train: [64][6400/10010]	Time 0.538 (3443.333)	Data 0.001 (5.227)	Loss 1.365	Prec@1 68.0452	Prec@5 86.6259
Train: [64][6600/10010]	Time 0.538 (3551.028)	Data 0.001 (5.350)	Loss 1.364	Prec@1 68.0554	Prec@5 86.6337
Train: [64][6800/10010]	Time 0.538 (3658.825)	Data 0.001 (5.475)	Loss 1.364	Prec@1 68.0466	Prec@5 86.6379
Train: [64][7000/10010]	Time 0.538 (3766.607)	Data 0.001 (5.602)	Loss 1.365	Prec@1 68.0418	Prec@5 86.6343
Train: [64][7200/10010]	Time 0.538 (3874.101)	Data 0.001 (5.725)	Loss 1.364	Prec@1 68.0589	Prec@5 86.6419
Train: [64][7400/10010]	Time 0.538 (3981.531)	Data 0.001 (5.851)	Loss 1.364	Prec@1 68.0575	Prec@5 86.6486
Train: [64][7600/10010]	Time 0.538 (4089.213)	Data 0.001 (5.979)	Loss 1.364	Prec@1 68.0596	Prec@5 86.6514
Train: [64][7800/10010]	Time 0.538 (4196.553)	Data 0.001 (6.102)	Loss 1.364	Prec@1 68.0484	Prec@5 86.6489
Train: [64][8000/10010]	Time 0.538 (4303.851)	Data 0.001 (6.225)	Loss 1.364	Prec@1 68.0572	Prec@5 86.6534
Train: [64][8200/10010]	Time 0.538 (4411.620)	Data 0.001 (6.350)	Loss 1.364	Prec@1 68.0669	Prec@5 86.6624
Train: [64][8400/10010]	Time 0.538 (4518.972)	Data 0.001 (6.476)	Loss 1.364	Prec@1 68.0590	Prec@5 86.6575
Train: [64][8600/10010]	Time 0.538 (4626.349)	Data 0.001 (6.601)	Loss 1.365	Prec@1 68.0586	Prec@5 86.6494
Train: [64][8800/10010]	Time 0.538 (4733.753)	Data 0.001 (6.725)	Loss 1.365	Prec@1 68.0485	Prec@5 86.6462
Train: [64][9000/10010]	Time 0.538 (4841.262)	Data 0.001 (6.850)	Loss 1.365	Prec@1 68.0577	Prec@5 86.6517
Train: [64][9200/10010]	Time 0.538 (4949.027)	Data 0.001 (6.978)	Loss 1.365	Prec@1 68.0565	Prec@5 86.6557
Train: [64][9400/10010]	Time 0.538 (5056.685)	Data 0.001 (7.107)	Loss 1.365	Prec@1 68.0463	Prec@5 86.6552
Train: [64][9600/10010]	Time 0.538 (5164.199)	Data 0.001 (7.231)	Loss 1.365	Prec@1 68.0373	Prec@5 86.6517
Train: [64][9800/10010]	Time 0.538 (5272.084)	Data 0.001 (7.361)	Loss 1.365	Prec@1 68.0428	Prec@5 86.6560
Train: [64][10000/10010]	Time 0.538 (5379.791)	Data 0.001 (7.488)	Loss 1.365	Prec@1 68.0402	Prec@5 86.6595
Train: [64]	Time 5384.197	Data 7.490	Loss 1.365	Prec@1 68.0417	Prec@5 86.6612	
Val: [64]	Time 68.021	Data 1.569	Loss 1.196	Prec@1 70.4240	Prec@5 89.7800	
Best Prec@1: [70.616]	
Starting epoch number: 65 Learning rate: 0.0010000000000000002
Train: [65][0/10010]	Time 1.756 (1.756)	Data 1.195 (1.195)	Loss 1.243	Prec@1 71.8750	Prec@5 89.8438
Train: [65][200/10010]	Time 0.550 (110.597)	Data 0.007 (1.327)	Loss 1.382	Prec@1 67.8716	Prec@5 86.3262
Train: [65][400/10010]	Time 0.548 (219.625)	Data 0.004 (1.458)	Loss 1.372	Prec@1 67.8460	Prec@5 86.5648
Train: [65][600/10010]	Time 0.546 (328.281)	Data 0.003 (1.584)	Loss 1.370	Prec@1 67.9649	Prec@5 86.5355
Train: [65][800/10010]	Time 0.544 (435.894)	Data 0.002 (1.708)	Loss 1.366	Prec@1 68.0107	Prec@5 86.6710
Train: [65][1000/10010]	Time 0.543 (543.548)	Data 0.002 (1.828)	Loss 1.360	Prec@1 68.0726	Prec@5 86.7835
Train: [65][1200/10010]	Time 0.542 (651.418)	Data 0.002 (1.953)	Loss 1.358	Prec@1 68.0806	Prec@5 86.8111
Train: [65][1400/10010]	Time 0.542 (759.334)	Data 0.001 (2.084)	Loss 1.356	Prec@1 68.1327	Prec@5 86.8253
Train: [65][1600/10010]	Time 0.542 (867.174)	Data 0.001 (2.211)	Loss 1.357	Prec@1 68.1186	Prec@5 86.8207
Train: [65][1800/10010]	Time 0.541 (974.910)	Data 0.001 (2.333)	Loss 1.355	Prec@1 68.1483	Prec@5 86.8281
Train: [65][2000/10010]	Time 0.541 (1082.482)	Data 0.001 (2.457)	Loss 1.354	Prec@1 68.1952	Prec@5 86.8425
Train: [65][2200/10010]	Time 0.541 (1189.906)	Data 0.001 (2.579)	Loss 1.353	Prec@1 68.2240	Prec@5 86.8735
Train: [65][2400/10010]	Time 0.540 (1297.419)	Data 0.001 (2.702)	Loss 1.354	Prec@1 68.1929	Prec@5 86.8616
Train: [65][2600/10010]	Time 0.540 (1405.187)	Data 0.001 (2.827)	Loss 1.354	Prec@1 68.1817	Prec@5 86.8491
Train: [65][2800/10010]	Time 0.540 (1512.582)	Data 0.001 (2.952)	Loss 1.353	Prec@1 68.2231	Prec@5 86.8582
Train: [65][3000/10010]	Time 0.540 (1619.733)	Data 0.001 (3.072)	Loss 1.353	Prec@1 68.2314	Prec@5 86.8570
Train: [65][3200/10010]	Time 0.540 (1726.966)	Data 0.001 (3.192)	Loss 1.353	Prec@1 68.2311	Prec@5 86.8557
Train: [65][3400/10010]	Time 0.539 (1834.244)	Data 0.001 (3.314)	Loss 1.352	Prec@1 68.2449	Prec@5 86.8708
Train: [65][3600/10010]	Time 0.539 (1941.756)	Data 0.001 (3.440)	Loss 1.352	Prec@1 68.2566	Prec@5 86.8786
Train: [65][3800/10010]	Time 0.539 (2049.271)	Data 0.001 (3.564)	Loss 1.352	Prec@1 68.2596	Prec@5 86.8840
Train: [65][4000/10010]	Time 0.539 (2156.743)	Data 0.001 (3.688)	Loss 1.353	Prec@1 68.2290	Prec@5 86.8593
Train: [65][4200/10010]	Time 0.539 (2264.264)	Data 0.001 (3.811)	Loss 1.353	Prec@1 68.2120	Prec@5 86.8608
Train: [65][4400/10010]	Time 0.539 (2371.783)	Data 0.001 (3.932)	Loss 1.352	Prec@1 68.2361	Prec@5 86.8767
Train: [65][4600/10010]	Time 0.539 (2479.210)	Data 0.001 (4.052)	Loss 1.353	Prec@1 68.2437	Prec@5 86.8804
Train: [65][4800/10010]	Time 0.539 (2586.302)	Data 0.001 (4.168)	Loss 1.353	Prec@1 68.2252	Prec@5 86.8693
Train: [65][5000/10010]	Time 0.539 (2693.813)	Data 0.001 (4.290)	Loss 1.354	Prec@1 68.2082	Prec@5 86.8637
Train: [65][5200/10010]	Time 0.539 (2801.466)	Data 0.001 (4.413)	Loss 1.354	Prec@1 68.2241	Prec@5 86.8551
Train: [65][5400/10010]	Time 0.539 (2909.076)	Data 0.001 (4.533)	Loss 1.354	Prec@1 68.2232	Prec@5 86.8502
Train: [65][5600/10010]	Time 0.539 (3016.939)	Data 0.001 (4.659)	Loss 1.354	Prec@1 68.2121	Prec@5 86.8493
Train: [65][5800/10010]	Time 0.539 (3124.881)	Data 0.001 (4.785)	Loss 1.354	Prec@1 68.2094	Prec@5 86.8510
Train: [65][6000/10010]	Time 0.539 (3232.758)	Data 0.001 (4.913)	Loss 1.354	Prec@1 68.2070	Prec@5 86.8431
Train: [65][6200/10010]	Time 0.539 (3340.649)	Data 0.001 (5.039)	Loss 1.354	Prec@1 68.2050	Prec@5 86.8459
Train: [65][6400/10010]	Time 0.539 (3448.493)	Data 0.001 (5.162)	Loss 1.354	Prec@1 68.2049	Prec@5 86.8502
Train: [65][6600/10010]	Time 0.539 (3556.737)	Data 0.001 (5.291)	Loss 1.354	Prec@1 68.2088	Prec@5 86.8462
Train: [65][6800/10010]	Time 0.539 (3665.073)	Data 0.001 (5.419)	Loss 1.353	Prec@1 68.2173	Prec@5 86.8552
Train: [65][7000/10010]	Time 0.539 (3773.025)	Data 0.001 (5.546)	Loss 1.354	Prec@1 68.2073	Prec@5 86.8446
Train: [65][7200/10010]	Time 0.539 (3880.768)	Data 0.001 (5.666)	Loss 1.354	Prec@1 68.2042	Prec@5 86.8534
Train: [65][7400/10010]	Time 0.539 (3989.030)	Data 0.001 (5.793)	Loss 1.354	Prec@1 68.2176	Prec@5 86.8484
Train: [65][7600/10010]	Time 0.539 (4097.242)	Data 0.001 (5.916)	Loss 1.354	Prec@1 68.2051	Prec@5 86.8427
Train: [65][7800/10010]	Time 0.539 (4205.209)	Data 0.001 (6.039)	Loss 1.354	Prec@1 68.2157	Prec@5 86.8426
Train: [65][8000/10010]	Time 0.539 (4312.969)	Data 0.001 (6.164)	Loss 1.354	Prec@1 68.2031	Prec@5 86.8368
Train: [65][8200/10010]	Time 0.539 (4420.865)	Data 0.001 (6.289)	Loss 1.355	Prec@1 68.2065	Prec@5 86.8317
Train: [65][8400/10010]	Time 0.539 (4529.009)	Data 0.001 (6.412)	Loss 1.355	Prec@1 68.2069	Prec@5 86.8295
Train: [65][8600/10010]	Time 0.539 (4637.071)	Data 0.001 (6.536)	Loss 1.355	Prec@1 68.2065	Prec@5 86.8282
Train: [65][8800/10010]	Time 0.539 (4744.938)	Data 0.001 (6.660)	Loss 1.355	Prec@1 68.1995	Prec@5 86.8167
Train: [65][9000/10010]	Time 0.539 (4852.605)	Data 0.001 (6.784)	Loss 1.356	Prec@1 68.1990	Prec@5 86.8120
Train: [65][9200/10010]	Time 0.539 (4960.322)	Data 0.001 (6.904)	Loss 1.356	Prec@1 68.2049	Prec@5 86.8044
Train: [65][9400/10010]	Time 0.539 (5068.485)	Data 0.001 (7.027)	Loss 1.356	Prec@1 68.2005	Prec@5 86.7988
Train: [65][9600/10010]	Time 0.539 (5176.375)	Data 0.001 (7.151)	Loss 1.356	Prec@1 68.1984	Prec@5 86.7948
Train: [65][9800/10010]	Time 0.539 (5284.063)	Data 0.001 (7.272)	Loss 1.356	Prec@1 68.1873	Prec@5 86.7904
Train: [65][10000/10010]	Time 0.539 (5391.990)	Data 0.001 (7.391)	Loss 1.357	Prec@1 68.1796	Prec@5 86.7820
Train: [65]	Time 5396.370	Data 7.393	Loss 1.357	Prec@1 68.1787	Prec@5 86.7825	
Val: [65]	Time 67.963	Data 1.646	Loss 1.203	Prec@1 70.2180	Prec@5 89.6320	
Best Prec@1: [70.616]	
Starting epoch number: 66 Learning rate: 0.0010000000000000002
Train: [66][0/10010]	Time 1.959 (1.959)	Data 1.307 (1.307)	Loss 1.197	Prec@1 71.8750	Prec@5 85.1562
Train: [66][200/10010]	Time 0.548 (110.076)	Data 0.007 (1.434)	Loss 1.341	Prec@1 68.3730	Prec@5 86.7537
Train: [66][400/10010]	Time 0.543 (217.912)	Data 0.004 (1.558)	Loss 1.337	Prec@1 68.5435	Prec@5 86.9779
Train: [66][600/10010]	Time 0.542 (325.510)	Data 0.003 (1.678)	Loss 1.332	Prec@1 68.6902	Prec@5 87.0515
Train: [66][800/10010]	Time 0.541 (433.134)	Data 0.002 (1.798)	Loss 1.336	Prec@1 68.6417	Prec@5 86.9918
Train: [66][1000/10010]	Time 0.540 (541.021)	Data 0.002 (1.916)	Loss 1.337	Prec@1 68.6087	Prec@5 86.9662
Train: [66][1200/10010]	Time 0.541 (649.290)	Data 0.002 (2.032)	Loss 1.335	Prec@1 68.6219	Prec@5 87.0303
Train: [66][1400/10010]	Time 0.540 (756.890)	Data 0.002 (2.149)	Loss 1.338	Prec@1 68.5743	Prec@5 87.0199
Train: [66][1600/10010]	Time 0.540 (864.753)	Data 0.001 (2.267)	Loss 1.338	Prec@1 68.5958	Prec@5 87.0023
Train: [66][1800/10010]	Time 0.540 (972.735)	Data 0.001 (2.387)	Loss 1.339	Prec@1 68.5834	Prec@5 86.9521
Train: [66][2000/10010]	Time 0.540 (1080.817)	Data 0.001 (2.505)	Loss 1.340	Prec@1 68.5677	Prec@5 86.9511
Train: [66][2200/10010]	Time 0.540 (1188.644)	Data 0.001 (2.627)	Loss 1.340	Prec@1 68.5523	Prec@5 86.9541
Train: [66][2400/10010]	Time 0.540 (1296.349)	Data 0.001 (2.748)	Loss 1.340	Prec@1 68.5619	Prec@5 86.9452
Train: [66][2600/10010]	Time 0.540 (1404.177)	Data 0.001 (2.873)	Loss 1.340	Prec@1 68.5572	Prec@5 86.9792
Train: [66][2800/10010]	Time 0.540 (1512.150)	Data 0.001 (2.995)	Loss 1.341	Prec@1 68.5366	Prec@5 86.9550
Train: [66][3000/10010]	Time 0.540 (1620.006)	Data 0.001 (3.115)	Loss 1.342	Prec@1 68.5175	Prec@5 86.9679
Train: [66][3200/10010]	Time 0.540 (1727.510)	Data 0.001 (3.236)	Loss 1.343	Prec@1 68.4945	Prec@5 86.9623
Train: [66][3400/10010]	Time 0.540 (1835.336)	Data 0.001 (3.360)	Loss 1.343	Prec@1 68.4996	Prec@5 86.9616
Train: [66][3600/10010]	Time 0.540 (1943.356)	Data 0.001 (3.485)	Loss 1.343	Prec@1 68.5081	Prec@5 86.9526
Train: [66][3800/10010]	Time 0.540 (2051.422)	Data 0.001 (3.603)	Loss 1.344	Prec@1 68.5034	Prec@5 86.9516
Train: [66][4000/10010]	Time 0.540 (2159.214)	Data 0.001 (3.721)	Loss 1.344	Prec@1 68.4893	Prec@5 86.9466
Train: [66][4200/10010]	Time 0.540 (2266.448)	Data 0.001 (3.834)	Loss 1.344	Prec@1 68.4781	Prec@5 86.9300
Train: [66][4400/10010]	Time 0.539 (2373.876)	Data 0.001 (3.953)	Loss 1.344	Prec@1 68.4729	Prec@5 86.9316
Train: [66][4600/10010]	Time 0.539 (2481.991)	Data 0.001 (4.074)	Loss 1.344	Prec@1 68.4705	Prec@5 86.9498
Train: [66][4800/10010]	Time 0.539 (2589.894)	Data 0.001 (4.194)	Loss 1.344	Prec@1 68.4634	Prec@5 86.9339
Train: [66][5000/10010]	Time 0.539 (2697.756)	Data 0.001 (4.319)	Loss 1.345	Prec@1 68.4605	Prec@5 86.9328
Train: [66][5200/10010]	Time 0.539 (2805.399)	Data 0.001 (4.441)	Loss 1.345	Prec@1 68.4602	Prec@5 86.9247
Train: [66][5400/10010]	Time 0.539 (2913.277)	Data 0.001 (4.559)	Loss 1.346	Prec@1 68.4416	Prec@5 86.9233
Train: [66][5600/10010]	Time 0.539 (3021.100)	Data 0.001 (4.674)	Loss 1.346	Prec@1 68.4300	Prec@5 86.9197
Train: [66][5800/10010]	Time 0.539 (3128.642)	Data 0.001 (4.791)	Loss 1.346	Prec@1 68.4196	Prec@5 86.9214
Train: [66][6000/10010]	Time 0.539 (3236.065)	Data 0.001 (4.908)	Loss 1.346	Prec@1 68.4139	Prec@5 86.9238
Train: [66][6200/10010]	Time 0.539 (3343.622)	Data 0.001 (5.022)	Loss 1.347	Prec@1 68.4062	Prec@5 86.9280
Train: [66][6400/10010]	Time 0.539 (3451.530)	Data 0.001 (5.141)	Loss 1.347	Prec@1 68.3937	Prec@5 86.9189
Train: [66][6600/10010]	Time 0.539 (3559.436)	Data 0.001 (5.260)	Loss 1.347	Prec@1 68.3895	Prec@5 86.9215
Train: [66][6800/10010]	Time 0.539 (3667.109)	Data 0.001 (5.379)	Loss 1.347	Prec@1 68.3975	Prec@5 86.9283
Train: [66][7000/10010]	Time 0.539 (3774.627)	Data 0.001 (5.496)	Loss 1.348	Prec@1 68.3886	Prec@5 86.9191
Train: [66][7200/10010]	Time 0.539 (3882.261)	Data 0.001 (5.611)	Loss 1.348	Prec@1 68.3802	Prec@5 86.9134
Train: [66][7400/10010]	Time 0.539 (3989.974)	Data 0.001 (5.727)	Loss 1.348	Prec@1 68.3816	Prec@5 86.9060
Train: [66][7600/10010]	Time 0.539 (4097.562)	Data 0.001 (5.841)	Loss 1.348	Prec@1 68.3730	Prec@5 86.8946
Train: [66][7800/10010]	Time 0.539 (4205.043)	Data 0.001 (5.957)	Loss 1.348	Prec@1 68.3738	Prec@5 86.8973
Train: [66][8000/10010]	Time 0.539 (4312.752)	Data 0.001 (6.075)	Loss 1.348	Prec@1 68.3750	Prec@5 86.8963
Train: [66][8200/10010]	Time 0.539 (4420.582)	Data 0.001 (6.195)	Loss 1.349	Prec@1 68.3636	Prec@5 86.8933
Train: [66][8400/10010]	Time 0.539 (4528.382)	Data 0.001 (6.318)	Loss 1.348	Prec@1 68.3649	Prec@5 86.8993
Train: [66][8600/10010]	Time 0.539 (4636.132)	Data 0.001 (6.438)	Loss 1.348	Prec@1 68.3550	Prec@5 86.8993
Train: [66][8800/10010]	Time 0.539 (4743.956)	Data 0.001 (6.559)	Loss 1.348	Prec@1 68.3587	Prec@5 86.9054
Train: [66][9000/10010]	Time 0.539 (4851.921)	Data 0.001 (6.683)	Loss 1.348	Prec@1 68.3566	Prec@5 86.8995
Train: [66][9200/10010]	Time 0.539 (4960.291)	Data 0.001 (6.807)	Loss 1.348	Prec@1 68.3519	Prec@5 86.8971
Train: [66][9400/10010]	Time 0.539 (5068.116)	Data 0.001 (6.927)	Loss 1.349	Prec@1 68.3450	Prec@5 86.8883
Train: [66][9600/10010]	Time 0.539 (5175.870)	Data 0.001 (7.050)	Loss 1.349	Prec@1 68.3380	Prec@5 86.8778
Train: [66][9800/10010]	Time 0.539 (5283.458)	Data 0.001 (7.171)	Loss 1.349	Prec@1 68.3405	Prec@5 86.8824
Train: [66][10000/10010]	Time 0.539 (5391.240)	Data 0.001 (7.289)	Loss 1.349	Prec@1 68.3334	Prec@5 86.8764
Train: [66]	Time 5395.648	Data 7.291	Loss 1.349	Prec@1 68.3341	Prec@5 86.8769	
Val: [66]	Time 68.219	Data 1.307	Loss 1.179	Prec@1 70.7800	Prec@5 90.0040	
Best Prec@1: [70.780]	
Starting epoch number: 67 Learning rate: 0.0010000000000000002
Train: [67][0/10010]	Time 1.690 (1.690)	Data 1.111 (1.111)	Loss 0.945	Prec@1 78.9062	Prec@5 92.1875
Train: [67][200/10010]	Time 0.545 (109.572)	Data 0.006 (1.239)	Loss 1.331	Prec@1 68.7345	Prec@5 86.9714
Train: [67][400/10010]	Time 0.542 (217.345)	Data 0.003 (1.362)	Loss 1.323	Prec@1 68.8688	Prec@5 87.2175
Train: [67][600/10010]	Time 0.541 (325.208)	Data 0.002 (1.485)	Loss 1.333	Prec@1 68.7461	Prec@5 87.0554
Train: [67][800/10010]	Time 0.541 (433.349)	Data 0.002 (1.608)	Loss 1.326	Prec@1 68.8885	Prec@5 87.1655
Train: [67][1000/10010]	Time 0.541 (541.336)	Data 0.002 (1.730)	Loss 1.331	Prec@1 68.8296	Prec@5 87.0707
Train: [67][1200/10010]	Time 0.541 (649.352)	Data 0.002 (1.858)	Loss 1.334	Prec@1 68.7526	Prec@5 87.0440
Train: [67][1400/10010]	Time 0.540 (757.022)	Data 0.001 (1.977)	Loss 1.336	Prec@1 68.7316	Prec@5 87.0227
Train: [67][1600/10010]	Time 0.540 (864.542)	Data 0.001 (2.093)	Loss 1.334	Prec@1 68.7329	Prec@5 87.0730
Train: [67][1800/10010]	Time 0.540 (972.404)	Data 0.001 (2.209)	Loss 1.333	Prec@1 68.7695	Prec@5 87.0831
Train: [67][2000/10010]	Time 0.540 (1079.890)	Data 0.001 (2.326)	Loss 1.335	Prec@1 68.7235	Prec@5 87.0553
Train: [67][2200/10010]	Time 0.539 (1187.418)	Data 0.001 (2.441)	Loss 1.335	Prec@1 68.7376	Prec@5 87.0542
Train: [67][2400/10010]	Time 0.539 (1294.854)	Data 0.001 (2.560)	Loss 1.336	Prec@1 68.7018	Prec@5 87.0747
Train: [67][2600/10010]	Time 0.539 (1402.813)	Data 0.001 (2.679)	Loss 1.335	Prec@1 68.7212	Prec@5 87.0750
Train: [67][2800/10010]	Time 0.539 (1510.753)	Data 0.001 (2.801)	Loss 1.335	Prec@1 68.7333	Prec@5 87.0744
Train: [67][3000/10010]	Time 0.539 (1618.613)	Data 0.001 (2.924)	Loss 1.336	Prec@1 68.7255	Prec@5 87.0767
Train: [67][3200/10010]	Time 0.539 (1726.491)	Data 0.001 (3.048)	Loss 1.336	Prec@1 68.7041	Prec@5 87.0607
Train: [67][3400/10010]	Time 0.539 (1834.629)	Data 0.001 (3.171)	Loss 1.337	Prec@1 68.6969	Prec@5 87.0530
Train: [67][3600/10010]	Time 0.539 (1942.691)	Data 0.001 (3.291)	Loss 1.336	Prec@1 68.6893	Prec@5 87.0633
Train: [67][3800/10010]	Time 0.539 (2050.444)	Data 0.001 (3.410)	Loss 1.337	Prec@1 68.6844	Prec@5 87.0624
Train: [67][4000/10010]	Time 0.539 (2158.325)	Data 0.001 (3.534)	Loss 1.337	Prec@1 68.6774	Prec@5 87.0587
Train: [67][4200/10010]	Time 0.539 (2266.429)	Data 0.001 (3.656)	Loss 1.337	Prec@1 68.6747	Prec@5 87.0585
Train: [67][4400/10010]	Time 0.540 (2374.671)	Data 0.001 (3.778)	Loss 1.338	Prec@1 68.6623	Prec@5 87.0402
Train: [67][4600/10010]	Time 0.540 (2483.107)	Data 0.001 (3.905)	Loss 1.338	Prec@1 68.6551	Prec@5 87.0517
Train: [67][4800/10010]	Time 0.540 (2591.190)	Data 0.001 (4.030)	Loss 1.338	Prec@1 68.6403	Prec@5 87.0453
Train: [67][5000/10010]	Time 0.540 (2699.037)	Data 0.001 (4.156)	Loss 1.338	Prec@1 68.6385	Prec@5 87.0487
Train: [67][5200/10010]	Time 0.540 (2807.041)	Data 0.001 (4.275)	Loss 1.339	Prec@1 68.6435	Prec@5 87.0416
Train: [67][5400/10010]	Time 0.540 (2915.390)	Data 0.001 (4.401)	Loss 1.338	Prec@1 68.6408	Prec@5 87.0475
Train: [67][5600/10010]	Time 0.540 (3023.184)	Data 0.001 (4.525)	Loss 1.339	Prec@1 68.6359	Prec@5 87.0348
Train: [67][5800/10010]	Time 0.540 (3131.223)	Data 0.001 (4.653)	Loss 1.339	Prec@1 68.6289	Prec@5 87.0266
Train: [67][6000/10010]	Time 0.540 (3239.214)	Data 0.001 (4.775)	Loss 1.339	Prec@1 68.6250	Prec@5 87.0287
Train: [67][6200/10010]	Time 0.540 (3347.417)	Data 0.001 (4.893)	Loss 1.340	Prec@1 68.6153	Prec@5 87.0312
Train: [67][6400/10010]	Time 0.540 (3455.416)	Data 0.001 (5.015)	Loss 1.340	Prec@1 68.6103	Prec@5 87.0273
Train: [67][6600/10010]	Time 0.540 (3563.114)	Data 0.001 (5.136)	Loss 1.340	Prec@1 68.6029	Prec@5 87.0171
Train: [67][6800/10010]	Time 0.540 (3670.785)	Data 0.001 (5.258)	Loss 1.340	Prec@1 68.6032	Prec@5 87.0251
Train: [67][7000/10010]	Time 0.540 (3778.652)	Data 0.001 (5.375)	Loss 1.341	Prec@1 68.5921	Prec@5 87.0129
Train: [67][7200/10010]	Time 0.540 (3886.180)	Data 0.001 (5.489)	Loss 1.341	Prec@1 68.5896	Prec@5 87.0134
Train: [67][7400/10010]	Time 0.540 (3993.543)	Data 0.001 (5.603)	Loss 1.341	Prec@1 68.5830	Prec@5 87.0150
Train: [67][7600/10010]	Time 0.540 (4100.821)	Data 0.001 (5.719)	Loss 1.340	Prec@1 68.5905	Prec@5 87.0254
Train: [67][7800/10010]	Time 0.539 (4208.446)	Data 0.001 (5.838)	Loss 1.340	Prec@1 68.5863	Prec@5 87.0172
Train: [67][8000/10010]	Time 0.539 (4316.470)	Data 0.001 (5.958)	Loss 1.341	Prec@1 68.5787	Prec@5 87.0095
Train: [67][8200/10010]	Time 0.540 (4424.486)	Data 0.001 (6.078)	Loss 1.341	Prec@1 68.5801	Prec@5 87.0037
Train: [67][8400/10010]	Time 0.539 (4532.259)	Data 0.001 (6.200)	Loss 1.340	Prec@1 68.5844	Prec@5 87.0114
Train: [67][8600/10010]	Time 0.539 (4640.054)	Data 0.001 (6.322)	Loss 1.340	Prec@1 68.5828	Prec@5 87.0113
Train: [67][8800/10010]	Time 0.540 (4748.225)	Data 0.001 (6.443)	Loss 1.341	Prec@1 68.5710	Prec@5 87.0013
Train: [67][9000/10010]	Time 0.540 (4856.268)	Data 0.001 (6.563)	Loss 1.341	Prec@1 68.5675	Prec@5 87.0043
Train: [67][9200/10010]	Time 0.540 (4964.262)	Data 0.001 (6.688)	Loss 1.341	Prec@1 68.5584	Prec@5 86.9967
Train: [67][9400/10010]	Time 0.540 (5072.302)	Data 0.001 (6.815)	Loss 1.341	Prec@1 68.5583	Prec@5 86.9965
Train: [67][9600/10010]	Time 0.540 (5180.520)	Data 0.001 (6.942)	Loss 1.341	Prec@1 68.5599	Prec@5 86.9965
Train: [67][9800/10010]	Time 0.540 (5288.964)	Data 0.001 (7.064)	Loss 1.341	Prec@1 68.5595	Prec@5 86.9976
Train: [67][10000/10010]	Time 0.540 (5397.022)	Data 0.001 (7.188)	Loss 1.341	Prec@1 68.5628	Prec@5 86.9979
Train: [67]	Time 5401.383	Data 7.190	Loss 1.341	Prec@1 68.5636	Prec@5 86.9992	
Val: [67]	Time 67.878	Data 1.445	Loss 1.163	Prec@1 71.1500	Prec@5 90.2160	
Best Prec@1: [71.150]	
Starting epoch number: 68 Learning rate: 0.0010000000000000002
Train: [68][0/10010]	Time 1.824 (1.824)	Data 1.204 (1.204)	Loss 1.228	Prec@1 68.7500	Prec@5 86.7188
Train: [68][200/10010]	Time 0.545 (109.461)	Data 0.007 (1.329)	Loss 1.315	Prec@1 68.9560	Prec@5 87.2474
Train: [68][400/10010]	Time 0.542 (217.284)	Data 0.004 (1.450)	Loss 1.321	Prec@1 68.8747	Prec@5 87.2292
Train: [68][600/10010]	Time 0.541 (325.222)	Data 0.003 (1.568)	Loss 1.323	Prec@1 68.8319	Prec@5 87.2036
Train: [68][800/10010]	Time 0.540 (432.916)	Data 0.002 (1.690)	Loss 1.328	Prec@1 68.7237	Prec@5 87.1216
Train: [68][1000/10010]	Time 0.540 (540.573)	Data 0.002 (1.810)	Loss 1.328	Prec@1 68.7227	Prec@5 87.1660
Train: [68][1200/10010]	Time 0.540 (648.219)	Data 0.002 (1.929)	Loss 1.328	Prec@1 68.7253	Prec@5 87.1826
Train: [68][1400/10010]	Time 0.540 (756.213)	Data 0.001 (2.047)	Loss 1.328	Prec@1 68.7087	Prec@5 87.1688
Train: [68][1600/10010]	Time 0.540 (863.863)	Data 0.001 (2.165)	Loss 1.330	Prec@1 68.6656	Prec@5 87.1462
Train: [68][1800/10010]	Time 0.540 (971.668)	Data 0.001 (2.285)	Loss 1.331	Prec@1 68.6376	Prec@5 87.1586
Train: [68][2000/10010]	Time 0.539 (1079.354)	Data 0.001 (2.405)	Loss 1.332	Prec@1 68.6399	Prec@5 87.1510
Train: [68][2200/10010]	Time 0.539 (1187.129)	Data 0.001 (2.521)	Loss 1.332	Prec@1 68.6588	Prec@5 87.1649
Train: [68][2400/10010]	Time 0.539 (1295.111)	Data 0.001 (2.637)	Loss 1.331	Prec@1 68.6651	Prec@5 87.1629
Train: [68][2600/10010]	Time 0.539 (1402.830)	Data 0.001 (2.756)	Loss 1.331	Prec@1 68.6815	Prec@5 87.1528
Train: [68][2800/10010]	Time 0.539 (1510.283)	Data 0.001 (2.872)	Loss 1.330	Prec@1 68.7115	Prec@5 87.1533
Train: [68][3000/10010]	Time 0.539 (1618.049)	Data 0.001 (2.991)	Loss 1.330	Prec@1 68.7099	Prec@5 87.1543
Train: [68][3200/10010]	Time 0.539 (1726.397)	Data 0.001 (3.116)	Loss 1.331	Prec@1 68.6897	Prec@5 87.1361
Train: [68][3400/10010]	Time 0.539 (1834.321)	Data 0.001 (3.235)	Loss 1.331	Prec@1 68.7105	Prec@5 87.1272
Train: [68][3600/10010]	Time 0.539 (1942.111)	Data 0.001 (3.357)	Loss 1.332	Prec@1 68.6825	Prec@5 87.1156
Train: [68][3800/10010]	Time 0.539 (2050.029)	Data 0.001 (3.481)	Loss 1.332	Prec@1 68.6955	Prec@5 87.1171
Train: [68][4000/10010]	Time 0.539 (2158.250)	Data 0.001 (3.603)	Loss 1.332	Prec@1 68.6836	Prec@5 87.1323
Train: [68][4200/10010]	Time 0.540 (2266.588)	Data 0.001 (3.727)	Loss 1.332	Prec@1 68.6844	Prec@5 87.1236
Train: [68][4400/10010]	Time 0.540 (2374.485)	Data 0.001 (3.847)	Loss 1.332	Prec@1 68.6669	Prec@5 87.1151
Train: [68][4600/10010]	Time 0.540 (2482.289)	Data 0.001 (3.971)	Loss 1.332	Prec@1 68.6704	Prec@5 87.1205
Train: [68][4800/10010]	Time 0.540 (2590.240)	Data 0.001 (4.092)	Loss 1.332	Prec@1 68.6787	Prec@5 87.1259
Train: [68][5000/10010]	Time 0.540 (2698.441)	Data 0.001 (4.213)	Loss 1.332	Prec@1 68.6720	Prec@5 87.1307
Train: [68][5200/10010]	Time 0.540 (2806.479)	Data 0.001 (4.332)	Loss 1.332	Prec@1 68.6726	Prec@5 87.1269
Train: [68][5400/10010]	Time 0.540 (2914.633)	Data 0.001 (4.465)	Loss 1.332	Prec@1 68.6804	Prec@5 87.1275
Train: [68][5600/10010]	Time 0.540 (3023.143)	Data 0.001 (4.605)	Loss 1.332	Prec@1 68.6878	Prec@5 87.1166
Train: [68][5800/10010]	Time 0.540 (3131.415)	Data 0.001 (4.731)	Loss 1.333	Prec@1 68.6895	Prec@5 87.1041
Train: [68][6000/10010]	Time 0.540 (3239.386)	Data 0.001 (4.852)	Loss 1.333	Prec@1 68.6827	Prec@5 87.0995
Train: [68][6200/10010]	Time 0.540 (3347.065)	Data 0.001 (4.972)	Loss 1.334	Prec@1 68.6708	Prec@5 87.0932
Train: [68][6400/10010]	Time 0.540 (3454.853)	Data 0.001 (5.095)	Loss 1.334	Prec@1 68.6510	Prec@5 87.0949
Train: [68][6600/10010]	Time 0.540 (3562.805)	Data 0.001 (5.215)	Loss 1.334	Prec@1 68.6326	Prec@5 87.0881
Train: [68][6800/10010]	Time 0.540 (3671.001)	Data 0.001 (5.335)	Loss 1.334	Prec@1 68.6369	Prec@5 87.0853
Train: [68][7000/10010]	Time 0.540 (3779.020)	Data 0.001 (5.456)	Loss 1.334	Prec@1 68.6463	Prec@5 87.0877
Train: [68][7200/10010]	Time 0.540 (3886.815)	Data 0.001 (5.577)	Loss 1.334	Prec@1 68.6541	Prec@5 87.0856
Train: [68][7400/10010]	Time 0.540 (3994.859)	Data 0.001 (5.706)	Loss 1.335	Prec@1 68.6414	Prec@5 87.0784
Train: [68][7600/10010]	Time 0.540 (4103.036)	Data 0.001 (5.826)	Loss 1.335	Prec@1 68.6305	Prec@5 87.0703
Train: [68][7800/10010]	Time 0.540 (4211.959)	Data 0.001 (5.946)	Loss 1.335	Prec@1 68.6414	Prec@5 87.0706
Train: [68][8000/10010]	Time 0.540 (4320.987)	Data 0.001 (6.071)	Loss 1.335	Prec@1 68.6415	Prec@5 87.0707
Train: [68][8200/10010]	Time 0.540 (4429.649)	Data 0.001 (6.193)	Loss 1.335	Prec@1 68.6444	Prec@5 87.0794
Train: [68][8400/10010]	Time 0.540 (4537.888)	Data 0.001 (6.316)	Loss 1.335	Prec@1 68.6467	Prec@5 87.0825
Train: [68][8600/10010]	Time 0.540 (4646.145)	Data 0.001 (6.438)	Loss 1.334	Prec@1 68.6538	Prec@5 87.0960
Train: [68][8800/10010]	Time 0.540 (4754.261)	Data 0.001 (6.565)	Loss 1.335	Prec@1 68.6471	Prec@5 87.0952
Train: [68][9000/10010]	Time 0.540 (4862.030)	Data 0.001 (6.689)	Loss 1.335	Prec@1 68.6358	Prec@5 87.0921
Train: [68][9200/10010]	Time 0.540 (4969.594)	Data 0.001 (6.807)	Loss 1.335	Prec@1 68.6429	Prec@5 87.0948
Train: [68][9400/10010]	Time 0.540 (5077.405)	Data 0.001 (6.926)	Loss 1.335	Prec@1 68.6477	Prec@5 87.0959
Train: [68][9600/10010]	Time 0.540 (5185.221)	Data 0.001 (7.044)	Loss 1.335	Prec@1 68.6466	Prec@5 87.0935
Train: [68][9800/10010]	Time 0.540 (5292.772)	Data 0.001 (7.164)	Loss 1.335	Prec@1 68.6438	Prec@5 87.0968
Train: [68][10000/10010]	Time 0.540 (5400.269)	Data 0.001 (7.280)	Loss 1.335	Prec@1 68.6374	Prec@5 87.0877
Train: [68]	Time 5404.600	Data 7.282	Loss 1.335	Prec@1 68.6369	Prec@5 87.0865	
Val: [68]	Time 67.978	Data 1.473	Loss 1.173	Prec@1 70.7180	Prec@5 90.1420	
Best Prec@1: [71.150]	
Starting epoch number: 69 Learning rate: 0.0010000000000000002
Train: [69][0/10010]	Time 1.771 (1.771)	Data 1.207 (1.207)	Loss 1.141	Prec@1 71.8750	Prec@5 88.2812
Train: [69][200/10010]	Time 0.548 (110.077)	Data 0.007 (1.336)	Loss 1.335	Prec@1 68.4429	Prec@5 87.1035
Train: [69][400/10010]	Time 0.544 (218.239)	Data 0.004 (1.457)	Loss 1.320	Prec@1 68.7968	Prec@5 87.3247
Train: [69][600/10010]	Time 0.543 (326.258)	Data 0.003 (1.585)	Loss 1.313	Prec@1 68.9723	Prec@5 87.3843
Train: [69][800/10010]	Time 0.542 (434.169)	Data 0.002 (1.708)	Loss 1.318	Prec@1 68.9012	Prec@5 87.2708
Train: [69][1000/10010]	Time 0.542 (542.392)	Data 0.002 (1.830)	Loss 1.317	Prec@1 68.9771	Prec@5 87.2698
Train: [69][1200/10010]	Time 0.542 (650.644)	Data 0.002 (1.954)	Loss 1.320	Prec@1 68.8827	Prec@5 87.2346
Train: [69][1400/10010]	Time 0.541 (758.626)	Data 0.001 (2.077)	Loss 1.323	Prec@1 68.8543	Prec@5 87.1950
Train: [69][1600/10010]	Time 0.541 (866.311)	Data 0.001 (2.197)	Loss 1.324	Prec@1 68.8495	Prec@5 87.1916
Train: [69][1800/10010]	Time 0.541 (974.127)	Data 0.001 (2.317)	Loss 1.324	Prec@1 68.8580	Prec@5 87.1725
Train: [69][2000/10010]	Time 0.541 (1082.343)	Data 0.001 (2.436)	Loss 1.324	Prec@1 68.8617	Prec@5 87.2001
Train: [69][2200/10010]	Time 0.541 (1190.298)	Data 0.001 (2.556)	Loss 1.323	Prec@1 68.8998	Prec@5 87.2196
Train: [69][2400/10010]	Time 0.541 (1298.037)	Data 0.001 (2.675)	Loss 1.324	Prec@1 68.8831	Prec@5 87.2101
Train: [69][2600/10010]	Time 0.540 (1405.737)	Data 0.001 (2.795)	Loss 1.324	Prec@1 68.8876	Prec@5 87.2089
Train: [69][2800/10010]	Time 0.540 (1513.655)	Data 0.001 (2.915)	Loss 1.325	Prec@1 68.8777	Prec@5 87.2066
Train: [69][3000/10010]	Time 0.540 (1621.632)	Data 0.001 (3.041)	Loss 1.324	Prec@1 68.8685	Prec@5 87.2235
Train: [69][3200/10010]	Time 0.540 (1729.581)	Data 0.001 (3.165)	Loss 1.325	Prec@1 68.8408	Prec@5 87.2061
Train: [69][3400/10010]	Time 0.540 (1837.234)	Data 0.001 (3.283)	Loss 1.325	Prec@1 68.8584	Prec@5 87.2117
Train: [69][3600/10010]	Time 0.540 (1945.382)	Data 0.001 (3.407)	Loss 1.325	Prec@1 68.8656	Prec@5 87.2084
Train: [69][3800/10010]	Time 0.540 (2053.808)	Data 0.001 (3.529)	Loss 1.326	Prec@1 68.8472	Prec@5 87.2127
Train: [69][4000/10010]	Time 0.540 (2161.670)	Data 0.001 (3.648)	Loss 1.326	Prec@1 68.8593	Prec@5 87.2132
Train: [69][4200/10010]	Time 0.540 (2269.530)	Data 0.001 (3.769)	Loss 1.326	Prec@1 68.8476	Prec@5 87.2012
Train: [69][4400/10010]	Time 0.540 (2377.163)	Data 0.001 (3.893)	Loss 1.326	Prec@1 68.8480	Prec@5 87.1940
Train: [69][4600/10010]	Time 0.540 (2485.279)	Data 0.001 (4.020)	Loss 1.327	Prec@1 68.8500	Prec@5 87.1857
Train: [69][4800/10010]	Time 0.540 (2593.305)	Data 0.001 (4.142)	Loss 1.327	Prec@1 68.8403	Prec@5 87.1853
Train: [69][5000/10010]	Time 0.540 (2701.242)	Data 0.001 (4.268)	Loss 1.326	Prec@1 68.8439	Prec@5 87.1965
Train: [69][5200/10010]	Time 0.540 (2809.159)	Data 0.001 (4.392)	Loss 1.326	Prec@1 68.8493	Prec@5 87.2059
Train: [69][5400/10010]	Time 0.540 (2917.373)	Data 0.001 (4.518)	Loss 1.326	Prec@1 68.8442	Prec@5 87.2046
Train: [69][5600/10010]	Time 0.540 (3025.623)	Data 0.001 (4.642)	Loss 1.326	Prec@1 68.8333	Prec@5 87.1990
Train: [69][5800/10010]	Time 0.540 (3133.500)	Data 0.001 (4.763)	Loss 1.326	Prec@1 68.8281	Prec@5 87.2020
Train: [69][6000/10010]	Time 0.540 (3241.243)	Data 0.001 (4.885)	Loss 1.326	Prec@1 68.8329	Prec@5 87.2014
Train: [69][6200/10010]	Time 0.540 (3349.240)	Data 0.001 (5.006)	Loss 1.326	Prec@1 68.8338	Prec@5 87.1998
Train: [69][6400/10010]	Time 0.540 (3457.673)	Data 0.001 (5.131)	Loss 1.326	Prec@1 68.8251	Prec@5 87.1907
Train: [69][6600/10010]	Time 0.540 (3565.594)	Data 0.001 (5.251)	Loss 1.326	Prec@1 68.8202	Prec@5 87.1951
Train: [69][6800/10010]	Time 0.540 (3673.309)	Data 0.001 (5.369)	Loss 1.327	Prec@1 68.8143	Prec@5 87.1963
Train: [69][7000/10010]	Time 0.540 (3781.028)	Data 0.001 (5.489)	Loss 1.327	Prec@1 68.8101	Prec@5 87.1882
Train: [69][7200/10010]	Time 0.540 (3888.561)	Data 0.001 (5.603)	Loss 1.327	Prec@1 68.8039	Prec@5 87.1766
Train: [69][7400/10010]	Time 0.540 (3996.294)	Data 0.001 (5.716)	Loss 1.327	Prec@1 68.8091	Prec@5 87.1833
Train: [69][7600/10010]	Time 0.540 (4103.918)	Data 0.001 (5.833)	Loss 1.327	Prec@1 68.8120	Prec@5 87.1869
Train: [69][7800/10010]	Time 0.540 (4211.355)	Data 0.001 (5.951)	Loss 1.327	Prec@1 68.8130	Prec@5 87.1804
Train: [69][8000/10010]	Time 0.540 (4318.948)	Data 0.001 (6.069)	Loss 1.327	Prec@1 68.8172	Prec@5 87.1790
Train: [69][8200/10010]	Time 0.540 (4426.838)	Data 0.001 (6.189)	Loss 1.327	Prec@1 68.8220	Prec@5 87.1753
Train: [69][8400/10010]	Time 0.540 (4534.644)	Data 0.001 (6.308)	Loss 1.328	Prec@1 68.8139	Prec@5 87.1754
Train: [69][8600/10010]	Time 0.540 (4642.317)	Data 0.001 (6.428)	Loss 1.328	Prec@1 68.8086	Prec@5 87.1725
Train: [69][8800/10010]	Time 0.540 (4749.922)	Data 0.001 (6.546)	Loss 1.328	Prec@1 68.7969	Prec@5 87.1684
Train: [69][9000/10010]	Time 0.540 (4857.844)	Data 0.001 (6.667)	Loss 1.329	Prec@1 68.7909	Prec@5 87.1657
Train: [69][9200/10010]	Time 0.540 (4965.759)	Data 0.001 (6.788)	Loss 1.328	Prec@1 68.7954	Prec@5 87.1694
Train: [69][9400/10010]	Time 0.540 (5073.960)	Data 0.001 (6.911)	Loss 1.328	Prec@1 68.7976	Prec@5 87.1691
Train: [69][9600/10010]	Time 0.540 (5181.914)	Data 0.001 (7.036)	Loss 1.328	Prec@1 68.7980	Prec@5 87.1690
Train: [69][9800/10010]	Time 0.540 (5289.942)	Data 0.001 (7.160)	Loss 1.328	Prec@1 68.7989	Prec@5 87.1702
Train: [69][10000/10010]	Time 0.540 (5397.842)	Data 0.001 (7.280)	Loss 1.329	Prec@1 68.7954	Prec@5 87.1639
Train: [69]	Time 5402.123	Data 7.283	Loss 1.329	Prec@1 68.7965	Prec@5 87.1642	
Val: [69]	Time 67.846	Data 1.470	Loss 1.159	Prec@1 71.2800	Prec@5 90.2280	
Best Prec@1: [71.280]	
Starting epoch number: 70 Learning rate: 0.0010000000000000002
Train: [70][0/10010]	Time 1.804 (1.804)	Data 1.247 (1.247)	Loss 0.979	Prec@1 75.0000	Prec@5 92.1875
Train: [70][200/10010]	Time 0.547 (109.915)	Data 0.007 (1.378)	Loss 1.303	Prec@1 69.4652	Prec@5 87.5544
Train: [70][400/10010]	Time 0.543 (217.865)	Data 0.004 (1.501)	Loss 1.308	Prec@1 69.2410	Prec@5 87.4805
Train: [70][600/10010]	Time 0.542 (325.633)	Data 0.003 (1.623)	Loss 1.312	Prec@1 69.1985	Prec@5 87.3739
Train: [70][800/10010]	Time 0.541 (433.524)	Data 0.002 (1.746)	Loss 1.314	Prec@1 69.2933	Prec@5 87.2659
Train: [70][1000/10010]	Time 0.540 (541.019)	Data 0.002 (1.866)	Loss 1.316	Prec@1 69.1441	Prec@5 87.2487
Train: [70][1200/10010]	Time 0.540 (648.840)	Data 0.002 (1.988)	Loss 1.318	Prec@1 69.1364	Prec@5 87.2248
Train: [70][1400/10010]	Time 0.540 (756.775)	Data 0.002 (2.108)	Loss 1.318	Prec@1 69.1175	Prec@5 87.2290
Train: [70][1600/10010]	Time 0.540 (864.526)	Data 0.001 (2.228)	Loss 1.319	Prec@1 69.1057	Prec@5 87.2311
Train: [70][1800/10010]	Time 0.540 (972.197)	Data 0.001 (2.347)	Loss 1.319	Prec@1 69.0766	Prec@5 87.2540
Train: [70][2000/10010]	Time 0.540 (1079.831)	Data 0.001 (2.467)	Loss 1.321	Prec@1 69.0174	Prec@5 87.2169
Train: [70][2200/10010]	Time 0.540 (1187.672)	Data 0.001 (2.589)	Loss 1.322	Prec@1 68.9896	Prec@5 87.2185
Train: [70][2400/10010]	Time 0.540 (1295.576)	Data 0.001 (2.709)	Loss 1.321	Prec@1 68.9869	Prec@5 87.2130
Train: [70][2600/10010]	Time 0.540 (1403.513)	Data 0.001 (2.831)	Loss 1.321	Prec@1 68.9957	Prec@5 87.2035
Train: [70][2800/10010]	Time 0.540 (1511.214)	Data 0.001 (2.951)	Loss 1.319	Prec@1 69.0091	Prec@5 87.2403
Train: [70][3000/10010]	Time 0.539 (1619.015)	Data 0.001 (3.073)	Loss 1.318	Prec@1 69.0166	Prec@5 87.2454
Train: [70][3200/10010]	Time 0.540 (1727.092)	Data 0.001 (3.194)	Loss 1.318	Prec@1 69.0229	Prec@5 87.2720
Train: [70][3400/10010]	Time 0.540 (1835.042)	Data 0.001 (3.312)	Loss 1.316	Prec@1 69.0369	Prec@5 87.2894
Train: [70][3600/10010]	Time 0.539 (1942.610)	Data 0.001 (3.431)	Loss 1.317	Prec@1 69.0201	Prec@5 87.2835
Train: [70][3800/10010]	Time 0.539 (2050.182)	Data 0.001 (3.550)	Loss 1.318	Prec@1 69.0065	Prec@5 87.2793
Train: [70][4000/10010]	Time 0.539 (2158.020)	Data 0.001 (3.666)	Loss 1.318	Prec@1 69.0040	Prec@5 87.2915
Train: [70][4200/10010]	Time 0.539 (2265.940)	Data 0.001 (3.783)	Loss 1.318	Prec@1 69.0122	Prec@5 87.2945
Train: [70][4400/10010]	Time 0.539 (2374.068)	Data 0.001 (3.906)	Loss 1.317	Prec@1 69.0007	Prec@5 87.3014
Train: [70][4600/10010]	Time 0.539 (2481.839)	Data 0.001 (4.028)	Loss 1.318	Prec@1 68.9923	Prec@5 87.2979
Train: [70][4800/10010]	Time 0.539 (2589.484)	Data 0.001 (4.148)	Loss 1.319	Prec@1 68.9721	Prec@5 87.2925
Train: [70][5000/10010]	Time 0.539 (2697.169)	Data 0.001 (4.266)	Loss 1.319	Prec@1 68.9637	Prec@5 87.2935
Train: [70][5200/10010]	Time 0.539 (2805.016)	Data 0.001 (4.387)	Loss 1.319	Prec@1 68.9570	Prec@5 87.2965
Train: [70][5400/10010]	Time 0.539 (2912.621)	Data 0.001 (4.507)	Loss 1.319	Prec@1 68.9560	Prec@5 87.2829
Train: [70][5600/10010]	Time 0.539 (3020.300)	Data 0.001 (4.628)	Loss 1.319	Prec@1 68.9527	Prec@5 87.2858
Train: [70][5800/10010]	Time 0.539 (3128.050)	Data 0.001 (4.747)	Loss 1.320	Prec@1 68.9538	Prec@5 87.2789
Train: [70][6000/10010]	Time 0.539 (3235.811)	Data 0.001 (4.865)	Loss 1.320	Prec@1 68.9459	Prec@5 87.2756
Train: [70][6200/10010]	Time 0.539 (3343.574)	Data 0.001 (4.985)	Loss 1.320	Prec@1 68.9313	Prec@5 87.2703
Train: [70][6400/10010]	Time 0.539 (3451.572)	Data 0.001 (5.111)	Loss 1.320	Prec@1 68.9273	Prec@5 87.2749
Train: [70][6600/10010]	Time 0.539 (3559.609)	Data 0.001 (5.235)	Loss 1.321	Prec@1 68.9139	Prec@5 87.2619
Train: [70][6800/10010]	Time 0.539 (3667.420)	Data 0.001 (5.354)	Loss 1.321	Prec@1 68.9146	Prec@5 87.2630
Train: [70][7000/10010]	Time 0.539 (3775.451)	Data 0.001 (5.476)	Loss 1.321	Prec@1 68.9173	Prec@5 87.2626
Train: [70][7200/10010]	Time 0.539 (3883.051)	Data 0.001 (5.597)	Loss 1.320	Prec@1 68.9185	Prec@5 87.2646
Train: [70][7400/10010]	Time 0.539 (3990.629)	Data 0.001 (5.716)	Loss 1.320	Prec@1 68.9283	Prec@5 87.2625
Train: [70][7600/10010]	Time 0.539 (4098.515)	Data 0.001 (5.837)	Loss 1.320	Prec@1 68.9230	Prec@5 87.2598
Train: [70][7800/10010]	Time 0.539 (4206.554)	Data 0.001 (5.957)	Loss 1.320	Prec@1 68.9295	Prec@5 87.2737
Train: [70][8000/10010]	Time 0.539 (4314.596)	Data 0.001 (6.086)	Loss 1.320	Prec@1 68.9257	Prec@5 87.2678
Train: [70][8200/10010]	Time 0.539 (4423.013)	Data 0.001 (6.210)	Loss 1.320	Prec@1 68.9241	Prec@5 87.2731
Train: [70][8400/10010]	Time 0.539 (4531.835)	Data 0.001 (6.333)	Loss 1.320	Prec@1 68.9220	Prec@5 87.2773
Train: [70][8600/10010]	Time 0.539 (4639.916)	Data 0.001 (6.460)	Loss 1.320	Prec@1 68.9099	Prec@5 87.2724
Train: [70][8800/10010]	Time 0.539 (4747.834)	Data 0.001 (6.586)	Loss 1.320	Prec@1 68.9149	Prec@5 87.2678
Train: [70][9000/10010]	Time 0.539 (4855.277)	Data 0.001 (6.709)	Loss 1.320	Prec@1 68.9154	Prec@5 87.2658
Train: [70][9200/10010]	Time 0.539 (4962.704)	Data 0.001 (6.830)	Loss 1.320	Prec@1 68.9191	Prec@5 87.2707
Train: [70][9400/10010]	Time 0.539 (5070.523)	Data 0.001 (6.955)	Loss 1.320	Prec@1 68.9118	Prec@5 87.2653
Train: [70][9600/10010]	Time 0.539 (5178.046)	Data 0.001 (7.074)	Loss 1.321	Prec@1 68.9040	Prec@5 87.2611
Train: [70][9800/10010]	Time 0.539 (5285.724)	Data 0.001 (7.196)	Loss 1.321	Prec@1 68.8924	Prec@5 87.2607
Train: [70][10000/10010]	Time 0.539 (5393.325)	Data 0.001 (7.318)	Loss 1.321	Prec@1 68.8965	Prec@5 87.2583
Train: [70]	Time 5397.725	Data 7.320	Loss 1.321	Prec@1 68.8967	Prec@5 87.2573	
Val: [70]	Time 67.432	Data 1.535	Loss 1.159	Prec@1 71.2100	Prec@5 90.2460	
Best Prec@1: [71.280]	
Starting epoch number: 71 Learning rate: 0.0010000000000000002
Train: [71][0/10010]	Time 1.796 (1.796)	Data 1.235 (1.235)	Loss 1.432	Prec@1 67.9688	Prec@5 82.8125
Train: [71][200/10010]	Time 0.543 (109.099)	Data 0.007 (1.364)	Loss 1.311	Prec@1 68.8899	Prec@5 87.5350
Train: [71][400/10010]	Time 0.539 (216.262)	Data 0.004 (1.484)	Loss 1.316	Prec@1 68.9994	Prec@5 87.3130
Train: [71][600/10010]	Time 0.538 (323.620)	Data 0.003 (1.600)	Loss 1.327	Prec@1 68.7396	Prec@5 87.1048
Train: [71][800/10010]	Time 0.538 (431.003)	Data 0.002 (1.721)	Loss 1.322	Prec@1 68.7949	Prec@5 87.2269
Train: [71][1000/10010]	Time 0.538 (538.333)	Data 0.002 (1.839)	Loss 1.318	Prec@1 68.9498	Prec@5 87.2627
Train: [71][1200/10010]	Time 0.538 (646.068)	Data 0.002 (1.956)	Loss 1.320	Prec@1 68.9386	Prec@5 87.2157
Train: [71][1400/10010]	Time 0.538 (754.266)	Data 0.001 (2.063)	Loss 1.319	Prec@1 68.9429	Prec@5 87.2485
Train: [71][1600/10010]	Time 0.539 (862.200)	Data 0.001 (2.173)	Loss 1.316	Prec@1 68.9613	Prec@5 87.2936
Train: [71][1800/10010]	Time 0.538 (969.453)	Data 0.001 (2.290)	Loss 1.317	Prec@1 68.9435	Prec@5 87.3152
Train: [71][2000/10010]	Time 0.538 (1076.873)	Data 0.001 (2.410)	Loss 1.318	Prec@1 68.9581	Prec@5 87.3005
Train: [71][2200/10010]	Time 0.538 (1184.245)	Data 0.001 (2.529)	Loss 1.318	Prec@1 68.9356	Prec@5 87.2970
Train: [71][2400/10010]	Time 0.538 (1291.757)	Data 0.001 (2.651)	Loss 1.319	Prec@1 68.9182	Prec@5 87.2761
Train: [71][2600/10010]	Time 0.538 (1399.456)	Data 0.001 (2.773)	Loss 1.319	Prec@1 68.9347	Prec@5 87.2777
Train: [71][2800/10010]	Time 0.538 (1507.047)	Data 0.001 (2.897)	Loss 1.319	Prec@1 68.9394	Prec@5 87.2850
Train: [71][3000/10010]	Time 0.538 (1614.850)	Data 0.001 (3.020)	Loss 1.320	Prec@1 68.9260	Prec@5 87.2842
Train: [71][3200/10010]	Time 0.538 (1722.590)	Data 0.001 (3.144)	Loss 1.318	Prec@1 68.9667	Prec@5 87.2945
Train: [71][3400/10010]	Time 0.538 (1830.279)	Data 0.001 (3.265)	Loss 1.318	Prec@1 68.9685	Prec@5 87.2891
Train: [71][3600/10010]	Time 0.538 (1937.679)	Data 0.001 (3.383)	Loss 1.318	Prec@1 68.9711	Prec@5 87.2837
Train: [71][3800/10010]	Time 0.538 (2044.993)	Data 0.001 (3.498)	Loss 1.318	Prec@1 68.9660	Prec@5 87.2844
Train: [71][4000/10010]	Time 0.538 (2152.884)	Data 0.001 (3.625)	Loss 1.318	Prec@1 68.9730	Prec@5 87.2858
Train: [71][4200/10010]	Time 0.538 (2260.855)	Data 0.001 (3.751)	Loss 1.318	Prec@1 68.9888	Prec@5 87.2754
Train: [71][4400/10010]	Time 0.538 (2368.653)	Data 0.001 (3.874)	Loss 1.317	Prec@1 69.0168	Prec@5 87.3006
Train: [71][4600/10010]	Time 0.538 (2476.436)	Data 0.001 (3.997)	Loss 1.317	Prec@1 69.0074	Prec@5 87.2974
Train: [71][4800/10010]	Time 0.538 (2584.315)	Data 0.001 (4.120)	Loss 1.318	Prec@1 68.9947	Prec@5 87.2862
Train: [71][5000/10010]	Time 0.538 (2691.920)	Data 0.001 (4.242)	Loss 1.318	Prec@1 68.9956	Prec@5 87.2941
Train: [71][5200/10010]	Time 0.538 (2799.664)	Data 0.001 (4.361)	Loss 1.319	Prec@1 68.9728	Prec@5 87.2771
Train: [71][5400/10010]	Time 0.538 (2907.254)	Data 0.001 (4.484)	Loss 1.319	Prec@1 68.9712	Prec@5 87.2772
Train: [71][5600/10010]	Time 0.538 (3014.911)	Data 0.001 (4.605)	Loss 1.319	Prec@1 68.9730	Prec@5 87.2672
Train: [71][5800/10010]	Time 0.538 (3122.665)	Data 0.001 (4.727)	Loss 1.320	Prec@1 68.9652	Prec@5 87.2600
Train: [71][6000/10010]	Time 0.538 (3230.502)	Data 0.001 (4.852)	Loss 1.320	Prec@1 68.9709	Prec@5 87.2618
Train: [71][6200/10010]	Time 0.538 (3338.453)	Data 0.001 (4.976)	Loss 1.319	Prec@1 68.9817	Prec@5 87.2746
Train: [71][6400/10010]	Time 0.539 (3447.041)	Data 0.001 (5.090)	Loss 1.319	Prec@1 68.9829	Prec@5 87.2774
Train: [71][6600/10010]	Time 0.539 (3554.663)	Data 0.001 (5.208)	Loss 1.319	Prec@1 68.9789	Prec@5 87.2676
Train: [71][6800/10010]	Time 0.539 (3662.431)	Data 0.001 (5.330)	Loss 1.319	Prec@1 68.9940	Prec@5 87.2714
Train: [71][7000/10010]	Time 0.539 (3770.255)	Data 0.001 (5.451)	Loss 1.318	Prec@1 69.0000	Prec@5 87.2789
Train: [71][7200/10010]	Time 0.539 (3878.190)	Data 0.001 (5.579)	Loss 1.318	Prec@1 68.9958	Prec@5 87.2780
Train: [71][7400/10010]	Time 0.539 (3986.033)	Data 0.001 (5.706)	Loss 1.318	Prec@1 69.0074	Prec@5 87.2829
Train: [71][7600/10010]	Time 0.539 (4093.943)	Data 0.001 (5.833)	Loss 1.318	Prec@1 69.0036	Prec@5 87.2829
Train: [71][7800/10010]	Time 0.539 (4201.368)	Data 0.001 (5.958)	Loss 1.318	Prec@1 68.9933	Prec@5 87.2813
Train: [71][8000/10010]	Time 0.539 (4309.341)	Data 0.001 (6.084)	Loss 1.318	Prec@1 68.9872	Prec@5 87.2813
Train: [71][8200/10010]	Time 0.539 (4417.128)	Data 0.001 (6.213)	Loss 1.318	Prec@1 68.9731	Prec@5 87.2758
Train: [71][8400/10010]	Time 0.539 (4524.501)	Data 0.001 (6.337)	Loss 1.319	Prec@1 68.9740	Prec@5 87.2769
Train: [71][8600/10010]	Time 0.539 (4632.201)	Data 0.001 (6.463)	Loss 1.319	Prec@1 68.9645	Prec@5 87.2671
Train: [71][8800/10010]	Time 0.539 (4740.030)	Data 0.001 (6.587)	Loss 1.319	Prec@1 68.9581	Prec@5 87.2699
Train: [71][9000/10010]	Time 0.539 (4848.047)	Data 0.001 (6.713)	Loss 1.319	Prec@1 68.9556	Prec@5 87.2660
Train: [71][9200/10010]	Time 0.539 (4955.958)	Data 0.001 (6.843)	Loss 1.319	Prec@1 68.9582	Prec@5 87.2666
Train: [71][9400/10010]	Time 0.539 (5063.567)	Data 0.001 (6.968)	Loss 1.319	Prec@1 68.9550	Prec@5 87.2667
Train: [71][9600/10010]	Time 0.539 (5171.179)	Data 0.001 (7.090)	Loss 1.319	Prec@1 68.9625	Prec@5 87.2725
Train: [71][9800/10010]	Time 0.539 (5278.635)	Data 0.001 (7.213)	Loss 1.319	Prec@1 68.9644	Prec@5 87.2776
Train: [71][10000/10010]	Time 0.539 (5386.079)	Data 0.001 (7.332)	Loss 1.319	Prec@1 68.9576	Prec@5 87.2740
Train: [71]	Time 5390.514	Data 7.334	Loss 1.319	Prec@1 68.9574	Prec@5 87.2741	
Val: [71]	Time 67.545	Data 1.398	Loss 1.153	Prec@1 71.3680	Prec@5 90.3420	
Best Prec@1: [71.368]	
Starting epoch number: 72 Learning rate: 0.0010000000000000002
Train: [72][0/10010]	Time 1.661 (1.661)	Data 1.107 (1.107)	Loss 1.321	Prec@1 67.9688	Prec@5 89.0625
Train: [72][200/10010]	Time 0.543 (109.157)	Data 0.006 (1.236)	Loss 1.307	Prec@1 69.2397	Prec@5 87.2474
Train: [72][400/10010]	Time 0.540 (216.477)	Data 0.003 (1.355)	Loss 1.312	Prec@1 69.0929	Prec@5 87.3188
Train: [72][600/10010]	Time 0.539 (323.696)	Data 0.002 (1.471)	Loss 1.316	Prec@1 69.0321	Prec@5 87.2062
Train: [72][800/10010]	Time 0.538 (431.231)	Data 0.002 (1.593)	Loss 1.317	Prec@1 69.0299	Prec@5 87.2932
Train: [72][1000/10010]	Time 0.538 (538.757)	Data 0.002 (1.713)	Loss 1.312	Prec@1 69.1558	Prec@5 87.3970
Train: [72][1200/10010]	Time 0.538 (646.097)	Data 0.002 (1.829)	Loss 1.311	Prec@1 69.1481	Prec@5 87.4278
Train: [72][1400/10010]	Time 0.538 (753.382)	Data 0.001 (1.942)	Loss 1.309	Prec@1 69.2056	Prec@5 87.4420
Train: [72][1600/10010]	Time 0.538 (860.757)	Data 0.001 (2.060)	Loss 1.309	Prec@1 69.2019	Prec@5 87.4585
Train: [72][1800/10010]	Time 0.538 (968.141)	Data 0.001 (2.175)	Loss 1.307	Prec@1 69.2163	Prec@5 87.4844
Train: [72][2000/10010]	Time 0.537 (1075.466)	Data 0.001 (2.293)	Loss 1.307	Prec@1 69.2212	Prec@5 87.4625
Train: [72][2200/10010]	Time 0.537 (1182.722)	Data 0.001 (2.409)	Loss 1.309	Prec@1 69.1987	Prec@5 87.4304
Train: [72][2400/10010]	Time 0.537 (1289.954)	Data 0.001 (2.524)	Loss 1.308	Prec@1 69.2029	Prec@5 87.4414
Train: [72][2600/10010]	Time 0.537 (1397.173)	Data 0.001 (2.637)	Loss 1.309	Prec@1 69.1990	Prec@5 87.4255
Train: [72][2800/10010]	Time 0.537 (1504.343)	Data 0.001 (2.750)	Loss 1.309	Prec@1 69.2169	Prec@5 87.4423
Train: [72][3000/10010]	Time 0.537 (1611.544)	Data 0.001 (2.863)	Loss 1.310	Prec@1 69.1972	Prec@5 87.4323
Train: [72][3200/10010]	Time 0.537 (1718.920)	Data 0.001 (2.978)	Loss 1.311	Prec@1 69.1830	Prec@5 87.4229
Train: [72][3400/10010]	Time 0.537 (1826.429)	Data 0.001 (3.094)	Loss 1.311	Prec@1 69.1653	Prec@5 87.4026
Train: [72][3600/10010]	Time 0.537 (1933.988)	Data 0.001 (3.214)	Loss 1.312	Prec@1 69.1585	Prec@5 87.4091
Train: [72][3800/10010]	Time 0.537 (2041.763)	Data 0.001 (3.334)	Loss 1.313	Prec@1 69.1251	Prec@5 87.3843
Train: [72][4000/10010]	Time 0.537 (2149.333)	Data 0.001 (3.454)	Loss 1.313	Prec@1 69.1397	Prec@5 87.4043
Train: [72][4200/10010]	Time 0.537 (2256.968)	Data 0.001 (3.574)	Loss 1.312	Prec@1 69.1528	Prec@5 87.4048
Train: [72][4400/10010]	Time 0.537 (2364.372)	Data 0.001 (3.695)	Loss 1.312	Prec@1 69.1459	Prec@5 87.4160
Train: [72][4600/10010]	Time 0.537 (2472.089)	Data 0.001 (3.819)	Loss 1.312	Prec@1 69.1321	Prec@5 87.4053
Train: [72][4800/10010]	Time 0.537 (2579.555)	Data 0.001 (3.943)	Loss 1.312	Prec@1 69.1412	Prec@5 87.4098
Train: [72][5000/10010]	Time 0.537 (2687.112)	Data 0.001 (4.066)	Loss 1.313	Prec@1 69.1335	Prec@5 87.4033
Train: [72][5200/10010]	Time 0.537 (2794.495)	Data 0.001 (4.189)	Loss 1.312	Prec@1 69.1487	Prec@5 87.4241
Train: [72][5400/10010]	Time 0.537 (2901.882)	Data 0.001 (4.311)	Loss 1.313	Prec@1 69.1313	Prec@5 87.4066
Train: [72][5600/10010]	Time 0.537 (3009.459)	Data 0.001 (4.438)	Loss 1.313	Prec@1 69.1340	Prec@5 87.3978
Train: [72][5800/10010]	Time 0.537 (3117.189)	Data 0.001 (4.567)	Loss 1.314	Prec@1 69.1275	Prec@5 87.3933
Train: [72][6000/10010]	Time 0.537 (3224.593)	Data 0.001 (4.688)	Loss 1.313	Prec@1 69.1311	Prec@5 87.3927
Train: [72][6200/10010]	Time 0.537 (3332.199)	Data 0.001 (4.808)	Loss 1.313	Prec@1 69.1230	Prec@5 87.3930
Train: [72][6400/10010]	Time 0.537 (3440.309)	Data 0.001 (4.930)	Loss 1.314	Prec@1 69.1096	Prec@5 87.3814
Train: [72][6600/10010]	Time 0.537 (3547.779)	Data 0.001 (5.053)	Loss 1.314	Prec@1 69.1170	Prec@5 87.3790
Train: [72][6800/10010]	Time 0.537 (3655.115)	Data 0.001 (5.174)	Loss 1.314	Prec@1 69.1101	Prec@5 87.3718
Train: [72][7000/10010]	Time 0.537 (3762.547)	Data 0.001 (5.294)	Loss 1.315	Prec@1 69.1032	Prec@5 87.3691
Train: [72][7200/10010]	Time 0.537 (3869.947)	Data 0.001 (5.416)	Loss 1.315	Prec@1 69.1060	Prec@5 87.3694
Train: [72][7400/10010]	Time 0.537 (3977.735)	Data 0.001 (5.541)	Loss 1.314	Prec@1 69.1134	Prec@5 87.3781
Train: [72][7600/10010]	Time 0.537 (4085.102)	Data 0.001 (5.662)	Loss 1.314	Prec@1 69.1200	Prec@5 87.3852
Train: [72][7800/10010]	Time 0.537 (4192.493)	Data 0.001 (5.785)	Loss 1.314	Prec@1 69.1155	Prec@5 87.3846
Train: [72][8000/10010]	Time 0.537 (4299.988)	Data 0.001 (5.906)	Loss 1.314	Prec@1 69.1063	Prec@5 87.3766
Train: [72][8200/10010]	Time 0.537 (4407.272)	Data 0.001 (6.025)	Loss 1.315	Prec@1 69.0969	Prec@5 87.3690
Train: [72][8400/10010]	Time 0.537 (4514.726)	Data 0.001 (6.143)	Loss 1.315	Prec@1 69.1019	Prec@5 87.3688
Train: [72][8600/10010]	Time 0.537 (4622.093)	Data 0.001 (6.261)	Loss 1.315	Prec@1 69.0964	Prec@5 87.3584
Train: [72][8800/10010]	Time 0.537 (4729.956)	Data 0.001 (6.389)	Loss 1.315	Prec@1 69.1093	Prec@5 87.3652
Train: [72][9000/10010]	Time 0.537 (4837.746)	Data 0.001 (6.511)	Loss 1.314	Prec@1 69.1121	Prec@5 87.3666
Train: [72][9200/10010]	Time 0.537 (4945.510)	Data 0.001 (6.633)	Loss 1.314	Prec@1 69.1100	Prec@5 87.3656
Train: [72][9400/10010]	Time 0.538 (5053.307)	Data 0.001 (6.756)	Loss 1.315	Prec@1 69.0940	Prec@5 87.3645
Train: [72][9600/10010]	Time 0.538 (5161.523)	Data 0.001 (6.883)	Loss 1.314	Prec@1 69.0930	Prec@5 87.3669
Train: [72][9800/10010]	Time 0.538 (5269.584)	Data 0.001 (7.011)	Loss 1.314	Prec@1 69.0917	Prec@5 87.3618
Train: [72][10000/10010]	Time 0.538 (5377.470)	Data 0.001 (7.137)	Loss 1.314	Prec@1 69.1007	Prec@5 87.3667
Train: [72]	Time 5381.834	Data 7.139	Loss 1.314	Prec@1 69.0988	Prec@5 87.3660	
Val: [72]	Time 67.956	Data 1.500	Loss 1.161	Prec@1 71.0320	Prec@5 90.1640	
Best Prec@1: [71.368]	
Starting epoch number: 73 Learning rate: 0.0010000000000000002
Train: [73][0/10010]	Time 1.897 (1.897)	Data 1.341 (1.341)	Loss 1.169	Prec@1 68.7500	Prec@5 92.1875
Train: [73][200/10010]	Time 0.545 (109.516)	Data 0.007 (1.465)	Loss 1.297	Prec@1 69.1192	Prec@5 87.5777
Train: [73][400/10010]	Time 0.542 (217.349)	Data 0.004 (1.588)	Loss 1.303	Prec@1 69.1650	Prec@5 87.4377
Train: [73][600/10010]	Time 0.541 (325.141)	Data 0.003 (1.714)	Loss 1.306	Prec@1 69.1972	Prec@5 87.3687
Train: [73][800/10010]	Time 0.540 (432.707)	Data 0.002 (1.834)	Loss 1.305	Prec@1 69.2679	Prec@5 87.4561
Train: [73][1000/10010]	Time 0.540 (540.230)	Data 0.002 (1.958)	Loss 1.304	Prec@1 69.2448	Prec@5 87.4579
Train: [73][1200/10010]	Time 0.539 (647.881)	Data 0.002 (2.079)	Loss 1.301	Prec@1 69.3270	Prec@5 87.5072
Train: [73][1400/10010]	Time 0.539 (755.684)	Data 0.002 (2.204)	Loss 1.303	Prec@1 69.2915	Prec@5 87.4699
Train: [73][1600/10010]	Time 0.539 (863.328)	Data 0.001 (2.331)	Loss 1.304	Prec@1 69.2707	Prec@5 87.4858
Train: [73][1800/10010]	Time 0.539 (970.911)	Data 0.001 (2.457)	Loss 1.308	Prec@1 69.1868	Prec@5 87.4323
Train: [73][2000/10010]	Time 0.539 (1078.250)	Data 0.001 (2.580)	Loss 1.310	Prec@1 69.1615	Prec@5 87.3903
Train: [73][2200/10010]	Time 0.539 (1185.710)	Data 0.001 (2.702)	Loss 1.308	Prec@1 69.1887	Prec@5 87.4212
Train: [73][2400/10010]	Time 0.539 (1292.995)	Data 0.001 (2.818)	Loss 1.308	Prec@1 69.1834	Prec@5 87.4265
Train: [73][2600/10010]	Time 0.538 (1400.456)	Data 0.001 (2.939)	Loss 1.309	Prec@1 69.1639	Prec@5 87.4156
Train: [73][2800/10010]	Time 0.538 (1507.997)	Data 0.001 (3.060)	Loss 1.307	Prec@1 69.2005	Prec@5 87.4445
Train: [73][3000/10010]	Time 0.538 (1615.495)	Data 0.001 (3.183)	Loss 1.308	Prec@1 69.2035	Prec@5 87.4347
Train: [73][3200/10010]	Time 0.538 (1722.766)	Data 0.001 (3.302)	Loss 1.308	Prec@1 69.2079	Prec@5 87.4280
Train: [73][3400/10010]	Time 0.538 (1830.177)	Data 0.001 (3.420)	Loss 1.308	Prec@1 69.1959	Prec@5 87.4201
Train: [73][3600/10010]	Time 0.538 (1937.671)	Data 0.001 (3.540)	Loss 1.308	Prec@1 69.2063	Prec@5 87.4252
Train: [73][3800/10010]	Time 0.538 (2045.593)	Data 0.001 (3.668)	Loss 1.307	Prec@1 69.1907	Prec@5 87.4205
Train: [73][4000/10010]	Time 0.538 (2153.081)	Data 0.001 (3.790)	Loss 1.308	Prec@1 69.1716	Prec@5 87.4043
Train: [73][4200/10010]	Time 0.538 (2260.743)	Data 0.001 (3.911)	Loss 1.308	Prec@1 69.1710	Prec@5 87.4128
Train: [73][4400/10010]	Time 0.538 (2368.593)	Data 0.001 (4.033)	Loss 1.308	Prec@1 69.1771	Prec@5 87.4267
Train: [73][4600/10010]	Time 0.538 (2476.323)	Data 0.001 (4.158)	Loss 1.307	Prec@1 69.1808	Prec@5 87.4328
Train: [73][4800/10010]	Time 0.538 (2584.030)	Data 0.001 (4.278)	Loss 1.308	Prec@1 69.1705	Prec@5 87.4237
Train: [73][5000/10010]	Time 0.538 (2691.530)	Data 0.001 (4.397)	Loss 1.307	Prec@1 69.1776	Prec@5 87.4292
Train: [73][5200/10010]	Time 0.538 (2799.328)	Data 0.001 (4.520)	Loss 1.307	Prec@1 69.1859	Prec@5 87.4348
Train: [73][5400/10010]	Time 0.538 (2907.246)	Data 0.001 (4.643)	Loss 1.307	Prec@1 69.1932	Prec@5 87.4322
Train: [73][5600/10010]	Time 0.538 (3015.217)	Data 0.001 (4.770)	Loss 1.307	Prec@1 69.1885	Prec@5 87.4282
Train: [73][5800/10010]	Time 0.538 (3123.109)	Data 0.001 (4.898)	Loss 1.307	Prec@1 69.1885	Prec@5 87.4312
Train: [73][6000/10010]	Time 0.538 (3231.062)	Data 0.001 (5.022)	Loss 1.308	Prec@1 69.1693	Prec@5 87.4189
Train: [73][6200/10010]	Time 0.539 (3339.500)	Data 0.001 (5.146)	Loss 1.309	Prec@1 69.1608	Prec@5 87.3998
Train: [73][6400/10010]	Time 0.539 (3447.906)	Data 0.001 (5.274)	Loss 1.308	Prec@1 69.1581	Prec@5 87.4004
Train: [73][6600/10010]	Time 0.539 (3555.894)	Data 0.001 (5.403)	Loss 1.308	Prec@1 69.1670	Prec@5 87.4134
Train: [73][6800/10010]	Time 0.539 (3663.576)	Data 0.001 (5.527)	Loss 1.308	Prec@1 69.1599	Prec@5 87.4124
Train: [73][7000/10010]	Time 0.539 (3771.118)	Data 0.001 (5.647)	Loss 1.308	Prec@1 69.1713	Prec@5 87.4203
Train: [73][7200/10010]	Time 0.539 (3878.845)	Data 0.001 (5.768)	Loss 1.308	Prec@1 69.1629	Prec@5 87.4152
Train: [73][7400/10010]	Time 0.539 (3987.065)	Data 0.001 (5.888)	Loss 1.309	Prec@1 69.1558	Prec@5 87.4107
Train: [73][7600/10010]	Time 0.539 (4095.121)	Data 0.001 (6.017)	Loss 1.309	Prec@1 69.1530	Prec@5 87.4057
Train: [73][7800/10010]	Time 0.539 (4202.760)	Data 0.001 (6.142)	Loss 1.309	Prec@1 69.1511	Prec@5 87.3952
Train: [73][8000/10010]	Time 0.539 (4309.950)	Data 0.001 (6.260)	Loss 1.310	Prec@1 69.1382	Prec@5 87.3874
Train: [73][8200/10010]	Time 0.539 (4417.780)	Data 0.001 (6.390)	Loss 1.310	Prec@1 69.1428	Prec@5 87.3895
Train: [73][8400/10010]	Time 0.539 (4526.418)	Data 0.001 (6.543)	Loss 1.310	Prec@1 69.1394	Prec@5 87.3890
Train: [73][8600/10010]	Time 0.539 (4634.463)	Data 0.001 (6.676)	Loss 1.310	Prec@1 69.1246	Prec@5 87.3834
Train: [73][8800/10010]	Time 0.539 (4742.087)	Data 0.001 (6.802)	Loss 1.310	Prec@1 69.1161	Prec@5 87.3798
Train: [73][9000/10010]	Time 0.539 (4849.757)	Data 0.001 (6.926)	Loss 1.310	Prec@1 69.1171	Prec@5 87.3803
Train: [73][9200/10010]	Time 0.539 (4957.234)	Data 0.001 (7.047)	Loss 1.310	Prec@1 69.1162	Prec@5 87.3785
Train: [73][9400/10010]	Time 0.539 (5064.660)	Data 0.001 (7.167)	Loss 1.310	Prec@1 69.1188	Prec@5 87.3729
Train: [73][9600/10010]	Time 0.539 (5172.716)	Data 0.001 (7.292)	Loss 1.311	Prec@1 69.1141	Prec@5 87.3622
Train: [73][9800/10010]	Time 0.539 (5280.462)	Data 0.001 (7.415)	Loss 1.311	Prec@1 69.1162	Prec@5 87.3581
Train: [73][10000/10010]	Time 0.539 (5387.877)	Data 0.001 (7.529)	Loss 1.311	Prec@1 69.1179	Prec@5 87.3567
Train: [73]	Time 5392.380	Data 7.531	Loss 1.311	Prec@1 69.1189	Prec@5 87.3570	
Val: [73]	Time 68.247	Data 1.316	Loss 1.158	Prec@1 71.2040	Prec@5 90.3520	
Best Prec@1: [71.368]	
Starting epoch number: 74 Learning rate: 0.0010000000000000002
Train: [74][0/10010]	Time 1.761 (1.761)	Data 1.194 (1.194)	Loss 1.078	Prec@1 71.8750	Prec@5 92.9688
Train: [74][200/10010]	Time 0.545 (109.533)	Data 0.007 (1.323)	Loss 1.315	Prec@1 69.1154	Prec@5 87.3795
Train: [74][400/10010]	Time 0.542 (217.355)	Data 0.004 (1.448)	Loss 1.309	Prec@1 69.3306	Prec@5 87.4221
Train: [74][600/10010]	Time 0.541 (325.116)	Data 0.003 (1.570)	Loss 1.303	Prec@1 69.2804	Prec@5 87.5234
Train: [74][800/10010]	Time 0.540 (432.816)	Data 0.002 (1.693)	Loss 1.303	Prec@1 69.2962	Prec@5 87.5371
Train: [74][1000/10010]	Time 0.540 (540.560)	Data 0.002 (1.814)	Loss 1.303	Prec@1 69.2831	Prec@5 87.5702
Train: [74][1200/10010]	Time 0.540 (648.320)	Data 0.002 (1.940)	Loss 1.301	Prec@1 69.3407	Prec@5 87.5716
Train: [74][1400/10010]	Time 0.540 (755.945)	Data 0.001 (2.065)	Loss 1.300	Prec@1 69.3383	Prec@5 87.5792
Train: [74][1600/10010]	Time 0.539 (863.488)	Data 0.001 (2.189)	Loss 1.301	Prec@1 69.3243	Prec@5 87.5683
Train: [74][1800/10010]	Time 0.539 (971.195)	Data 0.001 (2.311)	Loss 1.300	Prec@1 69.3105	Prec@5 87.5833
Train: [74][2000/10010]	Time 0.539 (1078.726)	Data 0.001 (2.433)	Loss 1.300	Prec@1 69.3243	Prec@5 87.5675
Train: [74][2200/10010]	Time 0.539 (1186.082)	Data 0.001 (2.555)	Loss 1.302	Prec@1 69.3190	Prec@5 87.5444
Train: [74][2400/10010]	Time 0.539 (1293.399)	Data 0.001 (2.678)	Loss 1.301	Prec@1 69.3211	Prec@5 87.5413
Train: [74][2600/10010]	Time 0.539 (1400.934)	Data 0.001 (2.801)	Loss 1.300	Prec@1 69.3540	Prec@5 87.5357
Train: [74][2800/10010]	Time 0.539 (1508.459)	Data 0.001 (2.925)	Loss 1.301	Prec@1 69.3477	Prec@5 87.5248
Train: [74][3000/10010]	Time 0.538 (1616.009)	Data 0.001 (3.048)	Loss 1.301	Prec@1 69.3425	Prec@5 87.5219
Train: [74][3200/10010]	Time 0.538 (1723.691)	Data 0.001 (3.174)	Loss 1.301	Prec@1 69.3453	Prec@5 87.5081
Train: [74][3400/10010]	Time 0.538 (1831.412)	Data 0.001 (3.301)	Loss 1.302	Prec@1 69.3502	Prec@5 87.5142
Train: [74][3600/10010]	Time 0.538 (1938.654)	Data 0.001 (3.419)	Loss 1.301	Prec@1 69.3625	Prec@5 87.5156
Train: [74][3800/10010]	Time 0.538 (2045.986)	Data 0.001 (3.535)	Loss 1.300	Prec@1 69.3810	Prec@5 87.5356
Train: [74][4000/10010]	Time 0.538 (2153.456)	Data 0.001 (3.658)	Loss 1.301	Prec@1 69.3704	Prec@5 87.5221
Train: [74][4200/10010]	Time 0.538 (2261.031)	Data 0.001 (3.783)	Loss 1.303	Prec@1 69.3410	Prec@5 87.5000
Train: [74][4400/10010]	Time 0.538 (2368.598)	Data 0.001 (3.906)	Loss 1.303	Prec@1 69.3422	Prec@5 87.4874
Train: [74][4600/10010]	Time 0.538 (2476.061)	Data 0.001 (4.026)	Loss 1.303	Prec@1 69.3460	Prec@5 87.4890
Train: [74][4800/10010]	Time 0.538 (2583.360)	Data 0.001 (4.143)	Loss 1.303	Prec@1 69.3462	Prec@5 87.4823
Train: [74][5000/10010]	Time 0.538 (2690.556)	Data 0.001 (4.256)	Loss 1.304	Prec@1 69.3205	Prec@5 87.4836
Train: [74][5200/10010]	Time 0.538 (2797.720)	Data 0.001 (4.371)	Loss 1.303	Prec@1 69.3283	Prec@5 87.4910
Train: [74][5400/10010]	Time 0.538 (2904.981)	Data 0.001 (4.484)	Loss 1.303	Prec@1 69.3316	Prec@5 87.5022
Train: [74][5600/10010]	Time 0.538 (3012.340)	Data 0.001 (4.600)	Loss 1.303	Prec@1 69.3010	Prec@5 87.4876
Train: [74][5800/10010]	Time 0.538 (3119.754)	Data 0.001 (4.722)	Loss 1.304	Prec@1 69.2688	Prec@5 87.4766
Train: [74][6000/10010]	Time 0.538 (3227.305)	Data 0.001 (4.847)	Loss 1.304	Prec@1 69.2687	Prec@5 87.4770
Train: [74][6200/10010]	Time 0.538 (3334.476)	Data 0.001 (4.962)	Loss 1.304	Prec@1 69.2783	Prec@5 87.4713
Train: [74][6400/10010]	Time 0.538 (3441.619)	Data 0.001 (5.075)	Loss 1.304	Prec@1 69.2829	Prec@5 87.4657
Train: [74][6600/10010]	Time 0.538 (3548.641)	Data 0.001 (5.191)	Loss 1.304	Prec@1 69.2992	Prec@5 87.4782
Train: [74][6800/10010]	Time 0.537 (3655.506)	Data 0.001 (5.305)	Loss 1.304	Prec@1 69.2868	Prec@5 87.4782
Train: [74][7000/10010]	Time 0.537 (3762.739)	Data 0.001 (5.426)	Loss 1.304	Prec@1 69.2805	Prec@5 87.4653
Train: [74][7200/10010]	Time 0.537 (3869.971)	Data 0.001 (5.548)	Loss 1.305	Prec@1 69.2662	Prec@5 87.4580
Train: [74][7400/10010]	Time 0.537 (3977.719)	Data 0.001 (5.660)	Loss 1.305	Prec@1 69.2603	Prec@5 87.4532
Train: [74][7600/10010]	Time 0.538 (4086.107)	Data 0.001 (5.794)	Loss 1.305	Prec@1 69.2627	Prec@5 87.4470
Train: [74][7800/10010]	Time 0.538 (4193.585)	Data 0.001 (5.915)	Loss 1.306	Prec@1 69.2527	Prec@5 87.4444
Train: [74][8000/10010]	Time 0.538 (4300.804)	Data 0.001 (6.031)	Loss 1.306	Prec@1 69.2516	Prec@5 87.4422
Train: [74][8200/10010]	Time 0.538 (4408.161)	Data 0.001 (6.148)	Loss 1.306	Prec@1 69.2513	Prec@5 87.4352
Train: [74][8400/10010]	Time 0.537 (4515.515)	Data 0.001 (6.267)	Loss 1.306	Prec@1 69.2512	Prec@5 87.4381
Train: [74][8600/10010]	Time 0.538 (4623.371)	Data 0.001 (6.391)	Loss 1.307	Prec@1 69.2403	Prec@5 87.4299
Train: [74][8800/10010]	Time 0.538 (4731.715)	Data 0.001 (6.525)	Loss 1.307	Prec@1 69.2319	Prec@5 87.4293
Train: [74][9000/10010]	Time 0.538 (4839.544)	Data 0.001 (6.649)	Loss 1.307	Prec@1 69.2262	Prec@5 87.4339
Train: [74][9200/10010]	Time 0.538 (4947.445)	Data 0.001 (6.771)	Loss 1.306	Prec@1 69.2281	Prec@5 87.4335
Train: [74][9400/10010]	Time 0.538 (5055.316)	Data 0.001 (6.895)	Loss 1.307	Prec@1 69.2237	Prec@5 87.4285
Train: [74][9600/10010]	Time 0.538 (5162.922)	Data 0.001 (7.011)	Loss 1.307	Prec@1 69.2162	Prec@5 87.4291
Train: [74][9800/10010]	Time 0.538 (5270.406)	Data 0.001 (7.130)	Loss 1.307	Prec@1 69.2091	Prec@5 87.4257
Train: [74][10000/10010]	Time 0.538 (5378.177)	Data 0.001 (7.254)	Loss 1.307	Prec@1 69.2040	Prec@5 87.4216
Train: [74]	Time 5382.559	Data 7.257	Loss 1.307	Prec@1 69.2033	Prec@5 87.4219	
Val: [74]	Time 68.337	Data 1.620	Loss 1.203	Prec@1 70.2500	Prec@5 89.6660	
Best Prec@1: [71.368]	
Starting epoch number: 75 Learning rate: 0.0010000000000000002
Train: [75][0/10010]	Time 2.092 (2.092)	Data 1.443 (1.443)	Loss 1.350	Prec@1 64.0625	Prec@5 89.8438
Train: [75][200/10010]	Time 0.547 (109.911)	Data 0.008 (1.573)	Loss 1.305	Prec@1 69.3291	Prec@5 87.5233
Train: [75][400/10010]	Time 0.544 (218.224)	Data 0.004 (1.709)	Loss 1.305	Prec@1 69.3968	Prec@5 87.3675
Train: [75][600/10010]	Time 0.546 (327.871)	Data 0.003 (1.845)	Loss 1.306	Prec@1 69.2817	Prec@5 87.4168
Train: [75][800/10010]	Time 0.545 (436.626)	Data 0.002 (1.985)	Loss 1.303	Prec@1 69.3381	Prec@5 87.4746
Train: [75][1000/10010]	Time 0.544 (544.794)	Data 0.002 (2.120)	Loss 1.303	Prec@1 69.3689	Prec@5 87.4344
Train: [75][1200/10010]	Time 0.544 (652.960)	Data 0.002 (2.254)	Loss 1.303	Prec@1 69.4038	Prec@5 87.4252
Train: [75][1400/10010]	Time 0.543 (761.319)	Data 0.002 (2.390)	Loss 1.300	Prec@1 69.4549	Prec@5 87.4621
Train: [75][1600/10010]	Time 0.543 (869.541)	Data 0.002 (2.524)	Loss 1.300	Prec@1 69.4698	Prec@5 87.4722
Train: [75][1800/10010]	Time 0.543 (977.968)	Data 0.001 (2.660)	Loss 1.299	Prec@1 69.4935	Prec@5 87.5074
Train: [75][2000/10010]	Time 0.543 (1086.349)	Data 0.001 (2.795)	Loss 1.302	Prec@1 69.4208	Prec@5 87.4629
Train: [75][2200/10010]	Time 0.543 (1194.749)	Data 0.001 (2.929)	Loss 1.299	Prec@1 69.5004	Prec@5 87.5135
Train: [75][2400/10010]	Time 0.543 (1303.028)	Data 0.001 (3.059)	Loss 1.299	Prec@1 69.4727	Prec@5 87.5120
Train: [75][2600/10010]	Time 0.542 (1410.701)	Data 0.001 (3.176)	Loss 1.299	Prec@1 69.4829	Prec@5 87.5267
Train: [75][2800/10010]	Time 0.542 (1518.268)	Data 0.001 (3.294)	Loss 1.299	Prec@1 69.4529	Prec@5 87.5232
Train: [75][3000/10010]	Time 0.542 (1625.802)	Data 0.001 (3.410)	Loss 1.300	Prec@1 69.4407	Prec@5 87.5148
Train: [75][3200/10010]	Time 0.541 (1733.321)	Data 0.001 (3.530)	Loss 1.300	Prec@1 69.4200	Prec@5 87.5044
Train: [75][3400/10010]	Time 0.541 (1840.742)	Data 0.001 (3.644)	Loss 1.300	Prec@1 69.4364	Prec@5 87.5177
Train: [75][3600/10010]	Time 0.541 (1948.614)	Data 0.001 (3.768)	Loss 1.299	Prec@1 69.4393	Prec@5 87.5323
Train: [75][3800/10010]	Time 0.541 (2056.281)	Data 0.001 (3.892)	Loss 1.299	Prec@1 69.4355	Prec@5 87.5304
Train: [75][4000/10010]	Time 0.541 (2163.771)	Data 0.001 (4.018)	Loss 1.299	Prec@1 69.4285	Prec@5 87.5348
Train: [75][4200/10010]	Time 0.541 (2271.613)	Data 0.001 (4.144)	Loss 1.299	Prec@1 69.4212	Prec@5 87.5344
Train: [75][4400/10010]	Time 0.541 (2379.045)	Data 0.001 (4.267)	Loss 1.299	Prec@1 69.4267	Prec@5 87.5272
Train: [75][4600/10010]	Time 0.540 (2486.666)	Data 0.001 (4.391)	Loss 1.300	Prec@1 69.4151	Prec@5 87.5236
Train: [75][4800/10010]	Time 0.540 (2594.523)	Data 0.001 (4.512)	Loss 1.301	Prec@1 69.3817	Prec@5 87.5101
Train: [75][5000/10010]	Time 0.540 (2702.167)	Data 0.001 (4.638)	Loss 1.302	Prec@1 69.3757	Prec@5 87.5050
Train: [75][5200/10010]	Time 0.540 (2809.958)	Data 0.001 (4.765)	Loss 1.301	Prec@1 69.3816	Prec@5 87.5065
Train: [75][5400/10010]	Time 0.540 (2917.692)	Data 0.001 (4.889)	Loss 1.301	Prec@1 69.3956	Prec@5 87.4994
Train: [75][5600/10010]	Time 0.540 (3025.256)	Data 0.001 (5.012)	Loss 1.301	Prec@1 69.3809	Prec@5 87.5043
Train: [75][5800/10010]	Time 0.540 (3132.960)	Data 0.001 (5.133)	Loss 1.302	Prec@1 69.3633	Prec@5 87.4974
Train: [75][6000/10010]	Time 0.540 (3240.631)	Data 0.001 (5.254)	Loss 1.302	Prec@1 69.3621	Prec@5 87.4945
Train: [75][6200/10010]	Time 0.540 (3348.438)	Data 0.001 (5.377)	Loss 1.302	Prec@1 69.3729	Prec@5 87.5052
Train: [75][6400/10010]	Time 0.540 (3456.258)	Data 0.001 (5.500)	Loss 1.302	Prec@1 69.3526	Prec@5 87.5035
Train: [75][6600/10010]	Time 0.540 (3563.821)	Data 0.001 (5.622)	Loss 1.302	Prec@1 69.3373	Prec@5 87.4988
Train: [75][6800/10010]	Time 0.540 (3671.310)	Data 0.001 (5.743)	Loss 1.302	Prec@1 69.3455	Prec@5 87.5023
Train: [75][7000/10010]	Time 0.540 (3779.058)	Data 0.001 (5.867)	Loss 1.301	Prec@1 69.3545	Prec@5 87.5047
Train: [75][7200/10010]	Time 0.540 (3886.865)	Data 0.001 (5.994)	Loss 1.302	Prec@1 69.3545	Prec@5 87.4913
Train: [75][7400/10010]	Time 0.540 (3994.567)	Data 0.001 (6.120)	Loss 1.302	Prec@1 69.3462	Prec@5 87.4897
Train: [75][7600/10010]	Time 0.540 (4102.121)	Data 0.001 (6.245)	Loss 1.302	Prec@1 69.3381	Prec@5 87.4901
Train: [75][7800/10010]	Time 0.540 (4209.605)	Data 0.001 (6.366)	Loss 1.302	Prec@1 69.3315	Prec@5 87.4841
Train: [75][8000/10010]	Time 0.540 (4317.111)	Data 0.001 (6.490)	Loss 1.302	Prec@1 69.3282	Prec@5 87.4823
Train: [75][8200/10010]	Time 0.540 (4424.859)	Data 0.001 (6.617)	Loss 1.302	Prec@1 69.3276	Prec@5 87.4820
Train: [75][8400/10010]	Time 0.540 (4532.434)	Data 0.001 (6.742)	Loss 1.302	Prec@1 69.3293	Prec@5 87.4789
Train: [75][8600/10010]	Time 0.539 (4639.998)	Data 0.001 (6.861)	Loss 1.302	Prec@1 69.3249	Prec@5 87.4790
Train: [75][8800/10010]	Time 0.539 (4747.666)	Data 0.001 (6.982)	Loss 1.303	Prec@1 69.3183	Prec@5 87.4719
Train: [75][9000/10010]	Time 0.539 (4855.335)	Data 0.001 (7.102)	Loss 1.302	Prec@1 69.3185	Prec@5 87.4775
Train: [75][9200/10010]	Time 0.539 (4963.124)	Data 0.001 (7.225)	Loss 1.303	Prec@1 69.3056	Prec@5 87.4742
Train: [75][9400/10010]	Time 0.539 (5070.932)	Data 0.001 (7.350)	Loss 1.303	Prec@1 69.3007	Prec@5 87.4722
Train: [75][9600/10010]	Time 0.539 (5178.519)	Data 0.001 (7.474)	Loss 1.303	Prec@1 69.2899	Prec@5 87.4675
Train: [75][9800/10010]	Time 0.539 (5286.115)	Data 0.001 (7.599)	Loss 1.303	Prec@1 69.2904	Prec@5 87.4668
Train: [75][10000/10010]	Time 0.539 (5393.439)	Data 0.001 (7.712)	Loss 1.303	Prec@1 69.2908	Prec@5 87.4673
Train: [75]	Time 5397.823	Data 7.714	Loss 1.303	Prec@1 69.2914	Prec@5 87.4668	
Val: [75]	Time 68.186	Data 1.637	Loss 1.226	Prec@1 69.8660	Prec@5 89.2400	
Best Prec@1: [71.368]	
Starting epoch number: 76 Learning rate: 0.0010000000000000002
Train: [76][0/10010]	Time 1.683 (1.683)	Data 1.122 (1.122)	Loss 1.051	Prec@1 71.0938	Prec@5 89.8438
Train: [76][200/10010]	Time 0.546 (109.698)	Data 0.006 (1.259)	Loss 1.300	Prec@1 69.1970	Prec@5 87.4806
Train: [76][400/10010]	Time 0.541 (216.970)	Data 0.003 (1.384)	Loss 1.291	Prec@1 69.5351	Prec@5 87.6422
Train: [76][600/10010]	Time 0.540 (324.388)	Data 0.003 (1.509)	Loss 1.287	Prec@1 69.6703	Prec@5 87.6976
Train: [76][800/10010]	Time 0.539 (431.645)	Data 0.002 (1.630)	Loss 1.287	Prec@1 69.5917	Prec@5 87.6756
Train: [76][1000/10010]	Time 0.539 (539.310)	Data 0.002 (1.751)	Loss 1.286	Prec@1 69.6413	Prec@5 87.7084
Train: [76][1200/10010]	Time 0.539 (647.004)	Data 0.002 (1.871)	Loss 1.285	Prec@1 69.6737	Prec@5 87.7290
Train: [76][1400/10010]	Time 0.539 (755.078)	Data 0.001 (1.999)	Loss 1.285	Prec@1 69.6523	Prec@5 87.7493
Train: [76][1600/10010]	Time 0.539 (863.075)	Data 0.001 (2.127)	Loss 1.286	Prec@1 69.6630	Prec@5 87.7298
Train: [76][1800/10010]	Time 0.539 (970.631)	Data 0.001 (2.243)	Loss 1.287	Prec@1 69.6562	Prec@5 87.7065
Train: [76][2000/10010]	Time 0.539 (1078.494)	Data 0.001 (2.366)	Loss 1.287	Prec@1 69.6511	Prec@5 87.6964
Train: [76][2200/10010]	Time 0.539 (1186.136)	Data 0.001 (2.482)	Loss 1.290	Prec@1 69.6012	Prec@5 87.6498
Train: [76][2400/10010]	Time 0.539 (1293.468)	Data 0.001 (2.597)	Loss 1.288	Prec@1 69.6494	Prec@5 87.6562
Train: [76][2600/10010]	Time 0.539 (1400.975)	Data 0.001 (2.715)	Loss 1.289	Prec@1 69.6334	Prec@5 87.6541
Train: [76][2800/10010]	Time 0.538 (1508.131)	Data 0.001 (2.827)	Loss 1.288	Prec@1 69.6515	Prec@5 87.6590
Train: [76][3000/10010]	Time 0.538 (1615.752)	Data 0.001 (2.946)	Loss 1.289	Prec@1 69.6052	Prec@5 87.6539
Train: [76][3200/10010]	Time 0.538 (1723.716)	Data 0.001 (3.077)	Loss 1.289	Prec@1 69.6008	Prec@5 87.6682
Train: [76][3400/10010]	Time 0.539 (1831.708)	Data 0.001 (3.206)	Loss 1.288	Prec@1 69.6241	Prec@5 87.6695
Train: [76][3600/10010]	Time 0.539 (1939.703)	Data 0.001 (3.334)	Loss 1.290	Prec@1 69.5712	Prec@5 87.6467
Train: [76][3800/10010]	Time 0.539 (2047.815)	Data 0.001 (3.460)	Loss 1.291	Prec@1 69.5407	Prec@5 87.6361
Train: [76][4000/10010]	Time 0.539 (2156.199)	Data 0.001 (3.585)	Loss 1.291	Prec@1 69.5281	Prec@5 87.6375
Train: [76][4200/10010]	Time 0.539 (2264.412)	Data 0.001 (3.707)	Loss 1.291	Prec@1 69.5368	Prec@5 87.6369
Train: [76][4400/10010]	Time 0.539 (2372.414)	Data 0.001 (3.833)	Loss 1.291	Prec@1 69.5222	Prec@5 87.6395
Train: [76][4600/10010]	Time 0.539 (2480.472)	Data 0.001 (3.955)	Loss 1.291	Prec@1 69.5262	Prec@5 87.6384
Train: [76][4800/10010]	Time 0.539 (2587.954)	Data 0.001 (4.075)	Loss 1.292	Prec@1 69.5199	Prec@5 87.6277
Train: [76][5000/10010]	Time 0.539 (2695.555)	Data 0.001 (4.197)	Loss 1.293	Prec@1 69.4978	Prec@5 87.6164
Train: [76][5200/10010]	Time 0.539 (2803.412)	Data 0.001 (4.318)	Loss 1.293	Prec@1 69.4899	Prec@5 87.6020
Train: [76][5400/10010]	Time 0.539 (2911.064)	Data 0.001 (4.436)	Loss 1.293	Prec@1 69.4945	Prec@5 87.6070
Train: [76][5600/10010]	Time 0.539 (3018.842)	Data 0.001 (4.555)	Loss 1.293	Prec@1 69.4999	Prec@5 87.6042
Train: [76][5800/10010]	Time 0.539 (3126.370)	Data 0.001 (4.671)	Loss 1.294	Prec@1 69.4795	Prec@5 87.5991
Train: [76][6000/10010]	Time 0.539 (3234.696)	Data 0.001 (4.790)	Loss 1.294	Prec@1 69.4639	Prec@5 87.5984
Train: [76][6200/10010]	Time 0.539 (3342.345)	Data 0.001 (4.907)	Loss 1.295	Prec@1 69.4422	Prec@5 87.5892
Train: [76][6400/10010]	Time 0.539 (3449.922)	Data 0.001 (5.026)	Loss 1.295	Prec@1 69.4347	Prec@5 87.5869
Train: [76][6600/10010]	Time 0.539 (3558.585)	Data 0.001 (5.145)	Loss 1.295	Prec@1 69.4327	Prec@5 87.5843
Train: [76][6800/10010]	Time 0.539 (3667.348)	Data 0.001 (5.263)	Loss 1.296	Prec@1 69.4203	Prec@5 87.5739
Train: [76][7000/10010]	Time 0.539 (3775.471)	Data 0.001 (5.380)	Loss 1.296	Prec@1 69.4236	Prec@5 87.5630
Train: [76][7200/10010]	Time 0.539 (3883.369)	Data 0.001 (5.498)	Loss 1.297	Prec@1 69.4160	Prec@5 87.5504
Train: [76][7400/10010]	Time 0.539 (3990.986)	Data 0.001 (5.618)	Loss 1.298	Prec@1 69.3990	Prec@5 87.5456
Train: [76][7600/10010]	Time 0.539 (4098.439)	Data 0.001 (5.737)	Loss 1.298	Prec@1 69.4085	Prec@5 87.5417
Train: [76][7800/10010]	Time 0.539 (4205.841)	Data 0.001 (5.854)	Loss 1.298	Prec@1 69.4038	Prec@5 87.5396
Train: [76][8000/10010]	Time 0.539 (4313.261)	Data 0.001 (5.972)	Loss 1.299	Prec@1 69.4043	Prec@5 87.5341
Train: [76][8200/10010]	Time 0.539 (4420.636)	Data 0.001 (6.088)	Loss 1.299	Prec@1 69.4005	Prec@5 87.5328
Train: [76][8400/10010]	Time 0.539 (4528.156)	Data 0.001 (6.205)	Loss 1.299	Prec@1 69.3933	Prec@5 87.5323
Train: [76][8600/10010]	Time 0.539 (4635.869)	Data 0.001 (6.324)	Loss 1.299	Prec@1 69.3994	Prec@5 87.5369
Train: [76][8800/10010]	Time 0.539 (4743.780)	Data 0.001 (6.443)	Loss 1.299	Prec@1 69.3857	Prec@5 87.5363
Train: [76][9000/10010]	Time 0.539 (4851.678)	Data 0.001 (6.563)	Loss 1.299	Prec@1 69.3827	Prec@5 87.5355
Train: [76][9200/10010]	Time 0.539 (4959.489)	Data 0.001 (6.683)	Loss 1.299	Prec@1 69.3800	Prec@5 87.5326
Train: [76][9400/10010]	Time 0.539 (5067.164)	Data 0.001 (6.804)	Loss 1.299	Prec@1 69.3881	Prec@5 87.5333
Train: [76][9600/10010]	Time 0.539 (5174.781)	Data 0.001 (6.923)	Loss 1.299	Prec@1 69.3870	Prec@5 87.5316
Train: [76][9800/10010]	Time 0.539 (5282.400)	Data 0.001 (7.041)	Loss 1.299	Prec@1 69.3815	Prec@5 87.5304
Train: [76][10000/10010]	Time 0.539 (5389.752)	Data 0.001 (7.159)	Loss 1.299	Prec@1 69.3757	Prec@5 87.5337
Train: [76]	Time 5394.126	Data 7.161	Loss 1.299	Prec@1 69.3739	Prec@5 87.5337	
Val: [76]	Time 68.061	Data 1.538	Loss 1.172	Prec@1 70.8760	Prec@5 90.1720	
Best Prec@1: [71.368]	
Starting epoch number: 77 Learning rate: 0.0010000000000000002
Train: [77][0/10010]	Time 1.717 (1.717)	Data 1.132 (1.132)	Loss 1.550	Prec@1 67.1875	Prec@5 82.8125
Train: [77][200/10010]	Time 0.544 (109.434)	Data 0.006 (1.257)	Loss 1.275	Prec@1 69.7645	Prec@5 87.9703
Train: [77][400/10010]	Time 0.542 (217.352)	Data 0.003 (1.373)	Loss 1.278	Prec@1 69.9365	Prec@5 87.9247
Train: [77][600/10010]	Time 0.541 (325.133)	Data 0.002 (1.492)	Loss 1.282	Prec@1 69.8419	Prec@5 87.8705
Train: [77][800/10010]	Time 0.541 (433.376)	Data 0.002 (1.602)	Loss 1.280	Prec@1 69.8365	Prec@5 87.8804
Train: [77][1000/10010]	Time 0.541 (541.288)	Data 0.002 (1.713)	Loss 1.284	Prec@1 69.7662	Prec@5 87.8083
Train: [77][1200/10010]	Time 0.541 (649.271)	Data 0.002 (1.834)	Loss 1.287	Prec@1 69.7023	Prec@5 87.7374
Train: [77][1400/10010]	Time 0.540 (757.065)	Data 0.001 (1.957)	Loss 1.285	Prec@1 69.7593	Prec@5 87.7576
Train: [77][1600/10010]	Time 0.540 (864.977)	Data 0.001 (2.085)	Loss 1.287	Prec@1 69.7108	Prec@5 87.7415
Train: [77][1800/10010]	Time 0.540 (972.740)	Data 0.001 (2.207)	Loss 1.286	Prec@1 69.7278	Prec@5 87.7663
Train: [77][2000/10010]	Time 0.540 (1080.656)	Data 0.001 (2.328)	Loss 1.288	Prec@1 69.7069	Prec@5 87.7327
Train: [77][2200/10010]	Time 0.540 (1188.573)	Data 0.001 (2.448)	Loss 1.289	Prec@1 69.6761	Prec@5 87.7215
Train: [77][2400/10010]	Time 0.540 (1296.546)	Data 0.001 (2.569)	Loss 1.289	Prec@1 69.6656	Prec@5 87.7089
Train: [77][2600/10010]	Time 0.540 (1404.236)	Data 0.001 (2.689)	Loss 1.289	Prec@1 69.6454	Prec@5 87.6898
Train: [77][2800/10010]	Time 0.540 (1512.185)	Data 0.001 (2.810)	Loss 1.290	Prec@1 69.6225	Prec@5 87.6757
Train: [77][3000/10010]	Time 0.540 (1619.820)	Data 0.001 (2.932)	Loss 1.291	Prec@1 69.6008	Prec@5 87.6807
Train: [77][3200/10010]	Time 0.540 (1727.469)	Data 0.001 (3.051)	Loss 1.291	Prec@1 69.5769	Prec@5 87.6840
Train: [77][3400/10010]	Time 0.540 (1835.250)	Data 0.001 (3.169)	Loss 1.292	Prec@1 69.5522	Prec@5 87.6629
Train: [77][3600/10010]	Time 0.540 (1942.776)	Data 0.001 (3.287)	Loss 1.292	Prec@1 69.5499	Prec@5 87.6668
Train: [77][3800/10010]	Time 0.540 (2051.364)	Data 0.001 (3.419)	Loss 1.293	Prec@1 69.5253	Prec@5 87.6772
Train: [77][4000/10010]	Time 0.540 (2160.308)	Data 0.001 (3.563)	Loss 1.293	Prec@1 69.5145	Prec@5 87.6753
Train: [77][4200/10010]	Time 0.540 (2269.159)	Data 0.001 (3.711)	Loss 1.295	Prec@1 69.4805	Prec@5 87.6477
Train: [77][4400/10010]	Time 0.540 (2378.597)	Data 0.001 (3.859)	Loss 1.295	Prec@1 69.4901	Prec@5 87.6394
Train: [77][4600/10010]	Time 0.541 (2487.440)	Data 0.001 (4.003)	Loss 1.295	Prec@1 69.4924	Prec@5 87.6245
Train: [77][4800/10010]	Time 0.541 (2596.227)	Data 0.001 (4.150)	Loss 1.296	Prec@1 69.4802	Prec@5 87.6110
Train: [77][5000/10010]	Time 0.541 (2705.147)	Data 0.001 (4.299)	Loss 1.296	Prec@1 69.4706	Prec@5 87.6111
Train: [77][5200/10010]	Time 0.541 (2814.066)	Data 0.001 (4.441)	Loss 1.297	Prec@1 69.4599	Prec@5 87.6014
Train: [77][5400/10010]	Time 0.541 (2923.158)	Data 0.001 (4.587)	Loss 1.297	Prec@1 69.4398	Prec@5 87.5992
Train: [77][5600/10010]	Time 0.541 (3032.284)	Data 0.001 (4.732)	Loss 1.298	Prec@1 69.4283	Prec@5 87.5916
Train: [77][5800/10010]	Time 0.542 (3141.410)	Data 0.001 (4.880)	Loss 1.298	Prec@1 69.4274	Prec@5 87.5936
Train: [77][6000/10010]	Time 0.542 (3250.401)	Data 0.001 (5.028)	Loss 1.298	Prec@1 69.4271	Prec@5 87.5877
Train: [77][6200/10010]	Time 0.542 (3359.352)	Data 0.001 (5.176)	Loss 1.299	Prec@1 69.4116	Prec@5 87.5761
Train: [77][6400/10010]	Time 0.542 (3468.304)	Data 0.001 (5.325)	Loss 1.299	Prec@1 69.4174	Prec@5 87.5691
Train: [77][6600/10010]	Time 0.542 (3577.356)	Data 0.001 (5.473)	Loss 1.299	Prec@1 69.4211	Prec@5 87.5676
Train: [77][6800/10010]	Time 0.542 (3686.703)	Data 0.001 (5.625)	Loss 1.298	Prec@1 69.4221	Prec@5 87.5683
Train: [77][7000/10010]	Time 0.542 (3795.670)	Data 0.001 (5.770)	Loss 1.299	Prec@1 69.4047	Prec@5 87.5623
Train: [77][7200/10010]	Time 0.542 (3904.720)	Data 0.001 (5.918)	Loss 1.299	Prec@1 69.3973	Prec@5 87.5630
Train: [77][7400/10010]	Time 0.542 (4013.557)	Data 0.001 (6.058)	Loss 1.299	Prec@1 69.3971	Prec@5 87.5627
Train: [77][7600/10010]	Time 0.542 (4122.423)	Data 0.001 (6.200)	Loss 1.299	Prec@1 69.4048	Prec@5 87.5629
Train: [77][7800/10010]	Time 0.542 (4231.343)	Data 0.001 (6.343)	Loss 1.299	Prec@1 69.4100	Prec@5 87.5616
Train: [77][8000/10010]	Time 0.542 (4340.009)	Data 0.001 (6.486)	Loss 1.299	Prec@1 69.4032	Prec@5 87.5534
Train: [77][8200/10010]	Time 0.542 (4448.701)	Data 0.001 (6.624)	Loss 1.299	Prec@1 69.4012	Prec@5 87.5536
Train: [77][8400/10010]	Time 0.543 (4557.669)	Data 0.001 (6.767)	Loss 1.299	Prec@1 69.3943	Prec@5 87.5540
Train: [77][8600/10010]	Time 0.543 (4666.605)	Data 0.001 (6.910)	Loss 1.299	Prec@1 69.3869	Prec@5 87.5502
Train: [77][8800/10010]	Time 0.543 (4775.365)	Data 0.001 (7.054)	Loss 1.299	Prec@1 69.3909	Prec@5 87.5546
Train: [77][9000/10010]	Time 0.543 (4884.463)	Data 0.001 (7.202)	Loss 1.299	Prec@1 69.3920	Prec@5 87.5548
Train: [77][9200/10010]	Time 0.543 (4993.336)	Data 0.001 (7.348)	Loss 1.299	Prec@1 69.4013	Prec@5 87.5549
Train: [77][9400/10010]	Time 0.543 (5102.024)	Data 0.001 (7.486)	Loss 1.299	Prec@1 69.4006	Prec@5 87.5543
Train: [77][9600/10010]	Time 0.543 (5210.912)	Data 0.001 (7.631)	Loss 1.299	Prec@1 69.3953	Prec@5 87.5562
Train: [77][9800/10010]	Time 0.543 (5319.715)	Data 0.001 (7.781)	Loss 1.299	Prec@1 69.3886	Prec@5 87.5486
Train: [77][10000/10010]	Time 0.543 (5428.741)	Data 0.001 (7.926)	Loss 1.300	Prec@1 69.3731	Prec@5 87.5484
Train: [77]	Time 5433.161	Data 7.929	Loss 1.300	Prec@1 69.3727	Prec@5 87.5482	
Val: [77]	Time 69.873	Data 1.393	Loss 1.149	Prec@1 71.6520	Prec@5 90.3080	
Best Prec@1: [71.652]	
Starting epoch number: 78 Learning rate: 0.0010000000000000002
Train: [78][0/10010]	Time 1.915 (1.915)	Data 1.364 (1.364)	Loss 1.432	Prec@1 73.4375	Prec@5 86.7188
Train: [78][200/10010]	Time 0.552 (110.973)	Data 0.008 (1.512)	Loss 1.290	Prec@1 69.4224	Prec@5 87.9003
Train: [78][400/10010]	Time 0.549 (220.074)	Data 0.004 (1.662)	Loss 1.286	Prec@1 69.5254	Prec@5 87.9111
Train: [78][600/10010]	Time 0.547 (328.944)	Data 0.003 (1.812)	Loss 1.284	Prec@1 69.6079	Prec@5 87.8575
Train: [78][800/10010]	Time 0.546 (437.734)	Data 0.002 (1.961)	Loss 1.283	Prec@1 69.6463	Prec@5 87.8258
Train: [78][1000/10010]	Time 0.546 (546.815)	Data 0.002 (2.113)	Loss 1.286	Prec@1 69.6585	Prec@5 87.7435
Train: [78][1200/10010]	Time 0.546 (655.905)	Data 0.002 (2.273)	Loss 1.286	Prec@1 69.6653	Prec@5 87.7407
Train: [78][1400/10010]	Time 0.546 (765.297)	Data 0.002 (2.433)	Loss 1.289	Prec@1 69.5759	Prec@5 87.6846
Train: [78][1600/10010]	Time 0.547 (875.099)	Data 0.002 (2.596)	Loss 1.286	Prec@1 69.6186	Prec@5 87.7152
Train: [78][1800/10010]	Time 0.547 (984.510)	Data 0.002 (2.756)	Loss 1.285	Prec@1 69.6679	Prec@5 87.7412
Train: [78][2000/10010]	Time 0.547 (1094.278)	Data 0.001 (2.922)	Loss 1.285	Prec@1 69.6722	Prec@5 87.7339
Train: [78][2200/10010]	Time 0.547 (1203.809)	Data 0.001 (3.091)	Loss 1.284	Prec@1 69.6814	Prec@5 87.7591
Train: [78][2400/10010]	Time 0.547 (1313.866)	Data 0.001 (3.257)	Loss 1.285	Prec@1 69.6718	Prec@5 87.7304
Train: [78][2600/10010]	Time 0.547 (1423.752)	Data 0.001 (3.425)	Loss 1.286	Prec@1 69.6634	Prec@5 87.6982
Train: [78][2800/10010]	Time 0.547 (1533.396)	Data 0.001 (3.590)	Loss 1.286	Prec@1 69.6741	Prec@5 87.7056
Train: [78][3000/10010]	Time 0.547 (1642.996)	Data 0.001 (3.755)	Loss 1.286	Prec@1 69.6549	Prec@5 87.7036
Train: [78][3200/10010]	Time 0.548 (1752.831)	Data 0.001 (3.920)	Loss 1.287	Prec@1 69.6184	Prec@5 87.6950
Train: [78][3400/10010]	Time 0.548 (1862.822)	Data 0.001 (4.091)	Loss 1.288	Prec@1 69.6029	Prec@5 87.7028
Train: [78][3600/10010]	Time 0.548 (1972.468)	Data 0.001 (4.259)	Loss 1.289	Prec@1 69.5848	Prec@5 87.6829
Train: [78][3800/10010]	Time 0.548 (2082.441)	Data 0.001 (4.427)	Loss 1.289	Prec@1 69.5785	Prec@5 87.6827
Train: [78][4000/10010]	Time 0.548 (2191.517)	Data 0.001 (4.580)	Loss 1.288	Prec@1 69.5851	Prec@5 87.6958
Train: [78][4200/10010]	Time 0.547 (2300.011)	Data 0.001 (4.714)	Loss 1.288	Prec@1 69.5895	Prec@5 87.7038
Train: [78][4400/10010]	Time 0.547 (2408.365)	Data 0.001 (4.848)	Loss 1.289	Prec@1 69.5767	Prec@5 87.6926
Train: [78][4600/10010]	Time 0.547 (2517.151)	Data 0.001 (4.990)	Loss 1.289	Prec@1 69.5574	Prec@5 87.6941
Train: [78][4800/10010]	Time 0.547 (2625.698)	Data 0.001 (5.126)	Loss 1.289	Prec@1 69.5456	Prec@5 87.6997
Train: [78][5000/10010]	Time 0.547 (2733.970)	Data 0.001 (5.260)	Loss 1.289	Prec@1 69.5591	Prec@5 87.7017
Train: [78][5200/10010]	Time 0.547 (2842.555)	Data 0.001 (5.399)	Loss 1.290	Prec@1 69.5542	Prec@5 87.6866
Train: [78][5400/10010]	Time 0.546 (2951.038)	Data 0.001 (5.534)	Loss 1.289	Prec@1 69.5784	Prec@5 87.6969
Train: [78][5600/10010]	Time 0.546 (3059.787)	Data 0.001 (5.670)	Loss 1.290	Prec@1 69.5637	Prec@5 87.6901
Train: [78][5800/10010]	Time 0.546 (3168.618)	Data 0.001 (5.809)	Loss 1.290	Prec@1 69.5725	Prec@5 87.6884
Train: [78][6000/10010]	Time 0.546 (3279.076)	Data 0.001 (5.990)	Loss 1.290	Prec@1 69.5759	Prec@5 87.6988
Train: [78][6200/10010]	Time 0.546 (3388.640)	Data 0.001 (6.159)	Loss 1.290	Prec@1 69.5758	Prec@5 87.7004
Train: [78][6400/10010]	Time 0.546 (3497.261)	Data 0.001 (6.297)	Loss 1.290	Prec@1 69.5690	Prec@5 87.6965
Train: [78][6600/10010]	Time 0.546 (3605.321)	Data 0.001 (6.421)	Loss 1.290	Prec@1 69.5600	Prec@5 87.6894
Train: [78][6800/10010]	Time 0.546 (3713.420)	Data 0.001 (6.549)	Loss 1.291	Prec@1 69.5563	Prec@5 87.6740
Train: [78][7000/10010]	Time 0.546 (3821.438)	Data 0.001 (6.676)	Loss 1.291	Prec@1 69.5536	Prec@5 87.6654
Train: [78][7200/10010]	Time 0.546 (3929.406)	Data 0.001 (6.798)	Loss 1.291	Prec@1 69.5349	Prec@5 87.6607
Train: [78][7400/10010]	Time 0.546 (4037.783)	Data 0.001 (6.921)	Loss 1.291	Prec@1 69.5345	Prec@5 87.6557
Train: [78][7600/10010]	Time 0.545 (4145.835)	Data 0.001 (7.041)	Loss 1.291	Prec@1 69.5302	Prec@5 87.6550
Train: [78][7800/10010]	Time 0.545 (4253.791)	Data 0.001 (7.160)	Loss 1.292	Prec@1 69.5286	Prec@5 87.6474
Train: [78][8000/10010]	Time 0.545 (4361.505)	Data 0.001 (7.276)	Loss 1.292	Prec@1 69.5196	Prec@5 87.6448
Train: [78][8200/10010]	Time 0.545 (4469.221)	Data 0.001 (7.396)	Loss 1.292	Prec@1 69.5227	Prec@5 87.6385
Train: [78][8400/10010]	Time 0.545 (4576.864)	Data 0.001 (7.514)	Loss 1.292	Prec@1 69.5397	Prec@5 87.6528
Train: [78][8600/10010]	Time 0.545 (4684.796)	Data 0.001 (7.640)	Loss 1.291	Prec@1 69.5393	Prec@5 87.6534
Train: [78][8800/10010]	Time 0.545 (4792.751)	Data 0.001 (7.765)	Loss 1.291	Prec@1 69.5487	Prec@5 87.6582
Train: [78][9000/10010]	Time 0.544 (4900.516)	Data 0.001 (7.882)	Loss 1.291	Prec@1 69.5412	Prec@5 87.6622
Train: [78][9200/10010]	Time 0.544 (5008.631)	Data 0.001 (8.000)	Loss 1.292	Prec@1 69.5191	Prec@5 87.6550
Train: [78][9400/10010]	Time 0.544 (5116.463)	Data 0.001 (8.116)	Loss 1.292	Prec@1 69.5207	Prec@5 87.6571
Train: [78][9600/10010]	Time 0.544 (5224.358)	Data 0.001 (8.233)	Loss 1.292	Prec@1 69.5084	Prec@5 87.6520
Train: [78][9800/10010]	Time 0.544 (5332.200)	Data 0.001 (8.350)	Loss 1.292	Prec@1 69.5057	Prec@5 87.6515
Train: [78][10000/10010]	Time 0.544 (5439.939)	Data 0.001 (8.466)	Loss 1.292	Prec@1 69.5070	Prec@5 87.6455
Train: [78]	Time 5444.387	Data 8.468	Loss 1.292	Prec@1 69.5069	Prec@5 87.6450	
Val: [78]	Time 67.964	Data 1.747	Loss 1.149	Prec@1 71.5800	Prec@5 90.3700	
Best Prec@1: [71.652]	
Starting epoch number: 79 Learning rate: 0.0010000000000000002
Train: [79][0/10010]	Time 1.911 (1.911)	Data 1.301 (1.301)	Loss 1.112	Prec@1 71.8750	Prec@5 92.9688
Train: [79][200/10010]	Time 0.547 (109.891)	Data 0.007 (1.429)	Loss 1.289	Prec@1 69.6401	Prec@5 87.5622
Train: [79][400/10010]	Time 0.543 (217.672)	Data 0.004 (1.546)	Loss 1.304	Prec@1 69.3384	Prec@5 87.3792
Train: [79][600/10010]	Time 0.542 (325.576)	Data 0.003 (1.662)	Loss 1.291	Prec@1 69.6404	Prec@5 87.6196
Train: [79][800/10010]	Time 0.542 (434.094)	Data 0.002 (1.792)	Loss 1.288	Prec@1 69.6980	Prec@5 87.7038
Train: [79][1000/10010]	Time 0.542 (542.873)	Data 0.002 (1.922)	Loss 1.285	Prec@1 69.7709	Prec@5 87.7232
Train: [79][1200/10010]	Time 0.543 (652.611)	Data 0.002 (2.040)	Loss 1.283	Prec@1 69.7576	Prec@5 87.7752
Train: [79][1400/10010]	Time 0.544 (762.586)	Data 0.002 (2.158)	Loss 1.285	Prec@1 69.7114	Prec@5 87.7571
Train: [79][1600/10010]	Time 0.545 (872.306)	Data 0.001 (2.273)	Loss 1.285	Prec@1 69.7025	Prec@5 87.7616
Train: [79][1800/10010]	Time 0.545 (981.785)	Data 0.001 (2.399)	Loss 1.286	Prec@1 69.6744	Prec@5 87.7186
Train: [79][2000/10010]	Time 0.545 (1090.744)	Data 0.001 (2.556)	Loss 1.284	Prec@1 69.6808	Prec@5 87.7612
Train: [79][2200/10010]	Time 0.545 (1199.501)	Data 0.001 (2.705)	Loss 1.284	Prec@1 69.6793	Prec@5 87.7623
Train: [79][2400/10010]	Time 0.545 (1308.051)	Data 0.001 (2.851)	Loss 1.285	Prec@1 69.6699	Prec@5 87.7665
Train: [79][2600/10010]	Time 0.545 (1416.824)	Data 0.001 (2.995)	Loss 1.285	Prec@1 69.6853	Prec@5 87.7406
Train: [79][2800/10010]	Time 0.545 (1525.699)	Data 0.001 (3.143)	Loss 1.284	Prec@1 69.6994	Prec@5 87.7541
Train: [79][3000/10010]	Time 0.545 (1634.452)	Data 0.001 (3.288)	Loss 1.284	Prec@1 69.6994	Prec@5 87.7658
Train: [79][3200/10010]	Time 0.545 (1743.302)	Data 0.001 (3.435)	Loss 1.283	Prec@1 69.6918	Prec@5 87.7763
Train: [79][3400/10010]	Time 0.545 (1852.179)	Data 0.001 (3.583)	Loss 1.284	Prec@1 69.6691	Prec@5 87.7717
Train: [79][3600/10010]	Time 0.545 (1961.035)	Data 0.001 (3.726)	Loss 1.285	Prec@1 69.6473	Prec@5 87.7506
Train: [79][3800/10010]	Time 0.545 (2069.816)	Data 0.001 (3.873)	Loss 1.285	Prec@1 69.6353	Prec@5 87.7524
Train: [79][4000/10010]	Time 0.544 (2178.402)	Data 0.001 (4.018)	Loss 1.284	Prec@1 69.6515	Prec@5 87.7671
Train: [79][4200/10010]	Time 0.544 (2286.831)	Data 0.001 (4.159)	Loss 1.285	Prec@1 69.6434	Prec@5 87.7566
Train: [79][4400/10010]	Time 0.544 (2395.318)	Data 0.001 (4.300)	Loss 1.286	Prec@1 69.6317	Prec@5 87.7466
Train: [79][4600/10010]	Time 0.544 (2504.089)	Data 0.001 (4.447)	Loss 1.286	Prec@1 69.6394	Prec@5 87.7501
Train: [79][4800/10010]	Time 0.544 (2613.014)	Data 0.001 (4.593)	Loss 1.285	Prec@1 69.6393	Prec@5 87.7377
Train: [79][5000/10010]	Time 0.544 (2721.761)	Data 0.001 (4.734)	Loss 1.286	Prec@1 69.6306	Prec@5 87.7368
Train: [79][5200/10010]	Time 0.544 (2831.177)	Data 0.001 (4.889)	Loss 1.285	Prec@1 69.6265	Prec@5 87.7421
Train: [79][5400/10010]	Time 0.544 (2940.007)	Data 0.001 (5.034)	Loss 1.286	Prec@1 69.6253	Prec@5 87.7372
Train: [79][5600/10010]	Time 0.544 (3048.766)	Data 0.001 (5.178)	Loss 1.287	Prec@1 69.6119	Prec@5 87.7240
Train: [79][5800/10010]	Time 0.544 (3157.363)	Data 0.001 (5.320)	Loss 1.287	Prec@1 69.6111	Prec@5 87.7104
Train: [79][6000/10010]	Time 0.544 (3265.895)	Data 0.001 (5.461)	Loss 1.287	Prec@1 69.6045	Prec@5 87.7061
Train: [79][6200/10010]	Time 0.544 (3374.616)	Data 0.001 (5.604)	Loss 1.287	Prec@1 69.5921	Prec@5 87.7080
Train: [79][6400/10010]	Time 0.544 (3483.309)	Data 0.001 (5.755)	Loss 1.287	Prec@1 69.5947	Prec@5 87.7111
Train: [79][6600/10010]	Time 0.544 (3592.222)	Data 0.001 (5.902)	Loss 1.288	Prec@1 69.5763	Prec@5 87.7005
Train: [79][6800/10010]	Time 0.544 (3700.977)	Data 0.001 (6.053)	Loss 1.288	Prec@1 69.5812	Prec@5 87.7022
Train: [79][7000/10010]	Time 0.544 (3809.927)	Data 0.001 (6.200)	Loss 1.288	Prec@1 69.5620	Prec@5 87.6936
Train: [79][7200/10010]	Time 0.544 (3919.055)	Data 0.001 (6.350)	Loss 1.288	Prec@1 69.5567	Prec@5 87.6904
Train: [79][7400/10010]	Time 0.544 (4028.162)	Data 0.001 (6.501)	Loss 1.288	Prec@1 69.5590	Prec@5 87.6860
Train: [79][7600/10010]	Time 0.544 (4137.047)	Data 0.001 (6.656)	Loss 1.289	Prec@1 69.5450	Prec@5 87.6778
Train: [79][7800/10010]	Time 0.544 (4246.047)	Data 0.001 (6.806)	Loss 1.289	Prec@1 69.5443	Prec@5 87.6754
Train: [79][8000/10010]	Time 0.544 (4354.807)	Data 0.001 (6.957)	Loss 1.289	Prec@1 69.5383	Prec@5 87.6747
Train: [79][8200/10010]	Time 0.544 (4463.556)	Data 0.001 (7.105)	Loss 1.289	Prec@1 69.5486	Prec@5 87.6724
Train: [79][8400/10010]	Time 0.544 (4572.248)	Data 0.001 (7.253)	Loss 1.289	Prec@1 69.5397	Prec@5 87.6711
Train: [79][8600/10010]	Time 0.544 (4681.200)	Data 0.001 (7.406)	Loss 1.290	Prec@1 69.5329	Prec@5 87.6665
Train: [79][8800/10010]	Time 0.544 (4790.291)	Data 0.001 (7.555)	Loss 1.290	Prec@1 69.5261	Prec@5 87.6668
Train: [79][9000/10010]	Time 0.544 (4899.402)	Data 0.001 (7.707)	Loss 1.290	Prec@1 69.5152	Prec@5 87.6638
Train: [79][9200/10010]	Time 0.544 (5008.431)	Data 0.001 (7.857)	Loss 1.291	Prec@1 69.5033	Prec@5 87.6600
Train: [79][9400/10010]	Time 0.544 (5117.442)	Data 0.001 (8.007)	Loss 1.291	Prec@1 69.5012	Prec@5 87.6605
Train: [79][9600/10010]	Time 0.544 (5225.870)	Data 0.001 (8.144)	Loss 1.291	Prec@1 69.4984	Prec@5 87.6613
Train: [79][9800/10010]	Time 0.544 (5334.185)	Data 0.001 (8.277)	Loss 1.291	Prec@1 69.4991	Prec@5 87.6648
Train: [79][10000/10010]	Time 0.544 (5442.393)	Data 0.001 (8.413)	Loss 1.291	Prec@1 69.4935	Prec@5 87.6640
Train: [79]	Time 5446.788	Data 8.416	Loss 1.291	Prec@1 69.4913	Prec@5 87.6635	
Val: [79]	Time 69.482	Data 1.650	Loss 1.148	Prec@1 71.4720	Prec@5 90.3960	
Best Prec@1: [71.652]	
Starting epoch number: 80 Learning rate: 0.0010000000000000002
Train: [80][0/10010]	Time 1.789 (1.789)	Data 1.234 (1.234)	Loss 1.484	Prec@1 65.6250	Prec@5 83.5938
Train: [80][200/10010]	Time 0.548 (110.050)	Data 0.007 (1.387)	Loss 1.292	Prec@1 69.2786	Prec@5 87.5505
Train: [80][400/10010]	Time 0.545 (218.581)	Data 0.004 (1.526)	Loss 1.282	Prec@1 69.6637	Prec@5 87.6052
Train: [80][600/10010]	Time 0.544 (327.009)	Data 0.003 (1.664)	Loss 1.284	Prec@1 69.6963	Prec@5 87.7171
Train: [80][800/10010]	Time 0.544 (435.614)	Data 0.002 (1.802)	Loss 1.288	Prec@1 69.5956	Prec@5 87.6444
Train: [80][1000/10010]	Time 0.543 (543.925)	Data 0.002 (1.937)	Loss 1.287	Prec@1 69.5234	Prec@5 87.6787
Train: [80][1200/10010]	Time 0.544 (653.479)	Data 0.002 (2.075)	Loss 1.286	Prec@1 69.5599	Prec@5 87.7264
Train: [80][1400/10010]	Time 0.544 (762.026)	Data 0.002 (2.205)	Loss 1.285	Prec@1 69.6272	Prec@5 87.7309
Train: [80][1600/10010]	Time 0.544 (870.244)	Data 0.001 (2.332)	Loss 1.287	Prec@1 69.5859	Prec@5 87.6757
Train: [80][1800/10010]	Time 0.543 (978.422)	Data 0.001 (2.463)	Loss 1.285	Prec@1 69.6163	Prec@5 87.6961
Train: [80][2000/10010]	Time 0.543 (1086.800)	Data 0.001 (2.599)	Loss 1.287	Prec@1 69.5879	Prec@5 87.6972
Train: [80][2200/10010]	Time 0.543 (1195.018)	Data 0.001 (2.732)	Loss 1.288	Prec@1 69.5621	Prec@5 87.7009
Train: [80][2400/10010]	Time 0.543 (1303.271)	Data 0.001 (2.864)	Loss 1.287	Prec@1 69.6061	Prec@5 87.7206
Train: [80][2600/10010]	Time 0.543 (1411.465)	Data 0.001 (3.000)	Loss 1.286	Prec@1 69.6280	Prec@5 87.7214
Train: [80][2800/10010]	Time 0.543 (1519.832)	Data 0.001 (3.135)	Loss 1.286	Prec@1 69.6448	Prec@5 87.7097
Train: [80][3000/10010]	Time 0.543 (1628.348)	Data 0.001 (3.275)	Loss 1.286	Prec@1 69.6437	Prec@5 87.6890
Train: [80][3200/10010]	Time 0.543 (1737.092)	Data 0.001 (3.415)	Loss 1.288	Prec@1 69.6206	Prec@5 87.6716
Train: [80][3400/10010]	Time 0.543 (1845.791)	Data 0.001 (3.554)	Loss 1.288	Prec@1 69.6236	Prec@5 87.6601
Train: [80][3600/10010]	Time 0.543 (1954.247)	Data 0.001 (3.692)	Loss 1.288	Prec@1 69.6054	Prec@5 87.6608
Train: [80][3800/10010]	Time 0.543 (2062.666)	Data 0.001 (3.827)	Loss 1.289	Prec@1 69.5997	Prec@5 87.6605
Train: [80][4000/10010]	Time 0.543 (2171.290)	Data 0.001 (3.966)	Loss 1.289	Prec@1 69.5990	Prec@5 87.6607
Train: [80][4200/10010]	Time 0.543 (2279.972)	Data 0.001 (4.106)	Loss 1.289	Prec@1 69.5934	Prec@5 87.6614
Train: [80][4400/10010]	Time 0.543 (2388.770)	Data 0.001 (4.252)	Loss 1.289	Prec@1 69.5959	Prec@5 87.6608
Train: [80][4600/10010]	Time 0.543 (2497.282)	Data 0.001 (4.392)	Loss 1.290	Prec@1 69.5674	Prec@5 87.6506
Train: [80][4800/10010]	Time 0.543 (2605.879)	Data 0.001 (4.532)	Loss 1.289	Prec@1 69.5858	Prec@5 87.6619
Train: [80][5000/10010]	Time 0.543 (2714.500)	Data 0.001 (4.675)	Loss 1.288	Prec@1 69.6014	Prec@5 87.6773
Train: [80][5200/10010]	Time 0.543 (2823.154)	Data 0.001 (4.817)	Loss 1.288	Prec@1 69.6058	Prec@5 87.6876
Train: [80][5400/10010]	Time 0.543 (2931.875)	Data 0.001 (4.959)	Loss 1.287	Prec@1 69.6002	Prec@5 87.6941
Train: [80][5600/10010]	Time 0.543 (3040.365)	Data 0.001 (5.103)	Loss 1.287	Prec@1 69.5942	Prec@5 87.6956
Train: [80][5800/10010]	Time 0.543 (3149.084)	Data 0.001 (5.245)	Loss 1.287	Prec@1 69.5869	Prec@5 87.6977
Train: [80][6000/10010]	Time 0.543 (3257.721)	Data 0.001 (5.385)	Loss 1.288	Prec@1 69.5682	Prec@5 87.6944
Train: [80][6200/10010]	Time 0.543 (3366.364)	Data 0.001 (5.525)	Loss 1.288	Prec@1 69.5607	Prec@5 87.6923
Train: [80][6400/10010]	Time 0.543 (3474.955)	Data 0.001 (5.665)	Loss 1.288	Prec@1 69.5648	Prec@5 87.6895
Train: [80][6600/10010]	Time 0.543 (3583.422)	Data 0.001 (5.806)	Loss 1.288	Prec@1 69.5606	Prec@5 87.6866
Train: [80][6800/10010]	Time 0.543 (3691.881)	Data 0.001 (5.945)	Loss 1.289	Prec@1 69.5550	Prec@5 87.6802
Train: [80][7000/10010]	Time 0.543 (3800.454)	Data 0.001 (6.083)	Loss 1.289	Prec@1 69.5445	Prec@5 87.6761
Train: [80][7200/10010]	Time 0.543 (3909.107)	Data 0.001 (6.225)	Loss 1.289	Prec@1 69.5546	Prec@5 87.6776
Train: [80][7400/10010]	Time 0.543 (4017.676)	Data 0.001 (6.363)	Loss 1.289	Prec@1 69.5582	Prec@5 87.6744
Train: [80][7600/10010]	Time 0.543 (4126.351)	Data 0.001 (6.503)	Loss 1.289	Prec@1 69.5544	Prec@5 87.6717
Train: [80][7800/10010]	Time 0.543 (4234.982)	Data 0.001 (6.639)	Loss 1.289	Prec@1 69.5476	Prec@5 87.6706
Train: [80][8000/10010]	Time 0.543 (4343.552)	Data 0.001 (6.781)	Loss 1.289	Prec@1 69.5425	Prec@5 87.6660
Train: [80][8200/10010]	Time 0.543 (4452.151)	Data 0.001 (6.925)	Loss 1.290	Prec@1 69.5409	Prec@5 87.6640
Train: [80][8400/10010]	Time 0.543 (4560.641)	Data 0.001 (7.067)	Loss 1.289	Prec@1 69.5457	Prec@5 87.6676
Train: [80][8600/10010]	Time 0.543 (4669.051)	Data 0.001 (7.209)	Loss 1.290	Prec@1 69.5362	Prec@5 87.6601
Train: [80][8800/10010]	Time 0.543 (4777.717)	Data 0.001 (7.349)	Loss 1.290	Prec@1 69.5310	Prec@5 87.6569
Train: [80][9000/10010]	Time 0.543 (4887.392)	Data 0.001 (7.495)	Loss 1.290	Prec@1 69.5315	Prec@5 87.6573
Train: [80][9200/10010]	Time 0.543 (4996.315)	Data 0.001 (7.633)	Loss 1.290	Prec@1 69.5258	Prec@5 87.6551
Train: [80][9400/10010]	Time 0.543 (5104.871)	Data 0.001 (7.771)	Loss 1.289	Prec@1 69.5308	Prec@5 87.6648
Train: [80][9600/10010]	Time 0.543 (5213.309)	Data 0.001 (7.913)	Loss 1.290	Prec@1 69.5294	Prec@5 87.6620
Train: [80][9800/10010]	Time 0.543 (5322.020)	Data 0.001 (8.051)	Loss 1.290	Prec@1 69.5288	Prec@5 87.6631
Train: [80][10000/10010]	Time 0.543 (5430.692)	Data 0.001 (8.192)	Loss 1.289	Prec@1 69.5376	Prec@5 87.6627
Train: [80]	Time 5435.114	Data 8.194	Loss 1.289	Prec@1 69.5342	Prec@5 87.6612	
Val: [80]	Time 68.877	Data 1.612	Loss 1.151	Prec@1 71.4020	Prec@5 90.4100	
Best Prec@1: [71.652]	
Starting epoch number: 81 Learning rate: 0.0010000000000000002
Train: [81][0/10010]	Time 1.856 (1.856)	Data 1.297 (1.297)	Loss 0.884	Prec@1 78.9062	Prec@5 92.1875
Train: [81][200/10010]	Time 0.549 (110.443)	Data 0.007 (1.442)	Loss 1.276	Prec@1 69.7994	Prec@5 88.0480
Train: [81][400/10010]	Time 0.545 (218.639)	Data 0.004 (1.579)	Loss 1.269	Prec@1 69.9930	Prec@5 87.9345
Train: [81][600/10010]	Time 0.544 (326.957)	Data 0.003 (1.718)	Loss 1.272	Prec@1 69.9277	Prec@5 87.8549
Train: [81][800/10010]	Time 0.543 (435.236)	Data 0.002 (1.850)	Loss 1.273	Prec@1 70.0267	Prec@5 87.8950
Train: [81][1000/10010]	Time 0.543 (543.661)	Data 0.002 (1.983)	Loss 1.274	Prec@1 70.0245	Prec@5 87.8785
Train: [81][1200/10010]	Time 0.543 (652.184)	Data 0.002 (2.121)	Loss 1.276	Prec@1 69.9547	Prec@5 87.8727
Train: [81][1400/10010]	Time 0.543 (761.018)	Data 0.002 (2.267)	Loss 1.275	Prec@1 69.9450	Prec@5 87.8641
Train: [81][1600/10010]	Time 0.543 (869.918)	Data 0.002 (2.410)	Loss 1.276	Prec@1 69.9451	Prec@5 87.8835
Train: [81][1800/10010]	Time 0.544 (978.847)	Data 0.001 (2.554)	Loss 1.279	Prec@1 69.8536	Prec@5 87.8232
Train: [81][2000/10010]	Time 0.544 (1087.699)	Data 0.001 (2.700)	Loss 1.279	Prec@1 69.8627	Prec@5 87.8436
Train: [81][2200/10010]	Time 0.544 (1197.088)	Data 0.001 (2.850)	Loss 1.278	Prec@1 69.8827	Prec@5 87.8550
Train: [81][2400/10010]	Time 0.544 (1306.318)	Data 0.001 (3.002)	Loss 1.278	Prec@1 69.8534	Prec@5 87.8635
Train: [81][2600/10010]	Time 0.544 (1415.608)	Data 0.001 (3.151)	Loss 1.277	Prec@1 69.8752	Prec@5 87.8622
Train: [81][2800/10010]	Time 0.544 (1524.423)	Data 0.001 (3.299)	Loss 1.278	Prec@1 69.8289	Prec@5 87.8509
Train: [81][3000/10010]	Time 0.544 (1633.398)	Data 0.001 (3.451)	Loss 1.278	Prec@1 69.8309	Prec@5 87.8460
Train: [81][3200/10010]	Time 0.544 (1742.253)	Data 0.001 (3.607)	Loss 1.278	Prec@1 69.8153	Prec@5 87.8488
Train: [81][3400/10010]	Time 0.544 (1851.429)	Data 0.001 (3.756)	Loss 1.277	Prec@1 69.8228	Prec@5 87.8627
Train: [81][3600/10010]	Time 0.544 (1960.464)	Data 0.001 (3.904)	Loss 1.277	Prec@1 69.8213	Prec@5 87.8582
Train: [81][3800/10010]	Time 0.544 (2069.139)	Data 0.001 (4.050)	Loss 1.279	Prec@1 69.7962	Prec@5 87.8266
Train: [81][4000/10010]	Time 0.544 (2177.823)	Data 0.001 (4.198)	Loss 1.280	Prec@1 69.7695	Prec@5 87.8142
Train: [81][4200/10010]	Time 0.544 (2286.383)	Data 0.001 (4.348)	Loss 1.280	Prec@1 69.7695	Prec@5 87.8132
Train: [81][4400/10010]	Time 0.544 (2394.872)	Data 0.001 (4.499)	Loss 1.280	Prec@1 69.7555	Prec@5 87.8076
Train: [81][4600/10010]	Time 0.544 (2503.561)	Data 0.001 (4.651)	Loss 1.280	Prec@1 69.7522	Prec@5 87.8092
Train: [81][4800/10010]	Time 0.544 (2612.191)	Data 0.001 (4.803)	Loss 1.280	Prec@1 69.7488	Prec@5 87.8064
Train: [81][5000/10010]	Time 0.544 (2720.838)	Data 0.001 (4.957)	Loss 1.281	Prec@1 69.7337	Prec@5 87.7956
Train: [81][5200/10010]	Time 0.544 (2829.698)	Data 0.001 (5.107)	Loss 1.282	Prec@1 69.7259	Prec@5 87.7856
Train: [81][5400/10010]	Time 0.544 (2938.636)	Data 0.001 (5.261)	Loss 1.281	Prec@1 69.7374	Prec@5 87.7889
Train: [81][5600/10010]	Time 0.544 (3048.288)	Data 0.001 (5.415)	Loss 1.282	Prec@1 69.7258	Prec@5 87.7801
Train: [81][5800/10010]	Time 0.544 (3157.519)	Data 0.001 (5.567)	Loss 1.283	Prec@1 69.7236	Prec@5 87.7727
Train: [81][6000/10010]	Time 0.544 (3266.164)	Data 0.001 (5.715)	Loss 1.283	Prec@1 69.7021	Prec@5 87.7619
Train: [81][6200/10010]	Time 0.544 (3374.659)	Data 0.001 (5.863)	Loss 1.284	Prec@1 69.6943	Prec@5 87.7642
Train: [81][6400/10010]	Time 0.544 (3483.090)	Data 0.001 (6.012)	Loss 1.283	Prec@1 69.7051	Prec@5 87.7730
Train: [81][6600/10010]	Time 0.544 (3591.729)	Data 0.001 (6.155)	Loss 1.284	Prec@1 69.6885	Prec@5 87.7688
Train: [81][6800/10010]	Time 0.544 (3700.487)	Data 0.001 (6.305)	Loss 1.284	Prec@1 69.6932	Prec@5 87.7640
Train: [81][7000/10010]	Time 0.544 (3809.947)	Data 0.001 (6.456)	Loss 1.284	Prec@1 69.6910	Prec@5 87.7630
Train: [81][7200/10010]	Time 0.544 (3918.449)	Data 0.001 (6.603)	Loss 1.284	Prec@1 69.6811	Prec@5 87.7628
Train: [81][7400/10010]	Time 0.544 (4026.939)	Data 0.001 (6.755)	Loss 1.284	Prec@1 69.6818	Prec@5 87.7609
Train: [81][7600/10010]	Time 0.544 (4135.470)	Data 0.001 (6.906)	Loss 1.284	Prec@1 69.6888	Prec@5 87.7646
Train: [81][7800/10010]	Time 0.544 (4244.017)	Data 0.001 (7.057)	Loss 1.284	Prec@1 69.6922	Prec@5 87.7582
Train: [81][8000/10010]	Time 0.544 (4352.775)	Data 0.001 (7.208)	Loss 1.285	Prec@1 69.6868	Prec@5 87.7586
Train: [81][8200/10010]	Time 0.544 (4461.404)	Data 0.001 (7.358)	Loss 1.285	Prec@1 69.6803	Prec@5 87.7525
Train: [81][8400/10010]	Time 0.544 (4570.105)	Data 0.001 (7.508)	Loss 1.285	Prec@1 69.6878	Prec@5 87.7622
Train: [81][8600/10010]	Time 0.544 (4678.831)	Data 0.001 (7.656)	Loss 1.285	Prec@1 69.6819	Prec@5 87.7546
Train: [81][8800/10010]	Time 0.544 (4787.580)	Data 0.001 (7.805)	Loss 1.285	Prec@1 69.6864	Prec@5 87.7501
Train: [81][9000/10010]	Time 0.544 (4896.454)	Data 0.001 (7.953)	Loss 1.286	Prec@1 69.6712	Prec@5 87.7427
Train: [81][9200/10010]	Time 0.544 (5005.474)	Data 0.001 (8.100)	Loss 1.286	Prec@1 69.6616	Prec@5 87.7348
Train: [81][9400/10010]	Time 0.544 (5114.248)	Data 0.001 (8.248)	Loss 1.286	Prec@1 69.6590	Prec@5 87.7323
Train: [81][9600/10010]	Time 0.544 (5223.158)	Data 0.001 (8.394)	Loss 1.286	Prec@1 69.6662	Prec@5 87.7354
Train: [81][9800/10010]	Time 0.544 (5332.076)	Data 0.001 (8.539)	Loss 1.286	Prec@1 69.6601	Prec@5 87.7301
Train: [81][10000/10010]	Time 0.544 (5441.025)	Data 0.001 (8.690)	Loss 1.286	Prec@1 69.6571	Prec@5 87.7247
Train: [81]	Time 5445.430	Data 8.694	Loss 1.286	Prec@1 69.6578	Prec@5 87.7251	
Val: [81]	Time 68.795	Data 1.299	Loss 1.169	Prec@1 71.0500	Prec@5 90.0880	
Best Prec@1: [71.652]	
Starting epoch number: 82 Learning rate: 0.0010000000000000002
Train: [82][0/10010]	Time 1.976 (1.976)	Data 1.294 (1.294)	Loss 1.721	Prec@1 63.2812	Prec@5 81.2500
Train: [82][200/10010]	Time 0.548 (110.229)	Data 0.007 (1.440)	Loss 1.282	Prec@1 69.5507	Prec@5 87.6516
Train: [82][400/10010]	Time 0.545 (218.679)	Data 0.004 (1.579)	Loss 1.272	Prec@1 69.9793	Prec@5 87.8721
Train: [82][600/10010]	Time 0.545 (327.263)	Data 0.003 (1.717)	Loss 1.280	Prec@1 69.8003	Prec@5 87.7197
Train: [82][800/10010]	Time 0.544 (435.613)	Data 0.002 (1.863)	Loss 1.277	Prec@1 69.8365	Prec@5 87.7692
Train: [82][1000/10010]	Time 0.543 (543.953)	Data 0.002 (2.003)	Loss 1.275	Prec@1 69.8879	Prec@5 87.7903
Train: [82][1200/10010]	Time 0.543 (652.409)	Data 0.002 (2.149)	Loss 1.275	Prec@1 69.8591	Prec@5 87.7992
Train: [82][1400/10010]	Time 0.543 (761.010)	Data 0.002 (2.296)	Loss 1.274	Prec@1 69.9160	Prec@5 87.8279
Train: [82][1600/10010]	Time 0.544 (870.483)	Data 0.002 (2.448)	Loss 1.274	Prec@1 69.8987	Prec@5 87.8196
Train: [82][1800/10010]	Time 0.544 (979.789)	Data 0.001 (2.594)	Loss 1.276	Prec@1 69.8336	Prec@5 87.8184
Train: [82][2000/10010]	Time 0.545 (1089.935)	Data 0.001 (2.743)	Loss 1.276	Prec@1 69.8057	Prec@5 87.8244
Train: [82][2200/10010]	Time 0.545 (1199.213)	Data 0.001 (2.896)	Loss 1.277	Prec@1 69.7822	Prec@5 87.7989
Train: [82][2400/10010]	Time 0.545 (1307.894)	Data 0.001 (3.042)	Loss 1.278	Prec@1 69.7662	Prec@5 87.7652
Train: [82][2600/10010]	Time 0.545 (1416.472)	Data 0.001 (3.183)	Loss 1.278	Prec@1 69.7514	Prec@5 87.7802
Train: [82][2800/10010]	Time 0.545 (1525.182)	Data 0.001 (3.327)	Loss 1.280	Prec@1 69.7056	Prec@5 87.7505
Train: [82][3000/10010]	Time 0.545 (1634.049)	Data 0.001 (3.471)	Loss 1.279	Prec@1 69.7231	Prec@5 87.7668
Train: [82][3200/10010]	Time 0.544 (1742.552)	Data 0.001 (3.615)	Loss 1.280	Prec@1 69.6994	Prec@5 87.7448
Train: [82][3400/10010]	Time 0.544 (1850.884)	Data 0.001 (3.759)	Loss 1.280	Prec@1 69.6941	Prec@5 87.7557
Train: [82][3600/10010]	Time 0.544 (1959.563)	Data 0.001 (3.906)	Loss 1.280	Prec@1 69.7087	Prec@5 87.7497
Train: [82][3800/10010]	Time 0.544 (2068.148)	Data 0.001 (4.049)	Loss 1.280	Prec@1 69.7267	Prec@5 87.7649
Train: [82][4000/10010]	Time 0.544 (2176.821)	Data 0.001 (4.195)	Loss 1.281	Prec@1 69.7132	Prec@5 87.7648
Train: [82][4200/10010]	Time 0.544 (2285.413)	Data 0.001 (4.343)	Loss 1.280	Prec@1 69.7444	Prec@5 87.7793
Train: [82][4400/10010]	Time 0.544 (2393.633)	Data 0.001 (4.486)	Loss 1.280	Prec@1 69.7400	Prec@5 87.7780
Train: [82][4600/10010]	Time 0.544 (2501.733)	Data 0.001 (4.622)	Loss 1.280	Prec@1 69.7399	Prec@5 87.7751
Train: [82][4800/10010]	Time 0.544 (2609.738)	Data 0.001 (4.756)	Loss 1.280	Prec@1 69.7534	Prec@5 87.7773
Train: [82][5000/10010]	Time 0.543 (2717.922)	Data 0.001 (4.894)	Loss 1.280	Prec@1 69.7614	Prec@5 87.7807
Train: [82][5200/10010]	Time 0.543 (2826.121)	Data 0.001 (5.036)	Loss 1.281	Prec@1 69.7409	Prec@5 87.7696
Train: [82][5400/10010]	Time 0.543 (2934.627)	Data 0.001 (5.179)	Loss 1.281	Prec@1 69.7299	Prec@5 87.7562
Train: [82][5600/10010]	Time 0.543 (3043.064)	Data 0.001 (5.320)	Loss 1.282	Prec@1 69.7131	Prec@5 87.7508
Train: [82][5800/10010]	Time 0.543 (3151.528)	Data 0.001 (5.463)	Loss 1.282	Prec@1 69.7194	Prec@5 87.7551
Train: [82][6000/10010]	Time 0.543 (3259.938)	Data 0.001 (5.603)	Loss 1.282	Prec@1 69.7096	Prec@5 87.7446
Train: [82][6200/10010]	Time 0.543 (3368.342)	Data 0.001 (5.741)	Loss 1.283	Prec@1 69.6997	Prec@5 87.7299
Train: [82][6400/10010]	Time 0.543 (3476.636)	Data 0.001 (5.876)	Loss 1.283	Prec@1 69.6949	Prec@5 87.7312
Train: [82][6600/10010]	Time 0.543 (3584.742)	Data 0.001 (6.009)	Loss 1.283	Prec@1 69.6907	Prec@5 87.7294
Train: [82][6800/10010]	Time 0.543 (3692.731)	Data 0.001 (6.143)	Loss 1.283	Prec@1 69.6890	Prec@5 87.7302
Train: [82][7000/10010]	Time 0.543 (3800.777)	Data 0.001 (6.277)	Loss 1.283	Prec@1 69.6897	Prec@5 87.7345
Train: [82][7200/10010]	Time 0.543 (3909.046)	Data 0.001 (6.414)	Loss 1.283	Prec@1 69.6825	Prec@5 87.7348
Train: [82][7400/10010]	Time 0.543 (4017.119)	Data 0.001 (6.549)	Loss 1.283	Prec@1 69.6853	Prec@5 87.7348
Train: [82][7600/10010]	Time 0.543 (4125.206)	Data 0.001 (6.687)	Loss 1.284	Prec@1 69.6819	Prec@5 87.7344
Train: [82][7800/10010]	Time 0.543 (4233.223)	Data 0.001 (6.823)	Loss 1.283	Prec@1 69.6832	Prec@5 87.7338
Train: [82][8000/10010]	Time 0.543 (4341.307)	Data 0.001 (6.963)	Loss 1.284	Prec@1 69.6860	Prec@5 87.7312
Train: [82][8200/10010]	Time 0.543 (4449.655)	Data 0.001 (7.105)	Loss 1.284	Prec@1 69.6724	Prec@5 87.7224
Train: [82][8400/10010]	Time 0.543 (4557.941)	Data 0.001 (7.244)	Loss 1.284	Prec@1 69.6740	Prec@5 87.7245
Train: [82][8600/10010]	Time 0.543 (4666.141)	Data 0.001 (7.377)	Loss 1.284	Prec@1 69.6725	Prec@5 87.7157
Train: [82][8800/10010]	Time 0.542 (4774.363)	Data 0.001 (7.511)	Loss 1.284	Prec@1 69.6771	Prec@5 87.7226
Train: [82][9000/10010]	Time 0.542 (4882.733)	Data 0.001 (7.649)	Loss 1.284	Prec@1 69.6784	Prec@5 87.7301
Train: [82][9200/10010]	Time 0.542 (4991.214)	Data 0.001 (7.787)	Loss 1.284	Prec@1 69.6742	Prec@5 87.7328
Train: [82][9400/10010]	Time 0.542 (5099.837)	Data 0.001 (7.930)	Loss 1.284	Prec@1 69.6641	Prec@5 87.7265
Train: [82][9600/10010]	Time 0.543 (5208.730)	Data 0.001 (8.083)	Loss 1.284	Prec@1 69.6688	Prec@5 87.7295
Train: [82][9800/10010]	Time 0.543 (5317.582)	Data 0.001 (8.231)	Loss 1.284	Prec@1 69.6628	Prec@5 87.7292
Train: [82][10000/10010]	Time 0.543 (5426.393)	Data 0.001 (8.380)	Loss 1.284	Prec@1 69.6716	Prec@5 87.7301
Train: [82]	Time 5430.986	Data 8.384	Loss 1.284	Prec@1 69.6713	Prec@5 87.7302	
Val: [82]	Time 69.025	Data 1.679	Loss 1.156	Prec@1 71.3200	Prec@5 90.3560	
Best Prec@1: [71.652]	
Starting epoch number: 83 Learning rate: 0.0010000000000000002
Train: [83][0/10010]	Time 1.856 (1.856)	Data 1.270 (1.270)	Loss 1.203	Prec@1 75.0000	Prec@5 89.0625
Train: [83][200/10010]	Time 0.549 (110.345)	Data 0.007 (1.417)	Loss 1.263	Prec@1 70.2425	Prec@5 88.0675
Train: [83][400/10010]	Time 0.545 (218.631)	Data 0.004 (1.556)	Loss 1.260	Prec@1 70.2950	Prec@5 88.1059
Train: [83][600/10010]	Time 0.544 (326.774)	Data 0.003 (1.693)	Loss 1.268	Prec@1 70.0447	Prec@5 87.9654
Train: [83][800/10010]	Time 0.543 (435.143)	Data 0.002 (1.833)	Loss 1.267	Prec@1 70.0930	Prec@5 87.9613
Train: [83][1000/10010]	Time 0.543 (543.792)	Data 0.002 (1.976)	Loss 1.267	Prec@1 70.0635	Prec@5 87.9730
Train: [83][1200/10010]	Time 0.543 (652.351)	Data 0.002 (2.120)	Loss 1.270	Prec@1 70.0367	Prec@5 87.9339
Train: [83][1400/10010]	Time 0.543 (760.953)	Data 0.002 (2.269)	Loss 1.270	Prec@1 70.0270	Prec@5 87.9511
Train: [83][1600/10010]	Time 0.543 (869.547)	Data 0.002 (2.420)	Loss 1.271	Prec@1 69.9880	Prec@5 87.9441
Train: [83][1800/10010]	Time 0.543 (978.053)	Data 0.001 (2.562)	Loss 1.269	Prec@1 70.0275	Prec@5 87.9546
Train: [83][2000/10010]	Time 0.543 (1086.708)	Data 0.001 (2.708)	Loss 1.268	Prec@1 70.0240	Prec@5 87.9431
Train: [83][2200/10010]	Time 0.543 (1195.724)	Data 0.001 (2.855)	Loss 1.270	Prec@1 69.9824	Prec@5 87.9103
Train: [83][2400/10010]	Time 0.543 (1304.668)	Data 0.001 (3.002)	Loss 1.270	Prec@1 69.9868	Prec@5 87.9175
Train: [83][2600/10010]	Time 0.544 (1413.989)	Data 0.001 (3.152)	Loss 1.270	Prec@1 69.9941	Prec@5 87.9199
Train: [83][2800/10010]	Time 0.544 (1524.286)	Data 0.001 (3.305)	Loss 1.271	Prec@1 69.9521	Prec@5 87.9128
Train: [83][3000/10010]	Time 0.544 (1633.857)	Data 0.001 (3.455)	Loss 1.272	Prec@1 69.9152	Prec@5 87.8931
Train: [83][3200/10010]	Time 0.545 (1743.314)	Data 0.001 (3.612)	Loss 1.272	Prec@1 69.9203	Prec@5 87.8998
Train: [83][3400/10010]	Time 0.545 (1852.147)	Data 0.001 (3.764)	Loss 1.273	Prec@1 69.8816	Prec@5 87.8873
Train: [83][3600/10010]	Time 0.544 (1960.672)	Data 0.001 (3.913)	Loss 1.275	Prec@1 69.8567	Prec@5 87.8617
Train: [83][3800/10010]	Time 0.544 (2069.284)	Data 0.001 (4.066)	Loss 1.275	Prec@1 69.8517	Prec@5 87.8585
Train: [83][4000/10010]	Time 0.544 (2177.871)	Data 0.001 (4.214)	Loss 1.276	Prec@1 69.8355	Prec@5 87.8374
Train: [83][4200/10010]	Time 0.544 (2286.357)	Data 0.001 (4.361)	Loss 1.276	Prec@1 69.8416	Prec@5 87.8286
Train: [83][4400/10010]	Time 0.544 (2394.754)	Data 0.001 (4.515)	Loss 1.277	Prec@1 69.8334	Prec@5 87.8298
Train: [83][4600/10010]	Time 0.544 (2503.256)	Data 0.001 (4.663)	Loss 1.277	Prec@1 69.8248	Prec@5 87.8372
Train: [83][4800/10010]	Time 0.544 (2611.822)	Data 0.001 (4.809)	Loss 1.276	Prec@1 69.8357	Prec@5 87.8479
Train: [83][5000/10010]	Time 0.544 (2720.463)	Data 0.001 (4.958)	Loss 1.277	Prec@1 69.8238	Prec@5 87.8417
Train: [83][5200/10010]	Time 0.544 (2828.926)	Data 0.001 (5.098)	Loss 1.278	Prec@1 69.8085	Prec@5 87.8305
Train: [83][5400/10010]	Time 0.544 (2937.458)	Data 0.001 (5.245)	Loss 1.279	Prec@1 69.7881	Prec@5 87.8192
Train: [83][5600/10010]	Time 0.544 (3046.125)	Data 0.001 (5.395)	Loss 1.279	Prec@1 69.7833	Prec@5 87.8205
Train: [83][5800/10010]	Time 0.544 (3154.860)	Data 0.001 (5.546)	Loss 1.279	Prec@1 69.7820	Prec@5 87.8263
Train: [83][6000/10010]	Time 0.544 (3263.557)	Data 0.001 (5.689)	Loss 1.279	Prec@1 69.7785	Prec@5 87.8175
Train: [83][6200/10010]	Time 0.544 (3372.243)	Data 0.001 (5.832)	Loss 1.279	Prec@1 69.7652	Prec@5 87.8160
Train: [83][6400/10010]	Time 0.544 (3480.935)	Data 0.001 (5.977)	Loss 1.278	Prec@1 69.7801	Prec@5 87.8354
Train: [83][6600/10010]	Time 0.544 (3589.620)	Data 0.001 (6.119)	Loss 1.279	Prec@1 69.7691	Prec@5 87.8256
Train: [83][6800/10010]	Time 0.544 (3698.371)	Data 0.001 (6.265)	Loss 1.278	Prec@1 69.7762	Prec@5 87.8283
Train: [83][7000/10010]	Time 0.544 (3806.992)	Data 0.001 (6.412)	Loss 1.279	Prec@1 69.7790	Prec@5 87.8306
Train: [83][7200/10010]	Time 0.544 (3915.855)	Data 0.001 (6.562)	Loss 1.278	Prec@1 69.7757	Prec@5 87.8357
Train: [83][7400/10010]	Time 0.544 (4024.475)	Data 0.001 (6.708)	Loss 1.279	Prec@1 69.7737	Prec@5 87.8343
Train: [83][7600/10010]	Time 0.544 (4133.179)	Data 0.001 (6.854)	Loss 1.279	Prec@1 69.7621	Prec@5 87.8319
Train: [83][7800/10010]	Time 0.544 (4241.904)	Data 0.001 (7.002)	Loss 1.279	Prec@1 69.7441	Prec@5 87.8255
Train: [83][8000/10010]	Time 0.544 (4350.463)	Data 0.001 (7.153)	Loss 1.280	Prec@1 69.7318	Prec@5 87.8214
Train: [83][8200/10010]	Time 0.544 (4459.241)	Data 0.001 (7.303)	Loss 1.280	Prec@1 69.7243	Prec@5 87.8127
Train: [83][8400/10010]	Time 0.544 (4567.924)	Data 0.001 (7.451)	Loss 1.280	Prec@1 69.7165	Prec@5 87.8111
Train: [83][8600/10010]	Time 0.544 (4676.661)	Data 0.001 (7.600)	Loss 1.281	Prec@1 69.7061	Prec@5 87.8003
Train: [83][8800/10010]	Time 0.544 (4785.389)	Data 0.001 (7.751)	Loss 1.281	Prec@1 69.7006	Prec@5 87.7891
Train: [83][9000/10010]	Time 0.544 (4894.065)	Data 0.001 (7.906)	Loss 1.282	Prec@1 69.6875	Prec@5 87.7808
Train: [83][9200/10010]	Time 0.544 (5002.784)	Data 0.001 (8.061)	Loss 1.282	Prec@1 69.6895	Prec@5 87.7746
Train: [83][9400/10010]	Time 0.544 (5111.452)	Data 0.001 (8.211)	Loss 1.282	Prec@1 69.6806	Prec@5 87.7742
Train: [83][9600/10010]	Time 0.544 (5220.146)	Data 0.001 (8.361)	Loss 1.282	Prec@1 69.6805	Prec@5 87.7732
Train: [83][9800/10010]	Time 0.544 (5329.055)	Data 0.001 (8.517)	Loss 1.282	Prec@1 69.6752	Prec@5 87.7701
Train: [83][10000/10010]	Time 0.544 (5437.761)	Data 0.001 (8.665)	Loss 1.283	Prec@1 69.6729	Prec@5 87.7603
Train: [83]	Time 5442.255	Data 8.669	Loss 1.283	Prec@1 69.6708	Prec@5 87.7607	
Val: [83]	Time 69.513	Data 1.661	Loss 1.144	Prec@1 71.5840	Prec@5 90.4420	
Best Prec@1: [71.652]	
Starting epoch number: 84 Learning rate: 0.0010000000000000002
Train: [84][0/10010]	Time 1.824 (1.824)	Data 1.267 (1.267)	Loss 1.230	Prec@1 75.0000	Prec@5 89.8438
Train: [84][200/10010]	Time 0.549 (110.363)	Data 0.007 (1.420)	Loss 1.266	Prec@1 70.4291	Prec@5 87.8615
Train: [84][400/10010]	Time 0.546 (218.963)	Data 0.004 (1.565)	Loss 1.268	Prec@1 70.2969	Prec@5 87.8838
Train: [84][600/10010]	Time 0.545 (327.661)	Data 0.003 (1.710)	Loss 1.267	Prec@1 70.1890	Prec@5 87.8926
Train: [84][800/10010]	Time 0.544 (436.031)	Data 0.002 (1.851)	Loss 1.270	Prec@1 70.1594	Prec@5 87.9145
Train: [84][1000/10010]	Time 0.544 (544.520)	Data 0.002 (1.991)	Loss 1.268	Prec@1 70.1775	Prec@5 87.9909
Train: [84][1200/10010]	Time 0.544 (652.856)	Data 0.002 (2.133)	Loss 1.265	Prec@1 70.1961	Prec@5 88.0386
Train: [84][1400/10010]	Time 0.543 (761.299)	Data 0.002 (2.274)	Loss 1.268	Prec@1 70.1251	Prec@5 87.9924
Train: [84][1600/10010]	Time 0.543 (869.859)	Data 0.002 (2.419)	Loss 1.268	Prec@1 70.1061	Prec@5 87.9621
Train: [84][1800/10010]	Time 0.543 (978.185)	Data 0.001 (2.555)	Loss 1.268	Prec@1 70.0609	Prec@5 87.9468
Train: [84][2000/10010]	Time 0.543 (1086.656)	Data 0.001 (2.695)	Loss 1.269	Prec@1 70.0654	Prec@5 87.9306
Train: [84][2200/10010]	Time 0.543 (1195.363)	Data 0.001 (2.839)	Loss 1.267	Prec@1 70.0733	Prec@5 87.9405
Train: [84][2400/10010]	Time 0.543 (1303.856)	Data 0.001 (2.983)	Loss 1.267	Prec@1 70.0727	Prec@5 87.9555
Train: [84][2600/10010]	Time 0.543 (1412.398)	Data 0.001 (3.124)	Loss 1.267	Prec@1 70.0854	Prec@5 87.9364
Train: [84][2800/10010]	Time 0.543 (1520.814)	Data 0.001 (3.264)	Loss 1.268	Prec@1 70.0618	Prec@5 87.9326
Train: [84][3000/10010]	Time 0.543 (1629.138)	Data 0.001 (3.403)	Loss 1.268	Prec@1 70.0652	Prec@5 87.9267
Train: [84][3200/10010]	Time 0.543 (1737.269)	Data 0.001 (3.541)	Loss 1.270	Prec@1 70.0164	Prec@5 87.9120
Train: [84][3400/10010]	Time 0.543 (1845.476)	Data 0.001 (3.679)	Loss 1.270	Prec@1 70.0366	Prec@5 87.8953
Train: [84][3600/10010]	Time 0.543 (1953.758)	Data 0.001 (3.817)	Loss 1.271	Prec@1 69.9905	Prec@5 87.8940
Train: [84][3800/10010]	Time 0.542 (2061.828)	Data 0.001 (3.955)	Loss 1.271	Prec@1 69.9814	Prec@5 87.8969
Train: [84][4000/10010]	Time 0.542 (2169.830)	Data 0.001 (4.090)	Loss 1.272	Prec@1 69.9720	Prec@5 87.8979
Train: [84][4200/10010]	Time 0.542 (2277.791)	Data 0.001 (4.229)	Loss 1.272	Prec@1 69.9703	Prec@5 87.8913
Train: [84][4400/10010]	Time 0.542 (2385.816)	Data 0.001 (4.360)	Loss 1.273	Prec@1 69.9363	Prec@5 87.8707
Train: [84][4600/10010]	Time 0.542 (2493.919)	Data 0.001 (4.493)	Loss 1.273	Prec@1 69.9420	Prec@5 87.8697
Train: [84][4800/10010]	Time 0.542 (2602.130)	Data 0.001 (4.636)	Loss 1.273	Prec@1 69.9319	Prec@5 87.8700
Train: [84][5000/10010]	Time 0.542 (2710.305)	Data 0.001 (4.775)	Loss 1.274	Prec@1 69.9210	Prec@5 87.8671
Train: [84][5200/10010]	Time 0.542 (2818.441)	Data 0.001 (4.912)	Loss 1.275	Prec@1 69.9095	Prec@5 87.8536
Train: [84][5400/10010]	Time 0.542 (2926.680)	Data 0.001 (5.050)	Loss 1.274	Prec@1 69.9101	Prec@5 87.8537
Train: [84][5600/10010]	Time 0.542 (3034.836)	Data 0.001 (5.188)	Loss 1.275	Prec@1 69.8967	Prec@5 87.8465
Train: [84][5800/10010]	Time 0.542 (3142.960)	Data 0.001 (5.325)	Loss 1.275	Prec@1 69.8772	Prec@5 87.8452
Train: [84][6000/10010]	Time 0.542 (3251.141)	Data 0.001 (5.455)	Loss 1.275	Prec@1 69.8752	Prec@5 87.8466
Train: [84][6200/10010]	Time 0.542 (3359.214)	Data 0.001 (5.587)	Loss 1.275	Prec@1 69.8855	Prec@5 87.8486
Train: [84][6400/10010]	Time 0.542 (3467.667)	Data 0.001 (5.725)	Loss 1.275	Prec@1 69.8878	Prec@5 87.8415
Train: [84][6600/10010]	Time 0.542 (3576.046)	Data 0.001 (5.868)	Loss 1.275	Prec@1 69.8890	Prec@5 87.8430
Train: [84][6800/10010]	Time 0.542 (3684.346)	Data 0.001 (6.009)	Loss 1.275	Prec@1 69.8875	Prec@5 87.8442
Train: [84][7000/10010]	Time 0.542 (3792.840)	Data 0.001 (6.147)	Loss 1.275	Prec@1 69.8863	Prec@5 87.8467
Train: [84][7200/10010]	Time 0.542 (3901.242)	Data 0.001 (6.282)	Loss 1.276	Prec@1 69.8733	Prec@5 87.8431
Train: [84][7400/10010]	Time 0.542 (4009.663)	Data 0.001 (6.421)	Loss 1.276	Prec@1 69.8716	Prec@5 87.8352
Train: [84][7600/10010]	Time 0.542 (4118.168)	Data 0.001 (6.562)	Loss 1.277	Prec@1 69.8590	Prec@5 87.8220
Train: [84][7800/10010]	Time 0.542 (4226.666)	Data 0.001 (6.699)	Loss 1.278	Prec@1 69.8337	Prec@5 87.8127
Train: [84][8000/10010]	Time 0.542 (4335.028)	Data 0.001 (6.835)	Loss 1.278	Prec@1 69.8259	Prec@5 87.8086
Train: [84][8200/10010]	Time 0.542 (4443.517)	Data 0.001 (6.974)	Loss 1.279	Prec@1 69.8096	Prec@5 87.7984
Train: [84][8400/10010]	Time 0.542 (4552.057)	Data 0.001 (7.117)	Loss 1.279	Prec@1 69.7966	Prec@5 87.7953
Train: [84][8600/10010]	Time 0.542 (4660.292)	Data 0.001 (7.256)	Loss 1.279	Prec@1 69.7948	Prec@5 87.7943
Train: [84][8800/10010]	Time 0.542 (4768.562)	Data 0.001 (7.394)	Loss 1.280	Prec@1 69.7850	Prec@5 87.7892
Train: [84][9000/10010]	Time 0.542 (4876.735)	Data 0.001 (7.529)	Loss 1.280	Prec@1 69.7873	Prec@5 87.7858
Train: [84][9200/10010]	Time 0.542 (4985.071)	Data 0.001 (7.670)	Loss 1.280	Prec@1 69.7895	Prec@5 87.7902
Train: [84][9400/10010]	Time 0.542 (5093.281)	Data 0.001 (7.807)	Loss 1.280	Prec@1 69.7809	Prec@5 87.7837
Train: [84][9600/10010]	Time 0.542 (5201.302)	Data 0.001 (7.945)	Loss 1.280	Prec@1 69.7759	Prec@5 87.7838
Train: [84][9800/10010]	Time 0.542 (5309.482)	Data 0.001 (8.084)	Loss 1.280	Prec@1 69.7689	Prec@5 87.7868
Train: [84][10000/10010]	Time 0.542 (5417.724)	Data 0.001 (8.220)	Loss 1.280	Prec@1 69.7826	Prec@5 87.7929
Train: [84]	Time 5422.118	Data 8.223	Loss 1.280	Prec@1 69.7839	Prec@5 87.7937	
Val: [84]	Time 68.999	Data 1.469	Loss 1.141	Prec@1 71.6780	Prec@5 90.4940	
Best Prec@1: [71.678]	
Starting epoch number: 85 Learning rate: 0.0010000000000000002
Train: [85][0/10010]	Time 1.843 (1.843)	Data 1.295 (1.295)	Loss 1.168	Prec@1 71.0938	Prec@5 89.8438
Train: [85][200/10010]	Time 0.548 (110.174)	Data 0.007 (1.446)	Loss 1.269	Prec@1 69.6129	Prec@5 87.9859
Train: [85][400/10010]	Time 0.545 (218.497)	Data 0.004 (1.588)	Loss 1.269	Prec@1 69.7241	Prec@5 87.8994
Train: [85][600/10010]	Time 0.545 (327.306)	Data 0.003 (1.730)	Loss 1.266	Prec@1 69.8237	Prec@5 87.9641
Train: [85][800/10010]	Time 0.544 (435.773)	Data 0.002 (1.874)	Loss 1.273	Prec@1 69.7907	Prec@5 87.8024
Train: [85][1000/10010]	Time 0.544 (544.218)	Data 0.002 (2.017)	Loss 1.270	Prec@1 69.9277	Prec@5 87.8582
Train: [85][1200/10010]	Time 0.543 (652.630)	Data 0.002 (2.156)	Loss 1.270	Prec@1 69.9638	Prec@5 87.8409
Train: [85][1400/10010]	Time 0.543 (761.038)	Data 0.002 (2.298)	Loss 1.271	Prec@1 69.9394	Prec@5 87.8491
Train: [85][1600/10010]	Time 0.543 (869.516)	Data 0.002 (2.442)	Loss 1.268	Prec@1 69.9777	Prec@5 87.8938
Train: [85][1800/10010]	Time 0.543 (977.937)	Data 0.001 (2.581)	Loss 1.267	Prec@1 69.9572	Prec@5 87.9229
Train: [85][2000/10010]	Time 0.543 (1086.364)	Data 0.001 (2.720)	Loss 1.267	Prec@1 69.9654	Prec@5 87.9295
Train: [85][2200/10010]	Time 0.543 (1194.587)	Data 0.001 (2.855)	Loss 1.267	Prec@1 69.9607	Prec@5 87.9227
Train: [85][2400/10010]	Time 0.543 (1302.834)	Data 0.001 (2.988)	Loss 1.268	Prec@1 69.9572	Prec@5 87.9259
Train: [85][2600/10010]	Time 0.542 (1410.917)	Data 0.001 (3.118)	Loss 1.267	Prec@1 69.9860	Prec@5 87.9355
Train: [85][2800/10010]	Time 0.543 (1519.704)	Data 0.001 (3.252)	Loss 1.267	Prec@1 69.9945	Prec@5 87.9340
Train: [85][3000/10010]	Time 0.542 (1628.027)	Data 0.001 (3.385)	Loss 1.267	Prec@1 70.0100	Prec@5 87.9306
Train: [85][3200/10010]	Time 0.542 (1736.409)	Data 0.001 (3.521)	Loss 1.267	Prec@1 69.9923	Prec@5 87.9354
Train: [85][3400/10010]	Time 0.542 (1844.792)	Data 0.001 (3.657)	Loss 1.267	Prec@1 70.0047	Prec@5 87.9489
Train: [85][3600/10010]	Time 0.542 (1953.234)	Data 0.001 (3.801)	Loss 1.268	Prec@1 69.9747	Prec@5 87.9400
Train: [85][3800/10010]	Time 0.542 (2061.722)	Data 0.001 (3.941)	Loss 1.268	Prec@1 69.9875	Prec@5 87.9536
Train: [85][4000/10010]	Time 0.542 (2170.273)	Data 0.001 (4.083)	Loss 1.268	Prec@1 69.9852	Prec@5 87.9456
Train: [85][4200/10010]	Time 0.542 (2278.892)	Data 0.001 (4.223)	Loss 1.269	Prec@1 69.9791	Prec@5 87.9322
Train: [85][4400/10010]	Time 0.542 (2387.245)	Data 0.001 (4.363)	Loss 1.269	Prec@1 69.9713	Prec@5 87.9347
Train: [85][4600/10010]	Time 0.542 (2495.509)	Data 0.001 (4.505)	Loss 1.270	Prec@1 69.9612	Prec@5 87.9216
Train: [85][4800/10010]	Time 0.542 (2603.753)	Data 0.001 (4.644)	Loss 1.270	Prec@1 69.9475	Prec@5 87.9226
Train: [85][5000/10010]	Time 0.542 (2711.989)	Data 0.001 (4.784)	Loss 1.271	Prec@1 69.9220	Prec@5 87.9166
Train: [85][5200/10010]	Time 0.542 (2820.090)	Data 0.001 (4.921)	Loss 1.271	Prec@1 69.9244	Prec@5 87.9173
Train: [85][5400/10010]	Time 0.542 (2928.338)	Data 0.001 (5.061)	Loss 1.272	Prec@1 69.9059	Prec@5 87.9096
Train: [85][5600/10010]	Time 0.542 (3036.492)	Data 0.001 (5.202)	Loss 1.271	Prec@1 69.9229	Prec@5 87.9196
Train: [85][5800/10010]	Time 0.542 (3144.635)	Data 0.001 (5.341)	Loss 1.271	Prec@1 69.9148	Prec@5 87.9151
Train: [85][6000/10010]	Time 0.542 (3252.889)	Data 0.001 (5.480)	Loss 1.272	Prec@1 69.8936	Prec@5 87.9045
Train: [85][6200/10010]	Time 0.542 (3361.188)	Data 0.001 (5.620)	Loss 1.272	Prec@1 69.8892	Prec@5 87.9024
Train: [85][6400/10010]	Time 0.542 (3469.476)	Data 0.001 (5.761)	Loss 1.272	Prec@1 69.8901	Prec@5 87.9022
Train: [85][6600/10010]	Time 0.542 (3577.748)	Data 0.001 (5.902)	Loss 1.273	Prec@1 69.8871	Prec@5 87.8907
Train: [85][6800/10010]	Time 0.542 (3685.990)	Data 0.001 (6.043)	Loss 1.272	Prec@1 69.8898	Prec@5 87.8929
Train: [85][7000/10010]	Time 0.542 (3794.251)	Data 0.001 (6.181)	Loss 1.273	Prec@1 69.8728	Prec@5 87.8816
Train: [85][7200/10010]	Time 0.542 (3902.613)	Data 0.001 (6.321)	Loss 1.274	Prec@1 69.8649	Prec@5 87.8670
Train: [85][7400/10010]	Time 0.542 (4010.887)	Data 0.001 (6.457)	Loss 1.274	Prec@1 69.8634	Prec@5 87.8616
Train: [85][7600/10010]	Time 0.542 (4119.402)	Data 0.001 (6.595)	Loss 1.274	Prec@1 69.8551	Prec@5 87.8570
Train: [85][7800/10010]	Time 0.542 (4227.635)	Data 0.001 (6.734)	Loss 1.275	Prec@1 69.8468	Prec@5 87.8577
Train: [85][8000/10010]	Time 0.542 (4336.073)	Data 0.001 (6.875)	Loss 1.275	Prec@1 69.8302	Prec@5 87.8575
Train: [85][8200/10010]	Time 0.542 (4444.442)	Data 0.001 (7.012)	Loss 1.275	Prec@1 69.8172	Prec@5 87.8472
Train: [85][8400/10010]	Time 0.542 (4552.859)	Data 0.001 (7.152)	Loss 1.275	Prec@1 69.8122	Prec@5 87.8433
Train: [85][8600/10010]	Time 0.542 (4661.398)	Data 0.001 (7.292)	Loss 1.276	Prec@1 69.7918	Prec@5 87.8370
Train: [85][8800/10010]	Time 0.542 (4769.684)	Data 0.001 (7.429)	Loss 1.277	Prec@1 69.7827	Prec@5 87.8309
Train: [85][9000/10010]	Time 0.542 (4878.019)	Data 0.001 (7.569)	Loss 1.277	Prec@1 69.7854	Prec@5 87.8324
Train: [85][9200/10010]	Time 0.542 (4986.545)	Data 0.001 (7.708)	Loss 1.277	Prec@1 69.7822	Prec@5 87.8264
Train: [85][9400/10010]	Time 0.542 (5094.978)	Data 0.001 (7.847)	Loss 1.277	Prec@1 69.7776	Prec@5 87.8268
Train: [85][9600/10010]	Time 0.542 (5203.499)	Data 0.001 (7.985)	Loss 1.277	Prec@1 69.7767	Prec@5 87.8189
Train: [85][9800/10010]	Time 0.542 (5311.945)	Data 0.001 (8.122)	Loss 1.277	Prec@1 69.7820	Prec@5 87.8217
Train: [85][10000/10010]	Time 0.542 (5420.372)	Data 0.001 (8.257)	Loss 1.278	Prec@1 69.7781	Prec@5 87.8180
Train: [85]	Time 5424.782	Data 8.259	Loss 1.278	Prec@1 69.7764	Prec@5 87.8177	
Val: [85]	Time 68.538	Data 1.533	Loss 1.162	Prec@1 71.1240	Prec@5 90.2880	
Best Prec@1: [71.678]	
Starting epoch number: 86 Learning rate: 0.0010000000000000002
Train: [86][0/10010]	Time 1.912 (1.912)	Data 1.250 (1.250)	Loss 1.247	Prec@1 71.8750	Prec@5 87.5000
Train: [86][200/10010]	Time 0.549 (110.258)	Data 0.007 (1.395)	Loss 1.261	Prec@1 70.2114	Prec@5 88.0442
Train: [86][400/10010]	Time 0.545 (218.614)	Data 0.004 (1.536)	Loss 1.274	Prec@1 69.9248	Prec@5 87.8877
Train: [86][600/10010]	Time 0.544 (327.008)	Data 0.003 (1.673)	Loss 1.265	Prec@1 70.0785	Prec@5 88.0252
Train: [86][800/10010]	Time 0.543 (435.299)	Data 0.002 (1.808)	Loss 1.266	Prec@1 70.0433	Prec@5 87.9867
Train: [86][1000/10010]	Time 0.543 (543.841)	Data 0.002 (1.946)	Loss 1.265	Prec@1 70.0308	Prec@5 88.0448
Train: [86][1200/10010]	Time 0.543 (652.284)	Data 0.002 (2.089)	Loss 1.269	Prec@1 69.9801	Prec@5 88.0015
Train: [86][1400/10010]	Time 0.543 (760.602)	Data 0.002 (2.225)	Loss 1.268	Prec@1 70.0091	Prec@5 87.9773
Train: [86][1600/10010]	Time 0.543 (869.082)	Data 0.001 (2.367)	Loss 1.270	Prec@1 69.9748	Prec@5 87.9436
Train: [86][1800/10010]	Time 0.543 (977.607)	Data 0.001 (2.506)	Loss 1.270	Prec@1 69.9663	Prec@5 87.9455
Train: [86][2000/10010]	Time 0.543 (1086.067)	Data 0.001 (2.648)	Loss 1.270	Prec@1 69.9568	Prec@5 87.9248
Train: [86][2200/10010]	Time 0.543 (1194.271)	Data 0.001 (2.789)	Loss 1.271	Prec@1 69.9284	Prec@5 87.9093
Train: [86][2400/10010]	Time 0.542 (1302.421)	Data 0.001 (2.927)	Loss 1.271	Prec@1 69.9246	Prec@5 87.9162
Train: [86][2600/10010]	Time 0.542 (1410.672)	Data 0.001 (3.066)	Loss 1.272	Prec@1 69.9364	Prec@5 87.9184
Train: [86][2800/10010]	Time 0.542 (1518.947)	Data 0.001 (3.207)	Loss 1.273	Prec@1 69.9254	Prec@5 87.9114
Train: [86][3000/10010]	Time 0.542 (1626.990)	Data 0.001 (3.347)	Loss 1.272	Prec@1 69.9267	Prec@5 87.9152
Train: [86][3200/10010]	Time 0.542 (1735.111)	Data 0.001 (3.490)	Loss 1.273	Prec@1 69.9230	Prec@5 87.9022
Train: [86][3400/10010]	Time 0.542 (1843.263)	Data 0.001 (3.634)	Loss 1.272	Prec@1 69.9459	Prec@5 87.9098
Train: [86][3600/10010]	Time 0.542 (1951.493)	Data 0.001 (3.777)	Loss 1.273	Prec@1 69.9083	Prec@5 87.8957
Train: [86][3800/10010]	Time 0.542 (2059.647)	Data 0.001 (3.917)	Loss 1.273	Prec@1 69.9039	Prec@5 87.8987
Train: [86][4000/10010]	Time 0.542 (2167.641)	Data 0.001 (4.048)	Loss 1.272	Prec@1 69.9171	Prec@5 87.8983
Train: [86][4200/10010]	Time 0.542 (2275.657)	Data 0.001 (4.185)	Loss 1.273	Prec@1 69.8943	Prec@5 87.8827
Train: [86][4400/10010]	Time 0.542 (2383.757)	Data 0.001 (4.322)	Loss 1.273	Prec@1 69.8952	Prec@5 87.8815
Train: [86][4600/10010]	Time 0.542 (2491.926)	Data 0.001 (4.460)	Loss 1.273	Prec@1 69.8962	Prec@5 87.8819
Train: [86][4800/10010]	Time 0.542 (2600.094)	Data 0.001 (4.599)	Loss 1.274	Prec@1 69.9031	Prec@5 87.8848
Train: [86][5000/10010]	Time 0.542 (2708.264)	Data 0.001 (4.737)	Loss 1.273	Prec@1 69.9066	Prec@5 87.8824
Train: [86][5200/10010]	Time 0.542 (2816.343)	Data 0.001 (4.873)	Loss 1.274	Prec@1 69.8979	Prec@5 87.8785
Train: [86][5400/10010]	Time 0.541 (2924.282)	Data 0.001 (5.004)	Loss 1.274	Prec@1 69.8916	Prec@5 87.8726
Train: [86][5600/10010]	Time 0.541 (3032.597)	Data 0.001 (5.141)	Loss 1.274	Prec@1 69.8995	Prec@5 87.8797
Train: [86][5800/10010]	Time 0.541 (3141.208)	Data 0.001 (5.286)	Loss 1.273	Prec@1 69.9082	Prec@5 87.8836
Train: [86][6000/10010]	Time 0.542 (3249.801)	Data 0.001 (5.427)	Loss 1.273	Prec@1 69.9213	Prec@5 87.8749
Train: [86][6200/10010]	Time 0.542 (3358.207)	Data 0.001 (5.573)	Loss 1.274	Prec@1 69.9100	Prec@5 87.8668
Train: [86][6400/10010]	Time 0.542 (3466.914)	Data 0.001 (5.722)	Loss 1.274	Prec@1 69.9005	Prec@5 87.8565
Train: [86][6600/10010]	Time 0.542 (3575.602)	Data 0.001 (5.865)	Loss 1.274	Prec@1 69.8971	Prec@5 87.8611
Train: [86][6800/10010]	Time 0.542 (3684.185)	Data 0.001 (5.997)	Loss 1.274	Prec@1 69.8948	Prec@5 87.8618
Train: [86][7000/10010]	Time 0.542 (3792.480)	Data 0.001 (6.126)	Loss 1.274	Prec@1 69.8870	Prec@5 87.8680
Train: [86][7200/10010]	Time 0.542 (3900.901)	Data 0.001 (6.265)	Loss 1.274	Prec@1 69.8853	Prec@5 87.8688
Train: [86][7400/10010]	Time 0.542 (4009.245)	Data 0.001 (6.400)	Loss 1.275	Prec@1 69.8700	Prec@5 87.8620
Train: [86][7600/10010]	Time 0.542 (4117.613)	Data 0.001 (6.533)	Loss 1.276	Prec@1 69.8573	Prec@5 87.8533
Train: [86][7800/10010]	Time 0.542 (4226.007)	Data 0.001 (6.667)	Loss 1.275	Prec@1 69.8681	Prec@5 87.8578
Train: [86][8000/10010]	Time 0.542 (4334.255)	Data 0.001 (6.798)	Loss 1.275	Prec@1 69.8673	Prec@5 87.8511
Train: [86][8200/10010]	Time 0.542 (4442.783)	Data 0.001 (6.939)	Loss 1.276	Prec@1 69.8596	Prec@5 87.8456
Train: [86][8400/10010]	Time 0.542 (4551.265)	Data 0.001 (7.080)	Loss 1.276	Prec@1 69.8481	Prec@5 87.8405
Train: [86][8600/10010]	Time 0.542 (4659.869)	Data 0.001 (7.219)	Loss 1.276	Prec@1 69.8607	Prec@5 87.8489
Train: [86][8800/10010]	Time 0.542 (4768.249)	Data 0.001 (7.356)	Loss 1.276	Prec@1 69.8554	Prec@5 87.8485
Train: [86][9000/10010]	Time 0.542 (4876.460)	Data 0.001 (7.488)	Loss 1.276	Prec@1 69.8493	Prec@5 87.8544
Train: [86][9200/10010]	Time 0.542 (4984.853)	Data 0.001 (7.627)	Loss 1.276	Prec@1 69.8407	Prec@5 87.8485
Train: [86][9400/10010]	Time 0.542 (5093.135)	Data 0.001 (7.759)	Loss 1.277	Prec@1 69.8329	Prec@5 87.8403
Train: [86][9600/10010]	Time 0.542 (5201.392)	Data 0.001 (7.889)	Loss 1.277	Prec@1 69.8318	Prec@5 87.8360
Train: [86][9800/10010]	Time 0.542 (5309.618)	Data 0.001 (8.023)	Loss 1.277	Prec@1 69.8255	Prec@5 87.8298
Train: [86][10000/10010]	Time 0.542 (5418.012)	Data 0.001 (8.154)	Loss 1.277	Prec@1 69.8200	Prec@5 87.8229
Train: [86]	Time 5422.469	Data 8.157	Loss 1.277	Prec@1 69.8215	Prec@5 87.8229	
Val: [86]	Time 68.921	Data 1.609	Loss 1.149	Prec@1 71.4040	Prec@5 90.4040	
Best Prec@1: [71.678]	
Starting epoch number: 87 Learning rate: 0.0010000000000000002
Train: [87][0/10010]	Time 1.885 (1.885)	Data 1.315 (1.315)	Loss 1.354	Prec@1 71.0938	Prec@5 84.3750
Train: [87][200/10010]	Time 0.548 (110.222)	Data 0.007 (1.461)	Loss 1.240	Prec@1 70.6390	Prec@5 88.3007
Train: [87][400/10010]	Time 0.545 (218.683)	Data 0.004 (1.598)	Loss 1.255	Prec@1 70.3885	Prec@5 88.1079
Train: [87][600/10010]	Time 0.544 (327.048)	Data 0.003 (1.733)	Loss 1.259	Prec@1 70.2696	Prec@5 88.0018
Train: [87][800/10010]	Time 0.544 (435.404)	Data 0.002 (1.869)	Loss 1.259	Prec@1 70.2218	Prec@5 88.0647
Train: [87][1000/10010]	Time 0.543 (543.762)	Data 0.002 (2.005)	Loss 1.260	Prec@1 70.1720	Prec@5 88.0580
Train: [87][1200/10010]	Time 0.543 (652.289)	Data 0.002 (2.145)	Loss 1.255	Prec@1 70.2488	Prec@5 88.1616
Train: [87][1400/10010]	Time 0.543 (760.608)	Data 0.002 (2.281)	Loss 1.258	Prec@1 70.1831	Prec@5 88.1078
Train: [87][1600/10010]	Time 0.543 (869.037)	Data 0.002 (2.420)	Loss 1.256	Prec@1 70.2183	Prec@5 88.1075
Train: [87][1800/10010]	Time 0.543 (977.490)	Data 0.001 (2.555)	Loss 1.257	Prec@1 70.2127	Prec@5 88.1216
Train: [87][2000/10010]	Time 0.543 (1085.849)	Data 0.001 (2.689)	Loss 1.259	Prec@1 70.1743	Prec@5 88.0813
Train: [87][2200/10010]	Time 0.543 (1195.108)	Data 0.001 (2.835)	Loss 1.261	Prec@1 70.1407	Prec@5 88.0654
Train: [87][2400/10010]	Time 0.543 (1304.323)	Data 0.001 (2.974)	Loss 1.263	Prec@1 70.1075	Prec@5 88.0431
Train: [87][2600/10010]	Time 0.543 (1412.845)	Data 0.001 (3.109)	Loss 1.264	Prec@1 70.0938	Prec@5 88.0145
Train: [87][2800/10010]	Time 0.543 (1521.562)	Data 0.001 (3.248)	Loss 1.265	Prec@1 70.0816	Prec@5 88.0104
Train: [87][3000/10010]	Time 0.543 (1630.301)	Data 0.001 (3.387)	Loss 1.265	Prec@1 70.0441	Prec@5 88.0006
Train: [87][3200/10010]	Time 0.543 (1738.958)	Data 0.001 (3.526)	Loss 1.265	Prec@1 70.0511	Prec@5 88.0030
Train: [87][3400/10010]	Time 0.543 (1847.725)	Data 0.001 (3.664)	Loss 1.266	Prec@1 70.0373	Prec@5 87.9911
Train: [87][3600/10010]	Time 0.543 (1956.336)	Data 0.001 (3.802)	Loss 1.267	Prec@1 70.0062	Prec@5 87.9710
Train: [87][3800/10010]	Time 0.543 (2064.681)	Data 0.001 (3.936)	Loss 1.267	Prec@1 69.9861	Prec@5 87.9487
Train: [87][4000/10010]	Time 0.543 (2172.921)	Data 0.001 (4.070)	Loss 1.267	Prec@1 69.9909	Prec@5 87.9548
Train: [87][4200/10010]	Time 0.543 (2280.967)	Data 0.001 (4.203)	Loss 1.269	Prec@1 69.9521	Prec@5 87.9274
Train: [87][4400/10010]	Time 0.543 (2389.215)	Data 0.001 (4.335)	Loss 1.270	Prec@1 69.9314	Prec@5 87.9193
Train: [87][4600/10010]	Time 0.543 (2497.490)	Data 0.001 (4.468)	Loss 1.270	Prec@1 69.9215	Prec@5 87.9157
Train: [87][4800/10010]	Time 0.543 (2605.660)	Data 0.001 (4.598)	Loss 1.270	Prec@1 69.9148	Prec@5 87.9172
Train: [87][5000/10010]	Time 0.543 (2713.701)	Data 0.001 (4.724)	Loss 1.271	Prec@1 69.8854	Prec@5 87.8987
Train: [87][5200/10010]	Time 0.543 (2822.619)	Data 0.001 (4.854)	Loss 1.271	Prec@1 69.8839	Prec@5 87.9039
Train: [87][5400/10010]	Time 0.543 (2932.310)	Data 0.001 (4.991)	Loss 1.271	Prec@1 69.8878	Prec@5 87.9024
Train: [87][5600/10010]	Time 0.543 (3041.001)	Data 0.001 (5.126)	Loss 1.271	Prec@1 69.8871	Prec@5 87.9028
Train: [87][5800/10010]	Time 0.543 (3149.410)	Data 0.001 (5.262)	Loss 1.272	Prec@1 69.8877	Prec@5 87.9047
Train: [87][6000/10010]	Time 0.543 (3257.979)	Data 0.001 (5.398)	Loss 1.272	Prec@1 69.8891	Prec@5 87.9084
Train: [87][6200/10010]	Time 0.543 (3366.229)	Data 0.001 (5.532)	Loss 1.272	Prec@1 69.8986	Prec@5 87.9030
Train: [87][6400/10010]	Time 0.543 (3474.543)	Data 0.001 (5.670)	Loss 1.272	Prec@1 69.8973	Prec@5 87.9059
Train: [87][6600/10010]	Time 0.543 (3583.021)	Data 0.001 (5.811)	Loss 1.272	Prec@1 69.8892	Prec@5 87.9052
Train: [87][6800/10010]	Time 0.543 (3691.494)	Data 0.001 (5.951)	Loss 1.272	Prec@1 69.8856	Prec@5 87.8995
Train: [87][7000/10010]	Time 0.543 (3800.076)	Data 0.001 (6.091)	Loss 1.273	Prec@1 69.8792	Prec@5 87.8934
Train: [87][7200/10010]	Time 0.543 (3908.622)	Data 0.001 (6.231)	Loss 1.273	Prec@1 69.8818	Prec@5 87.9001
Train: [87][7400/10010]	Time 0.543 (4017.393)	Data 0.001 (6.372)	Loss 1.273	Prec@1 69.8721	Prec@5 87.8945
Train: [87][7600/10010]	Time 0.543 (4125.938)	Data 0.001 (6.511)	Loss 1.273	Prec@1 69.8693	Prec@5 87.8962
Train: [87][7800/10010]	Time 0.543 (4234.504)	Data 0.001 (6.651)	Loss 1.273	Prec@1 69.8676	Prec@5 87.8916
Train: [87][8000/10010]	Time 0.543 (4343.200)	Data 0.001 (6.791)	Loss 1.273	Prec@1 69.8769	Prec@5 87.8969
Train: [87][8200/10010]	Time 0.543 (4451.988)	Data 0.001 (6.934)	Loss 1.273	Prec@1 69.8820	Prec@5 87.8926
Train: [87][8400/10010]	Time 0.543 (4560.839)	Data 0.001 (7.079)	Loss 1.273	Prec@1 69.8866	Prec@5 87.9007
Train: [87][8600/10010]	Time 0.543 (4669.385)	Data 0.001 (7.224)	Loss 1.273	Prec@1 69.8780	Prec@5 87.8973
Train: [87][8800/10010]	Time 0.543 (4777.985)	Data 0.001 (7.363)	Loss 1.274	Prec@1 69.8651	Prec@5 87.8869
Train: [87][9000/10010]	Time 0.543 (4886.632)	Data 0.001 (7.506)	Loss 1.274	Prec@1 69.8513	Prec@5 87.8796
Train: [87][9200/10010]	Time 0.543 (4995.287)	Data 0.001 (7.645)	Loss 1.274	Prec@1 69.8488	Prec@5 87.8790
Train: [87][9400/10010]	Time 0.543 (5103.756)	Data 0.001 (7.779)	Loss 1.275	Prec@1 69.8368	Prec@5 87.8714
Train: [87][9600/10010]	Time 0.543 (5212.377)	Data 0.001 (7.917)	Loss 1.275	Prec@1 69.8287	Prec@5 87.8721
Train: [87][9800/10010]	Time 0.543 (5321.290)	Data 0.001 (8.058)	Loss 1.275	Prec@1 69.8227	Prec@5 87.8699
Train: [87][10000/10010]	Time 0.543 (5429.851)	Data 0.001 (8.199)	Loss 1.276	Prec@1 69.8133	Prec@5 87.8620
Train: [87]	Time 5434.309	Data 8.202	Loss 1.276	Prec@1 69.8143	Prec@5 87.8623	
Val: [87]	Time 68.702	Data 1.537	Loss 1.158	Prec@1 71.2740	Prec@5 90.2560	
Best Prec@1: [71.678]	
Starting epoch number: 88 Learning rate: 0.0010000000000000002
Train: [88][0/10010]	Time 1.830 (1.830)	Data 1.257 (1.257)	Loss 1.106	Prec@1 72.6562	Prec@5 87.5000
Train: [88][200/10010]	Time 0.549 (110.420)	Data 0.007 (1.408)	Loss 1.278	Prec@1 69.8811	Prec@5 87.6632
Train: [88][400/10010]	Time 0.546 (218.999)	Data 0.004 (1.549)	Loss 1.267	Prec@1 70.1235	Prec@5 87.8409
Train: [88][600/10010]	Time 0.545 (327.340)	Data 0.003 (1.688)	Loss 1.266	Prec@1 70.0629	Prec@5 87.8822
Train: [88][800/10010]	Time 0.544 (435.754)	Data 0.002 (1.826)	Loss 1.264	Prec@1 70.1262	Prec@5 87.9399
Train: [88][1000/10010]	Time 0.544 (544.175)	Data 0.002 (1.963)	Loss 1.265	Prec@1 70.1751	Prec@5 87.9152
Train: [88][1200/10010]	Time 0.544 (653.651)	Data 0.002 (2.096)	Loss 1.261	Prec@1 70.2819	Prec@5 87.9742
Train: [88][1400/10010]	Time 0.544 (762.494)	Data 0.002 (2.226)	Loss 1.263	Prec@1 70.1753	Prec@5 87.9478
Train: [88][1600/10010]	Time 0.544 (870.678)	Data 0.001 (2.362)	Loss 1.263	Prec@1 70.1993	Prec@5 87.9499
Train: [88][1800/10010]	Time 0.544 (978.956)	Data 0.001 (2.502)	Loss 1.262	Prec@1 70.2015	Prec@5 87.9902
Train: [88][2000/10010]	Time 0.543 (1087.482)	Data 0.001 (2.644)	Loss 1.263	Prec@1 70.1477	Prec@5 87.9748
Train: [88][2200/10010]	Time 0.543 (1195.956)	Data 0.001 (2.785)	Loss 1.264	Prec@1 70.1212	Prec@5 87.9547
Train: [88][2400/10010]	Time 0.543 (1304.274)	Data 0.001 (2.921)	Loss 1.265	Prec@1 70.1182	Prec@5 87.9438
Train: [88][2600/10010]	Time 0.543 (1412.605)	Data 0.001 (3.058)	Loss 1.265	Prec@1 70.1134	Prec@5 87.9454
Train: [88][2800/10010]	Time 0.543 (1520.942)	Data 0.001 (3.189)	Loss 1.266	Prec@1 70.1036	Prec@5 87.9323
Train: [88][3000/10010]	Time 0.543 (1629.669)	Data 0.001 (3.325)	Loss 1.266	Prec@1 70.1102	Prec@5 87.9178
Train: [88][3200/10010]	Time 0.543 (1738.150)	Data 0.001 (3.459)	Loss 1.267	Prec@1 70.0726	Prec@5 87.9247
Train: [88][3400/10010]	Time 0.543 (1846.650)	Data 0.001 (3.592)	Loss 1.267	Prec@1 70.0637	Prec@5 87.9213
Train: [88][3600/10010]	Time 0.543 (1955.148)	Data 0.001 (3.728)	Loss 1.266	Prec@1 70.0619	Prec@5 87.9452
Train: [88][3800/10010]	Time 0.543 (2063.517)	Data 0.001 (3.863)	Loss 1.267	Prec@1 70.0741	Prec@5 87.9450
Train: [88][4000/10010]	Time 0.543 (2171.899)	Data 0.001 (3.995)	Loss 1.267	Prec@1 70.0637	Prec@5 87.9374
Train: [88][4200/10010]	Time 0.543 (2280.126)	Data 0.001 (4.129)	Loss 1.267	Prec@1 70.0635	Prec@5 87.9426
Train: [88][4400/10010]	Time 0.543 (2388.515)	Data 0.001 (4.263)	Loss 1.268	Prec@1 70.0429	Prec@5 87.9390
Train: [88][4600/10010]	Time 0.543 (2497.168)	Data 0.001 (4.403)	Loss 1.269	Prec@1 70.0165	Prec@5 87.9325
Train: [88][4800/10010]	Time 0.543 (2605.688)	Data 0.001 (4.539)	Loss 1.268	Prec@1 70.0294	Prec@5 87.9376
Train: [88][5000/10010]	Time 0.543 (2714.193)	Data 0.001 (4.678)	Loss 1.269	Prec@1 70.0088	Prec@5 87.9202
Train: [88][5200/10010]	Time 0.543 (2822.865)	Data 0.001 (4.817)	Loss 1.269	Prec@1 70.0097	Prec@5 87.9231
Train: [88][5400/10010]	Time 0.543 (2931.906)	Data 0.001 (4.950)	Loss 1.270	Prec@1 69.9798	Prec@5 87.9124
Train: [88][5600/10010]	Time 0.543 (3041.233)	Data 0.001 (5.090)	Loss 1.270	Prec@1 69.9846	Prec@5 87.9154
Train: [88][5800/10010]	Time 0.543 (3149.623)	Data 0.001 (5.225)	Loss 1.271	Prec@1 69.9614	Prec@5 87.9060
Train: [88][6000/10010]	Time 0.543 (3258.021)	Data 0.001 (5.364)	Loss 1.271	Prec@1 69.9583	Prec@5 87.8971
Train: [88][6200/10010]	Time 0.543 (3366.220)	Data 0.001 (5.499)	Loss 1.271	Prec@1 69.9589	Prec@5 87.8990
Train: [88][6400/10010]	Time 0.543 (3474.727)	Data 0.001 (5.639)	Loss 1.271	Prec@1 69.9537	Prec@5 87.9025
Train: [88][6600/10010]	Time 0.543 (3583.322)	Data 0.001 (5.779)	Loss 1.271	Prec@1 69.9563	Prec@5 87.9044
Train: [88][6800/10010]	Time 0.543 (3691.637)	Data 0.001 (5.912)	Loss 1.271	Prec@1 69.9411	Prec@5 87.8967
Train: [88][7000/10010]	Time 0.543 (3799.862)	Data 0.001 (6.044)	Loss 1.272	Prec@1 69.9259	Prec@5 87.8873
Train: [88][7200/10010]	Time 0.543 (3908.043)	Data 0.001 (6.176)	Loss 1.272	Prec@1 69.9220	Prec@5 87.8859
Train: [88][7400/10010]	Time 0.543 (4016.324)	Data 0.001 (6.307)	Loss 1.273	Prec@1 69.9115	Prec@5 87.8856
Train: [88][7600/10010]	Time 0.543 (4124.707)	Data 0.001 (6.439)	Loss 1.273	Prec@1 69.9053	Prec@5 87.8844
Train: [88][7800/10010]	Time 0.543 (4233.118)	Data 0.001 (6.577)	Loss 1.273	Prec@1 69.9015	Prec@5 87.8889
Train: [88][8000/10010]	Time 0.543 (4341.546)	Data 0.001 (6.713)	Loss 1.273	Prec@1 69.8990	Prec@5 87.8893
Train: [88][8200/10010]	Time 0.543 (4449.822)	Data 0.001 (6.852)	Loss 1.273	Prec@1 69.9008	Prec@5 87.8804
Train: [88][8400/10010]	Time 0.543 (4558.214)	Data 0.001 (6.988)	Loss 1.273	Prec@1 69.9009	Prec@5 87.8741
Train: [88][8600/10010]	Time 0.543 (4666.720)	Data 0.001 (7.130)	Loss 1.274	Prec@1 69.8824	Prec@5 87.8614
Train: [88][8800/10010]	Time 0.543 (4775.330)	Data 0.001 (7.273)	Loss 1.274	Prec@1 69.8824	Prec@5 87.8608
Train: [88][9000/10010]	Time 0.543 (4883.928)	Data 0.001 (7.413)	Loss 1.274	Prec@1 69.8839	Prec@5 87.8600
Train: [88][9200/10010]	Time 0.543 (4992.488)	Data 0.001 (7.557)	Loss 1.274	Prec@1 69.8937	Prec@5 87.8639
Train: [88][9400/10010]	Time 0.543 (5101.137)	Data 0.001 (7.699)	Loss 1.274	Prec@1 69.8931	Prec@5 87.8588
Train: [88][9600/10010]	Time 0.543 (5209.599)	Data 0.001 (7.837)	Loss 1.275	Prec@1 69.8699	Prec@5 87.8465
Train: [88][9800/10010]	Time 0.543 (5317.858)	Data 0.001 (7.976)	Loss 1.275	Prec@1 69.8653	Prec@5 87.8438
Train: [88][10000/10010]	Time 0.543 (5426.137)	Data 0.001 (8.109)	Loss 1.275	Prec@1 69.8629	Prec@5 87.8479
Train: [88]	Time 5430.608	Data 8.112	Loss 1.275	Prec@1 69.8632	Prec@5 87.8477	
Val: [88]	Time 69.151	Data 1.704	Loss 1.151	Prec@1 71.2340	Prec@5 90.3540	
Best Prec@1: [71.678]	
Starting epoch number: 89 Learning rate: 0.0010000000000000002
Train: [89][0/10010]	Time 1.874 (1.874)	Data 1.317 (1.317)	Loss 1.159	Prec@1 73.4375	Prec@5 89.0625
Train: [89][200/10010]	Time 0.548 (110.120)	Data 0.007 (1.457)	Loss 1.280	Prec@1 69.8383	Prec@5 87.6827
Train: [89][400/10010]	Time 0.545 (218.446)	Data 0.004 (1.592)	Loss 1.278	Prec@1 69.8663	Prec@5 87.8020
Train: [89][600/10010]	Time 0.544 (326.669)	Data 0.003 (1.723)	Loss 1.271	Prec@1 69.9485	Prec@5 87.9472
Train: [89][800/10010]	Time 0.543 (434.822)	Data 0.002 (1.855)	Loss 1.265	Prec@1 70.0570	Prec@5 88.0472
Train: [89][1000/10010]	Time 0.542 (542.841)	Data 0.002 (1.985)	Loss 1.263	Prec@1 70.1626	Prec@5 88.0830
Train: [89][1200/10010]	Time 0.542 (651.015)	Data 0.002 (2.120)	Loss 1.263	Prec@1 70.1518	Prec@5 88.0490
Train: [89][1400/10010]	Time 0.542 (759.258)	Data 0.002 (2.254)	Loss 1.263	Prec@1 70.1168	Prec@5 88.0431
Train: [89][1600/10010]	Time 0.542 (867.646)	Data 0.001 (2.389)	Loss 1.266	Prec@1 70.0856	Prec@5 88.0094
Train: [89][1800/10010]	Time 0.542 (976.267)	Data 0.001 (2.526)	Loss 1.268	Prec@1 70.0266	Prec@5 87.9663
Train: [89][2000/10010]	Time 0.542 (1084.901)	Data 0.001 (2.661)	Loss 1.269	Prec@1 70.0103	Prec@5 87.9287
Train: [89][2200/10010]	Time 0.542 (1193.311)	Data 0.001 (2.794)	Loss 1.270	Prec@1 70.0080	Prec@5 87.9327
Train: [89][2400/10010]	Time 0.542 (1301.669)	Data 0.001 (2.925)	Loss 1.270	Prec@1 70.0177	Prec@5 87.9032
Train: [89][2600/10010]	Time 0.542 (1409.994)	Data 0.001 (3.059)	Loss 1.267	Prec@1 70.0548	Prec@5 87.9448
Train: [89][2800/10010]	Time 0.542 (1518.450)	Data 0.001 (3.197)	Loss 1.267	Prec@1 70.0707	Prec@5 87.9499
Train: [89][3000/10010]	Time 0.542 (1627.030)	Data 0.001 (3.338)	Loss 1.267	Prec@1 70.0707	Prec@5 87.9600
Train: [89][3200/10010]	Time 0.542 (1735.546)	Data 0.001 (3.476)	Loss 1.268	Prec@1 70.0492	Prec@5 87.9515
Train: [89][3400/10010]	Time 0.542 (1844.120)	Data 0.001 (3.611)	Loss 1.267	Prec@1 70.0467	Prec@5 87.9597
Train: [89][3600/10010]	Time 0.542 (1952.611)	Data 0.001 (3.747)	Loss 1.268	Prec@1 70.0465	Prec@5 87.9541
Train: [89][3800/10010]	Time 0.542 (2060.994)	Data 0.001 (3.878)	Loss 1.268	Prec@1 70.0435	Prec@5 87.9431
Train: [89][4000/10010]	Time 0.542 (2169.609)	Data 0.001 (4.015)	Loss 1.267	Prec@1 70.0622	Prec@5 87.9497
Train: [89][4200/10010]	Time 0.542 (2278.261)	Data 0.001 (4.157)	Loss 1.268	Prec@1 70.0468	Prec@5 87.9437
Train: [89][4400/10010]	Time 0.542 (2386.813)	Data 0.001 (4.295)	Loss 1.269	Prec@1 70.0331	Prec@5 87.9289
Train: [89][4600/10010]	Time 0.542 (2495.221)	Data 0.001 (4.435)	Loss 1.268	Prec@1 70.0359	Prec@5 87.9401
Train: [89][4800/10010]	Time 0.542 (2603.734)	Data 0.001 (4.573)	Loss 1.268	Prec@1 70.0393	Prec@5 87.9429
Train: [89][5000/10010]	Time 0.542 (2712.208)	Data 0.001 (4.712)	Loss 1.268	Prec@1 70.0455	Prec@5 87.9398
Train: [89][5200/10010]	Time 0.542 (2820.745)	Data 0.001 (4.850)	Loss 1.269	Prec@1 70.0226	Prec@5 87.9322
Train: [89][5400/10010]	Time 0.542 (2929.435)	Data 0.001 (4.990)	Loss 1.269	Prec@1 70.0341	Prec@5 87.9303
Train: [89][5600/10010]	Time 0.542 (3037.986)	Data 0.001 (5.130)	Loss 1.269	Prec@1 70.0239	Prec@5 87.9270
Train: [89][5800/10010]	Time 0.542 (3146.642)	Data 0.001 (5.268)	Loss 1.271	Prec@1 69.9940	Prec@5 87.9056
Train: [89][6000/10010]	Time 0.542 (3255.114)	Data 0.001 (5.405)	Loss 1.271	Prec@1 69.9844	Prec@5 87.9014
Train: [89][6200/10010]	Time 0.542 (3363.671)	Data 0.001 (5.546)	Loss 1.271	Prec@1 69.9755	Prec@5 87.9010
Train: [89][6400/10010]	Time 0.542 (3471.892)	Data 0.001 (5.680)	Loss 1.271	Prec@1 69.9744	Prec@5 87.8987
Train: [89][6600/10010]	Time 0.542 (3580.186)	Data 0.001 (5.815)	Loss 1.271	Prec@1 69.9602	Prec@5 87.8947
Train: [89][6800/10010]	Time 0.542 (3689.167)	Data 0.001 (5.948)	Loss 1.272	Prec@1 69.9565	Prec@5 87.8890
Train: [89][7000/10010]	Time 0.543 (3798.174)	Data 0.001 (6.090)	Loss 1.272	Prec@1 69.9460	Prec@5 87.8814
Train: [89][7200/10010]	Time 0.543 (3906.830)	Data 0.001 (6.235)	Loss 1.272	Prec@1 69.9318	Prec@5 87.8795
Train: [89][7400/10010]	Time 0.543 (4015.518)	Data 0.001 (6.382)	Loss 1.272	Prec@1 69.9275	Prec@5 87.8824
Train: [89][7600/10010]	Time 0.543 (4124.641)	Data 0.001 (6.531)	Loss 1.272	Prec@1 69.9283	Prec@5 87.8792
Train: [89][7800/10010]	Time 0.543 (4233.236)	Data 0.001 (6.675)	Loss 1.272	Prec@1 69.9160	Prec@5 87.8775
Train: [89][8000/10010]	Time 0.543 (4341.927)	Data 0.001 (6.817)	Loss 1.273	Prec@1 69.9154	Prec@5 87.8723
Train: [89][8200/10010]	Time 0.543 (4450.541)	Data 0.001 (6.959)	Loss 1.273	Prec@1 69.9125	Prec@5 87.8707
Train: [89][8400/10010]	Time 0.543 (4559.207)	Data 0.001 (7.102)	Loss 1.273	Prec@1 69.9136	Prec@5 87.8678
Train: [89][8600/10010]	Time 0.543 (4667.808)	Data 0.001 (7.244)	Loss 1.273	Prec@1 69.9104	Prec@5 87.8692
Train: [89][8800/10010]	Time 0.543 (4776.694)	Data 0.001 (7.382)	Loss 1.273	Prec@1 69.8980	Prec@5 87.8584
Train: [89][9000/10010]	Time 0.543 (4885.774)	Data 0.001 (7.527)	Loss 1.274	Prec@1 69.8923	Prec@5 87.8598
Train: [89][9200/10010]	Time 0.543 (4994.334)	Data 0.001 (7.672)	Loss 1.274	Prec@1 69.8894	Prec@5 87.8592
Train: [89][9400/10010]	Time 0.543 (5102.663)	Data 0.001 (7.806)	Loss 1.273	Prec@1 69.8927	Prec@5 87.8610
Train: [89][9600/10010]	Time 0.543 (5211.002)	Data 0.001 (7.944)	Loss 1.274	Prec@1 69.8852	Prec@5 87.8586
Train: [89][9800/10010]	Time 0.543 (5319.422)	Data 0.001 (8.082)	Loss 1.274	Prec@1 69.8729	Prec@5 87.8566
Train: [89][10000/10010]	Time 0.543 (5427.806)	Data 0.001 (8.221)	Loss 1.274	Prec@1 69.8793	Prec@5 87.8615
Train: [89]	Time 5432.197	Data 8.224	Loss 1.274	Prec@1 69.8782	Prec@5 87.8607	
Val: [89]	Time 69.342	Data 1.489	Loss 1.156	Prec@1 71.3540	Prec@5 90.2260	
Best Prec@1: [71.678]	
