Namespace(acc_type='class', augment=True, batch_size=128, bottleneck=True, cachemode=True, cardinality=8, criterion='crossentropy', cuda=True, data_dir='/ssd_scratch/cvit/Imagenet12', dataset='imagenet12', decayinterval=30, decaylevel=10, droprate=0, epochs=90, evaluate=False, expandConfig=None, expandSize=2, from_modelzoo=False, growth=48, layers=100, learningratescheduler='imagenetschedular', logdir='../logs/imagenet_densenetexpander161_expandsize2_nov13', lr=0.1, manualSeed=123, maxlr=0.1, minlr=1e-05, model_def='densenetexpander161', momentum=0.9, name='imagenet_densenetexpander161_expandsize2_nov13', nclasses=1000, nesterov=True, ngpus=4, optimType='sgd', pretrained=False, pretrained_file='', printfreq=200, reduce=0.5, resume='savedmodels/densenetexpander161_imagenet_densenetexpander161_expandsize2_nov13_best.pth.tar', start_epoch=0, store='', tenCrop=False, tensorboard=True, testOnly=False, verbose=True, weightDecay=0.0001, weight_init=False, widen_factor=4, workers=12)
DataParallel (
  (module): DenseNet (
    (features): Sequential (
      (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)
      (relu0): ReLU (inplace)
      (pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))
      (denseblock1): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (transition1): _Transition (
        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU (inplace)
        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)
      )
      (denseblock2): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer7): _DenseLayer (
          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer8): _DenseLayer (
          (norm.1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer9): _DenseLayer (
          (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer10): _DenseLayer (
          (norm.1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer11): _DenseLayer (
          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer12): _DenseLayer (
          (norm.1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (transition2): _Transition (
        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU (inplace)
        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)
      )
      (denseblock3): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer7): _DenseLayer (
          (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer8): _DenseLayer (
          (norm.1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer9): _DenseLayer (
          (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer10): _DenseLayer (
          (norm.1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer11): _DenseLayer (
          (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer12): _DenseLayer (
          (norm.1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer13): _DenseLayer (
          (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer14): _DenseLayer (
          (norm.1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer15): _DenseLayer (
          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer16): _DenseLayer (
          (norm.1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer17): _DenseLayer (
          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer18): _DenseLayer (
          (norm.1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer19): _DenseLayer (
          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer20): _DenseLayer (
          (norm.1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer21): _DenseLayer (
          (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer22): _DenseLayer (
          (norm.1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer23): _DenseLayer (
          (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer24): _DenseLayer (
          (norm.1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer25): _DenseLayer (
          (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer26): _DenseLayer (
          (norm.1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer27): _DenseLayer (
          (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer28): _DenseLayer (
          (norm.1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer29): _DenseLayer (
          (norm.1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer30): _DenseLayer (
          (norm.1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer31): _DenseLayer (
          (norm.1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer32): _DenseLayer (
          (norm.1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer33): _DenseLayer (
          (norm.1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer34): _DenseLayer (
          (norm.1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer35): _DenseLayer (
          (norm.1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer36): _DenseLayer (
          (norm.1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (transition3): _Transition (
        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU (inplace)
        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)
      )
      (denseblock4): _DenseBlock (
        (denselayer1): _DenseLayer (
          (norm.1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer2): _DenseLayer (
          (norm.1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer3): _DenseLayer (
          (norm.1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer4): _DenseLayer (
          (norm.1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer5): _DenseLayer (
          (norm.1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer6): _DenseLayer (
          (norm.1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer7): _DenseLayer (
          (norm.1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer8): _DenseLayer (
          (norm.1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer9): _DenseLayer (
          (norm.1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer10): _DenseLayer (
          (norm.1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer11): _DenseLayer (
          (norm.1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer12): _DenseLayer (
          (norm.1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer13): _DenseLayer (
          (norm.1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer14): _DenseLayer (
          (norm.1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer15): _DenseLayer (
          (norm.1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer16): _DenseLayer (
          (norm.1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer17): _DenseLayer (
          (norm.1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer18): _DenseLayer (
          (norm.1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer19): _DenseLayer (
          (norm.1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer20): _DenseLayer (
          (norm.1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer21): _DenseLayer (
          (norm.1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer22): _DenseLayer (
          (norm.1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer23): _DenseLayer (
          (norm.1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
        (denselayer24): _DenseLayer (
          (norm.1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True)
          (relu.1): ReLU (inplace)
          (conv.1): ExpanderConv2d (
          )
          (norm.2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)
          (relu.2): ReLU (inplace)
          (conv.2): ExpanderConv2d (
          )
        )
      )
      (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True)
    )
    (classifier): Linear (2208 -> 1000)
  )
)
=> loading checkpoint 'savedmodels/densenetexpander161_imagenet_densenetexpander161_expandsize2_nov13_best.pth.tar'
=> loaded checkpoint 'savedmodels/densenetexpander161_imagenet_densenetexpander161_expandsize2_nov13_best.pth.tar' (epoch 14)
Starting epoch number: 14 Learning rate: 0.1
Train: [14][0/10010]	Time 24.348 (24.348)	Data 1.063 (1.063)	Loss 2.354	Prec@1 43.7500	Prec@5 71.8750
Train: [14][200/10010]	Time 0.701 (140.950)	Data 0.007 (1.310)	Loss 2.558	Prec@1 44.6867	Prec@5 69.1192
Train: [14][400/10010]	Time 0.645 (258.456)	Data 0.004 (1.533)	Loss 2.566	Prec@1 44.4455	Prec@5 69.0578
Train: [14][600/10010]	Time 0.624 (375.186)	Data 0.003 (1.688)	Loss 2.569	Prec@1 44.2999	Prec@5 68.9658
Train: [14][800/10010]	Time 0.614 (492.045)	Data 0.002 (1.846)	Loss 2.573	Prec@1 44.2572	Prec@5 68.9080
Train: [14][1000/10010]	Time 0.608 (608.792)	Data 0.002 (2.012)	Loss 2.570	Prec@1 44.2503	Prec@5 68.9670
Train: [14][1200/10010]	Time 0.604 (725.529)	Data 0.002 (2.182)	Loss 2.572	Prec@1 44.1780	Prec@5 68.9126
Train: [14][1400/10010]	Time 0.601 (842.614)	Data 0.002 (2.346)	Loss 2.579	Prec@1 44.1080	Prec@5 68.8214
Train: [14][1600/10010]	Time 0.599 (959.217)	Data 0.002 (2.506)	Loss 2.578	Prec@1 44.1282	Prec@5 68.8652
Train: [14][1800/10010]	Time 0.597 (1075.858)	Data 0.001 (2.676)	Loss 2.581	Prec@1 44.1170	Prec@5 68.8268
Train: [14][2000/10010]	Time 0.596 (1192.419)	Data 0.001 (2.850)	Loss 2.586	Prec@1 44.0249	Prec@5 68.7531
Train: [14][2200/10010]	Time 0.595 (1309.063)	Data 0.001 (3.006)	Loss 2.587	Prec@1 44.0041	Prec@5 68.7095
Train: [14][2400/10010]	Time 0.594 (1425.738)	Data 0.001 (3.171)	Loss 2.588	Prec@1 43.9875	Prec@5 68.7100
Train: [14][2600/10010]	Time 0.593 (1542.473)	Data 0.001 (3.318)	Loss 2.589	Prec@1 43.9774	Prec@5 68.6902
Train: [14][2800/10010]	Time 0.592 (1659.172)	Data 0.001 (3.473)	Loss 2.591	Prec@1 43.9681	Prec@5 68.6504
Train: [14][3000/10010]	Time 0.592 (1775.559)	Data 0.001 (3.627)	Loss 2.593	Prec@1 43.9348	Prec@5 68.6245
Train: [14][3200/10010]	Time 0.591 (1892.521)	Data 0.001 (3.774)	Loss 2.594	Prec@1 43.8913	Prec@5 68.5960
Train: [14][3400/10010]	Time 0.591 (2008.831)	Data 0.001 (3.930)	Loss 2.596	Prec@1 43.8931	Prec@5 68.5674
Train: [14][3600/10010]	Time 0.590 (2125.233)	Data 0.001 (4.088)	Loss 2.595	Prec@1 43.8986	Prec@5 68.5697
Train: [14][3800/10010]	Time 0.590 (2241.660)	Data 0.001 (4.232)	Loss 2.595	Prec@1 43.8863	Prec@5 68.5693
Train: [14][4000/10010]	Time 0.589 (2358.388)	Data 0.001 (4.391)	Loss 2.594	Prec@1 43.8925	Prec@5 68.5762
Train: [14][4200/10010]	Time 0.589 (2475.001)	Data 0.001 (4.560)	Loss 2.595	Prec@1 43.8936	Prec@5 68.5664
Train: [14][4400/10010]	Time 0.589 (2591.584)	Data 0.001 (4.731)	Loss 2.597	Prec@1 43.8624	Prec@5 68.5244
Train: [14][4600/10010]	Time 0.589 (2708.152)	Data 0.001 (4.879)	Loss 2.598	Prec@1 43.8442	Prec@5 68.5094
Train: [14][4800/10010]	Time 0.588 (2825.107)	Data 0.001 (5.019)	Loss 2.599	Prec@1 43.8470	Prec@5 68.4932
Train: [14][5000/10010]	Time 0.588 (2941.791)	Data 0.001 (5.168)	Loss 2.600	Prec@1 43.8415	Prec@5 68.4821
Train: [14][5200/10010]	Time 0.588 (3058.280)	Data 0.001 (5.314)	Loss 2.600	Prec@1 43.8347	Prec@5 68.4721
Train: [14][5400/10010]	Time 0.588 (3174.756)	Data 0.001 (5.466)	Loss 2.601	Prec@1 43.8204	Prec@5 68.4740
Train: [14][5600/10010]	Time 0.588 (3291.194)	Data 0.001 (5.626)	Loss 2.601	Prec@1 43.8266	Prec@5 68.4721
Train: [14][5800/10010]	Time 0.587 (3407.808)	Data 0.001 (5.776)	Loss 2.601	Prec@1 43.8247	Prec@5 68.4670
Train: [14][6000/10010]	Time 0.587 (3524.475)	Data 0.001 (5.925)	Loss 2.601	Prec@1 43.8103	Prec@5 68.4629
Train: [14][6200/10010]	Time 0.587 (3640.798)	Data 0.001 (6.089)	Loss 2.601	Prec@1 43.8064	Prec@5 68.4576
Train: [14][6400/10010]	Time 0.587 (3756.910)	Data 0.001 (6.255)	Loss 2.602	Prec@1 43.7858	Prec@5 68.4458
Train: [14][6600/10010]	Time 0.587 (3873.424)	Data 0.001 (6.410)	Loss 2.602	Prec@1 43.7901	Prec@5 68.4329
Train: [14][6800/10010]	Time 0.587 (3989.871)	Data 0.001 (6.559)	Loss 2.602	Prec@1 43.7891	Prec@5 68.4342
Train: [14][7000/10010]	Time 0.586 (4106.010)	Data 0.001 (6.708)	Loss 2.603	Prec@1 43.7820	Prec@5 68.4125
Train: [14][7200/10010]	Time 0.586 (4222.459)	Data 0.001 (6.847)	Loss 2.604	Prec@1 43.7744	Prec@5 68.3973
Train: [14][7400/10010]	Time 0.586 (4338.820)	Data 0.001 (6.992)	Loss 2.603	Prec@1 43.7759	Prec@5 68.4037
Train: [14][7600/10010]	Time 0.586 (4455.225)	Data 0.001 (7.120)	Loss 2.604	Prec@1 43.7598	Prec@5 68.3954
Train: [14][7800/10010]	Time 0.586 (4571.238)	Data 0.001 (7.276)	Loss 2.605	Prec@1 43.7571	Prec@5 68.3747
Train: [14][8000/10010]	Time 0.586 (4687.296)	Data 0.001 (7.422)	Loss 2.605	Prec@1 43.7454	Prec@5 68.3660
Train: [14][8200/10010]	Time 0.586 (4803.661)	Data 0.001 (7.565)	Loss 2.605	Prec@1 43.7487	Prec@5 68.3677
Train: [14][8400/10010]	Time 0.586 (4919.587)	Data 0.001 (7.716)	Loss 2.605	Prec@1 43.7471	Prec@5 68.3635
Train: [14][8600/10010]	Time 0.585 (5035.733)	Data 0.001 (7.855)	Loss 2.605	Prec@1 43.7538	Prec@5 68.3706
Train: [14][8800/10010]	Time 0.585 (5151.996)	Data 0.001 (8.008)	Loss 2.606	Prec@1 43.7429	Prec@5 68.3641
Train: [14][9000/10010]	Time 0.585 (5268.682)	Data 0.001 (8.187)	Loss 2.606	Prec@1 43.7383	Prec@5 68.3679
Train: [14][9200/10010]	Time 0.585 (5384.697)	Data 0.001 (8.334)	Loss 2.606	Prec@1 43.7348	Prec@5 68.3604
Train: [14][9400/10010]	Time 0.585 (5500.629)	Data 0.001 (8.470)	Loss 2.606	Prec@1 43.7274	Prec@5 68.3525
Train: [14][9600/10010]	Time 0.585 (5616.687)	Data 0.001 (8.602)	Loss 2.606	Prec@1 43.7289	Prec@5 68.3467
Train: [14][9800/10010]	Time 0.585 (5732.775)	Data 0.001 (8.739)	Loss 2.607	Prec@1 43.7177	Prec@5 68.3439
Train: [14][10000/10010]	Time 0.585 (5848.564)	Data 0.001 (8.874)	Loss 2.607	Prec@1 43.7214	Prec@5 68.3454
Train: [14]	Time 5849.124	Data 8.874	Loss 2.607	Prec@1 43.7215	Prec@5 68.3451	
Val: [14]	Time 91.590	Data 1.398	Loss 2.256	Prec@1 49.3980	Prec@5 75.6320	
Best Prec@1: [49.398]	
Starting epoch number: 15 Learning rate: 0.1
Train: [15][0/10010]	Time 3.282 (3.282)	Data 1.564 (1.564)	Loss 2.414	Prec@1 47.6562	Prec@5 71.8750
Train: [15][200/10010]	Time 0.598 (120.100)	Data 0.009 (1.714)	Loss 2.566	Prec@1 44.0221	Prec@5 69.0143
Train: [15][400/10010]	Time 0.591 (237.142)	Data 0.005 (1.868)	Loss 2.564	Prec@1 44.2332	Prec@5 69.2098
Train: [15][600/10010]	Time 0.589 (353.990)	Data 0.003 (2.019)	Loss 2.578	Prec@1 44.0568	Prec@5 68.9255
Train: [15][800/10010]	Time 0.588 (470.895)	Data 0.003 (2.184)	Loss 2.580	Prec@1 44.0894	Prec@5 68.8914
Train: [15][1000/10010]	Time 0.588 (588.244)	Data 0.002 (2.345)	Loss 2.577	Prec@1 44.1574	Prec@5 68.9420
Train: [15][1200/10010]	Time 0.587 (705.314)	Data 0.002 (2.505)	Loss 2.577	Prec@1 44.2132	Prec@5 68.9256
Train: [15][1400/10010]	Time 0.587 (822.537)	Data 0.002 (2.679)	Loss 2.582	Prec@1 44.1074	Prec@5 68.8370
Train: [15][1600/10010]	Time 0.587 (939.422)	Data 0.002 (2.838)	Loss 2.580	Prec@1 44.1770	Prec@5 68.8520
Train: [15][1800/10010]	Time 0.587 (1056.359)	Data 0.002 (2.990)	Loss 2.582	Prec@1 44.1708	Prec@5 68.7995
Train: [15][2000/10010]	Time 0.586 (1173.491)	Data 0.002 (3.157)	Loss 2.584	Prec@1 44.1357	Prec@5 68.7695
Train: [15][2200/10010]	Time 0.586 (1290.762)	Data 0.002 (3.336)	Loss 2.583	Prec@1 44.1699	Prec@5 68.7745
Train: [15][2400/10010]	Time 0.586 (1407.265)	Data 0.001 (3.506)	Loss 2.582	Prec@1 44.1606	Prec@5 68.7806
Train: [15][2600/10010]	Time 0.586 (1524.359)	Data 0.001 (3.667)	Loss 2.584	Prec@1 44.1480	Prec@5 68.7524
Train: [15][2800/10010]	Time 0.586 (1641.273)	Data 0.001 (3.832)	Loss 2.586	Prec@1 44.0855	Prec@5 68.7057
Train: [15][3000/10010]	Time 0.586 (1757.700)	Data 0.001 (3.988)	Loss 2.588	Prec@1 44.0377	Prec@5 68.6860
Train: [15][3200/10010]	Time 0.585 (1874.093)	Data 0.001 (4.136)	Loss 2.588	Prec@1 44.0285	Prec@5 68.6804
Train: [15][3400/10010]	Time 0.585 (1991.029)	Data 0.001 (4.304)	Loss 2.589	Prec@1 43.9868	Prec@5 68.6701
Train: [15][3600/10010]	Time 0.586 (2108.567)	Data 0.001 (4.481)	Loss 2.588	Prec@1 44.0156	Prec@5 68.6699
Train: [15][3800/10010]	Time 0.586 (2225.869)	Data 0.001 (4.652)	Loss 2.589	Prec@1 44.0153	Prec@5 68.6474
Train: [15][4000/10010]	Time 0.586 (2343.178)	Data 0.001 (4.814)	Loss 2.588	Prec@1 44.0048	Prec@5 68.6569
Train: [15][4200/10010]	Time 0.586 (2459.992)	Data 0.001 (4.986)	Loss 2.589	Prec@1 43.9691	Prec@5 68.6386
Train: [15][4400/10010]	Time 0.585 (2576.721)	Data 0.001 (5.150)	Loss 2.591	Prec@1 43.9531	Prec@5 68.6076
Train: [15][4600/10010]	Time 0.586 (2694.092)	Data 0.001 (5.308)	Loss 2.593	Prec@1 43.9247	Prec@5 68.5785
Train: [15][4800/10010]	Time 0.585 (2810.847)	Data 0.001 (5.478)	Loss 2.594	Prec@1 43.9181	Prec@5 68.5751
Train: [15][5000/10010]	Time 0.585 (2928.069)	Data 0.001 (5.661)	Loss 2.595	Prec@1 43.8850	Prec@5 68.5697
Train: [15][5200/10010]	Time 0.586 (3045.574)	Data 0.001 (5.823)	Loss 2.595	Prec@1 43.8808	Prec@5 68.5673
Train: [15][5400/10010]	Time 0.586 (3162.509)	Data 0.001 (6.009)	Loss 2.595	Prec@1 43.8877	Prec@5 68.5689
Train: [15][5600/10010]	Time 0.586 (3279.952)	Data 0.001 (6.180)	Loss 2.595	Prec@1 43.8859	Prec@5 68.5613
Train: [15][5800/10010]	Time 0.586 (3397.118)	Data 0.001 (6.339)	Loss 2.595	Prec@1 43.8824	Prec@5 68.5752
Train: [15][6000/10010]	Time 0.586 (3513.690)	Data 0.001 (6.509)	Loss 2.597	Prec@1 43.8575	Prec@5 68.5490
Train: [15][6200/10010]	Time 0.585 (3630.344)	Data 0.001 (6.702)	Loss 2.598	Prec@1 43.8417	Prec@5 68.5226
Train: [15][6400/10010]	Time 0.585 (3747.048)	Data 0.001 (6.875)	Loss 2.598	Prec@1 43.8284	Prec@5 68.5096
Train: [15][6600/10010]	Time 0.585 (3864.157)	Data 0.001 (7.049)	Loss 2.598	Prec@1 43.8197	Prec@5 68.5032
Train: [15][6800/10010]	Time 0.585 (3980.886)	Data 0.001 (7.225)	Loss 2.598	Prec@1 43.8213	Prec@5 68.4968
Train: [15][7000/10010]	Time 0.585 (4097.838)	Data 0.001 (7.377)	Loss 2.598	Prec@1 43.8245	Prec@5 68.5048
Train: [15][7200/10010]	Time 0.585 (4214.776)	Data 0.001 (7.542)	Loss 2.598	Prec@1 43.8310	Prec@5 68.5014
Train: [15][7400/10010]	Time 0.585 (4331.645)	Data 0.001 (7.711)	Loss 2.598	Prec@1 43.8405	Prec@5 68.4994
Train: [15][7600/10010]	Time 0.585 (4448.307)	Data 0.001 (7.862)	Loss 2.599	Prec@1 43.8252	Prec@5 68.4718
Train: [15][7800/10010]	Time 0.585 (4564.515)	Data 0.001 (8.004)	Loss 2.599	Prec@1 43.8313	Prec@5 68.4742
Train: [15][8000/10010]	Time 0.585 (4680.426)	Data 0.001 (8.161)	Loss 2.600	Prec@1 43.8121	Prec@5 68.4583
Train: [15][8200/10010]	Time 0.585 (4796.675)	Data 0.001 (8.318)	Loss 2.600	Prec@1 43.8031	Prec@5 68.4563
Train: [15][8400/10010]	Time 0.585 (4913.401)	Data 0.001 (8.477)	Loss 2.601	Prec@1 43.7966	Prec@5 68.4392
Train: [15][8600/10010]	Time 0.585 (5029.659)	Data 0.001 (8.652)	Loss 2.601	Prec@1 43.7923	Prec@5 68.4378
Train: [15][8800/10010]	Time 0.585 (5145.437)	Data 0.001 (8.853)	Loss 2.601	Prec@1 43.7910	Prec@5 68.4328
Train: [15][9000/10010]	Time 0.584 (5261.037)	Data 0.001 (9.022)	Loss 2.601	Prec@1 43.7956	Prec@5 68.4361
Train: [15][9200/10010]	Time 0.584 (5376.979)	Data 0.001 (9.217)	Loss 2.601	Prec@1 43.7930	Prec@5 68.4337
Train: [15][9400/10010]	Time 0.584 (5492.805)	Data 0.001 (9.385)	Loss 2.601	Prec@1 43.7932	Prec@5 68.4312
Train: [15][9600/10010]	Time 0.584 (5608.518)	Data 0.001 (9.531)	Loss 2.602	Prec@1 43.7893	Prec@5 68.4300
Train: [15][9800/10010]	Time 0.584 (5724.411)	Data 0.001 (9.695)	Loss 2.602	Prec@1 43.7832	Prec@5 68.4201
Train: [15][10000/10010]	Time 0.584 (5840.068)	Data 0.001 (9.835)	Loss 2.602	Prec@1 43.7752	Prec@5 68.4149
Train: [15]	Time 5840.613	Data 9.835	Loss 2.602	Prec@1 43.7748	Prec@5 68.4144	
Val: [15]	Time 88.325	Data 1.602	Loss 2.266	Prec@1 48.7520	Prec@5 74.9880	
Best Prec@1: [49.398]	
Starting epoch number: 16 Learning rate: 0.1
Train: [16][0/10010]	Time 2.366 (2.366)	Data 1.605 (1.605)	Loss 2.622	Prec@1 41.4062	Prec@5 69.5312
Train: [16][200/10010]	Time 0.595 (119.513)	Data 0.009 (1.735)	Loss 2.530	Prec@1 44.9316	Prec@5 69.6751
Train: [16][400/10010]	Time 0.591 (236.834)	Data 0.005 (1.884)	Loss 2.538	Prec@1 44.7358	Prec@5 69.6462
Train: [16][600/10010]	Time 0.590 (354.690)	Data 0.003 (2.030)	Loss 2.545	Prec@1 44.7262	Prec@5 69.5546
Train: [16][800/10010]	Time 0.589 (472.035)	Data 0.003 (2.186)	Loss 2.548	Prec@1 44.6093	Prec@5 69.4269
Train: [16][1000/10010]	Time 0.588 (589.004)	Data 0.002 (2.349)	Loss 2.557	Prec@1 44.4868	Prec@5 69.3010
Train: [16][1200/10010]	Time 0.588 (706.323)	Data 0.002 (2.518)	Loss 2.558	Prec@1 44.5371	Prec@5 69.2307
Train: [16][1400/10010]	Time 0.588 (823.408)	Data 0.002 (2.684)	Loss 2.558	Prec@1 44.5586	Prec@5 69.1900
Train: [16][1600/10010]	Time 0.588 (940.723)	Data 0.002 (2.845)	Loss 2.562	Prec@1 44.4907	Prec@5 69.1218
Train: [16][1800/10010]	Time 0.587 (1057.967)	Data 0.002 (3.009)	Loss 2.567	Prec@1 44.3872	Prec@5 69.0450
Train: [16][2000/10010]	Time 0.587 (1175.295)	Data 0.002 (3.168)	Loss 2.568	Prec@1 44.3442	Prec@5 69.0171
Train: [16][2200/10010]	Time 0.587 (1292.912)	Data 0.002 (3.334)	Loss 2.573	Prec@1 44.2615	Prec@5 68.9356
Train: [16][2400/10010]	Time 0.587 (1410.279)	Data 0.001 (3.499)	Loss 2.574	Prec@1 44.2553	Prec@5 68.9156
Train: [16][2600/10010]	Time 0.587 (1527.677)	Data 0.001 (3.661)	Loss 2.574	Prec@1 44.2519	Prec@5 68.8921
Train: [16][2800/10010]	Time 0.587 (1645.145)	Data 0.001 (3.829)	Loss 2.576	Prec@1 44.2164	Prec@5 68.8699
Train: [16][3000/10010]	Time 0.587 (1761.790)	Data 0.001 (3.993)	Loss 2.576	Prec@1 44.2142	Prec@5 68.8487
Train: [16][3200/10010]	Time 0.587 (1878.994)	Data 0.001 (4.153)	Loss 2.577	Prec@1 44.1844	Prec@5 68.8191
Train: [16][3400/10010]	Time 0.587 (1996.119)	Data 0.001 (4.311)	Loss 2.578	Prec@1 44.1839	Prec@5 68.8201
Train: [16][3600/10010]	Time 0.587 (2113.407)	Data 0.001 (4.473)	Loss 2.579	Prec@1 44.1438	Prec@5 68.8147
Train: [16][3800/10010]	Time 0.587 (2231.341)	Data 0.001 (4.633)	Loss 2.579	Prec@1 44.1568	Prec@5 68.8178
Train: [16][4000/10010]	Time 0.587 (2348.650)	Data 0.001 (4.802)	Loss 2.580	Prec@1 44.1411	Prec@5 68.8072
Train: [16][4200/10010]	Time 0.587 (2465.983)	Data 0.001 (4.977)	Loss 2.581	Prec@1 44.1125	Prec@5 68.7881
Train: [16][4400/10010]	Time 0.587 (2582.985)	Data 0.001 (5.143)	Loss 2.581	Prec@1 44.1086	Prec@5 68.7821
Train: [16][4600/10010]	Time 0.587 (2699.811)	Data 0.001 (5.308)	Loss 2.581	Prec@1 44.1130	Prec@5 68.7840
Train: [16][4800/10010]	Time 0.587 (2817.049)	Data 0.001 (5.470)	Loss 2.582	Prec@1 44.0885	Prec@5 68.7720
Train: [16][5000/10010]	Time 0.587 (2934.162)	Data 0.001 (5.626)	Loss 2.583	Prec@1 44.0754	Prec@5 68.7520
Train: [16][5200/10010]	Time 0.587 (3051.093)	Data 0.001 (5.790)	Loss 2.584	Prec@1 44.0608	Prec@5 68.7380
Train: [16][5400/10010]	Time 0.587 (3168.508)	Data 0.001 (5.965)	Loss 2.585	Prec@1 44.0517	Prec@5 68.7235
Train: [16][5600/10010]	Time 0.587 (3285.697)	Data 0.001 (6.124)	Loss 2.585	Prec@1 44.0477	Prec@5 68.7080
Train: [16][5800/10010]	Time 0.587 (3402.967)	Data 0.001 (6.292)	Loss 2.586	Prec@1 44.0316	Prec@5 68.6959
Train: [16][6000/10010]	Time 0.587 (3520.385)	Data 0.001 (6.458)	Loss 2.587	Prec@1 44.0205	Prec@5 68.6867
Train: [16][6200/10010]	Time 0.587 (3637.760)	Data 0.001 (6.633)	Loss 2.588	Prec@1 44.0171	Prec@5 68.6764
Train: [16][6400/10010]	Time 0.587 (3754.732)	Data 0.001 (6.799)	Loss 2.588	Prec@1 44.0166	Prec@5 68.6649
Train: [16][6600/10010]	Time 0.587 (3871.817)	Data 0.001 (6.962)	Loss 2.589	Prec@1 44.0075	Prec@5 68.6493
Train: [16][6800/10010]	Time 0.587 (3989.178)	Data 0.001 (7.133)	Loss 2.589	Prec@1 44.0039	Prec@5 68.6373
Train: [16][7000/10010]	Time 0.587 (4106.719)	Data 0.001 (7.303)	Loss 2.589	Prec@1 44.0010	Prec@5 68.6400
Train: [16][7200/10010]	Time 0.587 (4223.705)	Data 0.001 (7.465)	Loss 2.589	Prec@1 43.9955	Prec@5 68.6396
Train: [16][7400/10010]	Time 0.587 (4340.794)	Data 0.001 (7.633)	Loss 2.590	Prec@1 43.9918	Prec@5 68.6339
Train: [16][7600/10010]	Time 0.586 (4457.916)	Data 0.001 (7.791)	Loss 2.590	Prec@1 43.9913	Prec@5 68.6398
Train: [16][7800/10010]	Time 0.586 (4575.157)	Data 0.001 (7.963)	Loss 2.590	Prec@1 43.9920	Prec@5 68.6347
Train: [16][8000/10010]	Time 0.586 (4692.547)	Data 0.001 (8.131)	Loss 2.590	Prec@1 43.9996	Prec@5 68.6393
Train: [16][8200/10010]	Time 0.586 (4809.309)	Data 0.001 (8.295)	Loss 2.591	Prec@1 43.9873	Prec@5 68.6215
Train: [16][8400/10010]	Time 0.586 (4926.623)	Data 0.001 (8.474)	Loss 2.591	Prec@1 43.9873	Prec@5 68.6200
Train: [16][8600/10010]	Time 0.586 (5043.763)	Data 0.001 (8.644)	Loss 2.591	Prec@1 43.9871	Prec@5 68.6165
Train: [16][8800/10010]	Time 0.586 (5161.482)	Data 0.001 (8.805)	Loss 2.591	Prec@1 43.9870	Prec@5 68.6284
Train: [16][9000/10010]	Time 0.586 (5278.548)	Data 0.001 (8.972)	Loss 2.592	Prec@1 43.9748	Prec@5 68.6201
Train: [16][9200/10010]	Time 0.586 (5395.446)	Data 0.001 (9.112)	Loss 2.592	Prec@1 43.9751	Prec@5 68.6133
Train: [16][9400/10010]	Time 0.586 (5512.142)	Data 0.001 (9.261)	Loss 2.593	Prec@1 43.9645	Prec@5 68.6038
Train: [16][9600/10010]	Time 0.586 (5629.397)	Data 0.001 (9.415)	Loss 2.593	Prec@1 43.9592	Prec@5 68.6013
Train: [16][9800/10010]	Time 0.586 (5746.520)	Data 0.001 (9.574)	Loss 2.593	Prec@1 43.9554	Prec@5 68.5889
Train: [16][10000/10010]	Time 0.586 (5863.876)	Data 0.001 (9.747)	Loss 2.593	Prec@1 43.9537	Prec@5 68.5890
Train: [16]	Time 5864.422	Data 9.747	Loss 2.593	Prec@1 43.9543	Prec@5 68.5890	
Val: [16]	Time 88.233	Data 1.435	Loss 2.316	Prec@1 48.8520	Prec@5 74.9980	
Best Prec@1: [49.398]	
Starting epoch number: 17 Learning rate: 0.1
Train: [17][0/10010]	Time 2.373 (2.373)	Data 1.689 (1.689)	Loss 2.232	Prec@1 49.2188	Prec@5 71.8750
Train: [17][200/10010]	Time 0.596 (119.815)	Data 0.009 (1.832)	Loss 2.551	Prec@1 44.5546	Prec@5 69.3369
Train: [17][400/10010]	Time 0.591 (236.845)	Data 0.005 (1.983)	Loss 2.559	Prec@1 44.4124	Prec@5 69.1299
Train: [17][600/10010]	Time 0.590 (354.435)	Data 0.004 (2.155)	Loss 2.563	Prec@1 44.3857	Prec@5 69.0698
Train: [17][800/10010]	Time 0.589 (471.571)	Data 0.003 (2.318)	Loss 2.568	Prec@1 44.3284	Prec@5 68.9870
Train: [17][1000/10010]	Time 0.588 (588.859)	Data 0.002 (2.495)	Loss 2.567	Prec@1 44.3190	Prec@5 69.0154
Train: [17][1200/10010]	Time 0.588 (706.095)	Data 0.002 (2.686)	Loss 2.565	Prec@1 44.3413	Prec@5 69.0648
Train: [17][1400/10010]	Time 0.588 (823.182)	Data 0.002 (2.870)	Loss 2.568	Prec@1 44.3444	Prec@5 69.0271
Train: [17][1600/10010]	Time 0.588 (940.834)	Data 0.002 (3.045)	Loss 2.572	Prec@1 44.2853	Prec@5 68.9940
Train: [17][1800/10010]	Time 0.587 (1057.646)	Data 0.002 (3.228)	Loss 2.572	Prec@1 44.2484	Prec@5 69.0051
Train: [17][2000/10010]	Time 0.587 (1174.239)	Data 0.002 (3.400)	Loss 2.574	Prec@1 44.2373	Prec@5 68.9433
Train: [17][2200/10010]	Time 0.587 (1291.292)	Data 0.002 (3.563)	Loss 2.575	Prec@1 44.1909	Prec@5 68.9257
Train: [17][2400/10010]	Time 0.587 (1408.453)	Data 0.002 (3.744)	Loss 2.577	Prec@1 44.1883	Prec@5 68.8994
Train: [17][2600/10010]	Time 0.587 (1525.934)	Data 0.002 (3.906)	Loss 2.576	Prec@1 44.2420	Prec@5 68.9329
Train: [17][2800/10010]	Time 0.587 (1643.290)	Data 0.001 (4.061)	Loss 2.578	Prec@1 44.2314	Prec@5 68.9229
Train: [17][3000/10010]	Time 0.586 (1759.746)	Data 0.001 (4.229)	Loss 2.579	Prec@1 44.2074	Prec@5 68.8778
Train: [17][3200/10010]	Time 0.586 (1876.532)	Data 0.001 (4.386)	Loss 2.581	Prec@1 44.2269	Prec@5 68.8530
Train: [17][3400/10010]	Time 0.586 (1993.733)	Data 0.001 (4.544)	Loss 2.581	Prec@1 44.1977	Prec@5 68.8469
Train: [17][3600/10010]	Time 0.586 (2111.070)	Data 0.001 (4.705)	Loss 2.582	Prec@1 44.1882	Prec@5 68.8027
Train: [17][3800/10010]	Time 0.586 (2228.241)	Data 0.001 (4.862)	Loss 2.581	Prec@1 44.2104	Prec@5 68.8265
Train: [17][4000/10010]	Time 0.586 (2344.757)	Data 0.001 (5.017)	Loss 2.582	Prec@1 44.1950	Prec@5 68.8152
Train: [17][4200/10010]	Time 0.586 (2462.100)	Data 0.001 (5.187)	Loss 2.582	Prec@1 44.1969	Prec@5 68.8114
Train: [17][4400/10010]	Time 0.586 (2579.456)	Data 0.001 (5.341)	Loss 2.583	Prec@1 44.1778	Prec@5 68.7901
Train: [17][4600/10010]	Time 0.586 (2696.312)	Data 0.001 (5.495)	Loss 2.584	Prec@1 44.1531	Prec@5 68.7765
Train: [17][4800/10010]	Time 0.586 (2813.781)	Data 0.001 (5.674)	Loss 2.584	Prec@1 44.1293	Prec@5 68.7853
Train: [17][5000/10010]	Time 0.586 (2931.387)	Data 0.001 (5.822)	Loss 2.584	Prec@1 44.1231	Prec@5 68.7734
Train: [17][5200/10010]	Time 0.586 (3048.997)	Data 0.001 (5.990)	Loss 2.584	Prec@1 44.1518	Prec@5 68.7880
Train: [17][5400/10010]	Time 0.586 (3166.673)	Data 0.001 (6.170)	Loss 2.585	Prec@1 44.1364	Prec@5 68.7700
Train: [17][5600/10010]	Time 0.586 (3283.499)	Data 0.001 (6.363)	Loss 2.585	Prec@1 44.1277	Prec@5 68.7554
Train: [17][5800/10010]	Time 0.586 (3400.699)	Data 0.001 (6.535)	Loss 2.585	Prec@1 44.1267	Prec@5 68.7425
Train: [17][6000/10010]	Time 0.586 (3517.694)	Data 0.001 (6.718)	Loss 2.585	Prec@1 44.1413	Prec@5 68.7638
Train: [17][6200/10010]	Time 0.586 (3635.017)	Data 0.001 (6.897)	Loss 2.585	Prec@1 44.1401	Prec@5 68.7602
Train: [17][6400/10010]	Time 0.586 (3752.028)	Data 0.001 (7.040)	Loss 2.585	Prec@1 44.1353	Prec@5 68.7432
Train: [17][6600/10010]	Time 0.586 (3869.337)	Data 0.001 (7.194)	Loss 2.586	Prec@1 44.1226	Prec@5 68.7262
Train: [17][6800/10010]	Time 0.586 (3986.439)	Data 0.001 (7.335)	Loss 2.586	Prec@1 44.1206	Prec@5 68.7199
Train: [17][7000/10010]	Time 0.586 (4103.341)	Data 0.001 (7.492)	Loss 2.586	Prec@1 44.1053	Prec@5 68.7155
Train: [17][7200/10010]	Time 0.586 (4219.842)	Data 0.001 (7.656)	Loss 2.587	Prec@1 44.0895	Prec@5 68.6984
Train: [17][7400/10010]	Time 0.586 (4335.150)	Data 0.001 (7.801)	Loss 2.588	Prec@1 44.0807	Prec@5 68.6847
Train: [17][7600/10010]	Time 0.586 (4450.974)	Data 0.001 (7.937)	Loss 2.587	Prec@1 44.0904	Prec@5 68.6872
Train: [17][7800/10010]	Time 0.585 (4566.823)	Data 0.001 (8.082)	Loss 2.588	Prec@1 44.0845	Prec@5 68.6857
Train: [17][8000/10010]	Time 0.585 (4682.559)	Data 0.001 (8.228)	Loss 2.589	Prec@1 44.0720	Prec@5 68.6667
Train: [17][8200/10010]	Time 0.585 (4798.712)	Data 0.001 (8.385)	Loss 2.589	Prec@1 44.0697	Prec@5 68.6612
Train: [17][8400/10010]	Time 0.585 (4914.773)	Data 0.001 (8.576)	Loss 2.589	Prec@1 44.0719	Prec@5 68.6616
Train: [17][8600/10010]	Time 0.585 (5030.759)	Data 0.001 (8.741)	Loss 2.589	Prec@1 44.0614	Prec@5 68.6507
Train: [17][8800/10010]	Time 0.585 (5146.660)	Data 0.001 (8.905)	Loss 2.589	Prec@1 44.0535	Prec@5 68.6470
Train: [17][9000/10010]	Time 0.585 (5262.552)	Data 0.001 (9.063)	Loss 2.590	Prec@1 44.0454	Prec@5 68.6411
Train: [17][9200/10010]	Time 0.585 (5378.707)	Data 0.001 (9.214)	Loss 2.590	Prec@1 44.0432	Prec@5 68.6326
Train: [17][9400/10010]	Time 0.584 (5494.770)	Data 0.001 (9.371)	Loss 2.590	Prec@1 44.0487	Prec@5 68.6294
Train: [17][9600/10010]	Time 0.584 (5611.242)	Data 0.001 (9.537)	Loss 2.590	Prec@1 44.0508	Prec@5 68.6307
Train: [17][9800/10010]	Time 0.584 (5727.434)	Data 0.001 (9.710)	Loss 2.590	Prec@1 44.0469	Prec@5 68.6241
Train: [17][10000/10010]	Time 0.584 (5843.507)	Data 0.001 (9.864)	Loss 2.590	Prec@1 44.0401	Prec@5 68.6184
Train: [17]	Time 5844.055	Data 9.865	Loss 2.590	Prec@1 44.0401	Prec@5 68.6182	
Val: [17]	Time 86.885	Data 1.454	Loss 2.229	Prec@1 50.4120	Prec@5 75.9160	
Best Prec@1: [50.412]	
Starting epoch number: 18 Learning rate: 0.1
Train: [18][0/10010]	Time 2.357 (2.357)	Data 1.602 (1.602)	Loss 2.626	Prec@1 45.3125	Prec@5 69.5312
Train: [18][200/10010]	Time 0.594 (119.459)	Data 0.009 (1.754)	Loss 2.522	Prec@1 45.0132	Prec@5 69.7178
Train: [18][400/10010]	Time 0.589 (236.340)	Data 0.005 (1.901)	Loss 2.552	Prec@1 44.4825	Prec@5 69.1494
Train: [18][600/10010]	Time 0.589 (353.794)	Data 0.003 (2.065)	Loss 2.556	Prec@1 44.5170	Prec@5 69.0698
Train: [18][800/10010]	Time 0.588 (471.196)	Data 0.003 (2.235)	Loss 2.556	Prec@1 44.4883	Prec@5 69.1119
Train: [18][1000/10010]	Time 0.588 (588.825)	Data 0.002 (2.400)	Loss 2.556	Prec@1 44.5625	Prec@5 69.0942
Train: [18][1200/10010]	Time 0.588 (706.150)	Data 0.002 (2.555)	Loss 2.562	Prec@1 44.4428	Prec@5 69.0434
Train: [18][1400/10010]	Time 0.588 (823.397)	Data 0.002 (2.721)	Loss 2.564	Prec@1 44.3840	Prec@5 69.0651
Train: [18][1600/10010]	Time 0.587 (940.243)	Data 0.002 (2.881)	Loss 2.564	Prec@1 44.4298	Prec@5 69.0360
Train: [18][1800/10010]	Time 0.587 (1057.985)	Data 0.002 (3.050)	Loss 2.564	Prec@1 44.4228	Prec@5 69.0328
Train: [18][2000/10010]	Time 0.587 (1175.155)	Data 0.002 (3.207)	Loss 2.564	Prec@1 44.4379	Prec@5 69.0401
Train: [18][2200/10010]	Time 0.587 (1292.027)	Data 0.002 (3.354)	Loss 2.568	Prec@1 44.3864	Prec@5 68.9626
Train: [18][2400/10010]	Time 0.587 (1409.400)	Data 0.001 (3.511)	Loss 2.569	Prec@1 44.3738	Prec@5 68.9348
Train: [18][2600/10010]	Time 0.587 (1526.520)	Data 0.001 (3.666)	Loss 2.570	Prec@1 44.3369	Prec@5 68.9485
Train: [18][2800/10010]	Time 0.587 (1643.767)	Data 0.001 (3.837)	Loss 2.572	Prec@1 44.3106	Prec@5 68.9243
Train: [18][3000/10010]	Time 0.587 (1760.584)	Data 0.001 (3.993)	Loss 2.574	Prec@1 44.3014	Prec@5 68.8984
Train: [18][3200/10010]	Time 0.587 (1877.693)	Data 0.001 (4.145)	Loss 2.574	Prec@1 44.3194	Prec@5 68.8833
Train: [18][3400/10010]	Time 0.586 (1994.671)	Data 0.001 (4.298)	Loss 2.576	Prec@1 44.2811	Prec@5 68.8485
Train: [18][3600/10010]	Time 0.586 (2111.804)	Data 0.001 (4.449)	Loss 2.577	Prec@1 44.2575	Prec@5 68.8272
Train: [18][3800/10010]	Time 0.586 (2228.698)	Data 0.001 (4.607)	Loss 2.578	Prec@1 44.2571	Prec@5 68.8156
Train: [18][4000/10010]	Time 0.586 (2345.468)	Data 0.001 (4.758)	Loss 2.580	Prec@1 44.2468	Prec@5 68.7785
Train: [18][4200/10010]	Time 0.586 (2462.250)	Data 0.001 (4.925)	Loss 2.581	Prec@1 44.2263	Prec@5 68.7507
Train: [18][4400/10010]	Time 0.586 (2580.165)	Data 0.001 (5.092)	Loss 2.582	Prec@1 44.2133	Prec@5 68.7569
Train: [18][4600/10010]	Time 0.586 (2697.682)	Data 0.001 (5.253)	Loss 2.582	Prec@1 44.2032	Prec@5 68.7458
Train: [18][4800/10010]	Time 0.586 (2815.550)	Data 0.001 (5.417)	Loss 2.582	Prec@1 44.1934	Prec@5 68.7523
Train: [18][5000/10010]	Time 0.586 (2932.733)	Data 0.001 (5.578)	Loss 2.582	Prec@1 44.1905	Prec@5 68.7475
Train: [18][5200/10010]	Time 0.586 (3049.916)	Data 0.001 (5.721)	Loss 2.583	Prec@1 44.1737	Prec@5 68.7359
Train: [18][5400/10010]	Time 0.586 (3167.366)	Data 0.001 (5.864)	Loss 2.583	Prec@1 44.1740	Prec@5 68.7313
Train: [18][5600/10010]	Time 0.586 (3284.932)	Data 0.001 (6.019)	Loss 2.583	Prec@1 44.1736	Prec@5 68.7292
Train: [18][5800/10010]	Time 0.587 (3402.388)	Data 0.001 (6.177)	Loss 2.584	Prec@1 44.1653	Prec@5 68.7122
Train: [18][6000/10010]	Time 0.586 (3519.471)	Data 0.001 (6.330)	Loss 2.584	Prec@1 44.1799	Prec@5 68.7197
Train: [18][6200/10010]	Time 0.586 (3635.958)	Data 0.001 (6.487)	Loss 2.584	Prec@1 44.1558	Prec@5 68.7130
Train: [18][6400/10010]	Time 0.586 (3752.951)	Data 0.001 (6.650)	Loss 2.584	Prec@1 44.1573	Prec@5 68.7162
Train: [18][6600/10010]	Time 0.586 (3869.971)	Data 0.001 (6.811)	Loss 2.584	Prec@1 44.1574	Prec@5 68.7125
Train: [18][6800/10010]	Time 0.586 (3986.978)	Data 0.001 (6.970)	Loss 2.583	Prec@1 44.1714	Prec@5 68.7301
Train: [18][7000/10010]	Time 0.586 (4104.234)	Data 0.001 (7.134)	Loss 2.583	Prec@1 44.1642	Prec@5 68.7340
Train: [18][7200/10010]	Time 0.586 (4221.406)	Data 0.001 (7.289)	Loss 2.583	Prec@1 44.1689	Prec@5 68.7310
Train: [18][7400/10010]	Time 0.586 (4338.408)	Data 0.001 (7.440)	Loss 2.583	Prec@1 44.1773	Prec@5 68.7319
Train: [18][7600/10010]	Time 0.586 (4455.009)	Data 0.001 (7.587)	Loss 2.583	Prec@1 44.1784	Prec@5 68.7370
Train: [18][7800/10010]	Time 0.586 (4571.725)	Data 0.001 (7.729)	Loss 2.584	Prec@1 44.1752	Prec@5 68.7339
Train: [18][8000/10010]	Time 0.586 (4688.861)	Data 0.001 (7.890)	Loss 2.584	Prec@1 44.1688	Prec@5 68.7216
Train: [18][8200/10010]	Time 0.586 (4806.076)	Data 0.001 (8.039)	Loss 2.584	Prec@1 44.1648	Prec@5 68.7212
Train: [18][8400/10010]	Time 0.586 (4923.785)	Data 0.001 (8.195)	Loss 2.584	Prec@1 44.1720	Prec@5 68.7258
Train: [18][8600/10010]	Time 0.586 (5041.594)	Data 0.001 (8.359)	Loss 2.584	Prec@1 44.1705	Prec@5 68.7186
Train: [18][8800/10010]	Time 0.586 (5158.733)	Data 0.001 (8.500)	Loss 2.585	Prec@1 44.1525	Prec@5 68.7073
Train: [18][9000/10010]	Time 0.586 (5275.300)	Data 0.001 (8.654)	Loss 2.585	Prec@1 44.1596	Prec@5 68.7059
Train: [18][9200/10010]	Time 0.586 (5392.219)	Data 0.001 (8.802)	Loss 2.585	Prec@1 44.1529	Prec@5 68.7015
Train: [18][9400/10010]	Time 0.586 (5509.471)	Data 0.001 (8.949)	Loss 2.585	Prec@1 44.1543	Prec@5 68.6997
Train: [18][9600/10010]	Time 0.586 (5626.588)	Data 0.001 (9.097)	Loss 2.586	Prec@1 44.1429	Prec@5 68.6891
Train: [18][9800/10010]	Time 0.586 (5743.443)	Data 0.001 (9.258)	Loss 2.586	Prec@1 44.1429	Prec@5 68.6836
Train: [18][10000/10010]	Time 0.586 (5860.968)	Data 0.001 (9.406)	Loss 2.587	Prec@1 44.1371	Prec@5 68.6824
Train: [18]	Time 5861.529	Data 9.406	Loss 2.587	Prec@1 44.1373	Prec@5 68.6831	
Val: [18]	Time 87.331	Data 1.589	Loss 2.256	Prec@1 49.7660	Prec@5 75.6180	
Best Prec@1: [50.412]	
Starting epoch number: 19 Learning rate: 0.1
Train: [19][0/10010]	Time 2.134 (2.134)	Data 1.493 (1.493)	Loss 2.836	Prec@1 40.6250	Prec@5 62.5000
Train: [19][200/10010]	Time 0.593 (119.203)	Data 0.008 (1.649)	Loss 2.539	Prec@1 44.7334	Prec@5 69.5351
Train: [19][400/10010]	Time 0.590 (236.428)	Data 0.004 (1.799)	Loss 2.539	Prec@1 44.7709	Prec@5 69.4786
Train: [19][600/10010]	Time 0.588 (353.338)	Data 0.003 (1.947)	Loss 2.542	Prec@1 44.6391	Prec@5 69.5092
Train: [19][800/10010]	Time 0.588 (470.764)	Data 0.003 (2.103)	Loss 2.544	Prec@1 44.6571	Prec@5 69.4152
Train: [19][1000/10010]	Time 0.587 (588.002)	Data 0.002 (2.258)	Loss 2.551	Prec@1 44.4883	Prec@5 69.2916
Train: [19][1200/10010]	Time 0.587 (705.513)	Data 0.002 (2.415)	Loss 2.553	Prec@1 44.5208	Prec@5 69.2249
Train: [19][1400/10010]	Time 0.587 (823.018)	Data 0.002 (2.577)	Loss 2.554	Prec@1 44.5101	Prec@5 69.2034
Train: [19][1600/10010]	Time 0.587 (939.939)	Data 0.002 (2.747)	Loss 2.557	Prec@1 44.5025	Prec@5 69.1340
Train: [19][1800/10010]	Time 0.587 (1057.131)	Data 0.002 (2.911)	Loss 2.562	Prec@1 44.4289	Prec@5 69.0411
Train: [19][2000/10010]	Time 0.587 (1174.605)	Data 0.002 (3.069)	Loss 2.561	Prec@1 44.4700	Prec@5 69.0502
Train: [19][2200/10010]	Time 0.587 (1291.949)	Data 0.001 (3.228)	Loss 2.562	Prec@1 44.4950	Prec@5 69.0808
Train: [19][2400/10010]	Time 0.587 (1409.285)	Data 0.001 (3.388)	Loss 2.561	Prec@1 44.5342	Prec@5 69.1004
Train: [19][2600/10010]	Time 0.587 (1526.407)	Data 0.001 (3.558)	Loss 2.563	Prec@1 44.4967	Prec@5 69.0708
Train: [19][2800/10010]	Time 0.587 (1644.063)	Data 0.001 (3.707)	Loss 2.564	Prec@1 44.4933	Prec@5 69.0378
Train: [19][3000/10010]	Time 0.587 (1761.313)	Data 0.001 (3.878)	Loss 2.567	Prec@1 44.4693	Prec@5 69.0028
Train: [19][3200/10010]	Time 0.587 (1878.424)	Data 0.001 (4.039)	Loss 2.568	Prec@1 44.4407	Prec@5 68.9797
Train: [19][3400/10010]	Time 0.587 (1995.563)	Data 0.001 (4.203)	Loss 2.569	Prec@1 44.4028	Prec@5 68.9701
Train: [19][3600/10010]	Time 0.587 (2112.915)	Data 0.001 (4.371)	Loss 2.571	Prec@1 44.3629	Prec@5 68.9275
Train: [19][3800/10010]	Time 0.587 (2230.602)	Data 0.001 (4.540)	Loss 2.571	Prec@1 44.3522	Prec@5 68.9272
Train: [19][4000/10010]	Time 0.587 (2347.995)	Data 0.001 (4.694)	Loss 2.571	Prec@1 44.3631	Prec@5 68.9261
Train: [19][4200/10010]	Time 0.587 (2465.710)	Data 0.001 (4.854)	Loss 2.571	Prec@1 44.3497	Prec@5 68.9166
Train: [19][4400/10010]	Time 0.587 (2582.817)	Data 0.001 (5.029)	Loss 2.572	Prec@1 44.3289	Prec@5 68.9018
Train: [19][4600/10010]	Time 0.587 (2700.155)	Data 0.001 (5.179)	Loss 2.572	Prec@1 44.3514	Prec@5 68.9116
Train: [19][4800/10010]	Time 0.587 (2816.977)	Data 0.001 (5.323)	Loss 2.572	Prec@1 44.3415	Prec@5 68.9113
Train: [19][5000/10010]	Time 0.587 (2934.012)	Data 0.001 (5.493)	Loss 2.572	Prec@1 44.3243	Prec@5 68.9067
Train: [19][5200/10010]	Time 0.587 (3051.284)	Data 0.001 (5.651)	Loss 2.573	Prec@1 44.3085	Prec@5 68.8993
Train: [19][5400/10010]	Time 0.587 (3168.243)	Data 0.001 (5.809)	Loss 2.574	Prec@1 44.2888	Prec@5 68.9010
Train: [19][5600/10010]	Time 0.587 (3285.302)	Data 0.001 (5.983)	Loss 2.574	Prec@1 44.2654	Prec@5 68.8893
Train: [19][5800/10010]	Time 0.586 (3402.079)	Data 0.001 (6.135)	Loss 2.575	Prec@1 44.2571	Prec@5 68.8824
Train: [19][6000/10010]	Time 0.586 (3518.094)	Data 0.001 (6.281)	Loss 2.576	Prec@1 44.2430	Prec@5 68.8760
Train: [19][6200/10010]	Time 0.586 (3634.406)	Data 0.001 (6.423)	Loss 2.576	Prec@1 44.2403	Prec@5 68.8655
Train: [19][6400/10010]	Time 0.586 (3750.613)	Data 0.001 (6.577)	Loss 2.577	Prec@1 44.2265	Prec@5 68.8474
Train: [19][6600/10010]	Time 0.586 (3866.959)	Data 0.001 (6.729)	Loss 2.577	Prec@1 44.2305	Prec@5 68.8363
Train: [19][6800/10010]	Time 0.586 (3982.930)	Data 0.001 (6.890)	Loss 2.577	Prec@1 44.2414	Prec@5 68.8394
Train: [19][7000/10010]	Time 0.586 (4099.366)	Data 0.001 (7.043)	Loss 2.577	Prec@1 44.2466	Prec@5 68.8335
Train: [19][7200/10010]	Time 0.585 (4215.359)	Data 0.001 (7.181)	Loss 2.577	Prec@1 44.2430	Prec@5 68.8351
Train: [19][7400/10010]	Time 0.585 (4331.557)	Data 0.001 (7.325)	Loss 2.577	Prec@1 44.2540	Prec@5 68.8332
Train: [19][7600/10010]	Time 0.585 (4447.854)	Data 0.001 (7.490)	Loss 2.577	Prec@1 44.2467	Prec@5 68.8262
Train: [19][7800/10010]	Time 0.585 (4564.270)	Data 0.001 (7.648)	Loss 2.578	Prec@1 44.2440	Prec@5 68.8189
Train: [19][8000/10010]	Time 0.585 (4680.615)	Data 0.001 (7.818)	Loss 2.578	Prec@1 44.2331	Prec@5 68.8098
Train: [19][8200/10010]	Time 0.585 (4796.749)	Data 0.001 (7.991)	Loss 2.578	Prec@1 44.2307	Prec@5 68.8067
Train: [19][8400/10010]	Time 0.585 (4913.065)	Data 0.001 (8.166)	Loss 2.579	Prec@1 44.2286	Prec@5 68.8035
Train: [19][8600/10010]	Time 0.585 (5029.005)	Data 0.001 (8.317)	Loss 2.578	Prec@1 44.2319	Prec@5 68.8080
Train: [19][8800/10010]	Time 0.585 (5145.462)	Data 0.001 (8.475)	Loss 2.579	Prec@1 44.2276	Prec@5 68.8035
Train: [19][9000/10010]	Time 0.585 (5261.415)	Data 0.001 (8.628)	Loss 2.579	Prec@1 44.2207	Prec@5 68.7922
Train: [19][9200/10010]	Time 0.584 (5377.567)	Data 0.001 (8.799)	Loss 2.579	Prec@1 44.2336	Prec@5 68.8060
Train: [19][9400/10010]	Time 0.584 (5494.232)	Data 0.001 (8.969)	Loss 2.579	Prec@1 44.2285	Prec@5 68.8003
Train: [19][9600/10010]	Time 0.584 (5610.378)	Data 0.001 (9.120)	Loss 2.579	Prec@1 44.2237	Prec@5 68.8074
Train: [19][9800/10010]	Time 0.584 (5726.525)	Data 0.001 (9.274)	Loss 2.579	Prec@1 44.2256	Prec@5 68.8079
Train: [19][10000/10010]	Time 0.584 (5842.857)	Data 0.001 (9.421)	Loss 2.580	Prec@1 44.2150	Prec@5 68.8037
Train: [19]	Time 5843.425	Data 9.422	Loss 2.580	Prec@1 44.2151	Prec@5 68.8032	
Val: [19]	Time 87.471	Data 1.472	Loss 2.192	Prec@1 50.9220	Prec@5 76.4440	
Best Prec@1: [50.922]	
Starting epoch number: 20 Learning rate: 0.1
Train: [20][0/10010]	Time 2.173 (2.173)	Data 1.384 (1.384)	Loss 2.509	Prec@1 42.1875	Prec@5 71.0938
Train: [20][200/10010]	Time 0.592 (118.892)	Data 0.008 (1.528)	Loss 2.536	Prec@1 44.8344	Prec@5 69.7217
Train: [20][400/10010]	Time 0.587 (235.351)	Data 0.004 (1.675)	Loss 2.547	Prec@1 45.0397	Prec@5 69.3754
Train: [20][600/10010]	Time 0.587 (352.531)	Data 0.003 (1.815)	Loss 2.550	Prec@1 44.8315	Prec@5 69.3233
Train: [20][800/10010]	Time 0.585 (468.951)	Data 0.002 (1.964)	Loss 2.553	Prec@1 44.6795	Prec@5 69.2084
Train: [20][1000/10010]	Time 0.586 (586.206)	Data 0.002 (2.113)	Loss 2.553	Prec@1 44.6889	Prec@5 69.2347
Train: [20][1200/10010]	Time 0.586 (704.085)	Data 0.002 (2.275)	Loss 2.554	Prec@1 44.6561	Prec@5 69.2398
Train: [20][1400/10010]	Time 0.586 (821.602)	Data 0.002 (2.424)	Loss 2.555	Prec@1 44.6238	Prec@5 69.1660
Train: [20][1600/10010]	Time 0.586 (938.960)	Data 0.002 (2.579)	Loss 2.557	Prec@1 44.6044	Prec@5 69.1150
Train: [20][1800/10010]	Time 0.587 (1056.491)	Data 0.002 (2.735)	Loss 2.560	Prec@1 44.5469	Prec@5 69.1018
Train: [20][2000/10010]	Time 0.587 (1173.995)	Data 0.001 (2.883)	Loss 2.559	Prec@1 44.5711	Prec@5 69.1197
Train: [20][2200/10010]	Time 0.587 (1291.477)	Data 0.001 (3.041)	Loss 2.560	Prec@1 44.5242	Prec@5 69.1039
Train: [20][2400/10010]	Time 0.587 (1408.843)	Data 0.001 (3.197)	Loss 2.560	Prec@1 44.5391	Prec@5 69.0835
Train: [20][2600/10010]	Time 0.587 (1526.232)	Data 0.001 (3.354)	Loss 2.562	Prec@1 44.5117	Prec@5 69.0393
Train: [20][2800/10010]	Time 0.587 (1643.737)	Data 0.001 (3.524)	Loss 2.560	Prec@1 44.5354	Prec@5 69.0730
Train: [20][3000/10010]	Time 0.587 (1760.915)	Data 0.001 (3.700)	Loss 2.561	Prec@1 44.5159	Prec@5 69.0814
Train: [20][3200/10010]	Time 0.587 (1877.881)	Data 0.001 (3.860)	Loss 2.563	Prec@1 44.5086	Prec@5 69.0463
Train: [20][3400/10010]	Time 0.587 (1995.071)	Data 0.001 (4.021)	Loss 2.563	Prec@1 44.4924	Prec@5 69.0321
Train: [20][3600/10010]	Time 0.587 (2112.174)	Data 0.001 (4.185)	Loss 2.563	Prec@1 44.4900	Prec@5 69.0494
Train: [20][3800/10010]	Time 0.587 (2229.629)	Data 0.001 (4.349)	Loss 2.564	Prec@1 44.4885	Prec@5 69.0277
Train: [20][4000/10010]	Time 0.587 (2347.589)	Data 0.001 (4.502)	Loss 2.565	Prec@1 44.4762	Prec@5 68.9945
Train: [20][4200/10010]	Time 0.587 (2465.037)	Data 0.001 (4.662)	Loss 2.566	Prec@1 44.4611	Prec@5 68.9897
Train: [20][4400/10010]	Time 0.587 (2582.398)	Data 0.001 (4.825)	Loss 2.568	Prec@1 44.4256	Prec@5 68.9687
Train: [20][4600/10010]	Time 0.587 (2699.628)	Data 0.001 (4.978)	Loss 2.569	Prec@1 44.4031	Prec@5 68.9490
Train: [20][4800/10010]	Time 0.587 (2817.093)	Data 0.001 (5.133)	Loss 2.569	Prec@1 44.3998	Prec@5 68.9438
Train: [20][5000/10010]	Time 0.587 (2934.027)	Data 0.001 (5.287)	Loss 2.570	Prec@1 44.3917	Prec@5 68.9387
Train: [20][5200/10010]	Time 0.587 (3051.487)	Data 0.001 (5.463)	Loss 2.571	Prec@1 44.3786	Prec@5 68.9263
Train: [20][5400/10010]	Time 0.587 (3168.893)	Data 0.001 (5.629)	Loss 2.570	Prec@1 44.3961	Prec@5 68.9409
Train: [20][5600/10010]	Time 0.587 (3286.434)	Data 0.001 (5.781)	Loss 2.570	Prec@1 44.3962	Prec@5 68.9463
Train: [20][5800/10010]	Time 0.587 (3403.363)	Data 0.001 (5.965)	Loss 2.569	Prec@1 44.3985	Prec@5 68.9547
Train: [20][6000/10010]	Time 0.586 (3519.394)	Data 0.001 (6.153)	Loss 2.570	Prec@1 44.3822	Prec@5 68.9422
Train: [20][6200/10010]	Time 0.586 (3635.594)	Data 0.001 (6.315)	Loss 2.571	Prec@1 44.3569	Prec@5 68.9192
Train: [20][6400/10010]	Time 0.586 (3751.758)	Data 0.001 (6.498)	Loss 2.572	Prec@1 44.3395	Prec@5 68.9010
Train: [20][6600/10010]	Time 0.586 (3868.111)	Data 0.001 (6.656)	Loss 2.573	Prec@1 44.3355	Prec@5 68.8893
Train: [20][6800/10010]	Time 0.586 (3984.449)	Data 0.001 (6.813)	Loss 2.573	Prec@1 44.3423	Prec@5 68.8769
Train: [20][7000/10010]	Time 0.586 (4100.997)	Data 0.001 (6.986)	Loss 2.573	Prec@1 44.3338	Prec@5 68.8710
Train: [20][7200/10010]	Time 0.586 (4217.218)	Data 0.001 (7.153)	Loss 2.574	Prec@1 44.3082	Prec@5 68.8546
Train: [20][7400/10010]	Time 0.586 (4333.372)	Data 0.001 (7.315)	Loss 2.575	Prec@1 44.3136	Prec@5 68.8647
Train: [20][7600/10010]	Time 0.585 (4449.633)	Data 0.001 (7.459)	Loss 2.575	Prec@1 44.3167	Prec@5 68.8644
Train: [20][7800/10010]	Time 0.585 (4566.016)	Data 0.001 (7.626)	Loss 2.576	Prec@1 44.2984	Prec@5 68.8446
Train: [20][8000/10010]	Time 0.585 (4681.810)	Data 0.001 (7.795)	Loss 2.576	Prec@1 44.2889	Prec@5 68.8411
Train: [20][8200/10010]	Time 0.585 (4798.597)	Data 0.001 (7.970)	Loss 2.576	Prec@1 44.2991	Prec@5 68.8562
Train: [20][8400/10010]	Time 0.585 (4915.085)	Data 0.001 (8.154)	Loss 2.577	Prec@1 44.2834	Prec@5 68.8449
Train: [20][8600/10010]	Time 0.585 (5031.371)	Data 0.001 (8.316)	Loss 2.576	Prec@1 44.2868	Prec@5 68.8483
Train: [20][8800/10010]	Time 0.585 (5147.322)	Data 0.001 (8.485)	Loss 2.577	Prec@1 44.2772	Prec@5 68.8443
Train: [20][9000/10010]	Time 0.585 (5263.288)	Data 0.001 (8.636)	Loss 2.577	Prec@1 44.2688	Prec@5 68.8433
Train: [20][9200/10010]	Time 0.585 (5379.068)	Data 0.001 (8.795)	Loss 2.577	Prec@1 44.2595	Prec@5 68.8381
Train: [20][9400/10010]	Time 0.584 (5494.676)	Data 0.001 (8.958)	Loss 2.578	Prec@1 44.2500	Prec@5 68.8245
Train: [20][9600/10010]	Time 0.584 (5610.684)	Data 0.001 (9.137)	Loss 2.578	Prec@1 44.2432	Prec@5 68.8239
Train: [20][9800/10010]	Time 0.584 (5726.814)	Data 0.001 (9.318)	Loss 2.579	Prec@1 44.2395	Prec@5 68.8248
Train: [20][10000/10010]	Time 0.584 (5843.102)	Data 0.001 (9.479)	Loss 2.579	Prec@1 44.2318	Prec@5 68.8191
Train: [20]	Time 5843.714	Data 9.479	Loss 2.579	Prec@1 44.2319	Prec@5 68.8191	
Val: [20]	Time 87.821	Data 1.587	Loss 2.261	Prec@1 49.6140	Prec@5 75.4700	
Best Prec@1: [50.922]	
Starting epoch number: 21 Learning rate: 0.1
Train: [21][0/10010]	Time 2.140 (2.140)	Data 1.512 (1.512)	Loss 2.849	Prec@1 39.8438	Prec@5 63.2812
Train: [21][200/10010]	Time 0.594 (119.488)	Data 0.008 (1.665)	Loss 2.549	Prec@1 44.6168	Prec@5 69.2631
Train: [21][400/10010]	Time 0.591 (236.935)	Data 0.005 (1.824)	Loss 2.544	Prec@1 44.7261	Prec@5 69.3033
Train: [21][600/10010]	Time 0.590 (354.606)	Data 0.003 (1.985)	Loss 2.550	Prec@1 44.6508	Prec@5 69.1946
Train: [21][800/10010]	Time 0.589 (471.738)	Data 0.003 (2.141)	Loss 2.560	Prec@1 44.5751	Prec@5 69.0055
Train: [21][1000/10010]	Time 0.589 (589.496)	Data 0.002 (2.310)	Loss 2.554	Prec@1 44.6366	Prec@5 69.1707
Train: [21][1200/10010]	Time 0.589 (706.930)	Data 0.002 (2.456)	Loss 2.556	Prec@1 44.5495	Prec@5 69.1780
Train: [21][1400/10010]	Time 0.589 (824.677)	Data 0.002 (2.626)	Loss 2.558	Prec@1 44.4816	Prec@5 69.1325
Train: [21][1600/10010]	Time 0.589 (942.364)	Data 0.002 (2.776)	Loss 2.558	Prec@1 44.5088	Prec@5 69.0799
Train: [21][1800/10010]	Time 0.589 (1060.068)	Data 0.002 (2.938)	Loss 2.559	Prec@1 44.4931	Prec@5 69.0779
Train: [21][2000/10010]	Time 0.589 (1177.632)	Data 0.002 (3.110)	Loss 2.560	Prec@1 44.5254	Prec@5 69.1033
Train: [21][2200/10010]	Time 0.589 (1295.493)	Data 0.001 (3.266)	Loss 2.562	Prec@1 44.4599	Prec@5 69.0652
Train: [21][2400/10010]	Time 0.589 (1413.251)	Data 0.001 (3.444)	Loss 2.563	Prec@1 44.4919	Prec@5 69.0881
Train: [21][2600/10010]	Time 0.589 (1531.146)	Data 0.001 (3.601)	Loss 2.566	Prec@1 44.4219	Prec@5 69.0540
Train: [21][2800/10010]	Time 0.589 (1649.082)	Data 0.001 (3.772)	Loss 2.567	Prec@1 44.3957	Prec@5 69.0256
Train: [21][3000/10010]	Time 0.589 (1767.126)	Data 0.001 (3.933)	Loss 2.568	Prec@1 44.3597	Prec@5 69.0101
Train: [21][3200/10010]	Time 0.589 (1884.602)	Data 0.001 (4.108)	Loss 2.568	Prec@1 44.3585	Prec@5 68.9843
Train: [21][3400/10010]	Time 0.589 (2002.346)	Data 0.001 (4.278)	Loss 2.568	Prec@1 44.3668	Prec@5 68.9813
Train: [21][3600/10010]	Time 0.589 (2120.325)	Data 0.001 (4.449)	Loss 2.568	Prec@1 44.3774	Prec@5 68.9882
Train: [21][3800/10010]	Time 0.589 (2237.865)	Data 0.001 (4.637)	Loss 2.567	Prec@1 44.3794	Prec@5 69.0038
Train: [21][4000/10010]	Time 0.589 (2355.841)	Data 0.001 (4.785)	Loss 2.568	Prec@1 44.3579	Prec@5 68.9714
Train: [21][4200/10010]	Time 0.589 (2473.784)	Data 0.001 (4.932)	Loss 2.567	Prec@1 44.3663	Prec@5 68.9949
Train: [21][4400/10010]	Time 0.589 (2591.470)	Data 0.001 (5.114)	Loss 2.567	Prec@1 44.3603	Prec@5 68.9854
Train: [21][4600/10010]	Time 0.589 (2709.814)	Data 0.001 (5.281)	Loss 2.568	Prec@1 44.3609	Prec@5 68.9670
Train: [21][4800/10010]	Time 0.589 (2827.141)	Data 0.001 (5.452)	Loss 2.569	Prec@1 44.3441	Prec@5 68.9461
Train: [21][5000/10010]	Time 0.589 (2945.282)	Data 0.001 (5.626)	Loss 2.570	Prec@1 44.3441	Prec@5 68.9418
Train: [21][5200/10010]	Time 0.589 (3062.889)	Data 0.001 (5.795)	Loss 2.570	Prec@1 44.3409	Prec@5 68.9260
Train: [21][5400/10010]	Time 0.589 (3180.709)	Data 0.001 (5.969)	Loss 2.570	Prec@1 44.3497	Prec@5 68.9437
Train: [21][5600/10010]	Time 0.589 (3297.975)	Data 0.001 (6.123)	Loss 2.570	Prec@1 44.3435	Prec@5 68.9387
Train: [21][5800/10010]	Time 0.589 (3415.239)	Data 0.001 (6.289)	Loss 2.571	Prec@1 44.3395	Prec@5 68.9144
Train: [21][6000/10010]	Time 0.589 (3533.226)	Data 0.001 (6.443)	Loss 2.571	Prec@1 44.3664	Prec@5 68.9211
Train: [21][6200/10010]	Time 0.589 (3651.036)	Data 0.001 (6.602)	Loss 2.571	Prec@1 44.3644	Prec@5 68.9210
Train: [21][6400/10010]	Time 0.589 (3768.743)	Data 0.001 (6.743)	Loss 2.572	Prec@1 44.3500	Prec@5 68.8965
Train: [21][6600/10010]	Time 0.589 (3886.472)	Data 0.001 (6.916)	Loss 2.572	Prec@1 44.3485	Prec@5 68.9004
Train: [21][6800/10010]	Time 0.589 (4004.096)	Data 0.001 (7.092)	Loss 2.572	Prec@1 44.3400	Prec@5 68.8929
Train: [21][7000/10010]	Time 0.589 (4121.378)	Data 0.001 (7.248)	Loss 2.573	Prec@1 44.3282	Prec@5 68.8757
Train: [21][7200/10010]	Time 0.589 (4239.341)	Data 0.001 (7.418)	Loss 2.573	Prec@1 44.3264	Prec@5 68.8811
Train: [21][7400/10010]	Time 0.589 (4356.813)	Data 0.001 (7.574)	Loss 2.573	Prec@1 44.3342	Prec@5 68.8893
Train: [21][7600/10010]	Time 0.589 (4474.811)	Data 0.001 (7.752)	Loss 2.573	Prec@1 44.3303	Prec@5 68.8871
Train: [21][7800/10010]	Time 0.589 (4592.887)	Data 0.001 (7.940)	Loss 2.573	Prec@1 44.3407	Prec@5 68.8769
Train: [21][8000/10010]	Time 0.589 (4710.813)	Data 0.001 (8.109)	Loss 2.574	Prec@1 44.3420	Prec@5 68.8683
Train: [21][8200/10010]	Time 0.589 (4828.798)	Data 0.001 (8.303)	Loss 2.574	Prec@1 44.3463	Prec@5 68.8656
Train: [21][8400/10010]	Time 0.589 (4946.355)	Data 0.001 (8.494)	Loss 2.574	Prec@1 44.3413	Prec@5 68.8627
Train: [21][8600/10010]	Time 0.589 (5063.911)	Data 0.001 (8.667)	Loss 2.575	Prec@1 44.3284	Prec@5 68.8533
Train: [21][8800/10010]	Time 0.589 (5181.128)	Data 0.001 (8.847)	Loss 2.574	Prec@1 44.3352	Prec@5 68.8563
Train: [21][9000/10010]	Time 0.589 (5298.382)	Data 0.001 (9.015)	Loss 2.575	Prec@1 44.3281	Prec@5 68.8437
Train: [21][9200/10010]	Time 0.589 (5415.930)	Data 0.001 (9.186)	Loss 2.575	Prec@1 44.3291	Prec@5 68.8476
Train: [21][9400/10010]	Time 0.589 (5533.576)	Data 0.001 (9.379)	Loss 2.575	Prec@1 44.3330	Prec@5 68.8475
Train: [21][9600/10010]	Time 0.589 (5651.062)	Data 0.001 (9.551)	Loss 2.576	Prec@1 44.3268	Prec@5 68.8380
Train: [21][9800/10010]	Time 0.589 (5768.753)	Data 0.001 (9.713)	Loss 2.576	Prec@1 44.3139	Prec@5 68.8383
Train: [21][10000/10010]	Time 0.589 (5886.348)	Data 0.001 (9.888)	Loss 2.576	Prec@1 44.3127	Prec@5 68.8380
Train: [21]	Time 5886.903	Data 9.888	Loss 2.576	Prec@1 44.3127	Prec@5 68.8374	
Val: [21]	Time 87.562	Data 1.648	Loss 2.284	Prec@1 48.8120	Prec@5 74.7900	
Best Prec@1: [50.922]	
Starting epoch number: 22 Learning rate: 0.1
Train: [22][0/10010]	Time 2.180 (2.180)	Data 1.482 (1.482)	Loss 2.505	Prec@1 44.5312	Prec@5 68.7500
Train: [22][200/10010]	Time 0.595 (119.609)	Data 0.008 (1.657)	Loss 2.523	Prec@1 45.0016	Prec@5 69.6323
Train: [22][400/10010]	Time 0.591 (237.180)	Data 0.005 (1.816)	Loss 2.528	Prec@1 45.1060	Prec@5 69.5079
Train: [22][600/10010]	Time 0.591 (354.967)	Data 0.003 (1.966)	Loss 2.537	Prec@1 44.9368	Prec@5 69.4533
Train: [22][800/10010]	Time 0.589 (472.114)	Data 0.003 (2.131)	Loss 2.545	Prec@1 44.8404	Prec@5 69.3128
Train: [22][1000/10010]	Time 0.589 (589.160)	Data 0.002 (2.293)	Loss 2.552	Prec@1 44.7693	Prec@5 69.2300
Train: [22][1200/10010]	Time 0.588 (706.740)	Data 0.002 (2.452)	Loss 2.556	Prec@1 44.6802	Prec@5 69.1871
Train: [22][1400/10010]	Time 0.588 (824.370)	Data 0.002 (2.631)	Loss 2.557	Prec@1 44.6472	Prec@5 69.1409
Train: [22][1600/10010]	Time 0.588 (941.647)	Data 0.002 (2.807)	Loss 2.557	Prec@1 44.5991	Prec@5 69.1365
Train: [22][1800/10010]	Time 0.588 (1059.469)	Data 0.002 (2.976)	Loss 2.554	Prec@1 44.6753	Prec@5 69.1578
Train: [22][2000/10010]	Time 0.588 (1176.934)	Data 0.002 (3.124)	Loss 2.555	Prec@1 44.6246	Prec@5 69.1592
Train: [22][2200/10010]	Time 0.588 (1294.395)	Data 0.001 (3.288)	Loss 2.556	Prec@1 44.6239	Prec@5 69.1646
Train: [22][2400/10010]	Time 0.588 (1411.915)	Data 0.001 (3.456)	Loss 2.557	Prec@1 44.6045	Prec@5 69.1616
Train: [22][2600/10010]	Time 0.588 (1529.266)	Data 0.001 (3.625)	Loss 2.558	Prec@1 44.5967	Prec@5 69.1516
Train: [22][2800/10010]	Time 0.588 (1647.025)	Data 0.001 (3.791)	Loss 2.559	Prec@1 44.5619	Prec@5 69.1198
Train: [22][3000/10010]	Time 0.588 (1764.787)	Data 0.001 (3.970)	Loss 2.559	Prec@1 44.5523	Prec@5 69.1270
Train: [22][3200/10010]	Time 0.588 (1882.470)	Data 0.001 (4.132)	Loss 2.558	Prec@1 44.5649	Prec@5 69.1342
Train: [22][3400/10010]	Time 0.588 (2000.018)	Data 0.001 (4.298)	Loss 2.560	Prec@1 44.5087	Prec@5 69.0893
Train: [22][3600/10010]	Time 0.588 (2117.973)	Data 0.001 (4.466)	Loss 2.561	Prec@1 44.4887	Prec@5 69.0676
Train: [22][3800/10010]	Time 0.588 (2235.525)	Data 0.001 (4.617)	Loss 2.561	Prec@1 44.4681	Prec@5 69.0591
Train: [22][4000/10010]	Time 0.588 (2352.868)	Data 0.001 (4.782)	Loss 2.563	Prec@1 44.4699	Prec@5 69.0228
Train: [22][4200/10010]	Time 0.588 (2470.478)	Data 0.001 (4.954)	Loss 2.563	Prec@1 44.4712	Prec@5 69.0197
Train: [22][4400/10010]	Time 0.588 (2587.941)	Data 0.001 (5.113)	Loss 2.563	Prec@1 44.4601	Prec@5 69.0326
Train: [22][4600/10010]	Time 0.588 (2705.325)	Data 0.001 (5.278)	Loss 2.565	Prec@1 44.4329	Prec@5 69.0103
Train: [22][4800/10010]	Time 0.588 (2822.637)	Data 0.001 (5.442)	Loss 2.565	Prec@1 44.4349	Prec@5 68.9941
Train: [22][5000/10010]	Time 0.588 (2939.832)	Data 0.001 (5.598)	Loss 2.566	Prec@1 44.4327	Prec@5 68.9871
Train: [22][5200/10010]	Time 0.588 (3057.084)	Data 0.001 (5.761)	Loss 2.567	Prec@1 44.4009	Prec@5 68.9650
Train: [22][5400/10010]	Time 0.588 (3174.631)	Data 0.001 (5.926)	Loss 2.568	Prec@1 44.3927	Prec@5 68.9608
Train: [22][5600/10010]	Time 0.588 (3291.922)	Data 0.001 (6.105)	Loss 2.568	Prec@1 44.3803	Prec@5 68.9651
Train: [22][5800/10010]	Time 0.588 (3408.815)	Data 0.001 (6.274)	Loss 2.569	Prec@1 44.3730	Prec@5 68.9478
Train: [22][6000/10010]	Time 0.588 (3526.175)	Data 0.001 (6.437)	Loss 2.570	Prec@1 44.3533	Prec@5 68.9338
Train: [22][6200/10010]	Time 0.588 (3643.851)	Data 0.001 (6.610)	Loss 2.570	Prec@1 44.3541	Prec@5 68.9240
Train: [22][6400/10010]	Time 0.588 (3761.656)	Data 0.001 (6.777)	Loss 2.571	Prec@1 44.3612	Prec@5 68.9299
Train: [22][6600/10010]	Time 0.588 (3879.719)	Data 0.001 (6.938)	Loss 2.570	Prec@1 44.3702	Prec@5 68.9377
Train: [22][6800/10010]	Time 0.588 (3996.696)	Data 0.001 (7.104)	Loss 2.571	Prec@1 44.3633	Prec@5 68.9385
Train: [22][7000/10010]	Time 0.587 (4112.928)	Data 0.001 (7.262)	Loss 2.571	Prec@1 44.3597	Prec@5 68.9427
Train: [22][7200/10010]	Time 0.587 (4229.678)	Data 0.001 (7.434)	Loss 2.570	Prec@1 44.3681	Prec@5 68.9452
Train: [22][7400/10010]	Time 0.587 (4346.177)	Data 0.001 (7.627)	Loss 2.571	Prec@1 44.3571	Prec@5 68.9334
Train: [22][7600/10010]	Time 0.587 (4462.872)	Data 0.001 (7.807)	Loss 2.572	Prec@1 44.3481	Prec@5 68.9139
Train: [22][7800/10010]	Time 0.587 (4579.711)	Data 0.001 (7.991)	Loss 2.572	Prec@1 44.3514	Prec@5 68.9213
Train: [22][8000/10010]	Time 0.587 (4696.698)	Data 0.001 (8.171)	Loss 2.572	Prec@1 44.3487	Prec@5 68.9153
Train: [22][8200/10010]	Time 0.587 (4813.095)	Data 0.001 (8.327)	Loss 2.572	Prec@1 44.3476	Prec@5 68.9177
Train: [22][8400/10010]	Time 0.587 (4929.514)	Data 0.001 (8.509)	Loss 2.573	Prec@1 44.3344	Prec@5 68.9004
Train: [22][8600/10010]	Time 0.587 (5046.349)	Data 0.001 (8.687)	Loss 2.573	Prec@1 44.3372	Prec@5 68.9016
Train: [22][8800/10010]	Time 0.587 (5162.922)	Data 0.001 (8.846)	Loss 2.573	Prec@1 44.3231	Prec@5 68.8979
Train: [22][9000/10010]	Time 0.587 (5279.630)	Data 0.001 (9.030)	Loss 2.573	Prec@1 44.3217	Prec@5 68.9064
Train: [22][9200/10010]	Time 0.586 (5395.699)	Data 0.001 (9.203)	Loss 2.573	Prec@1 44.3287	Prec@5 68.9140
Train: [22][9400/10010]	Time 0.586 (5511.827)	Data 0.001 (9.387)	Loss 2.573	Prec@1 44.3288	Prec@5 68.9116
Train: [22][9600/10010]	Time 0.586 (5628.268)	Data 0.001 (9.549)	Loss 2.573	Prec@1 44.3354	Prec@5 68.9083
Train: [22][9800/10010]	Time 0.586 (5745.291)	Data 0.001 (9.683)	Loss 2.573	Prec@1 44.3345	Prec@5 68.9121
Train: [22][10000/10010]	Time 0.586 (5861.449)	Data 0.001 (9.829)	Loss 2.573	Prec@1 44.3242	Prec@5 68.9078
Train: [22]	Time 5862.016	Data 9.829	Loss 2.573	Prec@1 44.3236	Prec@5 68.9070	
Val: [22]	Time 88.283	Data 1.640	Loss 2.183	Prec@1 50.6860	Prec@5 76.4520	
Best Prec@1: [50.922]	
Starting epoch number: 23 Learning rate: 0.1
Train: [23][0/10010]	Time 1.931 (1.931)	Data 1.221 (1.221)	Loss 2.763	Prec@1 44.5312	Prec@5 64.8438
Train: [23][200/10010]	Time 0.595 (119.648)	Data 0.007 (1.385)	Loss 2.554	Prec@1 44.5507	Prec@5 69.1659
Train: [23][400/10010]	Time 0.592 (237.250)	Data 0.004 (1.535)	Loss 2.538	Prec@1 45.0436	Prec@5 69.3306
Train: [23][600/10010]	Time 0.591 (355.056)	Data 0.003 (1.701)	Loss 2.544	Prec@1 44.8731	Prec@5 69.2154
Train: [23][800/10010]	Time 0.589 (472.130)	Data 0.002 (1.857)	Loss 2.542	Prec@1 44.9545	Prec@5 69.1870
Train: [23][1000/10010]	Time 0.588 (588.813)	Data 0.002 (2.014)	Loss 2.544	Prec@1 44.9184	Prec@5 69.0801
Train: [23][1200/10010]	Time 0.588 (705.718)	Data 0.002 (2.178)	Loss 2.545	Prec@1 44.8806	Prec@5 69.0844
Train: [23][1400/10010]	Time 0.587 (822.891)	Data 0.002 (2.339)	Loss 2.546	Prec@1 44.8134	Prec@5 69.0907
Train: [23][1600/10010]	Time 0.587 (940.452)	Data 0.002 (2.501)	Loss 2.546	Prec@1 44.8440	Prec@5 69.1194
Train: [23][1800/10010]	Time 0.587 (1057.956)	Data 0.001 (2.655)	Loss 2.545	Prec@1 44.8752	Prec@5 69.1803
Train: [23][2000/10010]	Time 0.587 (1175.363)	Data 0.001 (2.819)	Loss 2.546	Prec@1 44.8709	Prec@5 69.1603
Train: [23][2200/10010]	Time 0.587 (1292.666)	Data 0.001 (2.973)	Loss 2.549	Prec@1 44.7740	Prec@5 69.1376
Train: [23][2400/10010]	Time 0.587 (1409.970)	Data 0.001 (3.137)	Loss 2.551	Prec@1 44.7437	Prec@5 69.1353
Train: [23][2600/10010]	Time 0.587 (1527.089)	Data 0.001 (3.311)	Loss 2.552	Prec@1 44.7322	Prec@5 69.1110
Train: [23][2800/10010]	Time 0.587 (1644.146)	Data 0.001 (3.491)	Loss 2.553	Prec@1 44.7298	Prec@5 69.0967
Train: [23][3000/10010]	Time 0.587 (1761.424)	Data 0.001 (3.658)	Loss 2.554	Prec@1 44.6908	Prec@5 69.1022
Train: [23][3200/10010]	Time 0.587 (1878.743)	Data 0.001 (3.822)	Loss 2.555	Prec@1 44.6738	Prec@5 69.0939
Train: [23][3400/10010]	Time 0.587 (1996.146)	Data 0.001 (3.992)	Loss 2.555	Prec@1 44.6505	Prec@5 69.0884
Train: [23][3600/10010]	Time 0.587 (2113.738)	Data 0.001 (4.154)	Loss 2.556	Prec@1 44.6467	Prec@5 69.0828
Train: [23][3800/10010]	Time 0.587 (2231.660)	Data 0.001 (4.298)	Loss 2.556	Prec@1 44.6570	Prec@5 69.0641
Train: [23][4000/10010]	Time 0.587 (2349.149)	Data 0.001 (4.462)	Loss 2.558	Prec@1 44.6254	Prec@5 69.0296
Train: [23][4200/10010]	Time 0.587 (2466.694)	Data 0.001 (4.645)	Loss 2.559	Prec@1 44.6257	Prec@5 69.0213
Train: [23][4400/10010]	Time 0.587 (2584.234)	Data 0.001 (4.800)	Loss 2.561	Prec@1 44.5905	Prec@5 69.0154
Train: [23][4600/10010]	Time 0.587 (2701.509)	Data 0.001 (4.967)	Loss 2.563	Prec@1 44.5487	Prec@5 68.9991
Train: [23][4800/10010]	Time 0.587 (2818.773)	Data 0.001 (5.143)	Loss 2.564	Prec@1 44.5309	Prec@5 68.9809
Train: [23][5000/10010]	Time 0.587 (2936.282)	Data 0.001 (5.304)	Loss 2.565	Prec@1 44.5038	Prec@5 68.9815
Train: [23][5200/10010]	Time 0.587 (3053.872)	Data 0.001 (5.478)	Loss 2.565	Prec@1 44.4890	Prec@5 68.9749
Train: [23][5400/10010]	Time 0.587 (3171.414)	Data 0.001 (5.637)	Loss 2.565	Prec@1 44.4934	Prec@5 68.9979
Train: [23][5600/10010]	Time 0.587 (3289.373)	Data 0.001 (5.811)	Loss 2.565	Prec@1 44.4729	Prec@5 68.9917
Train: [23][5800/10010]	Time 0.587 (3406.945)	Data 0.001 (5.984)	Loss 2.565	Prec@1 44.4791	Prec@5 68.9961
Train: [23][6000/10010]	Time 0.587 (3524.665)	Data 0.001 (6.163)	Loss 2.566	Prec@1 44.4746	Prec@5 68.9950
Train: [23][6200/10010]	Time 0.587 (3641.831)	Data 0.001 (6.346)	Loss 2.566	Prec@1 44.4495	Prec@5 68.9939
Train: [23][6400/10010]	Time 0.587 (3758.837)	Data 0.001 (6.521)	Loss 2.567	Prec@1 44.4307	Prec@5 68.9775
Train: [23][6600/10010]	Time 0.587 (3876.001)	Data 0.001 (6.690)	Loss 2.567	Prec@1 44.4258	Prec@5 68.9710
Train: [23][6800/10010]	Time 0.587 (3993.071)	Data 0.001 (6.855)	Loss 2.568	Prec@1 44.4106	Prec@5 68.9583
Train: [23][7000/10010]	Time 0.587 (4110.691)	Data 0.001 (7.043)	Loss 2.568	Prec@1 44.4222	Prec@5 68.9603
Train: [23][7200/10010]	Time 0.587 (4228.096)	Data 0.001 (7.222)	Loss 2.569	Prec@1 44.4273	Prec@5 68.9561
Train: [23][7400/10010]	Time 0.587 (4345.195)	Data 0.001 (7.372)	Loss 2.569	Prec@1 44.4198	Prec@5 68.9400
Train: [23][7600/10010]	Time 0.587 (4462.796)	Data 0.001 (7.540)	Loss 2.569	Prec@1 44.4092	Prec@5 68.9423
Train: [23][7800/10010]	Time 0.587 (4580.095)	Data 0.001 (7.707)	Loss 2.569	Prec@1 44.3970	Prec@5 68.9438
Train: [23][8000/10010]	Time 0.587 (4697.180)	Data 0.001 (7.884)	Loss 2.569	Prec@1 44.4006	Prec@5 68.9445
Train: [23][8200/10010]	Time 0.587 (4814.565)	Data 0.001 (8.061)	Loss 2.570	Prec@1 44.3985	Prec@5 68.9447
Train: [23][8400/10010]	Time 0.587 (4931.577)	Data 0.001 (8.226)	Loss 2.570	Prec@1 44.3981	Prec@5 68.9495
Train: [23][8600/10010]	Time 0.587 (5048.256)	Data 0.001 (8.410)	Loss 2.570	Prec@1 44.3959	Prec@5 68.9516
Train: [23][8800/10010]	Time 0.587 (5165.419)	Data 0.001 (8.575)	Loss 2.570	Prec@1 44.3948	Prec@5 68.9507
Train: [23][9000/10010]	Time 0.587 (5282.911)	Data 0.001 (8.729)	Loss 2.570	Prec@1 44.3896	Prec@5 68.9533
Train: [23][9200/10010]	Time 0.587 (5400.004)	Data 0.001 (8.891)	Loss 2.570	Prec@1 44.3840	Prec@5 68.9491
Train: [23][9400/10010]	Time 0.587 (5517.236)	Data 0.001 (9.067)	Loss 2.570	Prec@1 44.3760	Prec@5 68.9411
Train: [23][9600/10010]	Time 0.587 (5634.760)	Data 0.001 (9.234)	Loss 2.571	Prec@1 44.3616	Prec@5 68.9279
Train: [23][9800/10010]	Time 0.587 (5751.912)	Data 0.001 (9.385)	Loss 2.571	Prec@1 44.3602	Prec@5 68.9257
Train: [23][10000/10010]	Time 0.587 (5868.932)	Data 0.001 (9.528)	Loss 2.572	Prec@1 44.3383	Prec@5 68.9081
Train: [23]	Time 5869.554	Data 9.529	Loss 2.572	Prec@1 44.3390	Prec@5 68.9086	
Val: [23]	Time 87.389	Data 1.707	Loss 2.234	Prec@1 49.8560	Prec@5 75.7340	
Best Prec@1: [50.922]	
Starting epoch number: 24 Learning rate: 0.1
Train: [24][0/10010]	Time 2.317 (2.317)	Data 1.677 (1.677)	Loss 2.698	Prec@1 43.7500	Prec@5 68.7500
Train: [24][200/10010]	Time 0.594 (119.366)	Data 0.009 (1.826)	Loss 2.511	Prec@1 45.5224	Prec@5 69.8266
Train: [24][400/10010]	Time 0.589 (236.383)	Data 0.005 (1.982)	Loss 2.514	Prec@1 45.5463	Prec@5 69.7163
Train: [24][600/10010]	Time 0.589 (353.876)	Data 0.004 (2.142)	Loss 2.523	Prec@1 45.3710	Prec@5 69.6547
Train: [24][800/10010]	Time 0.588 (471.198)	Data 0.003 (2.309)	Loss 2.534	Prec@1 45.1603	Prec@5 69.4913
Train: [24][1000/10010]	Time 0.588 (588.489)	Data 0.002 (2.466)	Loss 2.537	Prec@1 45.1150	Prec@5 69.4961
Train: [24][1200/10010]	Time 0.588 (705.748)	Data 0.002 (2.633)	Loss 2.536	Prec@1 45.1219	Prec@5 69.4818
Train: [24][1400/10010]	Time 0.588 (823.443)	Data 0.002 (2.804)	Loss 2.537	Prec@1 45.0900	Prec@5 69.4777
Train: [24][1600/10010]	Time 0.588 (940.802)	Data 0.002 (2.973)	Loss 2.542	Prec@1 44.9943	Prec@5 69.3849
Train: [24][1800/10010]	Time 0.587 (1057.777)	Data 0.002 (3.125)	Loss 2.545	Prec@1 44.9715	Prec@5 69.3365
Train: [24][2000/10010]	Time 0.587 (1175.053)	Data 0.002 (3.293)	Loss 2.544	Prec@1 44.9428	Prec@5 69.3524
Train: [24][2200/10010]	Time 0.587 (1292.248)	Data 0.002 (3.471)	Loss 2.547	Prec@1 44.8738	Prec@5 69.3140
Train: [24][2400/10010]	Time 0.587 (1409.134)	Data 0.002 (3.632)	Loss 2.551	Prec@1 44.7890	Prec@5 69.2576
Train: [24][2600/10010]	Time 0.587 (1526.661)	Data 0.001 (3.793)	Loss 2.550	Prec@1 44.8145	Prec@5 69.2753
Train: [24][2800/10010]	Time 0.587 (1644.220)	Data 0.001 (3.944)	Loss 2.549	Prec@1 44.8146	Prec@5 69.3120
Train: [24][3000/10010]	Time 0.587 (1761.205)	Data 0.001 (4.116)	Loss 2.550	Prec@1 44.8101	Prec@5 69.2860
Train: [24][3200/10010]	Time 0.587 (1878.288)	Data 0.001 (4.281)	Loss 2.552	Prec@1 44.7507	Prec@5 69.2413
Train: [24][3400/10010]	Time 0.587 (1995.338)	Data 0.001 (4.453)	Loss 2.554	Prec@1 44.7258	Prec@5 69.2067
Train: [24][3600/10010]	Time 0.587 (2112.816)	Data 0.001 (4.610)	Loss 2.555	Prec@1 44.7200	Prec@5 69.2069
Train: [24][3800/10010]	Time 0.587 (2230.632)	Data 0.001 (4.760)	Loss 2.556	Prec@1 44.7119	Prec@5 69.1872
Train: [24][4000/10010]	Time 0.587 (2348.157)	Data 0.001 (4.915)	Loss 2.555	Prec@1 44.7101	Prec@5 69.1893
Train: [24][4200/10010]	Time 0.587 (2465.354)	Data 0.001 (5.075)	Loss 2.556	Prec@1 44.6981	Prec@5 69.1764
Train: [24][4400/10010]	Time 0.587 (2582.647)	Data 0.001 (5.227)	Loss 2.556	Prec@1 44.6915	Prec@5 69.1752
Train: [24][4600/10010]	Time 0.587 (2700.450)	Data 0.001 (5.394)	Loss 2.556	Prec@1 44.6808	Prec@5 69.1674
Train: [24][4800/10010]	Time 0.587 (2817.551)	Data 0.001 (5.537)	Loss 2.557	Prec@1 44.6668	Prec@5 69.1425
Train: [24][5000/10010]	Time 0.587 (2934.854)	Data 0.001 (5.674)	Loss 2.558	Prec@1 44.6279	Prec@5 69.1124
Train: [24][5200/10010]	Time 0.587 (3051.986)	Data 0.001 (5.829)	Loss 2.559	Prec@1 44.6005	Prec@5 69.1080
Train: [24][5400/10010]	Time 0.587 (3169.509)	Data 0.001 (5.978)	Loss 2.560	Prec@1 44.5725	Prec@5 69.0953
Train: [24][5600/10010]	Time 0.587 (3286.745)	Data 0.001 (6.131)	Loss 2.561	Prec@1 44.5637	Prec@5 69.0859
Train: [24][5800/10010]	Time 0.587 (3403.899)	Data 0.001 (6.285)	Loss 2.561	Prec@1 44.5529	Prec@5 69.0689
Train: [24][6000/10010]	Time 0.587 (3521.346)	Data 0.001 (6.451)	Loss 2.561	Prec@1 44.5599	Prec@5 69.0605
Train: [24][6200/10010]	Time 0.587 (3638.655)	Data 0.001 (6.613)	Loss 2.561	Prec@1 44.5698	Prec@5 69.0565
Train: [24][6400/10010]	Time 0.587 (3755.510)	Data 0.001 (6.776)	Loss 2.562	Prec@1 44.5569	Prec@5 69.0478
Train: [24][6600/10010]	Time 0.587 (3872.615)	Data 0.001 (6.925)	Loss 2.562	Prec@1 44.5507	Prec@5 69.0514
Train: [24][6800/10010]	Time 0.587 (3989.837)	Data 0.001 (7.086)	Loss 2.562	Prec@1 44.5492	Prec@5 69.0553
Train: [24][7000/10010]	Time 0.587 (4107.051)	Data 0.001 (7.236)	Loss 2.562	Prec@1 44.5469	Prec@5 69.0513
Train: [24][7200/10010]	Time 0.587 (4224.289)	Data 0.001 (7.390)	Loss 2.563	Prec@1 44.5477	Prec@5 69.0384
Train: [24][7400/10010]	Time 0.587 (4341.682)	Data 0.001 (7.552)	Loss 2.563	Prec@1 44.5273	Prec@5 69.0378
Train: [24][7600/10010]	Time 0.587 (4458.861)	Data 0.001 (7.711)	Loss 2.563	Prec@1 44.5307	Prec@5 69.0336
Train: [24][7800/10010]	Time 0.587 (4576.338)	Data 0.001 (7.862)	Loss 2.563	Prec@1 44.5305	Prec@5 69.0395
Train: [24][8000/10010]	Time 0.587 (4693.552)	Data 0.001 (8.028)	Loss 2.563	Prec@1 44.5278	Prec@5 69.0362
Train: [24][8200/10010]	Time 0.587 (4810.949)	Data 0.001 (8.204)	Loss 2.564	Prec@1 44.5151	Prec@5 69.0259
Train: [24][8400/10010]	Time 0.587 (4928.171)	Data 0.001 (8.369)	Loss 2.564	Prec@1 44.5163	Prec@5 69.0237
Train: [24][8600/10010]	Time 0.587 (5045.410)	Data 0.001 (8.542)	Loss 2.565	Prec@1 44.5036	Prec@5 69.0159
Train: [24][8800/10010]	Time 0.587 (5163.013)	Data 0.001 (8.710)	Loss 2.565	Prec@1 44.5064	Prec@5 69.0118
Train: [24][9000/10010]	Time 0.587 (5280.560)	Data 0.001 (8.880)	Loss 2.565	Prec@1 44.5033	Prec@5 69.0104
Train: [24][9200/10010]	Time 0.587 (5397.617)	Data 0.001 (9.065)	Loss 2.566	Prec@1 44.4982	Prec@5 68.9999
Train: [24][9400/10010]	Time 0.587 (5514.381)	Data 0.001 (9.233)	Loss 2.566	Prec@1 44.4842	Prec@5 68.9927
Train: [24][9600/10010]	Time 0.587 (5631.516)	Data 0.001 (9.410)	Loss 2.566	Prec@1 44.4794	Prec@5 68.9867
Train: [24][9800/10010]	Time 0.587 (5748.879)	Data 0.001 (9.572)	Loss 2.567	Prec@1 44.4748	Prec@5 68.9771
Train: [24][10000/10010]	Time 0.587 (5865.842)	Data 0.001 (9.733)	Loss 2.568	Prec@1 44.4588	Prec@5 68.9616
Train: [24]	Time 5866.408	Data 9.733	Loss 2.568	Prec@1 44.4586	Prec@5 68.9611	
Val: [24]	Time 87.671	Data 1.436	Loss 2.173	Prec@1 50.8640	Prec@5 76.8140	
Best Prec@1: [50.922]	
Starting epoch number: 25 Learning rate: 0.1
Train: [25][0/10010]	Time 2.094 (2.094)	Data 1.278 (1.278)	Loss 2.407	Prec@1 46.8750	Prec@5 71.8750
Train: [25][200/10010]	Time 0.589 (118.378)	Data 0.007 (1.441)	Loss 2.531	Prec@1 45.4991	Prec@5 69.7450
Train: [25][400/10010]	Time 0.586 (234.961)	Data 0.004 (1.596)	Loss 2.532	Prec@1 45.3651	Prec@5 69.7007
Train: [25][600/10010]	Time 0.585 (351.589)	Data 0.003 (1.788)	Loss 2.537	Prec@1 45.2267	Prec@5 69.5235
Train: [25][800/10010]	Time 0.585 (468.419)	Data 0.002 (1.952)	Loss 2.539	Prec@1 45.1028	Prec@5 69.4952
Train: [25][1000/10010]	Time 0.584 (584.985)	Data 0.002 (2.121)	Loss 2.536	Prec@1 45.1486	Prec@5 69.5461
Train: [25][1200/10010]	Time 0.584 (701.866)	Data 0.002 (2.317)	Loss 2.543	Prec@1 45.0399	Prec@5 69.4395
Train: [25][1400/10010]	Time 0.584 (818.508)	Data 0.002 (2.485)	Loss 2.541	Prec@1 45.0638	Prec@5 69.4588
Train: [25][1600/10010]	Time 0.584 (935.093)	Data 0.002 (2.665)	Loss 2.543	Prec@1 44.9807	Prec@5 69.3810
Train: [25][1800/10010]	Time 0.584 (1051.574)	Data 0.002 (2.825)	Loss 2.541	Prec@1 44.9585	Prec@5 69.4462
Train: [25][2000/10010]	Time 0.584 (1168.711)	Data 0.001 (2.995)	Loss 2.542	Prec@1 44.9326	Prec@5 69.4184
Train: [25][2200/10010]	Time 0.584 (1285.250)	Data 0.001 (3.177)	Loss 2.544	Prec@1 44.9118	Prec@5 69.3882
Train: [25][2400/10010]	Time 0.584 (1402.014)	Data 0.001 (3.337)	Loss 2.545	Prec@1 44.8970	Prec@5 69.3751
Train: [25][2600/10010]	Time 0.584 (1518.835)	Data 0.001 (3.497)	Loss 2.547	Prec@1 44.8650	Prec@5 69.3552
Train: [25][2800/10010]	Time 0.584 (1635.642)	Data 0.001 (3.647)	Loss 2.548	Prec@1 44.8542	Prec@5 69.3491
Train: [25][3000/10010]	Time 0.584 (1752.634)	Data 0.001 (3.799)	Loss 2.548	Prec@1 44.8517	Prec@5 69.3152
Train: [25][3200/10010]	Time 0.584 (1869.777)	Data 0.001 (3.976)	Loss 2.548	Prec@1 44.8378	Prec@5 69.3072
Train: [25][3400/10010]	Time 0.584 (1986.408)	Data 0.001 (4.137)	Loss 2.548	Prec@1 44.8361	Prec@5 69.3273
Train: [25][3600/10010]	Time 0.584 (2103.317)	Data 0.001 (4.313)	Loss 2.550	Prec@1 44.8139	Prec@5 69.2961
Train: [25][3800/10010]	Time 0.584 (2219.761)	Data 0.001 (4.476)	Loss 2.551	Prec@1 44.7876	Prec@5 69.2873
Train: [25][4000/10010]	Time 0.584 (2336.949)	Data 0.001 (4.616)	Loss 2.552	Prec@1 44.7808	Prec@5 69.2868
Train: [25][4200/10010]	Time 0.584 (2453.627)	Data 0.001 (4.756)	Loss 2.552	Prec@1 44.7598	Prec@5 69.2776
Train: [25][4400/10010]	Time 0.584 (2570.460)	Data 0.001 (4.909)	Loss 2.552	Prec@1 44.7713	Prec@5 69.2728
Train: [25][4600/10010]	Time 0.584 (2687.393)	Data 0.001 (5.047)	Loss 2.554	Prec@1 44.7221	Prec@5 69.2475
Train: [25][4800/10010]	Time 0.584 (2804.412)	Data 0.001 (5.208)	Loss 2.555	Prec@1 44.7225	Prec@5 69.2455
Train: [25][5000/10010]	Time 0.584 (2921.197)	Data 0.001 (5.374)	Loss 2.555	Prec@1 44.7359	Prec@5 69.2349
Train: [25][5200/10010]	Time 0.584 (3038.749)	Data 0.001 (5.547)	Loss 2.556	Prec@1 44.7168	Prec@5 69.2310
Train: [25][5400/10010]	Time 0.584 (3155.593)	Data 0.001 (5.733)	Loss 2.556	Prec@1 44.7097	Prec@5 69.2305
Train: [25][5600/10010]	Time 0.584 (3272.618)	Data 0.001 (5.917)	Loss 2.557	Prec@1 44.6989	Prec@5 69.2001
Train: [25][5800/10010]	Time 0.584 (3389.491)	Data 0.001 (6.097)	Loss 2.557	Prec@1 44.7055	Prec@5 69.1939
Train: [25][6000/10010]	Time 0.584 (3506.456)	Data 0.001 (6.284)	Loss 2.558	Prec@1 44.6997	Prec@5 69.1757
Train: [25][6200/10010]	Time 0.584 (3622.986)	Data 0.001 (6.427)	Loss 2.559	Prec@1 44.6836	Prec@5 69.1591
Train: [25][6400/10010]	Time 0.584 (3739.609)	Data 0.001 (6.607)	Loss 2.559	Prec@1 44.6622	Prec@5 69.1545
Train: [25][6600/10010]	Time 0.584 (3856.368)	Data 0.001 (6.786)	Loss 2.559	Prec@1 44.6508	Prec@5 69.1449
Train: [25][6800/10010]	Time 0.584 (3973.278)	Data 0.001 (6.971)	Loss 2.559	Prec@1 44.6449	Prec@5 69.1400
Train: [25][7000/10010]	Time 0.584 (4090.564)	Data 0.001 (7.182)	Loss 2.560	Prec@1 44.6149	Prec@5 69.1110
Train: [25][7200/10010]	Time 0.584 (4207.076)	Data 0.001 (7.382)	Loss 2.560	Prec@1 44.6210	Prec@5 69.1151
Train: [25][7400/10010]	Time 0.584 (4324.010)	Data 0.001 (7.559)	Loss 2.560	Prec@1 44.6022	Prec@5 69.0959
Train: [25][7600/10010]	Time 0.584 (4441.130)	Data 0.001 (7.737)	Loss 2.561	Prec@1 44.6028	Prec@5 69.0901
Train: [25][7800/10010]	Time 0.584 (4558.290)	Data 0.001 (7.913)	Loss 2.560	Prec@1 44.6076	Prec@5 69.0988
Train: [25][8000/10010]	Time 0.584 (4675.220)	Data 0.001 (8.091)	Loss 2.560	Prec@1 44.6072	Prec@5 69.0986
Train: [25][8200/10010]	Time 0.584 (4792.050)	Data 0.001 (8.279)	Loss 2.561	Prec@1 44.6013	Prec@5 69.0813
Train: [25][8400/10010]	Time 0.584 (4908.918)	Data 0.001 (8.447)	Loss 2.561	Prec@1 44.5937	Prec@5 69.0841
Train: [25][8600/10010]	Time 0.584 (5026.057)	Data 0.001 (8.621)	Loss 2.562	Prec@1 44.5884	Prec@5 69.0816
Train: [25][8800/10010]	Time 0.584 (5143.045)	Data 0.001 (8.792)	Loss 2.562	Prec@1 44.5721	Prec@5 69.0724
Train: [25][9000/10010]	Time 0.584 (5259.655)	Data 0.001 (8.972)	Loss 2.563	Prec@1 44.5561	Prec@5 69.0625
Train: [25][9200/10010]	Time 0.584 (5376.523)	Data 0.001 (9.148)	Loss 2.564	Prec@1 44.5418	Prec@5 69.0562
Train: [25][9400/10010]	Time 0.584 (5493.279)	Data 0.001 (9.327)	Loss 2.564	Prec@1 44.5386	Prec@5 69.0501
Train: [25][9600/10010]	Time 0.584 (5610.191)	Data 0.001 (9.520)	Loss 2.564	Prec@1 44.5275	Prec@5 69.0370
Train: [25][9800/10010]	Time 0.584 (5726.772)	Data 0.001 (9.704)	Loss 2.564	Prec@1 44.5237	Prec@5 69.0323
Train: [25][10000/10010]	Time 0.584 (5843.185)	Data 0.001 (9.867)	Loss 2.564	Prec@1 44.5202	Prec@5 69.0352
Train: [25]	Time 5843.746	Data 9.867	Loss 2.564	Prec@1 44.5195	Prec@5 69.0351	
Val: [25]	Time 87.671	Data 1.549	Loss 2.259	Prec@1 49.6080	Prec@5 75.6180	
Best Prec@1: [50.922]	
Starting epoch number: 26 Learning rate: 0.1
Train: [26][0/10010]	Time 2.029 (2.029)	Data 1.335 (1.335)	Loss 2.382	Prec@1 44.5312	Prec@5 73.4375
Train: [26][200/10010]	Time 0.595 (119.500)	Data 0.007 (1.488)	Loss 2.511	Prec@1 45.4874	Prec@5 69.7334
Train: [26][400/10010]	Time 0.592 (237.364)	Data 0.004 (1.631)	Loss 2.530	Prec@1 45.0885	Prec@5 69.5274
Train: [26][600/10010]	Time 0.591 (355.047)	Data 0.003 (1.791)	Loss 2.520	Prec@1 45.1396	Prec@5 69.7197
Train: [26][800/10010]	Time 0.590 (472.752)	Data 0.002 (1.942)	Loss 2.523	Prec@1 45.0735	Prec@5 69.6844
Train: [26][1000/10010]	Time 0.590 (590.237)	Data 0.002 (2.111)	Loss 2.531	Prec@1 44.9714	Prec@5 69.5984
Train: [26][1200/10010]	Time 0.589 (707.565)	Data 0.002 (2.277)	Loss 2.532	Prec@1 44.9820	Prec@5 69.5709
Train: [26][1400/10010]	Time 0.589 (825.017)	Data 0.002 (2.436)	Loss 2.533	Prec@1 44.9450	Prec@5 69.5536
Train: [26][1600/10010]	Time 0.589 (942.961)	Data 0.002 (2.622)	Loss 2.538	Prec@1 44.8733	Prec@5 69.4761
Train: [26][1800/10010]	Time 0.589 (1060.981)	Data 0.002 (2.790)	Loss 2.542	Prec@1 44.7907	Prec@5 69.4059
Train: [26][2000/10010]	Time 0.589 (1178.390)	Data 0.001 (2.955)	Loss 2.542	Prec@1 44.7686	Prec@5 69.3903
Train: [26][2200/10010]	Time 0.589 (1295.355)	Data 0.001 (3.123)	Loss 2.541	Prec@1 44.7676	Prec@5 69.3932
Train: [26][2400/10010]	Time 0.588 (1412.801)	Data 0.001 (3.321)	Loss 2.542	Prec@1 44.7587	Prec@5 69.3939
Train: [26][2600/10010]	Time 0.588 (1530.176)	Data 0.001 (3.518)	Loss 2.543	Prec@1 44.7661	Prec@5 69.3859
Train: [26][2800/10010]	Time 0.588 (1647.874)	Data 0.001 (3.712)	Loss 2.544	Prec@1 44.7541	Prec@5 69.3801
Train: [26][3000/10010]	Time 0.588 (1765.099)	Data 0.001 (3.897)	Loss 2.546	Prec@1 44.7369	Prec@5 69.3417
Train: [26][3200/10010]	Time 0.588 (1882.494)	Data 0.001 (4.073)	Loss 2.545	Prec@1 44.7536	Prec@5 69.3358
Train: [26][3400/10010]	Time 0.588 (1999.691)	Data 0.001 (4.249)	Loss 2.546	Prec@1 44.7279	Prec@5 69.3280
Train: [26][3600/10010]	Time 0.588 (2117.478)	Data 0.001 (4.428)	Loss 2.546	Prec@1 44.7265	Prec@5 69.3286
Train: [26][3800/10010]	Time 0.588 (2234.991)	Data 0.001 (4.590)	Loss 2.547	Prec@1 44.7107	Prec@5 69.3099
Train: [26][4000/10010]	Time 0.588 (2352.344)	Data 0.001 (4.757)	Loss 2.549	Prec@1 44.6871	Prec@5 69.2741
Train: [26][4200/10010]	Time 0.588 (2469.449)	Data 0.001 (4.919)	Loss 2.551	Prec@1 44.6534	Prec@5 69.2523
Train: [26][4400/10010]	Time 0.588 (2587.390)	Data 0.001 (5.078)	Loss 2.552	Prec@1 44.6328	Prec@5 69.2362
Train: [26][4600/10010]	Time 0.588 (2704.974)	Data 0.001 (5.252)	Loss 2.553	Prec@1 44.6136	Prec@5 69.2290
Train: [26][4800/10010]	Time 0.588 (2822.029)	Data 0.001 (5.389)	Loss 2.554	Prec@1 44.6002	Prec@5 69.2182
Train: [26][5000/10010]	Time 0.588 (2938.372)	Data 0.001 (5.546)	Loss 2.554	Prec@1 44.6108	Prec@5 69.2240
Train: [26][5200/10010]	Time 0.587 (3055.288)	Data 0.001 (5.711)	Loss 2.554	Prec@1 44.5981	Prec@5 69.2182
Train: [26][5400/10010]	Time 0.587 (3171.752)	Data 0.001 (5.883)	Loss 2.556	Prec@1 44.5767	Prec@5 69.1962
Train: [26][5600/10010]	Time 0.587 (3288.237)	Data 0.001 (6.029)	Loss 2.556	Prec@1 44.5684	Prec@5 69.1821
Train: [26][5800/10010]	Time 0.587 (3404.789)	Data 0.001 (6.206)	Loss 2.557	Prec@1 44.5730	Prec@5 69.1784
Train: [26][6000/10010]	Time 0.587 (3520.998)	Data 0.001 (6.383)	Loss 2.557	Prec@1 44.5814	Prec@5 69.1838
Train: [26][6200/10010]	Time 0.587 (3637.583)	Data 0.001 (6.543)	Loss 2.557	Prec@1 44.5821	Prec@5 69.1858
Train: [26][6400/10010]	Time 0.587 (3754.400)	Data 0.001 (6.710)	Loss 2.557	Prec@1 44.5668	Prec@5 69.1772
Train: [26][6600/10010]	Time 0.586 (3870.890)	Data 0.001 (6.883)	Loss 2.558	Prec@1 44.5620	Prec@5 69.1659
Train: [26][6800/10010]	Time 0.586 (3987.744)	Data 0.001 (7.058)	Loss 2.558	Prec@1 44.5671	Prec@5 69.1601
Train: [26][7000/10010]	Time 0.586 (4104.161)	Data 0.001 (7.229)	Loss 2.558	Prec@1 44.5787	Prec@5 69.1602
Train: [26][7200/10010]	Time 0.586 (4221.136)	Data 0.001 (7.393)	Loss 2.559	Prec@1 44.5631	Prec@5 69.1462
Train: [26][7400/10010]	Time 0.586 (4337.604)	Data 0.001 (7.543)	Loss 2.559	Prec@1 44.5707	Prec@5 69.1539
Train: [26][7600/10010]	Time 0.586 (4454.330)	Data 0.001 (7.691)	Loss 2.559	Prec@1 44.5705	Prec@5 69.1479
Train: [26][7800/10010]	Time 0.586 (4570.980)	Data 0.001 (7.861)	Loss 2.559	Prec@1 44.5814	Prec@5 69.1405
Train: [26][8000/10010]	Time 0.586 (4687.225)	Data 0.001 (8.004)	Loss 2.559	Prec@1 44.5798	Prec@5 69.1365
Train: [26][8200/10010]	Time 0.586 (4803.825)	Data 0.001 (8.136)	Loss 2.560	Prec@1 44.5741	Prec@5 69.1235
Train: [26][8400/10010]	Time 0.586 (4919.936)	Data 0.001 (8.276)	Loss 2.560	Prec@1 44.5677	Prec@5 69.1189
Train: [26][8600/10010]	Time 0.586 (5036.788)	Data 0.001 (8.438)	Loss 2.560	Prec@1 44.5638	Prec@5 69.1149
Train: [26][8800/10010]	Time 0.586 (5153.228)	Data 0.001 (8.615)	Loss 2.560	Prec@1 44.5691	Prec@5 69.1099
Train: [26][9000/10010]	Time 0.585 (5269.553)	Data 0.001 (8.791)	Loss 2.560	Prec@1 44.5717	Prec@5 69.0972
Train: [26][9200/10010]	Time 0.585 (5386.264)	Data 0.001 (8.966)	Loss 2.561	Prec@1 44.5678	Prec@5 69.0921
Train: [26][9400/10010]	Time 0.585 (5503.127)	Data 0.001 (9.121)	Loss 2.561	Prec@1 44.5649	Prec@5 69.0827
Train: [26][9600/10010]	Time 0.585 (5620.148)	Data 0.001 (9.312)	Loss 2.561	Prec@1 44.5675	Prec@5 69.0784
Train: [26][9800/10010]	Time 0.585 (5737.056)	Data 0.001 (9.498)	Loss 2.562	Prec@1 44.5592	Prec@5 69.0558
Train: [26][10000/10010]	Time 0.585 (5853.523)	Data 0.001 (9.683)	Loss 2.562	Prec@1 44.5529	Prec@5 69.0490
Train: [26]	Time 5854.083	Data 9.683	Loss 2.562	Prec@1 44.5539	Prec@5 69.0501	
Val: [26]	Time 88.360	Data 1.618	Loss 2.227	Prec@1 50.2800	Prec@5 75.9740	
Best Prec@1: [50.922]	
Starting epoch number: 27 Learning rate: 0.1
Train: [27][0/10010]	Time 2.407 (2.407)	Data 1.740 (1.740)	Loss 2.250	Prec@1 50.7812	Prec@5 73.4375
Train: [27][200/10010]	Time 0.592 (118.927)	Data 0.009 (1.884)	Loss 2.502	Prec@1 45.2542	Prec@5 69.8655
Train: [27][400/10010]	Time 0.588 (235.675)	Data 0.005 (2.051)	Loss 2.515	Prec@1 45.1547	Prec@5 69.8430
Train: [27][600/10010]	Time 0.586 (352.242)	Data 0.004 (2.228)	Loss 2.532	Prec@1 45.0460	Prec@5 69.5248
Train: [27][800/10010]	Time 0.585 (468.636)	Data 0.003 (2.400)	Loss 2.533	Prec@1 45.0687	Prec@5 69.5391
Train: [27][1000/10010]	Time 0.585 (585.531)	Data 0.003 (2.584)	Loss 2.532	Prec@1 45.0503	Prec@5 69.5469
Train: [27][1200/10010]	Time 0.585 (702.465)	Data 0.002 (2.737)	Loss 2.536	Prec@1 45.0354	Prec@5 69.4688
Train: [27][1400/10010]	Time 0.585 (820.107)	Data 0.002 (2.887)	Loss 2.538	Prec@1 44.9578	Prec@5 69.4102
Train: [27][1600/10010]	Time 0.586 (938.130)	Data 0.002 (3.054)	Loss 2.536	Prec@1 45.0246	Prec@5 69.4356
Train: [27][1800/10010]	Time 0.586 (1055.769)	Data 0.002 (3.217)	Loss 2.541	Prec@1 44.8930	Prec@5 69.3590
Train: [27][2000/10010]	Time 0.586 (1173.421)	Data 0.002 (3.374)	Loss 2.544	Prec@1 44.8506	Prec@5 69.3278
Train: [27][2200/10010]	Time 0.586 (1290.834)	Data 0.002 (3.536)	Loss 2.544	Prec@1 44.8709	Prec@5 69.3154
Train: [27][2400/10010]	Time 0.587 (1408.194)	Data 0.002 (3.691)	Loss 2.546	Prec@1 44.8459	Prec@5 69.2817
Train: [27][2600/10010]	Time 0.587 (1525.618)	Data 0.001 (3.854)	Loss 2.550	Prec@1 44.7454	Prec@5 69.2102
Train: [27][2800/10010]	Time 0.586 (1642.760)	Data 0.001 (4.020)	Loss 2.551	Prec@1 44.7212	Prec@5 69.2013
Train: [27][3000/10010]	Time 0.586 (1759.911)	Data 0.001 (4.179)	Loss 2.553	Prec@1 44.6768	Prec@5 69.1655
Train: [27][3200/10010]	Time 0.586 (1877.033)	Data 0.001 (4.328)	Loss 2.553	Prec@1 44.6706	Prec@5 69.1569
Train: [27][3400/10010]	Time 0.586 (1993.946)	Data 0.001 (4.504)	Loss 2.552	Prec@1 44.7045	Prec@5 69.1727
Train: [27][3600/10010]	Time 0.586 (2111.187)	Data 0.001 (4.693)	Loss 2.551	Prec@1 44.7178	Prec@5 69.1835
Train: [27][3800/10010]	Time 0.586 (2228.722)	Data 0.001 (4.869)	Loss 2.552	Prec@1 44.6996	Prec@5 69.1802
Train: [27][4000/10010]	Time 0.586 (2345.895)	Data 0.001 (5.039)	Loss 2.553	Prec@1 44.6781	Prec@5 69.1698
Train: [27][4200/10010]	Time 0.586 (2463.449)	Data 0.001 (5.208)	Loss 2.554	Prec@1 44.6462	Prec@5 69.1565
Train: [27][4400/10010]	Time 0.586 (2580.817)	Data 0.001 (5.366)	Loss 2.554	Prec@1 44.6399	Prec@5 69.1601
Train: [27][4600/10010]	Time 0.586 (2698.122)	Data 0.001 (5.537)	Loss 2.556	Prec@1 44.6163	Prec@5 69.1278
Train: [27][4800/10010]	Time 0.586 (2815.465)	Data 0.001 (5.694)	Loss 2.557	Prec@1 44.5806	Prec@5 69.1054
Train: [27][5000/10010]	Time 0.586 (2932.870)	Data 0.001 (5.873)	Loss 2.558	Prec@1 44.5798	Prec@5 69.0902
Train: [27][5200/10010]	Time 0.586 (3050.370)	Data 0.001 (6.039)	Loss 2.558	Prec@1 44.5678	Prec@5 69.0871
Train: [27][5400/10010]	Time 0.586 (3167.461)	Data 0.001 (6.220)	Loss 2.559	Prec@1 44.5596	Prec@5 69.0857
Train: [27][5600/10010]	Time 0.586 (3284.681)	Data 0.001 (6.402)	Loss 2.559	Prec@1 44.5576	Prec@5 69.0922
Train: [27][5800/10010]	Time 0.586 (3402.272)	Data 0.001 (6.595)	Loss 2.559	Prec@1 44.5581	Prec@5 69.0940
Train: [27][6000/10010]	Time 0.586 (3519.262)	Data 0.001 (6.760)	Loss 2.559	Prec@1 44.5565	Prec@5 69.0979
Train: [27][6200/10010]	Time 0.586 (3636.651)	Data 0.001 (6.937)	Loss 2.561	Prec@1 44.5242	Prec@5 69.0693
Train: [27][6400/10010]	Time 0.587 (3754.600)	Data 0.001 (7.115)	Loss 2.561	Prec@1 44.5205	Prec@5 69.0655
Train: [27][6600/10010]	Time 0.587 (3872.195)	Data 0.001 (7.297)	Loss 2.562	Prec@1 44.5004	Prec@5 69.0646
Train: [27][6800/10010]	Time 0.587 (3990.022)	Data 0.001 (7.467)	Loss 2.562	Prec@1 44.4952	Prec@5 69.0557
Train: [27][7000/10010]	Time 0.587 (4107.655)	Data 0.001 (7.627)	Loss 2.562	Prec@1 44.4978	Prec@5 69.0627
Train: [27][7200/10010]	Time 0.587 (4225.015)	Data 0.001 (7.785)	Loss 2.562	Prec@1 44.4854	Prec@5 69.0527
Train: [27][7400/10010]	Time 0.587 (4342.273)	Data 0.001 (7.939)	Loss 2.562	Prec@1 44.4929	Prec@5 69.0575
Train: [27][7600/10010]	Time 0.587 (4459.389)	Data 0.001 (8.123)	Loss 2.562	Prec@1 44.4916	Prec@5 69.0558
Train: [27][7800/10010]	Time 0.587 (4576.359)	Data 0.001 (8.301)	Loss 2.562	Prec@1 44.4785	Prec@5 69.0532
Train: [27][8000/10010]	Time 0.587 (4693.218)	Data 0.001 (8.487)	Loss 2.562	Prec@1 44.4830	Prec@5 69.0641
Train: [27][8200/10010]	Time 0.587 (4809.903)	Data 0.001 (8.671)	Loss 2.562	Prec@1 44.4829	Prec@5 69.0631
Train: [27][8400/10010]	Time 0.586 (4926.687)	Data 0.001 (8.813)	Loss 2.563	Prec@1 44.4683	Prec@5 69.0423
Train: [27][8600/10010]	Time 0.586 (5043.504)	Data 0.001 (8.977)	Loss 2.563	Prec@1 44.4631	Prec@5 69.0409
Train: [27][8800/10010]	Time 0.586 (5160.467)	Data 0.001 (9.134)	Loss 2.564	Prec@1 44.4635	Prec@5 69.0272
Train: [27][9000/10010]	Time 0.586 (5277.103)	Data 0.001 (9.314)	Loss 2.564	Prec@1 44.4602	Prec@5 69.0246
Train: [27][9200/10010]	Time 0.586 (5393.910)	Data 0.001 (9.489)	Loss 2.564	Prec@1 44.4594	Prec@5 69.0189
Train: [27][9400/10010]	Time 0.586 (5510.558)	Data 0.001 (9.678)	Loss 2.565	Prec@1 44.4451	Prec@5 69.0145
Train: [27][9600/10010]	Time 0.586 (5627.326)	Data 0.001 (9.853)	Loss 2.566	Prec@1 44.4315	Prec@5 69.0034
Train: [27][9800/10010]	Time 0.586 (5744.099)	Data 0.001 (10.041)	Loss 2.566	Prec@1 44.4329	Prec@5 69.0012
Train: [27][10000/10010]	Time 0.586 (5860.935)	Data 0.001 (10.217)	Loss 2.566	Prec@1 44.4344	Prec@5 69.0043
Train: [27]	Time 5861.499	Data 10.218	Loss 2.566	Prec@1 44.4349	Prec@5 69.0046	
Val: [27]	Time 87.542	Data 1.664	Loss 2.172	Prec@1 50.7740	Prec@5 76.6320	
Best Prec@1: [50.922]	
Starting epoch number: 28 Learning rate: 0.1
Train: [28][0/10010]	Time 2.120 (2.120)	Data 1.469 (1.469)	Loss 2.261	Prec@1 50.7812	Prec@5 73.4375
Train: [28][200/10010]	Time 0.591 (118.726)	Data 0.008 (1.620)	Loss 2.522	Prec@1 45.0326	Prec@5 69.8266
Train: [28][400/10010]	Time 0.587 (235.348)	Data 0.004 (1.762)	Loss 2.523	Prec@1 44.9852	Prec@5 69.8157
Train: [28][600/10010]	Time 0.585 (351.882)	Data 0.003 (1.899)	Loss 2.530	Prec@1 45.0122	Prec@5 69.6664
Train: [28][800/10010]	Time 0.585 (468.355)	Data 0.003 (2.054)	Loss 2.536	Prec@1 44.9848	Prec@5 69.5449
Train: [28][1000/10010]	Time 0.585 (586.047)	Data 0.002 (2.217)	Loss 2.539	Prec@1 44.9855	Prec@5 69.4618
Train: [28][1200/10010]	Time 0.586 (703.640)	Data 0.002 (2.378)	Loss 2.540	Prec@1 45.0074	Prec@5 69.3946
Train: [28][1400/10010]	Time 0.586 (821.294)	Data 0.002 (2.549)	Loss 2.540	Prec@1 44.9963	Prec@5 69.4008
Train: [28][1600/10010]	Time 0.586 (938.638)	Data 0.002 (2.709)	Loss 2.540	Prec@1 45.0143	Prec@5 69.4146
Train: [28][1800/10010]	Time 0.586 (1056.239)	Data 0.002 (2.869)	Loss 2.539	Prec@1 45.0110	Prec@5 69.4115
Train: [28][2000/10010]	Time 0.587 (1174.208)	Data 0.002 (3.039)	Loss 2.536	Prec@1 45.0326	Prec@5 69.4883
Train: [28][2200/10010]	Time 0.587 (1291.978)	Data 0.001 (3.210)	Loss 2.538	Prec@1 44.9980	Prec@5 69.4791
Train: [28][2400/10010]	Time 0.587 (1409.717)	Data 0.001 (3.360)	Loss 2.542	Prec@1 44.9058	Prec@5 69.4216
Train: [28][2600/10010]	Time 0.587 (1526.936)	Data 0.001 (3.518)	Loss 2.542	Prec@1 44.8755	Prec@5 69.4171
Train: [28][2800/10010]	Time 0.587 (1644.513)	Data 0.001 (3.671)	Loss 2.543	Prec@1 44.8392	Prec@5 69.4021
Train: [28][3000/10010]	Time 0.587 (1762.069)	Data 0.001 (3.846)	Loss 2.542	Prec@1 44.8439	Prec@5 69.4045
Train: [28][3200/10010]	Time 0.587 (1879.835)	Data 0.001 (4.019)	Loss 2.546	Prec@1 44.7726	Prec@5 69.3323
Train: [28][3400/10010]	Time 0.587 (1997.705)	Data 0.001 (4.174)	Loss 2.548	Prec@1 44.7637	Prec@5 69.3165
Train: [28][3600/10010]	Time 0.587 (2114.821)	Data 0.001 (4.346)	Loss 2.548	Prec@1 44.7517	Prec@5 69.3165
Train: [28][3800/10010]	Time 0.587 (2231.812)	Data 0.001 (4.512)	Loss 2.549	Prec@1 44.7300	Prec@5 69.2990
Train: [28][4000/10010]	Time 0.587 (2349.028)	Data 0.001 (4.675)	Loss 2.550	Prec@1 44.7136	Prec@5 69.2616
Train: [28][4200/10010]	Time 0.587 (2466.852)	Data 0.001 (4.861)	Loss 2.552	Prec@1 44.6916	Prec@5 69.2263
Train: [28][4400/10010]	Time 0.587 (2584.987)	Data 0.001 (5.042)	Loss 2.553	Prec@1 44.6697	Prec@5 69.1943
Train: [28][4600/10010]	Time 0.588 (2703.734)	Data 0.001 (5.213)	Loss 2.554	Prec@1 44.6527	Prec@5 69.1888
Train: [28][4800/10010]	Time 0.588 (2821.785)	Data 0.001 (5.372)	Loss 2.555	Prec@1 44.6509	Prec@5 69.1664
Train: [28][5000/10010]	Time 0.588 (2939.383)	Data 0.001 (5.545)	Loss 2.556	Prec@1 44.6353	Prec@5 69.1552
Train: [28][5200/10010]	Time 0.588 (3057.134)	Data 0.001 (5.688)	Loss 2.557	Prec@1 44.6130	Prec@5 69.1318
Train: [28][5400/10010]	Time 0.588 (3174.677)	Data 0.001 (5.843)	Loss 2.558	Prec@1 44.5995	Prec@5 69.1077
Train: [28][5600/10010]	Time 0.588 (3292.098)	Data 0.001 (6.005)	Loss 2.558	Prec@1 44.5936	Prec@5 69.0997
Train: [28][5800/10010]	Time 0.588 (3409.210)	Data 0.001 (6.160)	Loss 2.558	Prec@1 44.5832	Prec@5 69.0950
Train: [28][6000/10010]	Time 0.588 (3526.475)	Data 0.001 (6.317)	Loss 2.560	Prec@1 44.5583	Prec@5 69.0693
Train: [28][6200/10010]	Time 0.588 (3644.281)	Data 0.001 (6.467)	Loss 2.560	Prec@1 44.5480	Prec@5 69.0637
Train: [28][6400/10010]	Time 0.588 (3762.181)	Data 0.001 (6.640)	Loss 2.560	Prec@1 44.5416	Prec@5 69.0642
Train: [28][6600/10010]	Time 0.588 (3879.956)	Data 0.001 (6.814)	Loss 2.560	Prec@1 44.5342	Prec@5 69.0490
Train: [28][6800/10010]	Time 0.588 (3997.540)	Data 0.001 (6.967)	Loss 2.560	Prec@1 44.5304	Prec@5 69.0434
Train: [28][7000/10010]	Time 0.588 (4115.117)	Data 0.001 (7.125)	Loss 2.561	Prec@1 44.5154	Prec@5 69.0387
Train: [28][7200/10010]	Time 0.588 (4233.224)	Data 0.001 (7.286)	Loss 2.561	Prec@1 44.5115	Prec@5 69.0351
Train: [28][7400/10010]	Time 0.588 (4350.751)	Data 0.001 (7.456)	Loss 2.561	Prec@1 44.5289	Prec@5 69.0397
Train: [28][7600/10010]	Time 0.588 (4468.378)	Data 0.001 (7.615)	Loss 2.561	Prec@1 44.5348	Prec@5 69.0384
Train: [28][7800/10010]	Time 0.588 (4585.739)	Data 0.001 (7.784)	Loss 2.562	Prec@1 44.5239	Prec@5 69.0215
Train: [28][8000/10010]	Time 0.588 (4703.216)	Data 0.001 (7.942)	Loss 2.562	Prec@1 44.5309	Prec@5 69.0335
Train: [28][8200/10010]	Time 0.588 (4821.094)	Data 0.001 (8.096)	Loss 2.562	Prec@1 44.5279	Prec@5 69.0322
Train: [28][8400/10010]	Time 0.588 (4938.345)	Data 0.001 (8.256)	Loss 2.562	Prec@1 44.5326	Prec@5 69.0367
Train: [28][8600/10010]	Time 0.588 (5055.855)	Data 0.001 (8.414)	Loss 2.563	Prec@1 44.5262	Prec@5 69.0368
Train: [28][8800/10010]	Time 0.588 (5173.457)	Data 0.001 (8.574)	Loss 2.563	Prec@1 44.5250	Prec@5 69.0381
Train: [28][9000/10010]	Time 0.588 (5291.318)	Data 0.001 (8.738)	Loss 2.562	Prec@1 44.5481	Prec@5 69.0514
Train: [28][9200/10010]	Time 0.588 (5408.535)	Data 0.001 (8.906)	Loss 2.563	Prec@1 44.5357	Prec@5 69.0466
Train: [28][9400/10010]	Time 0.588 (5526.345)	Data 0.001 (9.071)	Loss 2.563	Prec@1 44.5205	Prec@5 69.0417
Train: [28][9600/10010]	Time 0.588 (5643.997)	Data 0.001 (9.228)	Loss 2.564	Prec@1 44.5195	Prec@5 69.0395
Train: [28][9800/10010]	Time 0.588 (5761.287)	Data 0.001 (9.391)	Loss 2.564	Prec@1 44.5191	Prec@5 69.0359
Train: [28][10000/10010]	Time 0.588 (5879.130)	Data 0.001 (9.538)	Loss 2.564	Prec@1 44.5105	Prec@5 69.0324
Train: [28]	Time 5879.698	Data 9.538	Loss 2.564	Prec@1 44.5106	Prec@5 69.0327	
Val: [28]	Time 87.621	Data 1.611	Loss 2.250	Prec@1 50.1040	Prec@5 75.7180	
Best Prec@1: [50.922]	
Starting epoch number: 29 Learning rate: 0.1
Train: [29][0/10010]	Time 2.171 (2.171)	Data 1.513 (1.513)	Loss 2.873	Prec@1 46.8750	Prec@5 66.4062
Train: [29][200/10010]	Time 0.595 (119.651)	Data 0.008 (1.670)	Loss 2.523	Prec@1 45.1803	Prec@5 69.4302
Train: [29][400/10010]	Time 0.591 (237.101)	Data 0.005 (1.816)	Loss 2.504	Prec@1 45.3554	Prec@5 69.7787
Train: [29][600/10010]	Time 0.591 (354.935)	Data 0.003 (1.977)	Loss 2.516	Prec@1 45.2202	Prec@5 69.5897
Train: [29][800/10010]	Time 0.590 (472.916)	Data 0.003 (2.132)	Loss 2.520	Prec@1 45.1399	Prec@5 69.6307
Train: [29][1000/10010]	Time 0.590 (590.285)	Data 0.002 (2.297)	Loss 2.524	Prec@1 45.0386	Prec@5 69.5375
Train: [29][1200/10010]	Time 0.589 (707.725)	Data 0.002 (2.479)	Loss 2.527	Prec@1 45.0022	Prec@5 69.4890
Train: [29][1400/10010]	Time 0.589 (824.913)	Data 0.002 (2.624)	Loss 2.532	Prec@1 44.9456	Prec@5 69.4420
Train: [29][1600/10010]	Time 0.589 (942.534)	Data 0.002 (2.789)	Loss 2.536	Prec@1 44.9260	Prec@5 69.3912
Train: [29][1800/10010]	Time 0.588 (1059.653)	Data 0.002 (2.975)	Loss 2.538	Prec@1 44.8523	Prec@5 69.3551
Train: [29][2000/10010]	Time 0.588 (1176.741)	Data 0.002 (3.151)	Loss 2.543	Prec@1 44.8143	Prec@5 69.3068
Train: [29][2200/10010]	Time 0.588 (1294.043)	Data 0.002 (3.322)	Loss 2.543	Prec@1 44.7872	Prec@5 69.2998
Train: [29][2400/10010]	Time 0.588 (1410.943)	Data 0.001 (3.480)	Loss 2.546	Prec@1 44.7652	Prec@5 69.2690
Train: [29][2600/10010]	Time 0.588 (1528.335)	Data 0.001 (3.645)	Loss 2.547	Prec@1 44.7598	Prec@5 69.2615
Train: [29][2800/10010]	Time 0.587 (1645.538)	Data 0.001 (3.790)	Loss 2.544	Prec@1 44.8116	Prec@5 69.3229
Train: [29][3000/10010]	Time 0.587 (1762.919)	Data 0.001 (3.942)	Loss 2.546	Prec@1 44.8054	Prec@5 69.3037
Train: [29][3200/10010]	Time 0.588 (1880.655)	Data 0.001 (4.106)	Loss 2.547	Prec@1 44.7592	Prec@5 69.2767
Train: [29][3400/10010]	Time 0.588 (1998.177)	Data 0.001 (4.260)	Loss 2.547	Prec@1 44.7697	Prec@5 69.2901
Train: [29][3600/10010]	Time 0.588 (2115.771)	Data 0.001 (4.430)	Loss 2.549	Prec@1 44.7276	Prec@5 69.2572
Train: [29][3800/10010]	Time 0.588 (2233.188)	Data 0.001 (4.612)	Loss 2.550	Prec@1 44.7090	Prec@5 69.2386
Train: [29][4000/10010]	Time 0.588 (2351.006)	Data 0.001 (4.779)	Loss 2.550	Prec@1 44.7025	Prec@5 69.2415
Train: [29][4200/10010]	Time 0.588 (2468.922)	Data 0.001 (4.950)	Loss 2.551	Prec@1 44.6865	Prec@5 69.2220
Train: [29][4400/10010]	Time 0.588 (2586.101)	Data 0.001 (5.127)	Loss 2.553	Prec@1 44.6505	Prec@5 69.1899
Train: [29][4600/10010]	Time 0.588 (2703.575)	Data 0.001 (5.293)	Loss 2.553	Prec@1 44.6540	Prec@5 69.1837
Train: [29][4800/10010]	Time 0.588 (2821.123)	Data 0.001 (5.447)	Loss 2.554	Prec@1 44.6325	Prec@5 69.1700
Train: [29][5000/10010]	Time 0.588 (2938.553)	Data 0.001 (5.615)	Loss 2.554	Prec@1 44.6136	Prec@5 69.1580
Train: [29][5200/10010]	Time 0.588 (3055.825)	Data 0.001 (5.769)	Loss 2.556	Prec@1 44.5963	Prec@5 69.1371
Train: [29][5400/10010]	Time 0.588 (3173.508)	Data 0.001 (5.934)	Loss 2.556	Prec@1 44.5869	Prec@5 69.1372
Train: [29][5600/10010]	Time 0.588 (3290.875)	Data 0.001 (6.106)	Loss 2.556	Prec@1 44.5829	Prec@5 69.1394
Train: [29][5800/10010]	Time 0.587 (3408.051)	Data 0.001 (6.275)	Loss 2.557	Prec@1 44.5855	Prec@5 69.1377
Train: [29][6000/10010]	Time 0.588 (3525.662)	Data 0.001 (6.424)	Loss 2.557	Prec@1 44.5799	Prec@5 69.1203
Train: [29][6200/10010]	Time 0.587 (3642.973)	Data 0.001 (6.587)	Loss 2.558	Prec@1 44.5728	Prec@5 69.1002
Train: [29][6400/10010]	Time 0.588 (3760.729)	Data 0.001 (6.761)	Loss 2.558	Prec@1 44.5674	Prec@5 69.1022
Train: [29][6600/10010]	Time 0.588 (3878.259)	Data 0.001 (6.937)	Loss 2.558	Prec@1 44.5662	Prec@5 69.0900
Train: [29][6800/10010]	Time 0.588 (3996.149)	Data 0.001 (7.120)	Loss 2.559	Prec@1 44.5582	Prec@5 69.0838
Train: [29][7000/10010]	Time 0.588 (4113.942)	Data 0.001 (7.282)	Loss 2.560	Prec@1 44.5427	Prec@5 69.0700
Train: [29][7200/10010]	Time 0.588 (4231.248)	Data 0.001 (7.467)	Loss 2.560	Prec@1 44.5400	Prec@5 69.0674
Train: [29][7400/10010]	Time 0.588 (4348.590)	Data 0.001 (7.632)	Loss 2.561	Prec@1 44.5276	Prec@5 69.0606
Train: [29][7600/10010]	Time 0.588 (4466.257)	Data 0.001 (7.779)	Loss 2.561	Prec@1 44.5377	Prec@5 69.0627
Train: [29][7800/10010]	Time 0.588 (4584.064)	Data 0.001 (7.944)	Loss 2.562	Prec@1 44.5187	Prec@5 69.0510
Train: [29][8000/10010]	Time 0.588 (4701.866)	Data 0.001 (8.121)	Loss 2.561	Prec@1 44.5179	Prec@5 69.0528
Train: [29][8200/10010]	Time 0.588 (4819.447)	Data 0.001 (8.288)	Loss 2.562	Prec@1 44.5101	Prec@5 69.0499
Train: [29][8400/10010]	Time 0.588 (4936.764)	Data 0.001 (8.452)	Loss 2.562	Prec@1 44.5165	Prec@5 69.0497
Train: [29][8600/10010]	Time 0.588 (5053.785)	Data 0.001 (8.614)	Loss 2.562	Prec@1 44.5269	Prec@5 69.0550
Train: [29][8800/10010]	Time 0.588 (5171.675)	Data 0.001 (8.818)	Loss 2.562	Prec@1 44.5220	Prec@5 69.0481
Train: [29][9000/10010]	Time 0.588 (5290.359)	Data 0.001 (9.001)	Loss 2.563	Prec@1 44.5089	Prec@5 69.0469
Train: [29][9200/10010]	Time 0.588 (5408.120)	Data 0.001 (9.167)	Loss 2.563	Prec@1 44.5116	Prec@5 69.0422
Train: [29][9400/10010]	Time 0.588 (5525.356)	Data 0.001 (9.335)	Loss 2.563	Prec@1 44.5146	Prec@5 69.0367
Train: [29][9600/10010]	Time 0.588 (5642.617)	Data 0.001 (9.506)	Loss 2.564	Prec@1 44.5096	Prec@5 69.0324
Train: [29][9800/10010]	Time 0.588 (5759.509)	Data 0.001 (9.667)	Loss 2.564	Prec@1 44.5082	Prec@5 69.0350
Train: [29][10000/10010]	Time 0.588 (5876.746)	Data 0.001 (9.833)	Loss 2.564	Prec@1 44.5068	Prec@5 69.0336
Train: [29]	Time 5877.384	Data 9.833	Loss 2.564	Prec@1 44.5074	Prec@5 69.0338	
Val: [29]	Time 87.478	Data 1.477	Loss 2.227	Prec@1 49.9460	Prec@5 75.9460	
Best Prec@1: [50.922]	
Starting epoch number: 30 Learning rate: 0.010000000000000002
Train: [30][0/10010]	Time 2.065 (2.065)	Data 1.421 (1.421)	Loss 2.338	Prec@1 43.7500	Prec@5 76.5625
Train: [30][200/10010]	Time 0.592 (118.941)	Data 0.008 (1.584)	Loss 2.314	Prec@1 49.1566	Prec@5 73.2043
Train: [30][400/10010]	Time 0.587 (235.515)	Data 0.004 (1.746)	Loss 2.233	Prec@1 50.8592	Prec@5 74.4331
Train: [30][600/10010]	Time 0.585 (351.784)	Data 0.003 (1.907)	Loss 2.205	Prec@1 51.3103	Prec@5 74.7322
Train: [30][800/10010]	Time 0.584 (467.856)	Data 0.003 (2.067)	Loss 2.178	Prec@1 51.8551	Prec@5 75.0663
Train: [30][1000/10010]	Time 0.584 (584.287)	Data 0.002 (2.228)	Loss 2.162	Prec@1 52.2719	Prec@5 75.2427
Train: [30][1200/10010]	Time 0.584 (701.165)	Data 0.002 (2.402)	Loss 2.142	Prec@1 52.6339	Prec@5 75.5666
Train: [30][1400/10010]	Time 0.584 (817.523)	Data 0.002 (2.580)	Loss 2.128	Prec@1 52.9125	Prec@5 75.7695
Train: [30][1600/10010]	Time 0.583 (933.922)	Data 0.002 (2.738)	Loss 2.116	Prec@1 53.1421	Prec@5 75.9213
Train: [30][1800/10010]	Time 0.583 (1050.058)	Data 0.002 (2.927)	Loss 2.104	Prec@1 53.3870	Prec@5 76.1304
Train: [30][2000/10010]	Time 0.583 (1166.644)	Data 0.002 (3.088)	Loss 2.092	Prec@1 53.6423	Prec@5 76.3185
Train: [30][2200/10010]	Time 0.583 (1282.780)	Data 0.001 (3.248)	Loss 2.081	Prec@1 53.8541	Prec@5 76.4979
Train: [30][2400/10010]	Time 0.583 (1399.152)	Data 0.001 (3.414)	Loss 2.071	Prec@1 54.0400	Prec@5 76.6377
Train: [30][2600/10010]	Time 0.583 (1515.501)	Data 0.001 (3.583)	Loss 2.062	Prec@1 54.2090	Prec@5 76.7661
Train: [30][2800/10010]	Time 0.582 (1631.572)	Data 0.001 (3.766)	Loss 2.054	Prec@1 54.3425	Prec@5 76.8827
Train: [30][3000/10010]	Time 0.582 (1747.629)	Data 0.001 (3.924)	Loss 2.048	Prec@1 54.4725	Prec@5 76.9822
Train: [30][3200/10010]	Time 0.582 (1863.453)	Data 0.001 (4.082)	Loss 2.041	Prec@1 54.6167	Prec@5 77.0865
Train: [30][3400/10010]	Time 0.582 (1979.188)	Data 0.001 (4.242)	Loss 2.037	Prec@1 54.6877	Prec@5 77.1496
Train: [30][3600/10010]	Time 0.582 (2095.718)	Data 0.001 (4.423)	Loss 2.030	Prec@1 54.8040	Prec@5 77.2587
Train: [30][3800/10010]	Time 0.582 (2211.844)	Data 0.001 (4.587)	Loss 2.024	Prec@1 54.9253	Prec@5 77.3497
Train: [30][4000/10010]	Time 0.582 (2327.994)	Data 0.001 (4.760)	Loss 2.019	Prec@1 55.0372	Prec@5 77.4367
Train: [30][4200/10010]	Time 0.582 (2444.138)	Data 0.001 (4.916)	Loss 2.013	Prec@1 55.1450	Prec@5 77.5046
Train: [30][4400/10010]	Time 0.582 (2560.166)	Data 0.001 (5.083)	Loss 2.009	Prec@1 55.2319	Prec@5 77.5841
Train: [30][4600/10010]	Time 0.582 (2676.450)	Data 0.001 (5.261)	Loss 2.004	Prec@1 55.3091	Prec@5 77.6603
Train: [30][4800/10010]	Time 0.582 (2792.829)	Data 0.001 (5.428)	Loss 1.999	Prec@1 55.3981	Prec@5 77.7338
Train: [30][5000/10010]	Time 0.582 (2909.352)	Data 0.001 (5.593)	Loss 1.995	Prec@1 55.4689	Prec@5 77.7779
Train: [30][5200/10010]	Time 0.582 (3025.882)	Data 0.001 (5.761)	Loss 1.991	Prec@1 55.5279	Prec@5 77.8334
Train: [30][5400/10010]	Time 0.582 (3141.846)	Data 0.001 (5.912)	Loss 1.988	Prec@1 55.5940	Prec@5 77.8863
Train: [30][5600/10010]	Time 0.582 (3258.359)	Data 0.001 (6.069)	Loss 1.984	Prec@1 55.6741	Prec@5 77.9366
Train: [30][5800/10010]	Time 0.582 (3375.050)	Data 0.001 (6.224)	Loss 1.981	Prec@1 55.7244	Prec@5 77.9697
Train: [30][6000/10010]	Time 0.582 (3492.722)	Data 0.001 (6.376)	Loss 1.978	Prec@1 55.7973	Prec@5 78.0227
Train: [30][6200/10010]	Time 0.582 (3610.179)	Data 0.001 (6.557)	Loss 1.974	Prec@1 55.8659	Prec@5 78.0730
Train: [30][6400/10010]	Time 0.582 (3727.367)	Data 0.001 (6.711)	Loss 1.970	Prec@1 55.9277	Prec@5 78.1262
Train: [30][6600/10010]	Time 0.582 (3844.523)	Data 0.001 (6.894)	Loss 1.967	Prec@1 55.9919	Prec@5 78.1753
Train: [30][6800/10010]	Time 0.582 (3961.514)	Data 0.001 (7.078)	Loss 1.965	Prec@1 56.0261	Prec@5 78.2081
Train: [30][7000/10010]	Time 0.583 (4078.673)	Data 0.001 (7.250)	Loss 1.963	Prec@1 56.0731	Prec@5 78.2556
Train: [30][7200/10010]	Time 0.583 (4195.681)	Data 0.001 (7.410)	Loss 1.960	Prec@1 56.1235	Prec@5 78.3018
Train: [30][7400/10010]	Time 0.583 (4312.890)	Data 0.001 (7.597)	Loss 1.958	Prec@1 56.1499	Prec@5 78.3340
Train: [30][7600/10010]	Time 0.583 (4430.199)	Data 0.001 (7.763)	Loss 1.955	Prec@1 56.2062	Prec@5 78.3745
Train: [30][7800/10010]	Time 0.583 (4547.444)	Data 0.001 (7.917)	Loss 1.953	Prec@1 56.2469	Prec@5 78.4018
Train: [30][8000/10010]	Time 0.583 (4664.680)	Data 0.001 (8.054)	Loss 1.951	Prec@1 56.2885	Prec@5 78.4392
Train: [30][8200/10010]	Time 0.583 (4781.927)	Data 0.001 (8.213)	Loss 1.949	Prec@1 56.3285	Prec@5 78.4734
Train: [30][8400/10010]	Time 0.583 (4899.386)	Data 0.001 (8.379)	Loss 1.946	Prec@1 56.3688	Prec@5 78.5146
Train: [30][8600/10010]	Time 0.583 (5016.364)	Data 0.001 (8.546)	Loss 1.944	Prec@1 56.4053	Prec@5 78.5431
Train: [30][8800/10010]	Time 0.583 (5133.237)	Data 0.001 (8.719)	Loss 1.942	Prec@1 56.4514	Prec@5 78.5687
Train: [30][9000/10010]	Time 0.583 (5250.355)	Data 0.001 (8.883)	Loss 1.940	Prec@1 56.4988	Prec@5 78.6091
Train: [30][9200/10010]	Time 0.583 (5367.849)	Data 0.001 (9.040)	Loss 1.937	Prec@1 56.5348	Prec@5 78.6388
Train: [30][9400/10010]	Time 0.583 (5485.448)	Data 0.001 (9.237)	Loss 1.936	Prec@1 56.5764	Prec@5 78.6633
Train: [30][9600/10010]	Time 0.584 (5602.618)	Data 0.001 (9.423)	Loss 1.934	Prec@1 56.6045	Prec@5 78.6932
Train: [30][9800/10010]	Time 0.584 (5720.213)	Data 0.001 (9.634)	Loss 1.932	Prec@1 56.6511	Prec@5 78.7148
Train: [30][10000/10010]	Time 0.584 (5837.200)	Data 0.001 (9.818)	Loss 1.931	Prec@1 56.6711	Prec@5 78.7380
Train: [30]	Time 5837.759	Data 9.819	Loss 1.931	Prec@1 56.6708	Prec@5 78.7382	
Val: [30]	Time 87.752	Data 1.486	Loss 1.479	Prec@1 65.1940	Prec@5 86.3960	
Best Prec@1: [65.194]	
Starting epoch number: 31 Learning rate: 0.010000000000000002
Train: [31][0/10010]	Time 2.132 (2.132)	Data 1.371 (1.371)	Loss 1.803	Prec@1 60.1562	Prec@5 79.6875
Train: [31][200/10010]	Time 0.594 (119.482)	Data 0.008 (1.527)	Loss 1.820	Prec@1 58.2984	Prec@5 80.4338
Train: [31][400/10010]	Time 0.590 (236.633)	Data 0.004 (1.684)	Loss 1.797	Prec@1 58.8587	Prec@5 80.7785
Train: [31][600/10010]	Time 0.589 (354.096)	Data 0.003 (1.840)	Loss 1.799	Prec@1 58.8641	Prec@5 80.6650
Train: [31][800/10010]	Time 0.589 (471.984)	Data 0.002 (1.982)	Loss 1.797	Prec@1 59.0053	Prec@5 80.6453
Train: [31][1000/10010]	Time 0.589 (589.825)	Data 0.002 (2.135)	Loss 1.794	Prec@1 59.1362	Prec@5 80.6576
Train: [31][1200/10010]	Time 0.589 (706.912)	Data 0.002 (2.291)	Loss 1.795	Prec@1 59.1109	Prec@5 80.6190
Train: [31][1400/10010]	Time 0.588 (823.744)	Data 0.002 (2.436)	Loss 1.795	Prec@1 59.1280	Prec@5 80.6360
Train: [31][1600/10010]	Time 0.588 (940.866)	Data 0.002 (2.583)	Loss 1.795	Prec@1 59.1632	Prec@5 80.6537
Train: [31][1800/10010]	Time 0.588 (1058.400)	Data 0.002 (2.734)	Loss 1.794	Prec@1 59.1759	Prec@5 80.6514
Train: [31][2000/10010]	Time 0.587 (1175.406)	Data 0.001 (2.873)	Loss 1.797	Prec@1 59.1685	Prec@5 80.6077
Train: [31][2200/10010]	Time 0.587 (1292.900)	Data 0.001 (3.015)	Loss 1.798	Prec@1 59.1627	Prec@5 80.5933
Train: [31][2400/10010]	Time 0.587 (1409.991)	Data 0.001 (3.164)	Loss 1.797	Prec@1 59.1873	Prec@5 80.6103
Train: [31][2600/10010]	Time 0.587 (1526.972)	Data 0.001 (3.314)	Loss 1.796	Prec@1 59.1918	Prec@5 80.6391
Train: [31][2800/10010]	Time 0.587 (1643.907)	Data 0.001 (3.463)	Loss 1.795	Prec@1 59.2425	Prec@5 80.6406
Train: [31][3000/10010]	Time 0.587 (1761.280)	Data 0.001 (3.617)	Loss 1.793	Prec@1 59.2844	Prec@5 80.6773
Train: [31][3200/10010]	Time 0.587 (1878.464)	Data 0.001 (3.759)	Loss 1.793	Prec@1 59.2918	Prec@5 80.6826
Train: [31][3400/10010]	Time 0.587 (1996.266)	Data 0.001 (3.924)	Loss 1.794	Prec@1 59.2879	Prec@5 80.6861
Train: [31][3600/10010]	Time 0.587 (2113.514)	Data 0.001 (4.088)	Loss 1.794	Prec@1 59.2854	Prec@5 80.6792
Train: [31][3800/10010]	Time 0.587 (2230.821)	Data 0.001 (4.244)	Loss 1.794	Prec@1 59.2930	Prec@5 80.6706
Train: [31][4000/10010]	Time 0.587 (2348.260)	Data 0.001 (4.417)	Loss 1.795	Prec@1 59.2682	Prec@5 80.6515
Train: [31][4200/10010]	Time 0.587 (2465.656)	Data 0.001 (4.595)	Loss 1.794	Prec@1 59.2965	Prec@5 80.6635
Train: [31][4400/10010]	Time 0.587 (2582.922)	Data 0.001 (4.768)	Loss 1.794	Prec@1 59.3178	Prec@5 80.6732
Train: [31][4600/10010]	Time 0.587 (2700.119)	Data 0.001 (4.946)	Loss 1.793	Prec@1 59.3168	Prec@5 80.6951
Train: [31][4800/10010]	Time 0.587 (2817.350)	Data 0.001 (5.117)	Loss 1.793	Prec@1 59.3182	Prec@5 80.6930
Train: [31][5000/10010]	Time 0.587 (2934.259)	Data 0.001 (5.293)	Loss 1.794	Prec@1 59.3133	Prec@5 80.6792
Train: [31][5200/10010]	Time 0.587 (3051.854)	Data 0.001 (5.474)	Loss 1.792	Prec@1 59.3314	Prec@5 80.7016
Train: [31][5400/10010]	Time 0.587 (3169.106)	Data 0.001 (5.639)	Loss 1.792	Prec@1 59.3359	Prec@5 80.7086
Train: [31][5600/10010]	Time 0.587 (3286.820)	Data 0.001 (5.801)	Loss 1.792	Prec@1 59.3521	Prec@5 80.7039
Train: [31][5800/10010]	Time 0.587 (3404.250)	Data 0.001 (5.987)	Loss 1.792	Prec@1 59.3450	Prec@5 80.7011
Train: [31][6000/10010]	Time 0.587 (3521.746)	Data 0.001 (6.171)	Loss 1.792	Prec@1 59.3525	Prec@5 80.7110
Train: [31][6200/10010]	Time 0.587 (3639.285)	Data 0.001 (6.360)	Loss 1.791	Prec@1 59.3567	Prec@5 80.7180
Train: [31][6400/10010]	Time 0.587 (3756.681)	Data 0.001 (6.534)	Loss 1.792	Prec@1 59.3521	Prec@5 80.7083
Train: [31][6600/10010]	Time 0.587 (3873.839)	Data 0.001 (6.712)	Loss 1.792	Prec@1 59.3472	Prec@5 80.7062
Train: [31][6800/10010]	Time 0.587 (3991.263)	Data 0.001 (6.894)	Loss 1.791	Prec@1 59.3565	Prec@5 80.7255
Train: [31][7000/10010]	Time 0.587 (4108.667)	Data 0.001 (7.075)	Loss 1.790	Prec@1 59.3683	Prec@5 80.7368
Train: [31][7200/10010]	Time 0.587 (4225.827)	Data 0.001 (7.247)	Loss 1.789	Prec@1 59.3888	Prec@5 80.7408
Train: [31][7400/10010]	Time 0.587 (4343.158)	Data 0.001 (7.423)	Loss 1.789	Prec@1 59.3900	Prec@5 80.7399
Train: [31][7600/10010]	Time 0.587 (4460.877)	Data 0.001 (7.605)	Loss 1.789	Prec@1 59.4005	Prec@5 80.7380
Train: [31][7800/10010]	Time 0.587 (4578.085)	Data 0.001 (7.771)	Loss 1.789	Prec@1 59.4087	Prec@5 80.7500
Train: [31][8000/10010]	Time 0.587 (4695.421)	Data 0.001 (7.954)	Loss 1.788	Prec@1 59.4131	Prec@5 80.7603
Train: [31][8200/10010]	Time 0.587 (4813.376)	Data 0.001 (8.152)	Loss 1.788	Prec@1 59.4248	Prec@5 80.7704
Train: [31][8400/10010]	Time 0.587 (4930.982)	Data 0.001 (8.324)	Loss 1.787	Prec@1 59.4363	Prec@5 80.7754
Train: [31][8600/10010]	Time 0.587 (5047.993)	Data 0.001 (8.498)	Loss 1.787	Prec@1 59.4408	Prec@5 80.7800
Train: [31][8800/10010]	Time 0.587 (5165.053)	Data 0.001 (8.655)	Loss 1.786	Prec@1 59.4674	Prec@5 80.7916
Train: [31][9000/10010]	Time 0.587 (5282.895)	Data 0.001 (8.837)	Loss 1.786	Prec@1 59.4807	Prec@5 80.7982
Train: [31][9200/10010]	Time 0.587 (5400.496)	Data 0.001 (9.019)	Loss 1.785	Prec@1 59.4891	Prec@5 80.8063
Train: [31][9400/10010]	Time 0.587 (5517.799)	Data 0.001 (9.212)	Loss 1.784	Prec@1 59.4975	Prec@5 80.8140
Train: [31][9600/10010]	Time 0.587 (5634.779)	Data 0.001 (9.381)	Loss 1.784	Prec@1 59.5065	Prec@5 80.8178
Train: [31][9800/10010]	Time 0.587 (5752.305)	Data 0.001 (9.557)	Loss 1.784	Prec@1 59.5134	Prec@5 80.8225
Train: [31][10000/10010]	Time 0.587 (5869.481)	Data 0.001 (9.730)	Loss 1.783	Prec@1 59.5372	Prec@5 80.8264
Train: [31]	Time 5870.026	Data 9.731	Loss 1.783	Prec@1 59.5375	Prec@5 80.8264	
Val: [31]	Time 87.613	Data 1.577	Loss 1.408	Prec@1 66.3960	Prec@5 87.2500	
Best Prec@1: [66.396]	
Starting epoch number: 32 Learning rate: 0.010000000000000002
Train: [32][0/10010]	Time 2.462 (2.462)	Data 1.670 (1.670)	Loss 1.600	Prec@1 60.9375	Prec@5 85.1562
Train: [32][200/10010]	Time 0.597 (119.956)	Data 0.009 (1.821)	Loss 1.733	Prec@1 60.5527	Prec@5 81.6270
Train: [32][400/10010]	Time 0.592 (237.520)	Data 0.005 (1.972)	Loss 1.736	Prec@1 60.4193	Prec@5 81.5851
Train: [32][600/10010]	Time 0.590 (354.781)	Data 0.004 (2.118)	Loss 1.739	Prec@1 60.4565	Prec@5 81.6114
Train: [32][800/10010]	Time 0.589 (471.907)	Data 0.003 (2.264)	Loss 1.741	Prec@1 60.3796	Prec@5 81.5670
Train: [32][1000/10010]	Time 0.588 (588.707)	Data 0.002 (2.414)	Loss 1.740	Prec@1 60.4325	Prec@5 81.5466
Train: [32][1200/10010]	Time 0.587 (704.538)	Data 0.002 (2.570)	Loss 1.739	Prec@1 60.4568	Prec@5 81.5570
Train: [32][1400/10010]	Time 0.586 (820.406)	Data 0.002 (2.713)	Loss 1.740	Prec@1 60.4384	Prec@5 81.5099
Train: [32][1600/10010]	Time 0.585 (936.760)	Data 0.002 (2.856)	Loss 1.738	Prec@1 60.4803	Prec@5 81.5369
Train: [32][1800/10010]	Time 0.585 (1053.052)	Data 0.002 (3.008)	Loss 1.736	Prec@1 60.5046	Prec@5 81.5649
Train: [32][2000/10010]	Time 0.584 (1169.073)	Data 0.002 (3.185)	Loss 1.737	Prec@1 60.4838	Prec@5 81.5514
Train: [32][2200/10010]	Time 0.584 (1285.705)	Data 0.002 (3.365)	Loss 1.736	Prec@1 60.4856	Prec@5 81.5652
Train: [32][2400/10010]	Time 0.584 (1401.865)	Data 0.001 (3.533)	Loss 1.737	Prec@1 60.4569	Prec@5 81.5503
Train: [32][2600/10010]	Time 0.584 (1517.831)	Data 0.001 (3.703)	Loss 1.735	Prec@1 60.5032	Prec@5 81.5720
Train: [32][2800/10010]	Time 0.583 (1634.038)	Data 0.001 (3.865)	Loss 1.735	Prec@1 60.4912	Prec@5 81.5655
Train: [32][3000/10010]	Time 0.583 (1750.483)	Data 0.001 (4.019)	Loss 1.735	Prec@1 60.5048	Prec@5 81.5520
Train: [32][3200/10010]	Time 0.583 (1866.603)	Data 0.001 (4.166)	Loss 1.736	Prec@1 60.4852	Prec@5 81.5475
Train: [32][3400/10010]	Time 0.583 (1982.956)	Data 0.001 (4.319)	Loss 1.736	Prec@1 60.4707	Prec@5 81.5456
Train: [32][3600/10010]	Time 0.583 (2099.896)	Data 0.001 (4.465)	Loss 1.737	Prec@1 60.4582	Prec@5 81.5292
Train: [32][3800/10010]	Time 0.583 (2216.521)	Data 0.001 (4.620)	Loss 1.737	Prec@1 60.4489	Prec@5 81.5318
Train: [32][4000/10010]	Time 0.583 (2332.793)	Data 0.001 (4.778)	Loss 1.736	Prec@1 60.4587	Prec@5 81.5491
Train: [32][4200/10010]	Time 0.583 (2448.707)	Data 0.001 (4.920)	Loss 1.736	Prec@1 60.4491	Prec@5 81.5595
Train: [32][4400/10010]	Time 0.583 (2564.708)	Data 0.001 (5.071)	Loss 1.735	Prec@1 60.4722	Prec@5 81.5734
Train: [32][4600/10010]	Time 0.583 (2681.143)	Data 0.001 (5.215)	Loss 1.735	Prec@1 60.4779	Prec@5 81.5725
Train: [32][4800/10010]	Time 0.583 (2797.594)	Data 0.001 (5.366)	Loss 1.735	Prec@1 60.4612	Prec@5 81.5641
Train: [32][5000/10010]	Time 0.583 (2914.181)	Data 0.001 (5.542)	Loss 1.735	Prec@1 60.4795	Prec@5 81.5643
Train: [32][5200/10010]	Time 0.583 (3031.022)	Data 0.001 (5.703)	Loss 1.735	Prec@1 60.4742	Prec@5 81.5555
Train: [32][5400/10010]	Time 0.583 (3147.467)	Data 0.001 (5.877)	Loss 1.735	Prec@1 60.4668	Prec@5 81.5513
Train: [32][5600/10010]	Time 0.583 (3263.825)	Data 0.001 (6.060)	Loss 1.735	Prec@1 60.4792	Prec@5 81.5608
Train: [32][5800/10010]	Time 0.583 (3381.162)	Data 0.001 (6.244)	Loss 1.734	Prec@1 60.4906	Prec@5 81.5697
Train: [32][6000/10010]	Time 0.583 (3498.905)	Data 0.001 (6.414)	Loss 1.734	Prec@1 60.4947	Prec@5 81.5658
Train: [32][6200/10010]	Time 0.583 (3616.501)	Data 0.001 (6.577)	Loss 1.733	Prec@1 60.5158	Prec@5 81.5790
Train: [32][6400/10010]	Time 0.583 (3733.548)	Data 0.001 (6.755)	Loss 1.732	Prec@1 60.5316	Prec@5 81.5932
Train: [32][6600/10010]	Time 0.583 (3850.991)	Data 0.001 (6.921)	Loss 1.732	Prec@1 60.5299	Prec@5 81.5935
Train: [32][6800/10010]	Time 0.584 (3969.033)	Data 0.001 (7.107)	Loss 1.732	Prec@1 60.5289	Prec@5 81.5998
Train: [32][7000/10010]	Time 0.584 (4086.716)	Data 0.001 (7.273)	Loss 1.732	Prec@1 60.5267	Prec@5 81.5970
Train: [32][7200/10010]	Time 0.584 (4204.607)	Data 0.001 (7.458)	Loss 1.733	Prec@1 60.5106	Prec@5 81.5793
Train: [32][7400/10010]	Time 0.584 (4321.613)	Data 0.001 (7.631)	Loss 1.733	Prec@1 60.5101	Prec@5 81.5767
Train: [32][7600/10010]	Time 0.584 (4438.860)	Data 0.001 (7.803)	Loss 1.732	Prec@1 60.5094	Prec@5 81.5845
Train: [32][7800/10010]	Time 0.584 (4556.125)	Data 0.001 (7.964)	Loss 1.732	Prec@1 60.5069	Prec@5 81.5813
Train: [32][8000/10010]	Time 0.584 (4673.397)	Data 0.001 (8.125)	Loss 1.732	Prec@1 60.5093	Prec@5 81.5885
Train: [32][8200/10010]	Time 0.584 (4790.880)	Data 0.001 (8.298)	Loss 1.732	Prec@1 60.5102	Prec@5 81.5888
Train: [32][8400/10010]	Time 0.584 (4908.213)	Data 0.001 (8.450)	Loss 1.732	Prec@1 60.5119	Prec@5 81.5797
Train: [32][8600/10010]	Time 0.584 (5025.763)	Data 0.001 (8.598)	Loss 1.733	Prec@1 60.5007	Prec@5 81.5680
Train: [32][8800/10010]	Time 0.584 (5142.494)	Data 0.001 (8.747)	Loss 1.733	Prec@1 60.4992	Prec@5 81.5636
Train: [32][9000/10010]	Time 0.584 (5259.696)	Data 0.001 (8.900)	Loss 1.733	Prec@1 60.5003	Prec@5 81.5570
Train: [32][9200/10010]	Time 0.584 (5377.027)	Data 0.001 (9.054)	Loss 1.733	Prec@1 60.5012	Prec@5 81.5558
Train: [32][9400/10010]	Time 0.584 (5494.148)	Data 0.001 (9.219)	Loss 1.733	Prec@1 60.5125	Prec@5 81.5681
Train: [32][9600/10010]	Time 0.584 (5611.613)	Data 0.001 (9.386)	Loss 1.733	Prec@1 60.5094	Prec@5 81.5694
Train: [32][9800/10010]	Time 0.584 (5728.368)	Data 0.001 (9.546)	Loss 1.732	Prec@1 60.5184	Prec@5 81.5730
Train: [32][10000/10010]	Time 0.584 (5845.388)	Data 0.001 (9.715)	Loss 1.733	Prec@1 60.5122	Prec@5 81.5721
Train: [32]	Time 5845.950	Data 9.715	Loss 1.733	Prec@1 60.5117	Prec@5 81.5724	
Val: [32]	Time 87.567	Data 1.605	Loss 1.382	Prec@1 66.7800	Prec@5 87.4980	
Best Prec@1: [66.780]	
Starting epoch number: 33 Learning rate: 0.010000000000000002
Train: [33][0/10010]	Time 2.353 (2.353)	Data 1.715 (1.715)	Loss 1.764	Prec@1 61.7188	Prec@5 83.5938
Train: [33][200/10010]	Time 0.596 (119.827)	Data 0.009 (1.883)	Loss 1.703	Prec@1 60.8792	Prec@5 81.9108
Train: [33][400/10010]	Time 0.592 (237.464)	Data 0.005 (2.050)	Loss 1.695	Prec@1 61.0602	Prec@5 82.1306
Train: [33][600/10010]	Time 0.590 (354.629)	Data 0.004 (2.224)	Loss 1.700	Prec@1 61.0012	Prec@5 82.0312
Train: [33][800/10010]	Time 0.589 (471.829)	Data 0.003 (2.398)	Loss 1.699	Prec@1 61.1394	Prec@5 82.0059
Train: [33][1000/10010]	Time 0.588 (588.863)	Data 0.003 (2.553)	Loss 1.701	Prec@1 61.0522	Prec@5 81.9719
Train: [33][1200/10010]	Time 0.588 (705.845)	Data 0.002 (2.705)	Loss 1.700	Prec@1 61.0884	Prec@5 81.9929
Train: [33][1400/10010]	Time 0.588 (823.361)	Data 0.002 (2.881)	Loss 1.697	Prec@1 61.1678	Prec@5 82.0262
Train: [33][1600/10010]	Time 0.588 (941.288)	Data 0.002 (3.041)	Loss 1.697	Prec@1 61.1761	Prec@5 82.0293
Train: [33][1800/10010]	Time 0.588 (1058.604)	Data 0.002 (3.223)	Loss 1.698	Prec@1 61.1887	Prec@5 82.0451
Train: [33][2000/10010]	Time 0.588 (1175.947)	Data 0.002 (3.404)	Loss 1.701	Prec@1 61.1370	Prec@5 82.0149
Train: [33][2200/10010]	Time 0.588 (1293.672)	Data 0.002 (3.571)	Loss 1.702	Prec@1 61.1185	Prec@5 82.0068
Train: [33][2400/10010]	Time 0.588 (1411.126)	Data 0.002 (3.737)	Loss 1.705	Prec@1 61.0449	Prec@5 81.9515
Train: [33][2600/10010]	Time 0.588 (1528.250)	Data 0.001 (3.897)	Loss 1.704	Prec@1 61.0703	Prec@5 81.9703
Train: [33][2800/10010]	Time 0.588 (1645.707)	Data 0.001 (4.053)	Loss 1.702	Prec@1 61.1026	Prec@5 81.9972
Train: [33][3000/10010]	Time 0.587 (1762.941)	Data 0.001 (4.193)	Loss 1.702	Prec@1 61.1236	Prec@5 81.9984
Train: [33][3200/10010]	Time 0.587 (1879.881)	Data 0.001 (4.331)	Loss 1.703	Prec@1 61.1120	Prec@5 81.9907
Train: [33][3400/10010]	Time 0.587 (1997.071)	Data 0.001 (4.481)	Loss 1.703	Prec@1 61.0983	Prec@5 81.9881
Train: [33][3600/10010]	Time 0.587 (2113.764)	Data 0.001 (4.658)	Loss 1.703	Prec@1 61.0703	Prec@5 81.9952
Train: [33][3800/10010]	Time 0.587 (2230.831)	Data 0.001 (4.821)	Loss 1.703	Prec@1 61.0717	Prec@5 82.0049
Train: [33][4000/10010]	Time 0.587 (2347.741)	Data 0.001 (4.972)	Loss 1.702	Prec@1 61.1009	Prec@5 82.0238
Train: [33][4200/10010]	Time 0.587 (2464.727)	Data 0.001 (5.123)	Loss 1.702	Prec@1 61.0941	Prec@5 82.0286
Train: [33][4400/10010]	Time 0.587 (2581.735)	Data 0.001 (5.277)	Loss 1.703	Prec@1 61.0671	Prec@5 82.0066
Train: [33][4600/10010]	Time 0.586 (2698.410)	Data 0.001 (5.441)	Loss 1.703	Prec@1 61.0526	Prec@5 82.0056
Train: [33][4800/10010]	Time 0.587 (2816.026)	Data 0.001 (5.621)	Loss 1.704	Prec@1 61.0415	Prec@5 82.0060
Train: [33][5000/10010]	Time 0.587 (2933.365)	Data 0.001 (5.795)	Loss 1.704	Prec@1 61.0390	Prec@5 81.9997
Train: [33][5200/10010]	Time 0.587 (3050.509)	Data 0.001 (5.957)	Loss 1.704	Prec@1 61.0351	Prec@5 81.9994
Train: [33][5400/10010]	Time 0.587 (3168.044)	Data 0.001 (6.128)	Loss 1.704	Prec@1 61.0197	Prec@5 81.9858
Train: [33][5600/10010]	Time 0.587 (3285.338)	Data 0.001 (6.318)	Loss 1.704	Prec@1 61.0216	Prec@5 81.9879
Train: [33][5800/10010]	Time 0.587 (3402.668)	Data 0.001 (6.475)	Loss 1.703	Prec@1 61.0400	Prec@5 82.0051
Train: [33][6000/10010]	Time 0.586 (3519.236)	Data 0.001 (6.654)	Loss 1.704	Prec@1 61.0241	Prec@5 81.9895
Train: [33][6200/10010]	Time 0.586 (3636.131)	Data 0.001 (6.825)	Loss 1.705	Prec@1 61.0191	Prec@5 81.9869
Train: [33][6400/10010]	Time 0.586 (3752.907)	Data 0.001 (6.981)	Loss 1.705	Prec@1 61.0232	Prec@5 81.9883
Train: [33][6600/10010]	Time 0.586 (3870.130)	Data 0.001 (7.136)	Loss 1.705	Prec@1 61.0080	Prec@5 81.9831
Train: [33][6800/10010]	Time 0.586 (3987.435)	Data 0.001 (7.303)	Loss 1.704	Prec@1 61.0282	Prec@5 81.9971
Train: [33][7000/10010]	Time 0.586 (4104.492)	Data 0.001 (7.475)	Loss 1.704	Prec@1 61.0278	Prec@5 82.0007
Train: [33][7200/10010]	Time 0.586 (4221.049)	Data 0.001 (7.641)	Loss 1.705	Prec@1 61.0090	Prec@5 81.9849
Train: [33][7400/10010]	Time 0.586 (4338.220)	Data 0.001 (7.823)	Loss 1.705	Prec@1 61.0065	Prec@5 81.9875
Train: [33][7600/10010]	Time 0.586 (4454.757)	Data 0.001 (7.976)	Loss 1.706	Prec@1 60.9950	Prec@5 81.9709
Train: [33][7800/10010]	Time 0.586 (4571.765)	Data 0.001 (8.159)	Loss 1.706	Prec@1 60.9898	Prec@5 81.9621
Train: [33][8000/10010]	Time 0.586 (4688.686)	Data 0.001 (8.313)	Loss 1.707	Prec@1 60.9821	Prec@5 81.9567
Train: [33][8200/10010]	Time 0.586 (4805.168)	Data 0.001 (8.489)	Loss 1.706	Prec@1 60.9892	Prec@5 81.9605
Train: [33][8400/10010]	Time 0.586 (4922.202)	Data 0.001 (8.668)	Loss 1.706	Prec@1 60.9917	Prec@5 81.9636
Train: [33][8600/10010]	Time 0.586 (5039.214)	Data 0.001 (8.844)	Loss 1.706	Prec@1 61.0001	Prec@5 81.9690
Train: [33][8800/10010]	Time 0.586 (5156.432)	Data 0.001 (9.013)	Loss 1.706	Prec@1 60.9967	Prec@5 81.9712
Train: [33][9000/10010]	Time 0.586 (5273.935)	Data 0.001 (9.171)	Loss 1.706	Prec@1 60.9943	Prec@5 81.9683
Train: [33][9200/10010]	Time 0.586 (5391.324)	Data 0.001 (9.328)	Loss 1.706	Prec@1 60.9909	Prec@5 81.9643
Train: [33][9400/10010]	Time 0.586 (5508.353)	Data 0.001 (9.485)	Loss 1.706	Prec@1 60.9951	Prec@5 81.9720
Train: [33][9600/10010]	Time 0.586 (5624.846)	Data 0.001 (9.658)	Loss 1.706	Prec@1 60.9891	Prec@5 81.9712
Train: [33][9800/10010]	Time 0.586 (5740.614)	Data 0.001 (9.817)	Loss 1.706	Prec@1 60.9804	Prec@5 81.9655
Train: [33][10000/10010]	Time 0.586 (5856.530)	Data 0.001 (9.974)	Loss 1.706	Prec@1 60.9777	Prec@5 81.9645
Train: [33]	Time 5857.085	Data 9.974	Loss 1.706	Prec@1 60.9777	Prec@5 81.9646	
Val: [33]	Time 88.845	Data 1.785	Loss 1.365	Prec@1 67.0120	Prec@5 88.0040	
Best Prec@1: [67.012]	
Starting epoch number: 34 Learning rate: 0.010000000000000002
Train: [34][0/10010]	Time 2.166 (2.166)	Data 1.474 (1.474)	Loss 1.589	Prec@1 62.5000	Prec@5 84.3750
Train: [34][200/10010]	Time 0.595 (119.520)	Data 0.008 (1.637)	Loss 1.658	Prec@1 62.1696	Prec@5 82.8591
Train: [34][400/10010]	Time 0.593 (237.674)	Data 0.004 (1.798)	Loss 1.666	Prec@1 61.9740	Prec@5 82.6294
Train: [34][600/10010]	Time 0.591 (355.067)	Data 0.003 (1.977)	Loss 1.669	Prec@1 61.9267	Prec@5 82.5759
Train: [34][800/10010]	Time 0.590 (472.399)	Data 0.003 (2.162)	Loss 1.671	Prec@1 61.8777	Prec@5 82.5384
Train: [34][1000/10010]	Time 0.589 (589.812)	Data 0.002 (2.339)	Loss 1.670	Prec@1 61.8483	Prec@5 82.5768
Train: [34][1200/10010]	Time 0.588 (706.464)	Data 0.002 (2.497)	Loss 1.670	Prec@1 61.8189	Prec@5 82.5217
Train: [34][1400/10010]	Time 0.587 (823.047)	Data 0.002 (2.667)	Loss 1.669	Prec@1 61.8096	Prec@5 82.5348
Train: [34][1600/10010]	Time 0.587 (940.298)	Data 0.002 (2.829)	Loss 1.668	Prec@1 61.8320	Prec@5 82.5344
Train: [34][1800/10010]	Time 0.587 (1057.838)	Data 0.002 (2.997)	Loss 1.670	Prec@1 61.8042	Prec@5 82.5102
Train: [34][2000/10010]	Time 0.587 (1175.022)	Data 0.002 (3.162)	Loss 1.672	Prec@1 61.7316	Prec@5 82.4674
Train: [34][2200/10010]	Time 0.587 (1291.226)	Data 0.002 (3.316)	Loss 1.673	Prec@1 61.6754	Prec@5 82.4409
Train: [34][2400/10010]	Time 0.587 (1408.574)	Data 0.001 (3.475)	Loss 1.674	Prec@1 61.6507	Prec@5 82.4325
Train: [34][2600/10010]	Time 0.587 (1525.610)	Data 0.001 (3.633)	Loss 1.675	Prec@1 61.6494	Prec@5 82.4130
Train: [34][2800/10010]	Time 0.586 (1642.785)	Data 0.001 (3.794)	Loss 1.676	Prec@1 61.6189	Prec@5 82.3813
Train: [34][3000/10010]	Time 0.587 (1760.375)	Data 0.001 (3.962)	Loss 1.678	Prec@1 61.5670	Prec@5 82.3421
Train: [34][3200/10010]	Time 0.587 (1877.780)	Data 0.001 (4.126)	Loss 1.678	Prec@1 61.5682	Prec@5 82.3685
Train: [34][3400/10010]	Time 0.587 (1994.782)	Data 0.001 (4.281)	Loss 1.679	Prec@1 61.5426	Prec@5 82.3568
Train: [34][3600/10010]	Time 0.586 (2111.615)	Data 0.001 (4.446)	Loss 1.680	Prec@1 61.5300	Prec@5 82.3549
Train: [34][3800/10010]	Time 0.586 (2228.181)	Data 0.001 (4.601)	Loss 1.681	Prec@1 61.5231	Prec@5 82.3330
Train: [34][4000/10010]	Time 0.586 (2345.044)	Data 0.001 (4.758)	Loss 1.681	Prec@1 61.5092	Prec@5 82.3392
Train: [34][4200/10010]	Time 0.586 (2461.672)	Data 0.001 (4.915)	Loss 1.682	Prec@1 61.4965	Prec@5 82.3396
Train: [34][4400/10010]	Time 0.586 (2577.887)	Data 0.001 (5.075)	Loss 1.683	Prec@1 61.4793	Prec@5 82.3208
Train: [34][4600/10010]	Time 0.586 (2694.871)	Data 0.001 (5.227)	Loss 1.684	Prec@1 61.4566	Prec@5 82.3167
Train: [34][4800/10010]	Time 0.586 (2812.348)	Data 0.001 (5.384)	Loss 1.685	Prec@1 61.4463	Prec@5 82.3017
Train: [34][5000/10010]	Time 0.586 (2929.568)	Data 0.001 (5.548)	Loss 1.685	Prec@1 61.4394	Prec@5 82.2910
Train: [34][5200/10010]	Time 0.586 (3046.844)	Data 0.001 (5.724)	Loss 1.686	Prec@1 61.4152	Prec@5 82.2719
Train: [34][5400/10010]	Time 0.586 (3163.488)	Data 0.001 (5.881)	Loss 1.687	Prec@1 61.4054	Prec@5 82.2695
Train: [34][5600/10010]	Time 0.586 (3280.005)	Data 0.001 (6.046)	Loss 1.686	Prec@1 61.4201	Prec@5 82.2751
Train: [34][5800/10010]	Time 0.586 (3396.500)	Data 0.001 (6.207)	Loss 1.687	Prec@1 61.4222	Prec@5 82.2722
Train: [34][6000/10010]	Time 0.586 (3513.806)	Data 0.001 (6.378)	Loss 1.688	Prec@1 61.4126	Prec@5 82.2566
Train: [34][6200/10010]	Time 0.586 (3631.280)	Data 0.001 (6.544)	Loss 1.688	Prec@1 61.4023	Prec@5 82.2463
Train: [34][6400/10010]	Time 0.586 (3748.649)	Data 0.001 (6.711)	Loss 1.688	Prec@1 61.4162	Prec@5 82.2552
Train: [34][6600/10010]	Time 0.586 (3866.072)	Data 0.001 (6.880)	Loss 1.688	Prec@1 61.4064	Prec@5 82.2581
Train: [34][6800/10010]	Time 0.586 (3983.463)	Data 0.001 (7.039)	Loss 1.688	Prec@1 61.4000	Prec@5 82.2639
Train: [34][7000/10010]	Time 0.586 (4100.891)	Data 0.001 (7.210)	Loss 1.689	Prec@1 61.3927	Prec@5 82.2499
Train: [34][7200/10010]	Time 0.586 (4217.741)	Data 0.001 (7.391)	Loss 1.689	Prec@1 61.3916	Prec@5 82.2464
Train: [34][7400/10010]	Time 0.586 (4334.915)	Data 0.001 (7.563)	Loss 1.689	Prec@1 61.3875	Prec@5 82.2482
Train: [34][7600/10010]	Time 0.586 (4452.171)	Data 0.001 (7.752)	Loss 1.690	Prec@1 61.3774	Prec@5 82.2412
Train: [34][7800/10010]	Time 0.586 (4569.646)	Data 0.001 (7.929)	Loss 1.690	Prec@1 61.3636	Prec@5 82.2306
Train: [34][8000/10010]	Time 0.586 (4687.350)	Data 0.001 (8.098)	Loss 1.691	Prec@1 61.3623	Prec@5 82.2183
Train: [34][8200/10010]	Time 0.586 (4804.310)	Data 0.001 (8.260)	Loss 1.691	Prec@1 61.3472	Prec@5 82.2100
Train: [34][8400/10010]	Time 0.586 (4921.429)	Data 0.001 (8.424)	Loss 1.691	Prec@1 61.3413	Prec@5 82.2114
Train: [34][8600/10010]	Time 0.586 (5038.432)	Data 0.001 (8.605)	Loss 1.691	Prec@1 61.3380	Prec@5 82.2065
Train: [34][8800/10010]	Time 0.586 (5155.152)	Data 0.001 (8.797)	Loss 1.691	Prec@1 61.3339	Prec@5 82.2091
Train: [34][9000/10010]	Time 0.586 (5271.917)	Data 0.001 (8.977)	Loss 1.692	Prec@1 61.3344	Prec@5 82.2054
Train: [34][9200/10010]	Time 0.586 (5388.454)	Data 0.001 (9.158)	Loss 1.692	Prec@1 61.3301	Prec@5 82.2038
Train: [34][9400/10010]	Time 0.586 (5505.766)	Data 0.001 (9.322)	Loss 1.692	Prec@1 61.3135	Prec@5 82.1938
Train: [34][9600/10010]	Time 0.586 (5622.667)	Data 0.001 (9.498)	Loss 1.692	Prec@1 61.3157	Prec@5 82.1916
Train: [34][9800/10010]	Time 0.586 (5740.597)	Data 0.001 (9.667)	Loss 1.693	Prec@1 61.3075	Prec@5 82.1832
Train: [34][10000/10010]	Time 0.586 (5857.761)	Data 0.001 (9.809)	Loss 1.693	Prec@1 61.2960	Prec@5 82.1727
Train: [34]	Time 5858.321	Data 9.809	Loss 1.693	Prec@1 61.2964	Prec@5 82.1725	
Val: [34]	Time 88.035	Data 1.632	Loss 1.379	Prec@1 66.9160	Prec@5 87.7300	
Best Prec@1: [67.012]	
Starting epoch number: 35 Learning rate: 0.010000000000000002
Train: [35][0/10010]	Time 2.046 (2.046)	Data 1.329 (1.329)	Loss 2.039	Prec@1 52.3438	Prec@5 78.9062
Train: [35][200/10010]	Time 0.592 (119.063)	Data 0.007 (1.496)	Loss 1.650	Prec@1 62.3640	Prec@5 82.9563
Train: [35][400/10010]	Time 0.590 (236.492)	Data 0.004 (1.666)	Loss 1.658	Prec@1 62.1513	Prec@5 82.7443
Train: [35][600/10010]	Time 0.588 (353.625)	Data 0.003 (1.845)	Loss 1.657	Prec@1 62.0827	Prec@5 82.7111
Train: [35][800/10010]	Time 0.588 (470.625)	Data 0.002 (2.002)	Loss 1.654	Prec@1 62.1235	Prec@5 82.7530
Train: [35][1000/10010]	Time 0.588 (588.106)	Data 0.002 (2.160)	Loss 1.656	Prec@1 62.0661	Prec@5 82.7430
Train: [35][1200/10010]	Time 0.587 (704.724)	Data 0.002 (2.314)	Loss 1.658	Prec@1 61.9796	Prec@5 82.7286
Train: [35][1400/10010]	Time 0.586 (821.588)	Data 0.002 (2.465)	Loss 1.656	Prec@1 62.0115	Prec@5 82.7422
Train: [35][1600/10010]	Time 0.587 (939.292)	Data 0.002 (2.641)	Loss 1.659	Prec@1 61.9501	Prec@5 82.7012
Train: [35][1800/10010]	Time 0.587 (1056.737)	Data 0.002 (2.828)	Loss 1.660	Prec@1 61.9591	Prec@5 82.6802
Train: [35][2000/10010]	Time 0.587 (1173.950)	Data 0.002 (3.004)	Loss 1.662	Prec@1 61.9491	Prec@5 82.6571
Train: [35][2200/10010]	Time 0.587 (1291.455)	Data 0.001 (3.160)	Loss 1.665	Prec@1 61.8877	Prec@5 82.5946
Train: [35][2400/10010]	Time 0.587 (1408.674)	Data 0.001 (3.307)	Loss 1.669	Prec@1 61.7783	Prec@5 82.5083
Train: [35][2600/10010]	Time 0.587 (1525.828)	Data 0.001 (3.472)	Loss 1.670	Prec@1 61.7710	Prec@5 82.4776
Train: [35][2800/10010]	Time 0.587 (1643.123)	Data 0.001 (3.628)	Loss 1.670	Prec@1 61.7656	Prec@5 82.4630
Train: [35][3000/10010]	Time 0.586 (1759.924)	Data 0.001 (3.800)	Loss 1.673	Prec@1 61.7023	Prec@5 82.4025
Train: [35][3200/10010]	Time 0.586 (1877.350)	Data 0.001 (3.964)	Loss 1.674	Prec@1 61.6670	Prec@5 82.3624
Train: [35][3400/10010]	Time 0.586 (1994.649)	Data 0.001 (4.119)	Loss 1.675	Prec@1 61.6583	Prec@5 82.3623
Train: [35][3600/10010]	Time 0.586 (2111.895)	Data 0.001 (4.298)	Loss 1.676	Prec@1 61.6413	Prec@5 82.3554
Train: [35][3800/10010]	Time 0.586 (2228.971)	Data 0.001 (4.475)	Loss 1.677	Prec@1 61.6180	Prec@5 82.3315
Train: [35][4000/10010]	Time 0.586 (2346.326)	Data 0.001 (4.637)	Loss 1.678	Prec@1 61.6119	Prec@5 82.3282
Train: [35][4200/10010]	Time 0.586 (2463.340)	Data 0.001 (4.813)	Loss 1.678	Prec@1 61.6051	Prec@5 82.3396
Train: [35][4400/10010]	Time 0.586 (2580.161)	Data 0.001 (4.974)	Loss 1.679	Prec@1 61.5806	Prec@5 82.3453
Train: [35][4600/10010]	Time 0.586 (2697.526)	Data 0.001 (5.158)	Loss 1.679	Prec@1 61.5693	Prec@5 82.3425
Train: [35][4800/10010]	Time 0.586 (2814.721)	Data 0.001 (5.342)	Loss 1.679	Prec@1 61.5720	Prec@5 82.3544
Train: [35][5000/10010]	Time 0.586 (2932.611)	Data 0.001 (5.505)	Loss 1.679	Prec@1 61.5522	Prec@5 82.3560
Train: [35][5200/10010]	Time 0.586 (3050.086)	Data 0.001 (5.684)	Loss 1.679	Prec@1 61.5435	Prec@5 82.3518
Train: [35][5400/10010]	Time 0.586 (3167.401)	Data 0.001 (5.848)	Loss 1.679	Prec@1 61.5355	Prec@5 82.3405
Train: [35][5600/10010]	Time 0.587 (3285.073)	Data 0.001 (5.996)	Loss 1.680	Prec@1 61.5168	Prec@5 82.3381
Train: [35][5800/10010]	Time 0.587 (3402.894)	Data 0.001 (6.142)	Loss 1.681	Prec@1 61.5064	Prec@5 82.3258
Train: [35][6000/10010]	Time 0.587 (3520.335)	Data 0.001 (6.325)	Loss 1.682	Prec@1 61.4905	Prec@5 82.3141
Train: [35][6200/10010]	Time 0.587 (3637.706)	Data 0.001 (6.486)	Loss 1.682	Prec@1 61.4775	Prec@5 82.3121
Train: [35][6400/10010]	Time 0.587 (3754.730)	Data 0.001 (6.653)	Loss 1.683	Prec@1 61.4699	Prec@5 82.3057
Train: [35][6600/10010]	Time 0.587 (3871.911)	Data 0.001 (6.805)	Loss 1.683	Prec@1 61.4651	Prec@5 82.3102
Train: [35][6800/10010]	Time 0.586 (3988.742)	Data 0.001 (6.960)	Loss 1.683	Prec@1 61.4583	Prec@5 82.3027
Train: [35][7000/10010]	Time 0.587 (4106.560)	Data 0.001 (7.129)	Loss 1.684	Prec@1 61.4533	Prec@5 82.3007
Train: [35][7200/10010]	Time 0.587 (4223.861)	Data 0.001 (7.292)	Loss 1.684	Prec@1 61.4360	Prec@5 82.2802
Train: [35][7400/10010]	Time 0.587 (4341.011)	Data 0.001 (7.453)	Loss 1.685	Prec@1 61.4428	Prec@5 82.2826
Train: [35][7600/10010]	Time 0.587 (4458.121)	Data 0.001 (7.642)	Loss 1.685	Prec@1 61.4377	Prec@5 82.2738
Train: [35][7800/10010]	Time 0.587 (4575.567)	Data 0.001 (7.797)	Loss 1.684	Prec@1 61.4457	Prec@5 82.2797
Train: [35][8000/10010]	Time 0.587 (4693.383)	Data 0.001 (7.957)	Loss 1.684	Prec@1 61.4395	Prec@5 82.2804
Train: [35][8200/10010]	Time 0.587 (4810.404)	Data 0.001 (8.120)	Loss 1.685	Prec@1 61.4262	Prec@5 82.2762
Train: [35][8400/10010]	Time 0.587 (4927.585)	Data 0.001 (8.286)	Loss 1.685	Prec@1 61.4264	Prec@5 82.2759
Train: [35][8600/10010]	Time 0.587 (5045.557)	Data 0.001 (8.462)	Loss 1.686	Prec@1 61.4104	Prec@5 82.2643
Train: [35][8800/10010]	Time 0.587 (5162.795)	Data 0.001 (8.653)	Loss 1.686	Prec@1 61.4049	Prec@5 82.2675
Train: [35][9000/10010]	Time 0.587 (5279.903)	Data 0.001 (8.823)	Loss 1.686	Prec@1 61.4076	Prec@5 82.2623
Train: [35][9200/10010]	Time 0.587 (5396.786)	Data 0.001 (9.008)	Loss 1.687	Prec@1 61.3902	Prec@5 82.2518
Train: [35][9400/10010]	Time 0.587 (5514.176)	Data 0.001 (9.194)	Loss 1.687	Prec@1 61.3809	Prec@5 82.2444
Train: [35][9600/10010]	Time 0.587 (5631.238)	Data 0.001 (9.377)	Loss 1.688	Prec@1 61.3732	Prec@5 82.2340
Train: [35][9800/10010]	Time 0.586 (5748.131)	Data 0.001 (9.553)	Loss 1.688	Prec@1 61.3703	Prec@5 82.2301
Train: [35][10000/10010]	Time 0.586 (5864.911)	Data 0.001 (9.708)	Loss 1.688	Prec@1 61.3683	Prec@5 82.2297
Train: [35]	Time 5865.457	Data 9.708	Loss 1.688	Prec@1 61.3689	Prec@5 82.2296	
Val: [35]	Time 87.465	Data 1.551	Loss 1.360	Prec@1 67.1180	Prec@5 87.9540	
Best Prec@1: [67.118]	
Starting epoch number: 36 Learning rate: 0.010000000000000002
Train: [36][0/10010]	Time 2.441 (2.441)	Data 1.713 (1.713)	Loss 1.722	Prec@1 59.3750	Prec@5 80.4688
Train: [36][200/10010]	Time 0.594 (119.482)	Data 0.009 (1.891)	Loss 1.655	Prec@1 61.8509	Prec@5 82.6726
Train: [36][400/10010]	Time 0.590 (236.613)	Data 0.005 (2.074)	Loss 1.660	Prec@1 61.8123	Prec@5 82.5358
Train: [36][600/10010]	Time 0.588 (353.450)	Data 0.004 (2.230)	Loss 1.661	Prec@1 61.8942	Prec@5 82.5577
Train: [36][800/10010]	Time 0.587 (470.413)	Data 0.003 (2.380)	Loss 1.659	Prec@1 61.8982	Prec@5 82.5979
Train: [36][1000/10010]	Time 0.587 (587.366)	Data 0.003 (2.534)	Loss 1.658	Prec@1 61.8920	Prec@5 82.6252
Train: [36][1200/10010]	Time 0.586 (704.158)	Data 0.002 (2.708)	Loss 1.656	Prec@1 61.9263	Prec@5 82.6531
Train: [36][1400/10010]	Time 0.586 (820.982)	Data 0.002 (2.873)	Loss 1.661	Prec@1 61.8598	Prec@5 82.6129
Train: [36][1600/10010]	Time 0.585 (937.273)	Data 0.002 (3.042)	Loss 1.661	Prec@1 61.8115	Prec@5 82.6075
Train: [36][1800/10010]	Time 0.585 (1054.143)	Data 0.002 (3.207)	Loss 1.664	Prec@1 61.7747	Prec@5 82.5913
Train: [36][2000/10010]	Time 0.585 (1170.941)	Data 0.002 (3.381)	Loss 1.664	Prec@1 61.7703	Prec@5 82.5689
Train: [36][2200/10010]	Time 0.585 (1287.974)	Data 0.002 (3.535)	Loss 1.665	Prec@1 61.7699	Prec@5 82.5523
Train: [36][2400/10010]	Time 0.585 (1405.308)	Data 0.002 (3.701)	Loss 1.667	Prec@1 61.7064	Prec@5 82.5362
Train: [36][2600/10010]	Time 0.585 (1522.629)	Data 0.001 (3.869)	Loss 1.668	Prec@1 61.7142	Prec@5 82.5241
Train: [36][2800/10010]	Time 0.585 (1639.491)	Data 0.001 (4.034)	Loss 1.669	Prec@1 61.7031	Prec@5 82.5029
Train: [36][3000/10010]	Time 0.585 (1756.286)	Data 0.001 (4.193)	Loss 1.670	Prec@1 61.6935	Prec@5 82.5077
Train: [36][3200/10010]	Time 0.585 (1873.051)	Data 0.001 (4.357)	Loss 1.671	Prec@1 61.6394	Prec@5 82.4962
Train: [36][3400/10010]	Time 0.585 (1989.426)	Data 0.001 (4.531)	Loss 1.672	Prec@1 61.5936	Prec@5 82.4819
Train: [36][3600/10010]	Time 0.585 (2106.977)	Data 0.001 (4.721)	Loss 1.672	Prec@1 61.5914	Prec@5 82.4801
Train: [36][3800/10010]	Time 0.585 (2223.807)	Data 0.001 (4.873)	Loss 1.672	Prec@1 61.5950	Prec@5 82.4869
Train: [36][4000/10010]	Time 0.585 (2340.837)	Data 0.001 (5.022)	Loss 1.671	Prec@1 61.6102	Prec@5 82.4915
Train: [36][4200/10010]	Time 0.585 (2457.257)	Data 0.001 (5.195)	Loss 1.671	Prec@1 61.6107	Prec@5 82.4783
Train: [36][4400/10010]	Time 0.585 (2574.585)	Data 0.001 (5.371)	Loss 1.672	Prec@1 61.6025	Prec@5 82.4573
Train: [36][4600/10010]	Time 0.585 (2691.375)	Data 0.001 (5.546)	Loss 1.673	Prec@1 61.5878	Prec@5 82.4396
Train: [36][4800/10010]	Time 0.585 (2808.522)	Data 0.001 (5.714)	Loss 1.673	Prec@1 61.6011	Prec@5 82.4475
Train: [36][5000/10010]	Time 0.585 (2925.670)	Data 0.001 (5.886)	Loss 1.673	Prec@1 61.5955	Prec@5 82.4430
Train: [36][5200/10010]	Time 0.585 (3042.719)	Data 0.001 (6.055)	Loss 1.674	Prec@1 61.5736	Prec@5 82.4361
Train: [36][5400/10010]	Time 0.585 (3159.839)	Data 0.001 (6.225)	Loss 1.674	Prec@1 61.5696	Prec@5 82.4364
Train: [36][5600/10010]	Time 0.585 (3276.639)	Data 0.001 (6.393)	Loss 1.675	Prec@1 61.5458	Prec@5 82.4249
Train: [36][5800/10010]	Time 0.585 (3393.824)	Data 0.001 (6.569)	Loss 1.676	Prec@1 61.5396	Prec@5 82.4052
Train: [36][6000/10010]	Time 0.585 (3510.942)	Data 0.001 (6.735)	Loss 1.676	Prec@1 61.5381	Prec@5 82.4101
Train: [36][6200/10010]	Time 0.585 (3628.523)	Data 0.001 (6.896)	Loss 1.676	Prec@1 61.5502	Prec@5 82.4131
Train: [36][6400/10010]	Time 0.585 (3744.521)	Data 0.001 (7.045)	Loss 1.677	Prec@1 61.5335	Prec@5 82.3959
Train: [36][6600/10010]	Time 0.585 (3860.019)	Data 0.001 (7.185)	Loss 1.678	Prec@1 61.5260	Prec@5 82.3856
Train: [36][6800/10010]	Time 0.585 (3976.259)	Data 0.001 (7.355)	Loss 1.678	Prec@1 61.5219	Prec@5 82.3860
Train: [36][7000/10010]	Time 0.585 (4092.629)	Data 0.001 (7.532)	Loss 1.678	Prec@1 61.5246	Prec@5 82.3885
Train: [36][7200/10010]	Time 0.584 (4208.933)	Data 0.001 (7.711)	Loss 1.679	Prec@1 61.5184	Prec@5 82.3799
Train: [36][7400/10010]	Time 0.584 (4325.264)	Data 0.001 (7.879)	Loss 1.679	Prec@1 61.5039	Prec@5 82.3643
Train: [36][7600/10010]	Time 0.584 (4441.578)	Data 0.001 (8.055)	Loss 1.679	Prec@1 61.4977	Prec@5 82.3667
Train: [36][7800/10010]	Time 0.584 (4557.786)	Data 0.001 (8.225)	Loss 1.680	Prec@1 61.4935	Prec@5 82.3604
Train: [36][8000/10010]	Time 0.584 (4673.823)	Data 0.001 (8.427)	Loss 1.680	Prec@1 61.4785	Prec@5 82.3591
Train: [36][8200/10010]	Time 0.584 (4790.288)	Data 0.001 (8.609)	Loss 1.681	Prec@1 61.4596	Prec@5 82.3550
Train: [36][8400/10010]	Time 0.584 (4906.775)	Data 0.001 (8.798)	Loss 1.681	Prec@1 61.4365	Prec@5 82.3402
Train: [36][8600/10010]	Time 0.584 (5022.425)	Data 0.001 (8.960)	Loss 1.681	Prec@1 61.4367	Prec@5 82.3436
Train: [36][8800/10010]	Time 0.584 (5138.313)	Data 0.001 (9.124)	Loss 1.682	Prec@1 61.4214	Prec@5 82.3324
Train: [36][9000/10010]	Time 0.584 (5254.260)	Data 0.001 (9.279)	Loss 1.682	Prec@1 61.4132	Prec@5 82.3265
Train: [36][9200/10010]	Time 0.584 (5370.741)	Data 0.001 (9.442)	Loss 1.683	Prec@1 61.3944	Prec@5 82.3172
Train: [36][9400/10010]	Time 0.584 (5486.977)	Data 0.001 (9.605)	Loss 1.683	Prec@1 61.3911	Prec@5 82.3146
Train: [36][9600/10010]	Time 0.584 (5602.943)	Data 0.001 (9.778)	Loss 1.683	Prec@1 61.3915	Prec@5 82.3144
Train: [36][9800/10010]	Time 0.584 (5719.103)	Data 0.001 (9.949)	Loss 1.684	Prec@1 61.3840	Prec@5 82.3127
Train: [36][10000/10010]	Time 0.583 (5835.100)	Data 0.001 (10.097)	Loss 1.684	Prec@1 61.3838	Prec@5 82.3147
Train: [36]	Time 5835.747	Data 10.097	Loss 1.684	Prec@1 61.3840	Prec@5 82.3149	
Val: [36]	Time 87.871	Data 1.607	Loss 1.370	Prec@1 67.0940	Prec@5 87.7560	
Best Prec@1: [67.118]	
Starting epoch number: 37 Learning rate: 0.010000000000000002
Train: [37][0/10010]	Time 2.075 (2.075)	Data 1.404 (1.404)	Loss 1.691	Prec@1 59.3750	Prec@5 79.6875
Train: [37][200/10010]	Time 0.593 (119.188)	Data 0.008 (1.560)	Loss 1.631	Prec@1 62.8576	Prec@5 82.6726
Train: [37][400/10010]	Time 0.590 (236.545)	Data 0.004 (1.714)	Loss 1.644	Prec@1 62.4221	Prec@5 82.7346
Train: [37][600/10010]	Time 0.589 (353.701)	Data 0.003 (1.874)	Loss 1.647	Prec@1 62.1308	Prec@5 82.8398
Train: [37][800/10010]	Time 0.588 (470.851)	Data 0.003 (2.040)	Loss 1.659	Prec@1 61.9704	Prec@5 82.6721
Train: [37][1000/10010]	Time 0.587 (587.381)	Data 0.002 (2.200)	Loss 1.662	Prec@1 61.9623	Prec@5 82.6244
Train: [37][1200/10010]	Time 0.586 (703.756)	Data 0.002 (2.361)	Loss 1.659	Prec@1 61.9516	Prec@5 82.6505
Train: [37][1400/10010]	Time 0.585 (820.097)	Data 0.002 (2.518)	Loss 1.663	Prec@1 61.9228	Prec@5 82.5883
Train: [37][1600/10010]	Time 0.585 (937.346)	Data 0.002 (2.663)	Loss 1.662	Prec@1 61.9115	Prec@5 82.5807
Train: [37][1800/10010]	Time 0.586 (1054.523)	Data 0.002 (2.823)	Loss 1.662	Prec@1 61.9200	Prec@5 82.6017
Train: [37][2000/10010]	Time 0.585 (1170.899)	Data 0.001 (2.983)	Loss 1.664	Prec@1 61.8722	Prec@5 82.5525
Train: [37][2200/10010]	Time 0.585 (1287.936)	Data 0.001 (3.150)	Loss 1.665	Prec@1 61.8728	Prec@5 82.5445
Train: [37][2400/10010]	Time 0.585 (1404.706)	Data 0.001 (3.299)	Loss 1.666	Prec@1 61.8688	Prec@5 82.5441
Train: [37][2600/10010]	Time 0.585 (1521.951)	Data 0.001 (3.449)	Loss 1.667	Prec@1 61.8509	Prec@5 82.5350
Train: [37][2800/10010]	Time 0.585 (1639.221)	Data 0.001 (3.616)	Loss 1.665	Prec@1 61.8613	Prec@5 82.5774
Train: [37][3000/10010]	Time 0.585 (1756.206)	Data 0.001 (3.775)	Loss 1.665	Prec@1 61.8502	Prec@5 82.5787
Train: [37][3200/10010]	Time 0.585 (1873.057)	Data 0.001 (3.929)	Loss 1.667	Prec@1 61.7871	Prec@5 82.5528
Train: [37][3400/10010]	Time 0.585 (1989.795)	Data 0.001 (4.098)	Loss 1.668	Prec@1 61.7569	Prec@5 82.5490
Train: [37][3600/10010]	Time 0.585 (2106.323)	Data 0.001 (4.258)	Loss 1.669	Prec@1 61.7333	Prec@5 82.5292
Train: [37][3800/10010]	Time 0.585 (2222.867)	Data 0.001 (4.431)	Loss 1.669	Prec@1 61.7198	Prec@5 82.5472
Train: [37][4000/10010]	Time 0.585 (2339.693)	Data 0.001 (4.598)	Loss 1.670	Prec@1 61.7145	Prec@5 82.5303
Train: [37][4200/10010]	Time 0.585 (2456.589)	Data 0.001 (4.763)	Loss 1.669	Prec@1 61.7160	Prec@5 82.5369
Train: [37][4400/10010]	Time 0.585 (2573.419)	Data 0.001 (4.927)	Loss 1.670	Prec@1 61.7090	Prec@5 82.5308
Train: [37][4600/10010]	Time 0.585 (2690.584)	Data 0.001 (5.104)	Loss 1.669	Prec@1 61.7140	Prec@5 82.5383
Train: [37][4800/10010]	Time 0.585 (2807.062)	Data 0.001 (5.280)	Loss 1.670	Prec@1 61.7028	Prec@5 82.5246
Train: [37][5000/10010]	Time 0.585 (2923.633)	Data 0.001 (5.458)	Loss 1.671	Prec@1 61.7038	Prec@5 82.5094
Train: [37][5200/10010]	Time 0.585 (3040.653)	Data 0.001 (5.610)	Loss 1.671	Prec@1 61.6853	Prec@5 82.4936
Train: [37][5400/10010]	Time 0.585 (3157.324)	Data 0.001 (5.772)	Loss 1.672	Prec@1 61.6580	Prec@5 82.4797
Train: [37][5600/10010]	Time 0.585 (3274.569)	Data 0.001 (5.937)	Loss 1.673	Prec@1 61.6411	Prec@5 82.4688
Train: [37][5800/10010]	Time 0.585 (3392.037)	Data 0.001 (6.110)	Loss 1.674	Prec@1 61.6439	Prec@5 82.4579
Train: [37][6000/10010]	Time 0.585 (3509.340)	Data 0.001 (6.300)	Loss 1.673	Prec@1 61.6537	Prec@5 82.4540
Train: [37][6200/10010]	Time 0.585 (3626.286)	Data 0.001 (6.472)	Loss 1.673	Prec@1 61.6413	Prec@5 82.4565
Train: [37][6400/10010]	Time 0.585 (3743.431)	Data 0.001 (6.647)	Loss 1.674	Prec@1 61.6329	Prec@5 82.4505
Train: [37][6600/10010]	Time 0.585 (3860.265)	Data 0.001 (6.823)	Loss 1.674	Prec@1 61.6289	Prec@5 82.4553
Train: [37][6800/10010]	Time 0.585 (3977.294)	Data 0.001 (6.990)	Loss 1.674	Prec@1 61.6148	Prec@5 82.4494
Train: [37][7000/10010]	Time 0.585 (4094.331)	Data 0.001 (7.179)	Loss 1.675	Prec@1 61.5998	Prec@5 82.4380
Train: [37][7200/10010]	Time 0.585 (4211.508)	Data 0.001 (7.366)	Loss 1.675	Prec@1 61.6024	Prec@5 82.4359
Train: [37][7400/10010]	Time 0.585 (4328.340)	Data 0.001 (7.543)	Loss 1.675	Prec@1 61.6036	Prec@5 82.4409
Train: [37][7600/10010]	Time 0.585 (4445.097)	Data 0.001 (7.724)	Loss 1.675	Prec@1 61.5952	Prec@5 82.4336
Train: [37][7800/10010]	Time 0.585 (4562.127)	Data 0.001 (7.905)	Loss 1.675	Prec@1 61.5878	Prec@5 82.4352
Train: [37][8000/10010]	Time 0.585 (4679.138)	Data 0.001 (8.065)	Loss 1.675	Prec@1 61.5831	Prec@5 82.4327
Train: [37][8200/10010]	Time 0.585 (4796.472)	Data 0.001 (8.244)	Loss 1.676	Prec@1 61.5824	Prec@5 82.4325
Train: [37][8400/10010]	Time 0.585 (4913.255)	Data 0.001 (8.404)	Loss 1.675	Prec@1 61.5909	Prec@5 82.4383
Train: [37][8600/10010]	Time 0.585 (5030.485)	Data 0.001 (8.573)	Loss 1.676	Prec@1 61.5672	Prec@5 82.4315
Train: [37][8800/10010]	Time 0.585 (5147.346)	Data 0.001 (8.753)	Loss 1.676	Prec@1 61.5495	Prec@5 82.4219
Train: [37][9000/10010]	Time 0.585 (5263.750)	Data 0.001 (8.914)	Loss 1.677	Prec@1 61.5504	Prec@5 82.4197
Train: [37][9200/10010]	Time 0.585 (5380.471)	Data 0.001 (9.083)	Loss 1.677	Prec@1 61.5443	Prec@5 82.4217
Train: [37][9400/10010]	Time 0.585 (5497.597)	Data 0.001 (9.260)	Loss 1.677	Prec@1 61.5317	Prec@5 82.4162
Train: [37][9600/10010]	Time 0.585 (5614.615)	Data 0.001 (9.426)	Loss 1.678	Prec@1 61.5187	Prec@5 82.4126
Train: [37][9800/10010]	Time 0.585 (5731.543)	Data 0.001 (9.591)	Loss 1.678	Prec@1 61.5144	Prec@5 82.4137
Train: [37][10000/10010]	Time 0.585 (5848.133)	Data 0.001 (9.743)	Loss 1.679	Prec@1 61.5036	Prec@5 82.4030
Train: [37]	Time 5848.697	Data 9.743	Loss 1.679	Prec@1 61.5036	Prec@5 82.4029	
Val: [37]	Time 87.976	Data 1.547	Loss 1.377	Prec@1 66.8920	Prec@5 87.6580	
Best Prec@1: [67.118]	
Starting epoch number: 38 Learning rate: 0.010000000000000002
Train: [38][0/10010]	Time 2.394 (2.394)	Data 1.653 (1.653)	Loss 1.295	Prec@1 70.3125	Prec@5 85.1562
Train: [38][200/10010]	Time 0.595 (119.522)	Data 0.009 (1.835)	Loss 1.653	Prec@1 61.9053	Prec@5 82.6803
Train: [38][400/10010]	Time 0.590 (236.655)	Data 0.005 (1.991)	Loss 1.655	Prec@1 61.9058	Prec@5 82.6781
Train: [38][600/10010]	Time 0.588 (353.330)	Data 0.004 (2.143)	Loss 1.652	Prec@1 61.9748	Prec@5 82.7345
Train: [38][800/10010]	Time 0.587 (469.868)	Data 0.003 (2.305)	Loss 1.654	Prec@1 61.9928	Prec@5 82.6779
Train: [38][1000/10010]	Time 0.586 (586.522)	Data 0.002 (2.473)	Loss 1.658	Prec@1 61.8866	Prec@5 82.6143
Train: [38][1200/10010]	Time 0.586 (703.651)	Data 0.002 (2.643)	Loss 1.660	Prec@1 61.8339	Prec@5 82.5796
Train: [38][1400/10010]	Time 0.586 (820.422)	Data 0.002 (2.803)	Loss 1.659	Prec@1 61.8297	Prec@5 82.6419
Train: [38][1600/10010]	Time 0.585 (936.071)	Data 0.002 (2.957)	Loss 1.658	Prec@1 61.8695	Prec@5 82.6593
Train: [38][1800/10010]	Time 0.584 (1051.678)	Data 0.002 (3.104)	Loss 1.659	Prec@1 61.8450	Prec@5 82.6477
Train: [38][2000/10010]	Time 0.583 (1167.316)	Data 0.002 (3.261)	Loss 1.660	Prec@1 61.8285	Prec@5 82.6204
Train: [38][2200/10010]	Time 0.583 (1283.260)	Data 0.002 (3.434)	Loss 1.663	Prec@1 61.7940	Prec@5 82.5711
Train: [38][2400/10010]	Time 0.583 (1398.798)	Data 0.002 (3.607)	Loss 1.662	Prec@1 61.8167	Prec@5 82.5893
Train: [38][2600/10010]	Time 0.582 (1514.737)	Data 0.001 (3.758)	Loss 1.662	Prec@1 61.8215	Prec@5 82.5869
Train: [38][2800/10010]	Time 0.582 (1630.496)	Data 0.001 (3.935)	Loss 1.662	Prec@1 61.8169	Prec@5 82.5860
Train: [38][3000/10010]	Time 0.582 (1745.866)	Data 0.001 (4.107)	Loss 1.662	Prec@1 61.8268	Prec@5 82.5733
Train: [38][3200/10010]	Time 0.582 (1861.846)	Data 0.001 (4.278)	Loss 1.663	Prec@1 61.7805	Prec@5 82.5628
Train: [38][3400/10010]	Time 0.582 (1977.925)	Data 0.001 (4.454)	Loss 1.665	Prec@1 61.7420	Prec@5 82.5532
Train: [38][3600/10010]	Time 0.581 (2093.610)	Data 0.001 (4.625)	Loss 1.667	Prec@1 61.6843	Prec@5 82.5157
Train: [38][3800/10010]	Time 0.581 (2208.925)	Data 0.001 (4.782)	Loss 1.669	Prec@1 61.6528	Prec@5 82.4869
Train: [38][4000/10010]	Time 0.581 (2324.573)	Data 0.001 (4.949)	Loss 1.669	Prec@1 61.6483	Prec@5 82.4899
Train: [38][4200/10010]	Time 0.581 (2440.233)	Data 0.001 (5.113)	Loss 1.668	Prec@1 61.6749	Prec@5 82.5127
Train: [38][4400/10010]	Time 0.581 (2556.450)	Data 0.001 (5.265)	Loss 1.668	Prec@1 61.6827	Prec@5 82.5097
Train: [38][4600/10010]	Time 0.581 (2672.286)	Data 0.001 (5.435)	Loss 1.668	Prec@1 61.6838	Prec@5 82.5094
Train: [38][4800/10010]	Time 0.581 (2788.191)	Data 0.001 (5.585)	Loss 1.669	Prec@1 61.6637	Prec@5 82.5080
Train: [38][5000/10010]	Time 0.581 (2903.759)	Data 0.001 (5.731)	Loss 1.669	Prec@1 61.6663	Prec@5 82.5176
Train: [38][5200/10010]	Time 0.581 (3019.455)	Data 0.001 (5.915)	Loss 1.668	Prec@1 61.6750	Prec@5 82.5315
Train: [38][5400/10010]	Time 0.580 (3135.043)	Data 0.001 (6.094)	Loss 1.669	Prec@1 61.6555	Prec@5 82.5252
Train: [38][5600/10010]	Time 0.580 (3250.817)	Data 0.001 (6.276)	Loss 1.670	Prec@1 61.6252	Prec@5 82.5097
Train: [38][5800/10010]	Time 0.580 (3366.721)	Data 0.001 (6.450)	Loss 1.670	Prec@1 61.6266	Prec@5 82.5130
Train: [38][6000/10010]	Time 0.580 (3482.584)	Data 0.001 (6.609)	Loss 1.670	Prec@1 61.6313	Prec@5 82.5089
Train: [38][6200/10010]	Time 0.580 (3597.981)	Data 0.001 (6.768)	Loss 1.670	Prec@1 61.6183	Prec@5 82.5051
Train: [38][6400/10010]	Time 0.580 (3713.466)	Data 0.001 (6.932)	Loss 1.670	Prec@1 61.6256	Prec@5 82.5110
Train: [38][6600/10010]	Time 0.580 (3828.794)	Data 0.001 (7.101)	Loss 1.670	Prec@1 61.6242	Prec@5 82.5119
Train: [38][6800/10010]	Time 0.580 (3944.382)	Data 0.001 (7.277)	Loss 1.670	Prec@1 61.6134	Prec@5 82.5072
Train: [38][7000/10010]	Time 0.580 (4060.379)	Data 0.001 (7.442)	Loss 1.671	Prec@1 61.6035	Prec@5 82.5038
Train: [38][7200/10010]	Time 0.580 (4175.742)	Data 0.001 (7.617)	Loss 1.671	Prec@1 61.5969	Prec@5 82.4884
Train: [38][7400/10010]	Time 0.580 (4291.419)	Data 0.001 (7.785)	Loss 1.672	Prec@1 61.5810	Prec@5 82.4725
Train: [38][7600/10010]	Time 0.580 (4407.267)	Data 0.001 (7.952)	Loss 1.673	Prec@1 61.5638	Prec@5 82.4624
Train: [38][7800/10010]	Time 0.580 (4523.499)	Data 0.001 (8.096)	Loss 1.673	Prec@1 61.5579	Prec@5 82.4602
Train: [38][8000/10010]	Time 0.580 (4639.114)	Data 0.001 (8.250)	Loss 1.674	Prec@1 61.5334	Prec@5 82.4508
Train: [38][8200/10010]	Time 0.580 (4754.362)	Data 0.001 (8.405)	Loss 1.674	Prec@1 61.5247	Prec@5 82.4424
Train: [38][8400/10010]	Time 0.580 (4869.867)	Data 0.001 (8.560)	Loss 1.675	Prec@1 61.5101	Prec@5 82.4354
Train: [38][8600/10010]	Time 0.580 (4985.734)	Data 0.001 (8.724)	Loss 1.675	Prec@1 61.5095	Prec@5 82.4391
Train: [38][8800/10010]	Time 0.580 (5101.434)	Data 0.001 (8.901)	Loss 1.675	Prec@1 61.5073	Prec@5 82.4345
Train: [38][9000/10010]	Time 0.580 (5216.663)	Data 0.001 (9.070)	Loss 1.676	Prec@1 61.4965	Prec@5 82.4254
Train: [38][9200/10010]	Time 0.580 (5332.331)	Data 0.001 (9.235)	Loss 1.676	Prec@1 61.5013	Prec@5 82.4229
Train: [38][9400/10010]	Time 0.580 (5448.209)	Data 0.001 (9.408)	Loss 1.676	Prec@1 61.5048	Prec@5 82.4171
Train: [38][9600/10010]	Time 0.580 (5564.491)	Data 0.001 (9.576)	Loss 1.676	Prec@1 61.4973	Prec@5 82.4140
Train: [38][9800/10010]	Time 0.580 (5680.734)	Data 0.001 (9.738)	Loss 1.677	Prec@1 61.5028	Prec@5 82.4132
Train: [38][10000/10010]	Time 0.580 (5796.609)	Data 0.001 (9.901)	Loss 1.677	Prec@1 61.4996	Prec@5 82.4108
Train: [38]	Time 5797.170	Data 9.902	Loss 1.677	Prec@1 61.4996	Prec@5 82.4105	
Val: [38]	Time 87.154	Data 1.790	Loss 1.380	Prec@1 66.8260	Prec@5 87.5900	
Best Prec@1: [67.118]	
Starting epoch number: 39 Learning rate: 0.010000000000000002
Train: [39][0/10010]	Time 2.260 (2.260)	Data 1.500 (1.500)	Loss 1.598	Prec@1 62.5000	Prec@5 82.8125
Train: [39][200/10010]	Time 0.592 (119.012)	Data 0.008 (1.654)	Loss 1.652	Prec@1 62.0336	Prec@5 82.6298
Train: [39][400/10010]	Time 0.589 (236.125)	Data 0.005 (1.812)	Loss 1.653	Prec@1 62.0577	Prec@5 82.6527
Train: [39][600/10010]	Time 0.587 (352.664)	Data 0.003 (1.966)	Loss 1.651	Prec@1 61.9852	Prec@5 82.7306
Train: [39][800/10010]	Time 0.586 (469.641)	Data 0.003 (2.142)	Loss 1.649	Prec@1 62.0299	Prec@5 82.7608
Train: [39][1000/10010]	Time 0.586 (586.179)	Data 0.002 (2.301)	Loss 1.652	Prec@1 62.0060	Prec@5 82.7134
Train: [39][1200/10010]	Time 0.585 (703.026)	Data 0.002 (2.451)	Loss 1.654	Prec@1 61.9881	Prec@5 82.6811
Train: [39][1400/10010]	Time 0.585 (819.399)	Data 0.002 (2.602)	Loss 1.657	Prec@1 61.9435	Prec@5 82.6279
Train: [39][1600/10010]	Time 0.585 (936.893)	Data 0.002 (2.763)	Loss 1.661	Prec@1 61.8115	Prec@5 82.5758
Train: [39][1800/10010]	Time 0.585 (1054.096)	Data 0.002 (2.921)	Loss 1.663	Prec@1 61.7847	Prec@5 82.5548
Train: [39][2000/10010]	Time 0.585 (1171.294)	Data 0.002 (3.092)	Loss 1.665	Prec@1 61.7113	Prec@5 82.5423
Train: [39][2200/10010]	Time 0.585 (1287.721)	Data 0.001 (3.242)	Loss 1.663	Prec@1 61.7560	Prec@5 82.5569
Train: [39][2400/10010]	Time 0.585 (1404.354)	Data 0.001 (3.393)	Loss 1.661	Prec@1 61.7907	Prec@5 82.5756
Train: [39][2600/10010]	Time 0.585 (1521.229)	Data 0.001 (3.554)	Loss 1.661	Prec@1 61.8001	Prec@5 82.5875
Train: [39][2800/10010]	Time 0.585 (1638.261)	Data 0.001 (3.718)	Loss 1.662	Prec@1 61.7492	Prec@5 82.5804
Train: [39][3000/10010]	Time 0.585 (1755.628)	Data 0.001 (3.901)	Loss 1.662	Prec@1 61.7380	Prec@5 82.5764
Train: [39][3200/10010]	Time 0.585 (1872.159)	Data 0.001 (4.070)	Loss 1.662	Prec@1 61.7283	Prec@5 82.5828
Train: [39][3400/10010]	Time 0.585 (1989.394)	Data 0.001 (4.238)	Loss 1.663	Prec@1 61.7176	Prec@5 82.5819
Train: [39][3600/10010]	Time 0.585 (2106.036)	Data 0.001 (4.407)	Loss 1.663	Prec@1 61.7266	Prec@5 82.5762
Train: [39][3800/10010]	Time 0.585 (2222.725)	Data 0.001 (4.560)	Loss 1.665	Prec@1 61.6793	Prec@5 82.5525
Train: [39][4000/10010]	Time 0.585 (2339.497)	Data 0.001 (4.729)	Loss 1.666	Prec@1 61.6717	Prec@5 82.5284
Train: [39][4200/10010]	Time 0.585 (2456.762)	Data 0.001 (4.903)	Loss 1.667	Prec@1 61.6706	Prec@5 82.5148
Train: [39][4400/10010]	Time 0.585 (2573.657)	Data 0.001 (5.060)	Loss 1.667	Prec@1 61.6632	Prec@5 82.5040
Train: [39][4600/10010]	Time 0.585 (2691.047)	Data 0.001 (5.220)	Loss 1.668	Prec@1 61.6474	Prec@5 82.5065
Train: [39][4800/10010]	Time 0.585 (2808.291)	Data 0.001 (5.393)	Loss 1.668	Prec@1 61.6411	Prec@5 82.5129
Train: [39][5000/10010]	Time 0.585 (2925.347)	Data 0.001 (5.564)	Loss 1.668	Prec@1 61.6505	Prec@5 82.5093
Train: [39][5200/10010]	Time 0.585 (3042.229)	Data 0.001 (5.711)	Loss 1.668	Prec@1 61.6421	Prec@5 82.5071
Train: [39][5400/10010]	Time 0.585 (3159.135)	Data 0.001 (5.869)	Loss 1.668	Prec@1 61.6552	Prec@5 82.5121
Train: [39][5600/10010]	Time 0.585 (3276.097)	Data 0.001 (6.032)	Loss 1.669	Prec@1 61.6418	Prec@5 82.5084
Train: [39][5800/10010]	Time 0.585 (3393.367)	Data 0.001 (6.193)	Loss 1.669	Prec@1 61.6354	Prec@5 82.5050
Train: [39][6000/10010]	Time 0.585 (3510.148)	Data 0.001 (6.346)	Loss 1.669	Prec@1 61.6277	Prec@5 82.5089
Train: [39][6200/10010]	Time 0.585 (3627.309)	Data 0.001 (6.516)	Loss 1.670	Prec@1 61.6222	Prec@5 82.4983
Train: [39][6400/10010]	Time 0.585 (3743.941)	Data 0.001 (6.681)	Loss 1.670	Prec@1 61.6249	Prec@5 82.4983
Train: [39][6600/10010]	Time 0.585 (3860.704)	Data 0.001 (6.838)	Loss 1.670	Prec@1 61.6142	Prec@5 82.4928
Train: [39][6800/10010]	Time 0.585 (3977.530)	Data 0.001 (6.999)	Loss 1.670	Prec@1 61.6058	Prec@5 82.4910
Train: [39][7000/10010]	Time 0.585 (4094.681)	Data 0.001 (7.172)	Loss 1.670	Prec@1 61.6069	Prec@5 82.4897
Train: [39][7200/10010]	Time 0.585 (4211.214)	Data 0.001 (7.342)	Loss 1.670	Prec@1 61.6054	Prec@5 82.4877
Train: [39][7400/10010]	Time 0.585 (4328.237)	Data 0.001 (7.494)	Loss 1.670	Prec@1 61.6006	Prec@5 82.4856
Train: [39][7600/10010]	Time 0.585 (4444.953)	Data 0.001 (7.650)	Loss 1.671	Prec@1 61.5909	Prec@5 82.4757
Train: [39][7800/10010]	Time 0.585 (4562.069)	Data 0.001 (7.822)	Loss 1.671	Prec@1 61.5877	Prec@5 82.4703
Train: [39][8000/10010]	Time 0.585 (4679.408)	Data 0.001 (7.989)	Loss 1.671	Prec@1 61.5997	Prec@5 82.4762
Train: [39][8200/10010]	Time 0.585 (4796.496)	Data 0.001 (8.167)	Loss 1.672	Prec@1 61.5902	Prec@5 82.4746
Train: [39][8400/10010]	Time 0.585 (4913.791)	Data 0.001 (8.353)	Loss 1.672	Prec@1 61.5794	Prec@5 82.4626
Train: [39][8600/10010]	Time 0.585 (5031.097)	Data 0.001 (8.541)	Loss 1.673	Prec@1 61.5642	Prec@5 82.4533
Train: [39][8800/10010]	Time 0.585 (5147.492)	Data 0.001 (8.710)	Loss 1.673	Prec@1 61.5745	Prec@5 82.4513
Train: [39][9000/10010]	Time 0.585 (5264.654)	Data 0.001 (8.884)	Loss 1.674	Prec@1 61.5553	Prec@5 82.4430
Train: [39][9200/10010]	Time 0.585 (5381.133)	Data 0.001 (9.051)	Loss 1.674	Prec@1 61.5511	Prec@5 82.4433
Train: [39][9400/10010]	Time 0.585 (5497.871)	Data 0.001 (9.237)	Loss 1.674	Prec@1 61.5462	Prec@5 82.4385
Train: [39][9600/10010]	Time 0.585 (5614.597)	Data 0.001 (9.411)	Loss 1.674	Prec@1 61.5469	Prec@5 82.4423
Train: [39][9800/10010]	Time 0.585 (5731.518)	Data 0.001 (9.596)	Loss 1.674	Prec@1 61.5431	Prec@5 82.4350
Train: [39][10000/10010]	Time 0.585 (5848.324)	Data 0.001 (9.773)	Loss 1.674	Prec@1 61.5424	Prec@5 82.4368
Train: [39]	Time 5848.875	Data 9.774	Loss 1.674	Prec@1 61.5413	Prec@5 82.4357	
Val: [39]	Time 87.584	Data 1.470	Loss 1.367	Prec@1 66.9640	Prec@5 88.0320	
Best Prec@1: [67.118]	
Starting epoch number: 40 Learning rate: 0.010000000000000002
Train: [40][0/10010]	Time 2.227 (2.227)	Data 1.566 (1.566)	Loss 1.799	Prec@1 61.7188	Prec@5 79.6875
Train: [40][200/10010]	Time 0.589 (118.431)	Data 0.009 (1.713)	Loss 1.634	Prec@1 62.5972	Prec@5 83.2362
Train: [40][400/10010]	Time 0.587 (235.403)	Data 0.005 (1.859)	Loss 1.643	Prec@1 62.1337	Prec@5 83.0736
Train: [40][600/10010]	Time 0.585 (351.852)	Data 0.003 (2.026)	Loss 1.637	Prec@1 62.3245	Prec@5 83.1453
Train: [40][800/10010]	Time 0.585 (468.540)	Data 0.003 (2.180)	Loss 1.634	Prec@1 62.4151	Prec@5 83.2212
Train: [40][1000/10010]	Time 0.585 (585.519)	Data 0.002 (2.336)	Loss 1.637	Prec@1 62.2963	Prec@5 83.1801
Train: [40][1200/10010]	Time 0.585 (702.980)	Data 0.002 (2.507)	Loss 1.639	Prec@1 62.2457	Prec@5 83.1430
Train: [40][1400/10010]	Time 0.585 (820.022)	Data 0.002 (2.658)	Loss 1.641	Prec@1 62.2217	Prec@5 83.1008
Train: [40][1600/10010]	Time 0.585 (936.911)	Data 0.002 (2.822)	Loss 1.642	Prec@1 62.2023	Prec@5 83.0448
Train: [40][1800/10010]	Time 0.585 (1053.325)	Data 0.002 (2.968)	Loss 1.644	Prec@1 62.1417	Prec@5 83.0112
Train: [40][2000/10010]	Time 0.585 (1170.283)	Data 0.002 (3.133)	Loss 1.644	Prec@1 62.1010	Prec@5 83.0124
Train: [40][2200/10010]	Time 0.585 (1287.203)	Data 0.001 (3.293)	Loss 1.644	Prec@1 62.1358	Prec@5 82.9868
Train: [40][2400/10010]	Time 0.585 (1404.001)	Data 0.001 (3.457)	Loss 1.647	Prec@1 62.0786	Prec@5 82.9238
Train: [40][2600/10010]	Time 0.585 (1520.320)	Data 0.001 (3.620)	Loss 1.647	Prec@1 62.1014	Prec@5 82.9203
Train: [40][2800/10010]	Time 0.584 (1636.399)	Data 0.001 (3.793)	Loss 1.647	Prec@1 62.0797	Prec@5 82.9143
Train: [40][3000/10010]	Time 0.584 (1752.661)	Data 0.001 (3.951)	Loss 1.646	Prec@1 62.0947	Prec@5 82.9364
Train: [40][3200/10010]	Time 0.584 (1868.219)	Data 0.001 (4.104)	Loss 1.648	Prec@1 62.0560	Prec@5 82.9189
Train: [40][3400/10010]	Time 0.583 (1983.941)	Data 0.001 (4.259)	Loss 1.651	Prec@1 61.9910	Prec@5 82.8690
Train: [40][3600/10010]	Time 0.583 (2100.090)	Data 0.001 (4.429)	Loss 1.651	Prec@1 61.9763	Prec@5 82.8591
Train: [40][3800/10010]	Time 0.583 (2216.162)	Data 0.001 (4.596)	Loss 1.652	Prec@1 61.9635	Prec@5 82.8380
Train: [40][4000/10010]	Time 0.583 (2331.826)	Data 0.001 (4.764)	Loss 1.652	Prec@1 61.9726	Prec@5 82.8275
Train: [40][4200/10010]	Time 0.583 (2447.582)	Data 0.001 (4.937)	Loss 1.654	Prec@1 61.9553	Prec@5 82.7904
Train: [40][4400/10010]	Time 0.582 (2563.358)	Data 0.001 (5.096)	Loss 1.655	Prec@1 61.9264	Prec@5 82.7743
Train: [40][4600/10010]	Time 0.582 (2678.710)	Data 0.001 (5.260)	Loss 1.655	Prec@1 61.9300	Prec@5 82.7668
Train: [40][4800/10010]	Time 0.582 (2794.264)	Data 0.001 (5.429)	Loss 1.655	Prec@1 61.9012	Prec@5 82.7617
Train: [40][5000/10010]	Time 0.582 (2909.824)	Data 0.001 (5.585)	Loss 1.656	Prec@1 61.8939	Prec@5 82.7492
Train: [40][5200/10010]	Time 0.582 (3025.577)	Data 0.001 (5.741)	Loss 1.657	Prec@1 61.8928	Prec@5 82.7431
Train: [40][5400/10010]	Time 0.582 (3141.677)	Data 0.001 (5.900)	Loss 1.657	Prec@1 61.8851	Prec@5 82.7353
Train: [40][5600/10010]	Time 0.582 (3257.359)	Data 0.001 (6.066)	Loss 1.658	Prec@1 61.8718	Prec@5 82.7086
Train: [40][5800/10010]	Time 0.581 (3372.998)	Data 0.001 (6.228)	Loss 1.659	Prec@1 61.8647	Prec@5 82.6867
Train: [40][6000/10010]	Time 0.581 (3488.614)	Data 0.001 (6.381)	Loss 1.660	Prec@1 61.8437	Prec@5 82.6739
Train: [40][6200/10010]	Time 0.581 (3604.510)	Data 0.001 (6.544)	Loss 1.661	Prec@1 61.8241	Prec@5 82.6661
Train: [40][6400/10010]	Time 0.581 (3720.329)	Data 0.001 (6.712)	Loss 1.662	Prec@1 61.8131	Prec@5 82.6581
Train: [40][6600/10010]	Time 0.581 (3836.446)	Data 0.001 (6.881)	Loss 1.662	Prec@1 61.8229	Prec@5 82.6506
Train: [40][6800/10010]	Time 0.581 (3952.426)	Data 0.001 (7.049)	Loss 1.663	Prec@1 61.7993	Prec@5 82.6316
Train: [40][7000/10010]	Time 0.581 (4068.139)	Data 0.001 (7.200)	Loss 1.663	Prec@1 61.8114	Prec@5 82.6431
Train: [40][7200/10010]	Time 0.581 (4183.793)	Data 0.001 (7.355)	Loss 1.663	Prec@1 61.8104	Prec@5 82.6447
Train: [40][7400/10010]	Time 0.581 (4299.305)	Data 0.001 (7.520)	Loss 1.663	Prec@1 61.7978	Prec@5 82.6368
Train: [40][7600/10010]	Time 0.581 (4415.357)	Data 0.001 (7.694)	Loss 1.663	Prec@1 61.7977	Prec@5 82.6316
Train: [40][7800/10010]	Time 0.581 (4531.594)	Data 0.001 (7.872)	Loss 1.663	Prec@1 61.7979	Prec@5 82.6368
Train: [40][8000/10010]	Time 0.581 (4647.564)	Data 0.001 (8.043)	Loss 1.664	Prec@1 61.7881	Prec@5 82.6282
Train: [40][8200/10010]	Time 0.581 (4763.695)	Data 0.001 (8.195)	Loss 1.664	Prec@1 61.7798	Prec@5 82.6234
Train: [40][8400/10010]	Time 0.581 (4880.049)	Data 0.001 (8.364)	Loss 1.664	Prec@1 61.7734	Prec@5 82.6145
Train: [40][8600/10010]	Time 0.581 (4997.030)	Data 0.001 (8.557)	Loss 1.665	Prec@1 61.7614	Prec@5 82.6103
Train: [40][8800/10010]	Time 0.581 (5114.320)	Data 0.001 (8.744)	Loss 1.665	Prec@1 61.7575	Prec@5 82.6088
Train: [40][9000/10010]	Time 0.581 (5231.246)	Data 0.001 (8.922)	Loss 1.666	Prec@1 61.7482	Prec@5 82.5971
Train: [40][9200/10010]	Time 0.581 (5348.330)	Data 0.001 (9.078)	Loss 1.666	Prec@1 61.7299	Prec@5 82.5887
Train: [40][9400/10010]	Time 0.581 (5465.492)	Data 0.001 (9.238)	Loss 1.667	Prec@1 61.7192	Prec@5 82.5798
Train: [40][9600/10010]	Time 0.581 (5582.492)	Data 0.001 (9.409)	Loss 1.667	Prec@1 61.7104	Prec@5 82.5784
Train: [40][9800/10010]	Time 0.582 (5699.309)	Data 0.001 (9.586)	Loss 1.667	Prec@1 61.7042	Prec@5 82.5728
Train: [40][10000/10010]	Time 0.582 (5816.172)	Data 0.001 (9.740)	Loss 1.668	Prec@1 61.6959	Prec@5 82.5685
Train: [40]	Time 5816.725	Data 9.740	Loss 1.668	Prec@1 61.6958	Prec@5 82.5688	
Val: [40]	Time 88.587	Data 1.596	Loss 1.363	Prec@1 67.3040	Prec@5 87.8300	
Best Prec@1: [67.304]	
Starting epoch number: 41 Learning rate: 0.010000000000000002
Train: [41][0/10010]	Time 2.411 (2.411)	Data 1.778 (1.778)	Loss 1.576	Prec@1 67.9688	Prec@5 82.8125
Train: [41][200/10010]	Time 0.593 (119.155)	Data 0.010 (1.939)	Loss 1.635	Prec@1 62.3951	Prec@5 83.0535
Train: [41][400/10010]	Time 0.590 (236.729)	Data 0.005 (2.098)	Loss 1.639	Prec@1 62.1766	Prec@5 83.0404
Train: [41][600/10010]	Time 0.589 (353.712)	Data 0.004 (2.256)	Loss 1.635	Prec@1 62.2049	Prec@5 83.0556
Train: [41][800/10010]	Time 0.588 (470.812)	Data 0.003 (2.431)	Loss 1.639	Prec@1 62.1567	Prec@5 82.9744
Train: [41][1000/10010]	Time 0.586 (586.676)	Data 0.003 (2.604)	Loss 1.640	Prec@1 62.2003	Prec@5 82.9389
Train: [41][1200/10010]	Time 0.585 (702.209)	Data 0.002 (2.771)	Loss 1.639	Prec@1 62.2470	Prec@5 82.9387
Train: [41][1400/10010]	Time 0.584 (817.627)	Data 0.002 (2.933)	Loss 1.640	Prec@1 62.2078	Prec@5 82.9363
Train: [41][1600/10010]	Time 0.583 (932.931)	Data 0.002 (3.099)	Loss 1.639	Prec@1 62.2111	Prec@5 82.9579
Train: [41][1800/10010]	Time 0.582 (1048.643)	Data 0.002 (3.239)	Loss 1.638	Prec@1 62.2332	Prec@5 82.9656
Train: [41][2000/10010]	Time 0.582 (1164.782)	Data 0.002 (3.403)	Loss 1.641	Prec@1 62.1752	Prec@5 82.8980
Train: [41][2200/10010]	Time 0.582 (1280.914)	Data 0.002 (3.571)	Loss 1.643	Prec@1 62.1529	Prec@5 82.8682
Train: [41][2400/10010]	Time 0.582 (1397.121)	Data 0.002 (3.731)	Loss 1.644	Prec@1 62.1352	Prec@5 82.8724
Train: [41][2600/10010]	Time 0.582 (1512.886)	Data 0.001 (3.889)	Loss 1.644	Prec@1 62.1318	Prec@5 82.8738
Train: [41][2800/10010]	Time 0.581 (1628.469)	Data 0.001 (4.036)	Loss 1.645	Prec@1 62.1023	Prec@5 82.8741
Train: [41][3000/10010]	Time 0.581 (1744.744)	Data 0.001 (4.192)	Loss 1.644	Prec@1 62.1223	Prec@5 82.8791
Train: [41][3200/10010]	Time 0.581 (1860.498)	Data 0.001 (4.346)	Loss 1.646	Prec@1 62.0685	Prec@5 82.8511
Train: [41][3400/10010]	Time 0.581 (1976.379)	Data 0.001 (4.506)	Loss 1.648	Prec@1 62.0112	Prec@5 82.8231
Train: [41][3600/10010]	Time 0.581 (2092.137)	Data 0.001 (4.707)	Loss 1.649	Prec@1 62.0001	Prec@5 82.8249
Train: [41][3800/10010]	Time 0.581 (2207.818)	Data 0.001 (4.871)	Loss 1.650	Prec@1 61.9857	Prec@5 82.8076
Train: [41][4000/10010]	Time 0.581 (2323.133)	Data 0.001 (5.057)	Loss 1.652	Prec@1 61.9562	Prec@5 82.7904
Train: [41][4200/10010]	Time 0.580 (2438.548)	Data 0.001 (5.232)	Loss 1.652	Prec@1 61.9622	Prec@5 82.7829
Train: [41][4400/10010]	Time 0.580 (2554.025)	Data 0.001 (5.399)	Loss 1.653	Prec@1 61.9481	Prec@5 82.7752
Train: [41][4600/10010]	Time 0.580 (2669.439)	Data 0.001 (5.557)	Loss 1.654	Prec@1 61.9364	Prec@5 82.7622
Train: [41][4800/10010]	Time 0.580 (2784.895)	Data 0.001 (5.718)	Loss 1.655	Prec@1 61.9314	Prec@5 82.7617
Train: [41][5000/10010]	Time 0.580 (2900.934)	Data 0.001 (5.884)	Loss 1.655	Prec@1 61.9145	Prec@5 82.7606
Train: [41][5200/10010]	Time 0.580 (3016.829)	Data 0.001 (6.049)	Loss 1.656	Prec@1 61.8928	Prec@5 82.7485
Train: [41][5400/10010]	Time 0.580 (3132.102)	Data 0.001 (6.238)	Loss 1.657	Prec@1 61.8961	Prec@5 82.7451
Train: [41][5600/10010]	Time 0.580 (3247.661)	Data 0.001 (6.424)	Loss 1.657	Prec@1 61.8676	Prec@5 82.7386
Train: [41][5800/10010]	Time 0.580 (3363.042)	Data 0.001 (6.601)	Loss 1.658	Prec@1 61.8622	Prec@5 82.7316
Train: [41][6000/10010]	Time 0.580 (3478.648)	Data 0.001 (6.784)	Loss 1.658	Prec@1 61.8601	Prec@5 82.7238
Train: [41][6200/10010]	Time 0.580 (3594.342)	Data 0.001 (6.965)	Loss 1.659	Prec@1 61.8486	Prec@5 82.7102
Train: [41][6400/10010]	Time 0.580 (3710.293)	Data 0.001 (7.130)	Loss 1.660	Prec@1 61.8434	Prec@5 82.6929
Train: [41][6600/10010]	Time 0.580 (3826.159)	Data 0.001 (7.314)	Loss 1.659	Prec@1 61.8523	Prec@5 82.6949
Train: [41][6800/10010]	Time 0.580 (3941.821)	Data 0.001 (7.496)	Loss 1.660	Prec@1 61.8497	Prec@5 82.6937
Train: [41][7000/10010]	Time 0.580 (4058.057)	Data 0.001 (7.659)	Loss 1.661	Prec@1 61.8363	Prec@5 82.6793
Train: [41][7200/10010]	Time 0.580 (4173.786)	Data 0.001 (7.840)	Loss 1.661	Prec@1 61.8212	Prec@5 82.6758
Train: [41][7400/10010]	Time 0.580 (4289.719)	Data 0.001 (8.027)	Loss 1.661	Prec@1 61.8128	Prec@5 82.6715
Train: [41][7600/10010]	Time 0.580 (4405.233)	Data 0.001 (8.209)	Loss 1.663	Prec@1 61.7740	Prec@5 82.6516
Train: [41][7800/10010]	Time 0.580 (4520.958)	Data 0.001 (8.380)	Loss 1.663	Prec@1 61.7704	Prec@5 82.6446
Train: [41][8000/10010]	Time 0.579 (4636.578)	Data 0.001 (8.533)	Loss 1.663	Prec@1 61.7679	Prec@5 82.6407
Train: [41][8200/10010]	Time 0.580 (4752.664)	Data 0.001 (8.672)	Loss 1.664	Prec@1 61.7637	Prec@5 82.6365
Train: [41][8400/10010]	Time 0.580 (4868.384)	Data 0.001 (8.831)	Loss 1.664	Prec@1 61.7596	Prec@5 82.6316
Train: [41][8600/10010]	Time 0.579 (4984.202)	Data 0.001 (9.007)	Loss 1.664	Prec@1 61.7515	Prec@5 82.6310
Train: [41][8800/10010]	Time 0.580 (5100.662)	Data 0.001 (9.187)	Loss 1.664	Prec@1 61.7543	Prec@5 82.6272
Train: [41][9000/10010]	Time 0.580 (5216.896)	Data 0.001 (9.382)	Loss 1.664	Prec@1 61.7496	Prec@5 82.6258
Train: [41][9200/10010]	Time 0.580 (5332.503)	Data 0.001 (9.555)	Loss 1.665	Prec@1 61.7345	Prec@5 82.6156
Train: [41][9400/10010]	Time 0.580 (5448.243)	Data 0.001 (9.694)	Loss 1.666	Prec@1 61.7265	Prec@5 82.6063
Train: [41][9600/10010]	Time 0.580 (5564.231)	Data 0.001 (9.888)	Loss 1.666	Prec@1 61.7258	Prec@5 82.6075
Train: [41][9800/10010]	Time 0.580 (5680.032)	Data 0.001 (10.060)	Loss 1.666	Prec@1 61.7215	Prec@5 82.5957
Train: [41][10000/10010]	Time 0.579 (5795.429)	Data 0.001 (10.244)	Loss 1.666	Prec@1 61.7249	Prec@5 82.5903
Train: [41]	Time 5795.992	Data 10.244	Loss 1.666	Prec@1 61.7246	Prec@5 82.5903	
Val: [41]	Time 88.134	Data 1.632	Loss 1.333	Prec@1 67.7980	Prec@5 88.2300	
Best Prec@1: [67.798]	
Starting epoch number: 42 Learning rate: 0.010000000000000002
Train: [42][0/10010]	Time 2.293 (2.293)	Data 1.670 (1.670)	Loss 1.727	Prec@1 64.8438	Prec@5 82.0312
Train: [42][200/10010]	Time 0.594 (119.414)	Data 0.009 (1.850)	Loss 1.623	Prec@1 62.4417	Prec@5 83.2362
Train: [42][400/10010]	Time 0.591 (236.893)	Data 0.005 (2.014)	Loss 1.635	Prec@1 62.2701	Prec@5 83.1398
Train: [42][600/10010]	Time 0.589 (354.082)	Data 0.004 (2.182)	Loss 1.629	Prec@1 62.3830	Prec@5 83.2077
Train: [42][800/10010]	Time 0.588 (471.357)	Data 0.003 (2.343)	Loss 1.640	Prec@1 62.1508	Prec@5 83.0680
Train: [42][1000/10010]	Time 0.588 (588.790)	Data 0.003 (2.517)	Loss 1.638	Prec@1 62.1738	Prec@5 83.0576
Train: [42][1200/10010]	Time 0.588 (705.721)	Data 0.002 (2.699)	Loss 1.635	Prec@1 62.2274	Prec@5 83.0734
Train: [42][1400/10010]	Time 0.587 (822.876)	Data 0.002 (2.867)	Loss 1.635	Prec@1 62.2686	Prec@5 83.0685
Train: [42][1600/10010]	Time 0.587 (939.788)	Data 0.002 (3.039)	Loss 1.638	Prec@1 62.2087	Prec@5 83.0121
Train: [42][1800/10010]	Time 0.587 (1057.122)	Data 0.002 (3.225)	Loss 1.637	Prec@1 62.2189	Prec@5 83.0168
Train: [42][2000/10010]	Time 0.587 (1174.187)	Data 0.002 (3.413)	Loss 1.640	Prec@1 62.1303	Prec@5 82.9761
Train: [42][2200/10010]	Time 0.587 (1290.963)	Data 0.002 (3.586)	Loss 1.639	Prec@1 62.1447	Prec@5 82.9847
Train: [42][2400/10010]	Time 0.587 (1408.701)	Data 0.002 (3.765)	Loss 1.640	Prec@1 62.1200	Prec@5 82.9713
Train: [42][2600/10010]	Time 0.587 (1525.578)	Data 0.002 (3.926)	Loss 1.640	Prec@1 62.1660	Prec@5 82.9726
Train: [42][2800/10010]	Time 0.587 (1642.983)	Data 0.001 (4.108)	Loss 1.642	Prec@1 62.1491	Prec@5 82.9481
Train: [42][3000/10010]	Time 0.586 (1760.080)	Data 0.001 (4.290)	Loss 1.642	Prec@1 62.1478	Prec@5 82.9515
Train: [42][3200/10010]	Time 0.586 (1877.241)	Data 0.001 (4.445)	Loss 1.643	Prec@1 62.1573	Prec@5 82.9358
Train: [42][3400/10010]	Time 0.587 (1994.737)	Data 0.001 (4.594)	Loss 1.643	Prec@1 62.1444	Prec@5 82.9320
Train: [42][3600/10010]	Time 0.586 (2111.906)	Data 0.001 (4.761)	Loss 1.644	Prec@1 62.1138	Prec@5 82.9260
Train: [42][3800/10010]	Time 0.586 (2228.950)	Data 0.001 (4.920)	Loss 1.644	Prec@1 62.1062	Prec@5 82.9210
Train: [42][4000/10010]	Time 0.586 (2346.096)	Data 0.001 (5.108)	Loss 1.644	Prec@1 62.1132	Prec@5 82.9017
Train: [42][4200/10010]	Time 0.586 (2463.457)	Data 0.001 (5.294)	Loss 1.644	Prec@1 62.1041	Prec@5 82.8882
Train: [42][4400/10010]	Time 0.586 (2580.951)	Data 0.001 (5.481)	Loss 1.646	Prec@1 62.0930	Prec@5 82.8785
Train: [42][4600/10010]	Time 0.586 (2698.030)	Data 0.001 (5.662)	Loss 1.647	Prec@1 62.0658	Prec@5 82.8546
Train: [42][4800/10010]	Time 0.586 (2814.924)	Data 0.001 (5.853)	Loss 1.648	Prec@1 62.0466	Prec@5 82.8454
Train: [42][5000/10010]	Time 0.586 (2931.930)	Data 0.001 (6.054)	Loss 1.649	Prec@1 62.0409	Prec@5 82.8397
Train: [42][5200/10010]	Time 0.586 (3048.401)	Data 0.001 (6.236)	Loss 1.650	Prec@1 61.9998	Prec@5 82.8179
Train: [42][5400/10010]	Time 0.586 (3163.889)	Data 0.001 (6.414)	Loss 1.651	Prec@1 61.9800	Prec@5 82.7990
Train: [42][5600/10010]	Time 0.586 (3279.924)	Data 0.001 (6.580)	Loss 1.652	Prec@1 61.9497	Prec@5 82.7818
Train: [42][5800/10010]	Time 0.585 (3396.094)	Data 0.001 (6.770)	Loss 1.652	Prec@1 61.9406	Prec@5 82.7850
Train: [42][6000/10010]	Time 0.585 (3512.111)	Data 0.001 (6.926)	Loss 1.653	Prec@1 61.9294	Prec@5 82.7872
Train: [42][6200/10010]	Time 0.585 (3628.297)	Data 0.001 (7.082)	Loss 1.653	Prec@1 61.9241	Prec@5 82.7773
Train: [42][6400/10010]	Time 0.585 (3744.310)	Data 0.001 (7.250)	Loss 1.653	Prec@1 61.9189	Prec@5 82.7726
Train: [42][6600/10010]	Time 0.585 (3860.099)	Data 0.001 (7.434)	Loss 1.654	Prec@1 61.9127	Prec@5 82.7674
Train: [42][6800/10010]	Time 0.585 (3975.840)	Data 0.001 (7.612)	Loss 1.655	Prec@1 61.8885	Prec@5 82.7570
Train: [42][7000/10010]	Time 0.584 (4091.540)	Data 0.001 (7.784)	Loss 1.655	Prec@1 61.8851	Prec@5 82.7539
Train: [42][7200/10010]	Time 0.584 (4206.984)	Data 0.001 (7.945)	Loss 1.656	Prec@1 61.8800	Prec@5 82.7487
Train: [42][7400/10010]	Time 0.584 (4322.455)	Data 0.001 (8.094)	Loss 1.656	Prec@1 61.8712	Prec@5 82.7386
Train: [42][7600/10010]	Time 0.584 (4438.248)	Data 0.001 (8.249)	Loss 1.657	Prec@1 61.8708	Prec@5 82.7314
Train: [42][7800/10010]	Time 0.584 (4554.494)	Data 0.001 (8.401)	Loss 1.657	Prec@1 61.8583	Prec@5 82.7241
Train: [42][8000/10010]	Time 0.584 (4670.701)	Data 0.001 (8.547)	Loss 1.657	Prec@1 61.8536	Prec@5 82.7246
Train: [42][8200/10010]	Time 0.584 (4786.426)	Data 0.001 (8.677)	Loss 1.657	Prec@1 61.8464	Prec@5 82.7193
Train: [42][8400/10010]	Time 0.584 (4901.996)	Data 0.001 (8.823)	Loss 1.658	Prec@1 61.8307	Prec@5 82.7109
Train: [42][8600/10010]	Time 0.583 (5018.064)	Data 0.001 (8.970)	Loss 1.658	Prec@1 61.8181	Prec@5 82.7045
Train: [42][8800/10010]	Time 0.583 (5133.829)	Data 0.001 (9.135)	Loss 1.659	Prec@1 61.8010	Prec@5 82.6929
Train: [42][9000/10010]	Time 0.583 (5249.547)	Data 0.001 (9.316)	Loss 1.660	Prec@1 61.7882	Prec@5 82.6833
Train: [42][9200/10010]	Time 0.583 (5365.872)	Data 0.001 (9.503)	Loss 1.660	Prec@1 61.7879	Prec@5 82.6829
Train: [42][9400/10010]	Time 0.583 (5481.650)	Data 0.001 (9.667)	Loss 1.660	Prec@1 61.7827	Prec@5 82.6731
Train: [42][9600/10010]	Time 0.583 (5597.214)	Data 0.001 (9.817)	Loss 1.661	Prec@1 61.7795	Prec@5 82.6694
Train: [42][9800/10010]	Time 0.583 (5712.976)	Data 0.001 (10.000)	Loss 1.661	Prec@1 61.7761	Prec@5 82.6666
Train: [42][10000/10010]	Time 0.583 (5828.972)	Data 0.001 (10.152)	Loss 1.662	Prec@1 61.7611	Prec@5 82.6533
Train: [42]	Time 5829.532	Data 10.152	Loss 1.662	Prec@1 61.7606	Prec@5 82.6528	
Val: [42]	Time 88.528	Data 1.704	Loss 1.357	Prec@1 67.5160	Prec@5 88.1540	
Best Prec@1: [67.798]	
Starting epoch number: 43 Learning rate: 0.010000000000000002
Train: [43][0/10010]	Time 2.364 (2.364)	Data 1.712 (1.712)	Loss 1.652	Prec@1 63.2812	Prec@5 82.0312
Train: [43][200/10010]	Time 0.597 (120.074)	Data 0.009 (1.877)	Loss 1.610	Prec@1 62.7410	Prec@5 83.4461
Train: [43][400/10010]	Time 0.592 (237.502)	Data 0.005 (2.034)	Loss 1.622	Prec@1 62.5682	Prec@5 83.3502
Train: [43][600/10010]	Time 0.591 (355.009)	Data 0.004 (2.196)	Loss 1.625	Prec@1 62.5559	Prec@5 83.4066
Train: [43][800/10010]	Time 0.590 (472.307)	Data 0.003 (2.355)	Loss 1.627	Prec@1 62.5302	Prec@5 83.3002
Train: [43][1000/10010]	Time 0.589 (589.623)	Data 0.003 (2.528)	Loss 1.629	Prec@1 62.4781	Prec@5 83.2176
Train: [43][1200/10010]	Time 0.588 (706.435)	Data 0.002 (2.699)	Loss 1.631	Prec@1 62.4154	Prec@5 83.1456
Train: [43][1400/10010]	Time 0.588 (823.349)	Data 0.002 (2.866)	Loss 1.628	Prec@1 62.5167	Prec@5 83.1962
Train: [43][1600/10010]	Time 0.587 (940.567)	Data 0.002 (3.029)	Loss 1.630	Prec@1 62.4571	Prec@5 83.1307
Train: [43][1800/10010]	Time 0.587 (1057.870)	Data 0.002 (3.198)	Loss 1.632	Prec@1 62.4523	Prec@5 83.1218
Train: [43][2000/10010]	Time 0.587 (1175.534)	Data 0.002 (3.347)	Loss 1.633	Prec@1 62.4086	Prec@5 83.0991
Train: [43][2200/10010]	Time 0.587 (1292.489)	Data 0.002 (3.520)	Loss 1.632	Prec@1 62.4066	Prec@5 83.1100
Train: [43][2400/10010]	Time 0.587 (1409.726)	Data 0.002 (3.702)	Loss 1.631	Prec@1 62.4206	Prec@5 83.1099
Train: [43][2600/10010]	Time 0.587 (1526.740)	Data 0.001 (3.857)	Loss 1.633	Prec@1 62.3772	Prec@5 83.0726
Train: [43][2800/10010]	Time 0.587 (1644.244)	Data 0.001 (4.031)	Loss 1.634	Prec@1 62.3706	Prec@5 83.0772
Train: [43][3000/10010]	Time 0.587 (1761.072)	Data 0.001 (4.207)	Loss 1.633	Prec@1 62.3545	Prec@5 83.0744
Train: [43][3200/10010]	Time 0.587 (1877.988)	Data 0.001 (4.370)	Loss 1.635	Prec@1 62.3296	Prec@5 83.0427
Train: [43][3400/10010]	Time 0.587 (1994.879)	Data 0.001 (4.535)	Loss 1.635	Prec@1 62.3151	Prec@5 83.0390
Train: [43][3600/10010]	Time 0.587 (2112.159)	Data 0.001 (4.722)	Loss 1.635	Prec@1 62.3184	Prec@5 83.0223
Train: [43][3800/10010]	Time 0.586 (2228.980)	Data 0.001 (4.897)	Loss 1.637	Prec@1 62.3002	Prec@5 82.9921
Train: [43][4000/10010]	Time 0.586 (2345.949)	Data 0.001 (5.072)	Loss 1.638	Prec@1 62.2860	Prec@5 82.9902
Train: [43][4200/10010]	Time 0.586 (2463.313)	Data 0.001 (5.243)	Loss 1.638	Prec@1 62.2731	Prec@5 82.9663
Train: [43][4400/10010]	Time 0.586 (2580.704)	Data 0.001 (5.410)	Loss 1.639	Prec@1 62.2550	Prec@5 82.9609
Train: [43][4600/10010]	Time 0.586 (2697.531)	Data 0.001 (5.577)	Loss 1.640	Prec@1 62.2431	Prec@5 82.9548
Train: [43][4800/10010]	Time 0.586 (2815.301)	Data 0.001 (5.738)	Loss 1.642	Prec@1 62.1931	Prec@5 82.9267
Train: [43][5000/10010]	Time 0.586 (2932.174)	Data 0.001 (5.915)	Loss 1.643	Prec@1 62.1782	Prec@5 82.9248
Train: [43][5200/10010]	Time 0.586 (3049.684)	Data 0.001 (6.067)	Loss 1.644	Prec@1 62.1536	Prec@5 82.9040
Train: [43][5400/10010]	Time 0.586 (3167.448)	Data 0.001 (6.236)	Loss 1.645	Prec@1 62.1346	Prec@5 82.9022
Train: [43][5600/10010]	Time 0.587 (3285.368)	Data 0.001 (6.401)	Loss 1.645	Prec@1 62.1390	Prec@5 82.9124
Train: [43][5800/10010]	Time 0.587 (3402.543)	Data 0.001 (6.568)	Loss 1.644	Prec@1 62.1406	Prec@5 82.9173
Train: [43][6000/10010]	Time 0.586 (3519.414)	Data 0.001 (6.742)	Loss 1.645	Prec@1 62.1426	Prec@5 82.8984
Train: [43][6200/10010]	Time 0.586 (3636.386)	Data 0.001 (6.906)	Loss 1.645	Prec@1 62.1484	Prec@5 82.9001
Train: [43][6400/10010]	Time 0.586 (3753.517)	Data 0.001 (7.087)	Loss 1.646	Prec@1 62.1203	Prec@5 82.8838
Train: [43][6600/10010]	Time 0.586 (3870.259)	Data 0.001 (7.272)	Loss 1.647	Prec@1 62.0898	Prec@5 82.8655
Train: [43][6800/10010]	Time 0.586 (3987.056)	Data 0.001 (7.468)	Loss 1.648	Prec@1 62.0660	Prec@5 82.8593
Train: [43][7000/10010]	Time 0.586 (4104.404)	Data 0.001 (7.643)	Loss 1.648	Prec@1 62.0511	Prec@5 82.8501
Train: [43][7200/10010]	Time 0.586 (4221.573)	Data 0.001 (7.827)	Loss 1.649	Prec@1 62.0396	Prec@5 82.8456
Train: [43][7400/10010]	Time 0.586 (4338.304)	Data 0.001 (8.002)	Loss 1.649	Prec@1 62.0409	Prec@5 82.8481
Train: [43][7600/10010]	Time 0.586 (4456.053)	Data 0.001 (8.184)	Loss 1.650	Prec@1 62.0246	Prec@5 82.8394
Train: [43][7800/10010]	Time 0.586 (4573.100)	Data 0.001 (8.358)	Loss 1.650	Prec@1 62.0211	Prec@5 82.8367
Train: [43][8000/10010]	Time 0.586 (4690.463)	Data 0.001 (8.530)	Loss 1.651	Prec@1 62.0088	Prec@5 82.8203
Train: [43][8200/10010]	Time 0.586 (4808.233)	Data 0.001 (8.706)	Loss 1.652	Prec@1 62.0002	Prec@5 82.8108
Train: [43][8400/10010]	Time 0.586 (4925.617)	Data 0.001 (8.871)	Loss 1.652	Prec@1 61.9922	Prec@5 82.7983
Train: [43][8600/10010]	Time 0.586 (5043.373)	Data 0.001 (9.038)	Loss 1.653	Prec@1 61.9764	Prec@5 82.7909
Train: [43][8800/10010]	Time 0.586 (5160.900)	Data 0.001 (9.201)	Loss 1.653	Prec@1 61.9633	Prec@5 82.7826
Train: [43][9000/10010]	Time 0.586 (5277.740)	Data 0.001 (9.360)	Loss 1.654	Prec@1 61.9514	Prec@5 82.7700
Train: [43][9200/10010]	Time 0.586 (5394.616)	Data 0.001 (9.525)	Loss 1.655	Prec@1 61.9428	Prec@5 82.7606
Train: [43][9400/10010]	Time 0.586 (5511.564)	Data 0.001 (9.687)	Loss 1.656	Prec@1 61.9208	Prec@5 82.7417
Train: [43][9600/10010]	Time 0.586 (5628.815)	Data 0.001 (9.857)	Loss 1.656	Prec@1 61.9117	Prec@5 82.7344
Train: [43][9800/10010]	Time 0.586 (5746.583)	Data 0.001 (10.030)	Loss 1.656	Prec@1 61.9005	Prec@5 82.7316
Train: [43][10000/10010]	Time 0.586 (5863.612)	Data 0.001 (10.181)	Loss 1.657	Prec@1 61.8939	Prec@5 82.7245
Train: [43]	Time 5864.173	Data 10.182	Loss 1.657	Prec@1 61.8932	Prec@5 82.7241	
Val: [43]	Time 88.184	Data 1.605	Loss 1.352	Prec@1 67.4260	Prec@5 88.2800	
Best Prec@1: [67.798]	
Starting epoch number: 44 Learning rate: 0.010000000000000002
Train: [44][0/10010]	Time 2.398 (2.398)	Data 1.790 (1.790)	Loss 1.930	Prec@1 57.0312	Prec@5 79.6875
Train: [44][200/10010]	Time 0.592 (118.963)	Data 0.010 (1.932)	Loss 1.600	Prec@1 63.0442	Prec@5 83.8930
Train: [44][400/10010]	Time 0.589 (236.328)	Data 0.005 (2.096)	Loss 1.614	Prec@1 62.7299	Prec@5 83.4827
Train: [44][600/10010]	Time 0.588 (353.614)	Data 0.004 (2.271)	Loss 1.623	Prec@1 62.6157	Prec@5 83.2168
Train: [44][800/10010]	Time 0.587 (470.495)	Data 0.003 (2.438)	Loss 1.623	Prec@1 62.6375	Prec@5 83.2787
Train: [44][1000/10010]	Time 0.587 (587.509)	Data 0.003 (2.593)	Loss 1.623	Prec@1 62.6561	Prec@5 83.2410
Train: [44][1200/10010]	Time 0.587 (704.565)	Data 0.002 (2.749)	Loss 1.623	Prec@1 62.6451	Prec@5 83.2230
Train: [44][1400/10010]	Time 0.586 (821.362)	Data 0.002 (2.907)	Loss 1.626	Prec@1 62.6277	Prec@5 83.1973
Train: [44][1600/10010]	Time 0.586 (937.678)	Data 0.002 (3.083)	Loss 1.628	Prec@1 62.6039	Prec@5 83.1682
Train: [44][1800/10010]	Time 0.586 (1054.732)	Data 0.002 (3.249)	Loss 1.630	Prec@1 62.5711	Prec@5 83.1201
Train: [44][2000/10010]	Time 0.586 (1171.661)	Data 0.002 (3.425)	Loss 1.630	Prec@1 62.5672	Prec@5 83.1135
Train: [44][2200/10010]	Time 0.586 (1288.883)	Data 0.002 (3.594)	Loss 1.631	Prec@1 62.5792	Prec@5 83.1011
Train: [44][2400/10010]	Time 0.585 (1404.272)	Data 0.002 (3.751)	Loss 1.631	Prec@1 62.5654	Prec@5 83.1021
Train: [44][2600/10010]	Time 0.584 (1519.826)	Data 0.002 (3.903)	Loss 1.632	Prec@1 62.5339	Prec@5 83.0960
Train: [44][2800/10010]	Time 0.584 (1635.778)	Data 0.001 (4.086)	Loss 1.633	Prec@1 62.4746	Prec@5 83.0764
Train: [44][3000/10010]	Time 0.584 (1751.620)	Data 0.001 (4.255)	Loss 1.633	Prec@1 62.4485	Prec@5 83.0947
Train: [44][3200/10010]	Time 0.583 (1867.413)	Data 0.001 (4.429)	Loss 1.634	Prec@1 62.4253	Prec@5 83.0832
Train: [44][3400/10010]	Time 0.583 (1983.544)	Data 0.001 (4.580)	Loss 1.635	Prec@1 62.3828	Prec@5 83.0597
Train: [44][3600/10010]	Time 0.583 (2099.583)	Data 0.001 (4.735)	Loss 1.636	Prec@1 62.3553	Prec@5 83.0514
Train: [44][3800/10010]	Time 0.583 (2215.732)	Data 0.001 (4.893)	Loss 1.636	Prec@1 62.3389	Prec@5 83.0443
Train: [44][4000/10010]	Time 0.583 (2331.949)	Data 0.001 (5.045)	Loss 1.636	Prec@1 62.3332	Prec@5 83.0488
Train: [44][4200/10010]	Time 0.583 (2447.949)	Data 0.001 (5.205)	Loss 1.637	Prec@1 62.3148	Prec@5 83.0319
Train: [44][4400/10010]	Time 0.583 (2563.937)	Data 0.001 (5.373)	Loss 1.638	Prec@1 62.3033	Prec@5 83.0133
Train: [44][4600/10010]	Time 0.583 (2680.560)	Data 0.001 (5.523)	Loss 1.639	Prec@1 62.2935	Prec@5 83.0066
Train: [44][4800/10010]	Time 0.583 (2796.776)	Data 0.001 (5.677)	Loss 1.639	Prec@1 62.2968	Prec@5 83.0100
Train: [44][5000/10010]	Time 0.582 (2912.629)	Data 0.001 (5.816)	Loss 1.639	Prec@1 62.2724	Prec@5 83.0087
Train: [44][5200/10010]	Time 0.582 (3028.587)	Data 0.001 (5.996)	Loss 1.640	Prec@1 62.2299	Prec@5 82.9788
Train: [44][5400/10010]	Time 0.582 (3144.503)	Data 0.001 (6.161)	Loss 1.641	Prec@1 62.2163	Prec@5 82.9751
Train: [44][5600/10010]	Time 0.582 (3259.647)	Data 0.001 (6.304)	Loss 1.641	Prec@1 62.2000	Prec@5 82.9648
Train: [44][5800/10010]	Time 0.582 (3375.543)	Data 0.001 (6.459)	Loss 1.641	Prec@1 62.2051	Prec@5 82.9788
Train: [44][6000/10010]	Time 0.582 (3491.608)	Data 0.001 (6.610)	Loss 1.641	Prec@1 62.1905	Prec@5 82.9696
Train: [44][6200/10010]	Time 0.582 (3608.811)	Data 0.001 (6.773)	Loss 1.642	Prec@1 62.1713	Prec@5 82.9552
Train: [44][6400/10010]	Time 0.582 (3725.380)	Data 0.001 (6.936)	Loss 1.643	Prec@1 62.1567	Prec@5 82.9437
Train: [44][6600/10010]	Time 0.582 (3841.499)	Data 0.001 (7.088)	Loss 1.643	Prec@1 62.1565	Prec@5 82.9443
Train: [44][6800/10010]	Time 0.582 (3957.693)	Data 0.001 (7.250)	Loss 1.644	Prec@1 62.1486	Prec@5 82.9304
Train: [44][7000/10010]	Time 0.582 (4074.034)	Data 0.001 (7.410)	Loss 1.643	Prec@1 62.1611	Prec@5 82.9379
Train: [44][7200/10010]	Time 0.582 (4190.565)	Data 0.001 (7.568)	Loss 1.644	Prec@1 62.1478	Prec@5 82.9199
Train: [44][7400/10010]	Time 0.582 (4306.721)	Data 0.001 (7.731)	Loss 1.644	Prec@1 62.1357	Prec@5 82.9208
Train: [44][7600/10010]	Time 0.582 (4423.349)	Data 0.001 (7.885)	Loss 1.645	Prec@1 62.1310	Prec@5 82.9124
Train: [44][7800/10010]	Time 0.582 (4540.102)	Data 0.001 (8.048)	Loss 1.646	Prec@1 62.1044	Prec@5 82.9010
Train: [44][8000/10010]	Time 0.582 (4656.471)	Data 0.001 (8.214)	Loss 1.645	Prec@1 62.1169	Prec@5 82.9088
Train: [44][8200/10010]	Time 0.582 (4773.100)	Data 0.001 (8.387)	Loss 1.646	Prec@1 62.0984	Prec@5 82.8939
Train: [44][8400/10010]	Time 0.582 (4889.924)	Data 0.001 (8.555)	Loss 1.646	Prec@1 62.0882	Prec@5 82.8901
Train: [44][8600/10010]	Time 0.582 (5007.185)	Data 0.001 (8.730)	Loss 1.647	Prec@1 62.0663	Prec@5 82.8869
Train: [44][8800/10010]	Time 0.582 (5124.812)	Data 0.001 (8.897)	Loss 1.647	Prec@1 62.0637	Prec@5 82.8836
Train: [44][9000/10010]	Time 0.582 (5241.962)	Data 0.001 (9.069)	Loss 1.647	Prec@1 62.0665	Prec@5 82.8881
Train: [44][9200/10010]	Time 0.582 (5359.149)	Data 0.001 (9.238)	Loss 1.647	Prec@1 62.0536	Prec@5 82.8747
Train: [44][9400/10010]	Time 0.583 (5476.578)	Data 0.001 (9.403)	Loss 1.647	Prec@1 62.0509	Prec@5 82.8720
Train: [44][9600/10010]	Time 0.583 (5594.124)	Data 0.001 (9.606)	Loss 1.648	Prec@1 62.0368	Prec@5 82.8571
Train: [44][9800/10010]	Time 0.583 (5712.001)	Data 0.001 (9.786)	Loss 1.648	Prec@1 62.0276	Prec@5 82.8547
Train: [44][10000/10010]	Time 0.583 (5829.305)	Data 0.001 (9.947)	Loss 1.648	Prec@1 62.0283	Prec@5 82.8526
Train: [44]	Time 5829.856	Data 9.947	Loss 1.649	Prec@1 62.0278	Prec@5 82.8521	
Val: [44]	Time 87.437	Data 1.499	Loss 1.339	Prec@1 67.6580	Prec@5 88.3340	
Best Prec@1: [67.798]	
Starting epoch number: 45 Learning rate: 0.010000000000000002
Train: [45][0/10010]	Time 2.268 (2.268)	Data 1.515 (1.515)	Loss 1.626	Prec@1 61.7188	Prec@5 81.2500
Train: [45][200/10010]	Time 0.593 (119.162)	Data 0.008 (1.668)	Loss 1.613	Prec@1 62.6244	Prec@5 83.3372
Train: [45][400/10010]	Time 0.588 (235.746)	Data 0.005 (1.827)	Loss 1.627	Prec@1 62.5994	Prec@5 83.1593
Train: [45][600/10010]	Time 0.585 (351.825)	Data 0.003 (2.000)	Loss 1.621	Prec@1 62.5858	Prec@5 83.2532
Train: [45][800/10010]	Time 0.584 (467.507)	Data 0.003 (2.175)	Loss 1.622	Prec@1 62.6034	Prec@5 83.2865
Train: [45][1000/10010]	Time 0.583 (583.601)	Data 0.002 (2.341)	Loss 1.624	Prec@1 62.6272	Prec@5 83.2098
Train: [45][1200/10010]	Time 0.582 (699.207)	Data 0.002 (2.512)	Loss 1.625	Prec@1 62.5520	Prec@5 83.1560
Train: [45][1400/10010]	Time 0.582 (815.245)	Data 0.002 (2.684)	Loss 1.622	Prec@1 62.6210	Prec@5 83.1911
Train: [45][1600/10010]	Time 0.582 (931.259)	Data 0.002 (2.850)	Loss 1.623	Prec@1 62.6035	Prec@5 83.2078
Train: [45][1800/10010]	Time 0.582 (1048.372)	Data 0.002 (3.013)	Loss 1.625	Prec@1 62.5108	Prec@5 83.1817
Train: [45][2000/10010]	Time 0.582 (1164.404)	Data 0.002 (3.175)	Loss 1.625	Prec@1 62.4973	Prec@5 83.1740
Train: [45][2200/10010]	Time 0.582 (1280.602)	Data 0.002 (3.324)	Loss 1.626	Prec@1 62.4752	Prec@5 83.1401
Train: [45][2400/10010]	Time 0.582 (1397.012)	Data 0.001 (3.510)	Loss 1.626	Prec@1 62.4610	Prec@5 83.1467
Train: [45][2600/10010]	Time 0.582 (1513.154)	Data 0.001 (3.691)	Loss 1.627	Prec@1 62.4150	Prec@5 83.1480
Train: [45][2800/10010]	Time 0.582 (1629.216)	Data 0.001 (3.854)	Loss 1.627	Prec@1 62.4096	Prec@5 83.1452
Train: [45][3000/10010]	Time 0.582 (1745.319)	Data 0.001 (4.029)	Loss 1.628	Prec@1 62.4112	Prec@5 83.1554
Train: [45][3200/10010]	Time 0.582 (1861.661)	Data 0.001 (4.209)	Loss 1.630	Prec@1 62.3797	Prec@5 83.1064
Train: [45][3400/10010]	Time 0.582 (1978.147)	Data 0.001 (4.399)	Loss 1.629	Prec@1 62.3872	Prec@5 83.1208
Train: [45][3600/10010]	Time 0.582 (2094.405)	Data 0.001 (4.588)	Loss 1.631	Prec@1 62.3325	Prec@5 83.1024
Train: [45][3800/10010]	Time 0.582 (2210.858)	Data 0.001 (4.769)	Loss 1.631	Prec@1 62.3234	Prec@5 83.0916
Train: [45][4000/10010]	Time 0.582 (2326.812)	Data 0.001 (4.942)	Loss 1.631	Prec@1 62.3274	Prec@5 83.0925
Train: [45][4200/10010]	Time 0.581 (2442.864)	Data 0.001 (5.124)	Loss 1.632	Prec@1 62.2854	Prec@5 83.0771
Train: [45][4400/10010]	Time 0.581 (2559.009)	Data 0.001 (5.293)	Loss 1.632	Prec@1 62.3191	Prec@5 83.0882
Train: [45][4600/10010]	Time 0.581 (2674.994)	Data 0.001 (5.486)	Loss 1.632	Prec@1 62.3200	Prec@5 83.0810
Train: [45][4800/10010]	Time 0.581 (2791.477)	Data 0.001 (5.691)	Loss 1.633	Prec@1 62.2981	Prec@5 83.0716
Train: [45][5000/10010]	Time 0.581 (2907.753)	Data 0.001 (5.868)	Loss 1.634	Prec@1 62.2729	Prec@5 83.0600
Train: [45][5200/10010]	Time 0.582 (3024.775)	Data 0.001 (6.044)	Loss 1.635	Prec@1 62.2606	Prec@5 83.0613
Train: [45][5400/10010]	Time 0.582 (3141.420)	Data 0.001 (6.232)	Loss 1.635	Prec@1 62.2443	Prec@5 83.0574
Train: [45][5600/10010]	Time 0.582 (3258.050)	Data 0.001 (6.393)	Loss 1.635	Prec@1 62.2527	Prec@5 83.0605
Train: [45][5800/10010]	Time 0.582 (3374.686)	Data 0.001 (6.570)	Loss 1.636	Prec@1 62.2426	Prec@5 83.0518
Train: [45][6000/10010]	Time 0.582 (3491.317)	Data 0.001 (6.752)	Loss 1.636	Prec@1 62.2323	Prec@5 83.0408
Train: [45][6200/10010]	Time 0.582 (3607.860)	Data 0.001 (6.946)	Loss 1.637	Prec@1 62.2090	Prec@5 83.0204
Train: [45][6400/10010]	Time 0.582 (3724.255)	Data 0.001 (7.101)	Loss 1.638	Prec@1 62.1988	Prec@5 83.0121
Train: [45][6600/10010]	Time 0.582 (3840.774)	Data 0.001 (7.255)	Loss 1.638	Prec@1 62.1991	Prec@5 83.0072
Train: [45][6800/10010]	Time 0.582 (3956.900)	Data 0.001 (7.431)	Loss 1.638	Prec@1 62.1865	Prec@5 82.9937
Train: [45][7000/10010]	Time 0.582 (4073.389)	Data 0.001 (7.622)	Loss 1.638	Prec@1 62.1768	Prec@5 82.9943
Train: [45][7200/10010]	Time 0.582 (4189.956)	Data 0.001 (7.792)	Loss 1.639	Prec@1 62.1693	Prec@5 82.9847
Train: [45][7400/10010]	Time 0.582 (4306.665)	Data 0.001 (7.988)	Loss 1.639	Prec@1 62.1732	Prec@5 82.9783
Train: [45][7600/10010]	Time 0.582 (4422.978)	Data 0.001 (8.143)	Loss 1.640	Prec@1 62.1488	Prec@5 82.9642
Train: [45][7800/10010]	Time 0.582 (4539.619)	Data 0.001 (8.321)	Loss 1.640	Prec@1 62.1429	Prec@5 82.9570
Train: [45][8000/10010]	Time 0.582 (4656.414)	Data 0.001 (8.500)	Loss 1.640	Prec@1 62.1378	Prec@5 82.9547
Train: [45][8200/10010]	Time 0.582 (4772.904)	Data 0.001 (8.671)	Loss 1.641	Prec@1 62.1287	Prec@5 82.9541
Train: [45][8400/10010]	Time 0.582 (4889.841)	Data 0.001 (8.838)	Loss 1.641	Prec@1 62.1174	Prec@5 82.9484
Train: [45][8600/10010]	Time 0.582 (5006.839)	Data 0.001 (9.012)	Loss 1.640	Prec@1 62.1281	Prec@5 82.9527
Train: [45][8800/10010]	Time 0.582 (5122.933)	Data 0.001 (9.206)	Loss 1.641	Prec@1 62.1128	Prec@5 82.9424
Train: [45][9000/10010]	Time 0.582 (5239.223)	Data 0.001 (9.369)	Loss 1.642	Prec@1 62.0968	Prec@5 82.9320
Train: [45][9200/10010]	Time 0.582 (5355.424)	Data 0.001 (9.537)	Loss 1.642	Prec@1 62.0974	Prec@5 82.9289
Train: [45][9400/10010]	Time 0.582 (5472.065)	Data 0.001 (9.703)	Loss 1.642	Prec@1 62.0906	Prec@5 82.9319
Train: [45][9600/10010]	Time 0.582 (5588.142)	Data 0.001 (9.871)	Loss 1.642	Prec@1 62.0852	Prec@5 82.9267
Train: [45][9800/10010]	Time 0.582 (5704.041)	Data 0.001 (10.032)	Loss 1.643	Prec@1 62.0758	Prec@5 82.9198
Train: [45][10000/10010]	Time 0.582 (5819.909)	Data 0.001 (10.174)	Loss 1.644	Prec@1 62.0709	Prec@5 82.9089
Train: [45]	Time 5820.526	Data 10.174	Loss 1.644	Prec@1 62.0710	Prec@5 82.9090	
Val: [45]	Time 88.177	Data 1.664	Loss 1.340	Prec@1 67.8400	Prec@5 88.3400	
Best Prec@1: [67.840]	
Starting epoch number: 46 Learning rate: 0.010000000000000002
Train: [46][0/10010]	Time 2.163 (2.163)	Data 1.474 (1.474)	Loss 1.423	Prec@1 65.6250	Prec@5 88.2812
Train: [46][200/10010]	Time 0.593 (119.256)	Data 0.008 (1.627)	Loss 1.600	Prec@1 62.8770	Prec@5 83.5393
Train: [46][400/10010]	Time 0.589 (236.190)	Data 0.004 (1.796)	Loss 1.605	Prec@1 62.7357	Prec@5 83.5080
Train: [46][600/10010]	Time 0.588 (353.220)	Data 0.003 (1.956)	Loss 1.610	Prec@1 62.7314	Prec@5 83.2935
Train: [46][800/10010]	Time 0.587 (470.389)	Data 0.003 (2.110)	Loss 1.610	Prec@1 62.8209	Prec@5 83.3187
Train: [46][1000/10010]	Time 0.587 (587.895)	Data 0.002 (2.280)	Loss 1.608	Prec@1 62.8216	Prec@5 83.3659
Train: [46][1200/10010]	Time 0.587 (704.933)	Data 0.002 (2.423)	Loss 1.611	Prec@1 62.7439	Prec@5 83.3388
Train: [46][1400/10010]	Time 0.587 (822.249)	Data 0.002 (2.591)	Loss 1.613	Prec@1 62.7225	Prec@5 83.3194
Train: [46][1600/10010]	Time 0.587 (939.354)	Data 0.002 (2.764)	Loss 1.612	Prec@1 62.7835	Prec@5 83.3429
Train: [46][1800/10010]	Time 0.587 (1056.877)	Data 0.002 (2.936)	Loss 1.614	Prec@1 62.7260	Prec@5 83.3222
Train: [46][2000/10010]	Time 0.587 (1173.674)	Data 0.002 (3.109)	Loss 1.616	Prec@1 62.7058	Prec@5 83.3181
Train: [46][2200/10010]	Time 0.587 (1290.918)	Data 0.001 (3.278)	Loss 1.618	Prec@1 62.6381	Prec@5 83.3041
Train: [46][2400/10010]	Time 0.587 (1408.269)	Data 0.001 (3.437)	Loss 1.620	Prec@1 62.6272	Prec@5 83.2706
Train: [46][2600/10010]	Time 0.586 (1525.231)	Data 0.001 (3.617)	Loss 1.620	Prec@1 62.6162	Prec@5 83.2664
Train: [46][2800/10010]	Time 0.586 (1642.183)	Data 0.001 (3.791)	Loss 1.621	Prec@1 62.5881	Prec@5 83.2420
Train: [46][3000/10010]	Time 0.586 (1759.430)	Data 0.001 (3.963)	Loss 1.621	Prec@1 62.5651	Prec@5 83.2350
Train: [46][3200/10010]	Time 0.586 (1876.627)	Data 0.001 (4.123)	Loss 1.623	Prec@1 62.5164	Prec@5 83.1981
Train: [46][3400/10010]	Time 0.586 (1994.030)	Data 0.001 (4.268)	Loss 1.623	Prec@1 62.5165	Prec@5 83.2067
Train: [46][3600/10010]	Time 0.586 (2111.389)	Data 0.001 (4.424)	Loss 1.625	Prec@1 62.4905	Prec@5 83.1750
Train: [46][3800/10010]	Time 0.586 (2228.716)	Data 0.001 (4.574)	Loss 1.626	Prec@1 62.4852	Prec@5 83.1695
Train: [46][4000/10010]	Time 0.586 (2345.817)	Data 0.001 (4.718)	Loss 1.626	Prec@1 62.4551	Prec@5 83.1595
Train: [46][4200/10010]	Time 0.586 (2463.120)	Data 0.001 (4.873)	Loss 1.627	Prec@1 62.4360	Prec@5 83.1402
Train: [46][4400/10010]	Time 0.586 (2580.432)	Data 0.001 (5.015)	Loss 1.627	Prec@1 62.4240	Prec@5 83.1338
Train: [46][4600/10010]	Time 0.586 (2697.728)	Data 0.001 (5.168)	Loss 1.628	Prec@1 62.4002	Prec@5 83.1343
Train: [46][4800/10010]	Time 0.586 (2815.158)	Data 0.001 (5.336)	Loss 1.629	Prec@1 62.3802	Prec@5 83.1135
Train: [46][5000/10010]	Time 0.586 (2932.777)	Data 0.001 (5.520)	Loss 1.629	Prec@1 62.3658	Prec@5 83.1093
Train: [46][5200/10010]	Time 0.586 (3050.264)	Data 0.001 (5.702)	Loss 1.629	Prec@1 62.3834	Prec@5 83.1086
Train: [46][5400/10010]	Time 0.586 (3167.461)	Data 0.001 (5.864)	Loss 1.629	Prec@1 62.3743	Prec@5 83.0973
Train: [46][5600/10010]	Time 0.586 (3284.942)	Data 0.001 (6.018)	Loss 1.630	Prec@1 62.3729	Prec@5 83.0940
Train: [46][5800/10010]	Time 0.586 (3402.192)	Data 0.001 (6.167)	Loss 1.630	Prec@1 62.3605	Prec@5 83.0801
Train: [46][6000/10010]	Time 0.586 (3519.336)	Data 0.001 (6.354)	Loss 1.631	Prec@1 62.3517	Prec@5 83.0746
Train: [46][6200/10010]	Time 0.586 (3636.530)	Data 0.001 (6.532)	Loss 1.630	Prec@1 62.3720	Prec@5 83.0816
Train: [46][6400/10010]	Time 0.586 (3753.805)	Data 0.001 (6.699)	Loss 1.631	Prec@1 62.3501	Prec@5 83.0733
Train: [46][6600/10010]	Time 0.586 (3871.162)	Data 0.001 (6.856)	Loss 1.631	Prec@1 62.3508	Prec@5 83.0685
Train: [46][6800/10010]	Time 0.586 (3988.409)	Data 0.001 (7.004)	Loss 1.632	Prec@1 62.3491	Prec@5 83.0627
Train: [46][7000/10010]	Time 0.586 (4105.994)	Data 0.001 (7.178)	Loss 1.633	Prec@1 62.3234	Prec@5 83.0459
Train: [46][7200/10010]	Time 0.586 (4223.050)	Data 0.001 (7.361)	Loss 1.634	Prec@1 62.3153	Prec@5 83.0371
Train: [46][7400/10010]	Time 0.586 (4340.088)	Data 0.001 (7.531)	Loss 1.634	Prec@1 62.3172	Prec@5 83.0305
Train: [46][7600/10010]	Time 0.586 (4457.197)	Data 0.001 (7.693)	Loss 1.635	Prec@1 62.2925	Prec@5 83.0197
Train: [46][7800/10010]	Time 0.586 (4574.637)	Data 0.001 (7.873)	Loss 1.636	Prec@1 62.2760	Prec@5 83.0162
Train: [46][8000/10010]	Time 0.586 (4691.759)	Data 0.001 (8.050)	Loss 1.636	Prec@1 62.2775	Prec@5 83.0201
Train: [46][8200/10010]	Time 0.586 (4809.488)	Data 0.001 (8.223)	Loss 1.636	Prec@1 62.2749	Prec@5 83.0154
Train: [46][8400/10010]	Time 0.586 (4926.782)	Data 0.001 (8.396)	Loss 1.636	Prec@1 62.2764	Prec@5 83.0193
Train: [46][8600/10010]	Time 0.586 (5043.973)	Data 0.001 (8.573)	Loss 1.636	Prec@1 62.2617	Prec@5 83.0196
Train: [46][8800/10010]	Time 0.586 (5161.357)	Data 0.001 (8.765)	Loss 1.637	Prec@1 62.2506	Prec@5 83.0112
Train: [46][9000/10010]	Time 0.586 (5278.791)	Data 0.001 (8.921)	Loss 1.637	Prec@1 62.2449	Prec@5 83.0078
Train: [46][9200/10010]	Time 0.586 (5396.226)	Data 0.001 (9.070)	Loss 1.637	Prec@1 62.2403	Prec@5 83.0069
Train: [46][9400/10010]	Time 0.586 (5513.472)	Data 0.001 (9.208)	Loss 1.638	Prec@1 62.2251	Prec@5 82.9996
Train: [46][9600/10010]	Time 0.586 (5630.601)	Data 0.001 (9.355)	Loss 1.638	Prec@1 62.2197	Prec@5 82.9943
Train: [46][9800/10010]	Time 0.586 (5747.653)	Data 0.001 (9.502)	Loss 1.639	Prec@1 62.2020	Prec@5 82.9837
Train: [46][10000/10010]	Time 0.586 (5864.806)	Data 0.001 (9.650)	Loss 1.639	Prec@1 62.1993	Prec@5 82.9820
Train: [46]	Time 5865.355	Data 9.650	Loss 1.639	Prec@1 62.1994	Prec@5 82.9818	
Val: [46]	Time 87.556	Data 1.464	Loss 1.367	Prec@1 67.1000	Prec@5 88.0980	
Best Prec@1: [67.840]	
Starting epoch number: 47 Learning rate: 0.010000000000000002
Train: [47][0/10010]	Time 2.073 (2.073)	Data 1.455 (1.455)	Loss 1.538	Prec@1 58.5938	Prec@5 84.3750
Train: [47][200/10010]	Time 0.593 (119.198)	Data 0.008 (1.596)	Loss 1.592	Prec@1 63.3551	Prec@5 83.6015
Train: [47][400/10010]	Time 0.590 (236.541)	Data 0.004 (1.753)	Loss 1.600	Prec@1 63.0260	Prec@5 83.4204
Train: [47][600/10010]	Time 0.589 (354.063)	Data 0.003 (1.907)	Loss 1.603	Prec@1 62.8796	Prec@5 83.4326
Train: [47][800/10010]	Time 0.588 (471.386)	Data 0.003 (2.048)	Loss 1.608	Prec@1 62.8248	Prec@5 83.4543
Train: [47][1000/10010]	Time 0.588 (588.823)	Data 0.002 (2.194)	Loss 1.609	Prec@1 62.7857	Prec@5 83.4525
Train: [47][1200/10010]	Time 0.588 (706.135)	Data 0.002 (2.341)	Loss 1.607	Prec@1 62.8363	Prec@5 83.4845
Train: [47][1400/10010]	Time 0.588 (823.415)	Data 0.002 (2.480)	Loss 1.607	Prec@1 62.8346	Prec@5 83.4672
Train: [47][1600/10010]	Time 0.588 (940.693)	Data 0.002 (2.630)	Loss 1.608	Prec@1 62.8548	Prec@5 83.4513
Train: [47][1800/10010]	Time 0.587 (1057.563)	Data 0.002 (2.775)	Loss 1.608	Prec@1 62.8618	Prec@5 83.4445
Train: [47][2000/10010]	Time 0.587 (1174.951)	Data 0.001 (2.930)	Loss 1.609	Prec@1 62.8362	Prec@5 83.4594
Train: [47][2200/10010]	Time 0.587 (1291.811)	Data 0.001 (3.087)	Loss 1.612	Prec@1 62.7687	Prec@5 83.3943
Train: [47][2400/10010]	Time 0.587 (1408.793)	Data 0.001 (3.258)	Loss 1.610	Prec@1 62.7880	Prec@5 83.4193
Train: [47][2600/10010]	Time 0.587 (1526.263)	Data 0.001 (3.421)	Loss 1.611	Prec@1 62.7802	Prec@5 83.4234
Train: [47][2800/10010]	Time 0.587 (1643.848)	Data 0.001 (3.580)	Loss 1.611	Prec@1 62.7711	Prec@5 83.4055
Train: [47][3000/10010]	Time 0.587 (1761.394)	Data 0.001 (3.749)	Loss 1.613	Prec@1 62.7398	Prec@5 83.3675
Train: [47][3200/10010]	Time 0.587 (1878.807)	Data 0.001 (3.924)	Loss 1.614	Prec@1 62.7204	Prec@5 83.3575
Train: [47][3400/10010]	Time 0.587 (1996.494)	Data 0.001 (4.092)	Loss 1.615	Prec@1 62.6831	Prec@5 83.3385
Train: [47][3600/10010]	Time 0.587 (2114.431)	Data 0.001 (4.274)	Loss 1.616	Prec@1 62.6430	Prec@5 83.3061
Train: [47][3800/10010]	Time 0.587 (2231.723)	Data 0.001 (4.466)	Loss 1.617	Prec@1 62.6287	Prec@5 83.3007
Train: [47][4000/10010]	Time 0.587 (2348.925)	Data 0.001 (4.644)	Loss 1.618	Prec@1 62.6138	Prec@5 83.2905
Train: [47][4200/10010]	Time 0.587 (2466.604)	Data 0.001 (4.820)	Loss 1.618	Prec@1 62.6114	Prec@5 83.2832
Train: [47][4400/10010]	Time 0.587 (2583.581)	Data 0.001 (4.971)	Loss 1.619	Prec@1 62.6204	Prec@5 83.2792
Train: [47][4600/10010]	Time 0.587 (2699.729)	Data 0.001 (5.113)	Loss 1.619	Prec@1 62.6133	Prec@5 83.2696
Train: [47][4800/10010]	Time 0.587 (2815.991)	Data 0.001 (5.286)	Loss 1.620	Prec@1 62.5991	Prec@5 83.2590
Train: [47][5000/10010]	Time 0.586 (2932.746)	Data 0.001 (5.470)	Loss 1.621	Prec@1 62.5715	Prec@5 83.2437
Train: [47][5200/10010]	Time 0.586 (3049.011)	Data 0.001 (5.672)	Loss 1.622	Prec@1 62.5578	Prec@5 83.2367
Train: [47][5400/10010]	Time 0.586 (3165.602)	Data 0.001 (5.846)	Loss 1.622	Prec@1 62.5487	Prec@5 83.2362
Train: [47][5600/10010]	Time 0.586 (3281.982)	Data 0.001 (6.011)	Loss 1.622	Prec@1 62.5292	Prec@5 83.2342
Train: [47][5800/10010]	Time 0.586 (3398.312)	Data 0.001 (6.200)	Loss 1.623	Prec@1 62.5194	Prec@5 83.2212
Train: [47][6000/10010]	Time 0.586 (3514.337)	Data 0.001 (6.348)	Loss 1.623	Prec@1 62.5202	Prec@5 83.2245
Train: [47][6200/10010]	Time 0.585 (3630.490)	Data 0.001 (6.508)	Loss 1.624	Prec@1 62.4814	Prec@5 83.2141
Train: [47][6400/10010]	Time 0.585 (3747.110)	Data 0.001 (6.675)	Loss 1.624	Prec@1 62.4795	Prec@5 83.2127
Train: [47][6600/10010]	Time 0.585 (3863.670)	Data 0.001 (6.877)	Loss 1.625	Prec@1 62.4607	Prec@5 83.1992
Train: [47][6800/10010]	Time 0.585 (3979.963)	Data 0.001 (7.066)	Loss 1.626	Prec@1 62.4452	Prec@5 83.1963
Train: [47][7000/10010]	Time 0.585 (4096.319)	Data 0.001 (7.266)	Loss 1.626	Prec@1 62.4199	Prec@5 83.1822
Train: [47][7200/10010]	Time 0.585 (4212.700)	Data 0.001 (7.434)	Loss 1.627	Prec@1 62.4060	Prec@5 83.1756
Train: [47][7400/10010]	Time 0.585 (4328.671)	Data 0.001 (7.590)	Loss 1.627	Prec@1 62.3910	Prec@5 83.1681
Train: [47][7600/10010]	Time 0.585 (4445.074)	Data 0.001 (7.747)	Loss 1.628	Prec@1 62.3735	Prec@5 83.1580
Train: [47][7800/10010]	Time 0.585 (4561.258)	Data 0.001 (7.920)	Loss 1.629	Prec@1 62.3654	Prec@5 83.1498
Train: [47][8000/10010]	Time 0.585 (4677.619)	Data 0.001 (8.104)	Loss 1.629	Prec@1 62.3653	Prec@5 83.1438
Train: [47][8200/10010]	Time 0.585 (4794.095)	Data 0.001 (8.260)	Loss 1.629	Prec@1 62.3542	Prec@5 83.1396
Train: [47][8400/10010]	Time 0.585 (4910.492)	Data 0.001 (8.417)	Loss 1.630	Prec@1 62.3450	Prec@5 83.1318
Train: [47][8600/10010]	Time 0.584 (5026.601)	Data 0.001 (8.573)	Loss 1.631	Prec@1 62.3339	Prec@5 83.1244
Train: [47][8800/10010]	Time 0.584 (5143.120)	Data 0.001 (8.762)	Loss 1.631	Prec@1 62.3224	Prec@5 83.1186
Train: [47][9000/10010]	Time 0.584 (5259.400)	Data 0.001 (8.928)	Loss 1.632	Prec@1 62.3114	Prec@5 83.1145
Train: [47][9200/10010]	Time 0.584 (5375.486)	Data 0.001 (9.119)	Loss 1.632	Prec@1 62.3157	Prec@5 83.1082
Train: [47][9400/10010]	Time 0.584 (5491.727)	Data 0.001 (9.292)	Loss 1.632	Prec@1 62.2969	Prec@5 83.0926
Train: [47][9600/10010]	Time 0.584 (5607.636)	Data 0.001 (9.459)	Loss 1.632	Prec@1 62.3011	Prec@5 83.0888
Train: [47][9800/10010]	Time 0.584 (5723.915)	Data 0.001 (9.619)	Loss 1.633	Prec@1 62.2831	Prec@5 83.0779
Train: [47][10000/10010]	Time 0.584 (5840.784)	Data 0.001 (9.770)	Loss 1.633	Prec@1 62.2807	Prec@5 83.0758
Train: [47]	Time 5841.349	Data 9.771	Loss 1.633	Prec@1 62.2797	Prec@5 83.0757	
Val: [47]	Time 86.881	Data 1.484	Loss 1.324	Prec@1 67.9680	Prec@5 88.5040	
Best Prec@1: [67.968]	
Starting epoch number: 48 Learning rate: 0.010000000000000002
Train: [48][0/10010]	Time 2.290 (2.290)	Data 1.690 (1.690)	Loss 1.402	Prec@1 64.0625	Prec@5 87.5000
Train: [48][200/10010]	Time 0.592 (119.064)	Data 0.009 (1.842)	Loss 1.592	Prec@1 63.1180	Prec@5 83.5704
Train: [48][400/10010]	Time 0.591 (236.860)	Data 0.005 (1.999)	Loss 1.599	Prec@1 63.0299	Prec@5 83.5022
Train: [48][600/10010]	Time 0.590 (354.885)	Data 0.004 (2.156)	Loss 1.598	Prec@1 62.9472	Prec@5 83.6106
Train: [48][800/10010]	Time 0.590 (472.256)	Data 0.003 (2.306)	Loss 1.604	Prec@1 62.8911	Prec@5 83.5762
Train: [48][1000/10010]	Time 0.589 (589.864)	Data 0.002 (2.464)	Loss 1.601	Prec@1 62.9831	Prec@5 83.6047
Train: [48][1200/10010]	Time 0.589 (707.769)	Data 0.002 (2.619)	Loss 1.602	Prec@1 63.0243	Prec@5 83.5866
Train: [48][1400/10010]	Time 0.589 (825.491)	Data 0.002 (2.771)	Loss 1.603	Prec@1 62.9640	Prec@5 83.5374
Train: [48][1600/10010]	Time 0.589 (943.307)	Data 0.002 (2.933)	Loss 1.608	Prec@1 62.8933	Prec@5 83.4557
Train: [48][1800/10010]	Time 0.589 (1060.761)	Data 0.002 (3.090)	Loss 1.610	Prec@1 62.8440	Prec@5 83.4025
Train: [48][2000/10010]	Time 0.589 (1178.677)	Data 0.002 (3.246)	Loss 1.611	Prec@1 62.8522	Prec@5 83.3724
Train: [48][2200/10010]	Time 0.589 (1296.147)	Data 0.002 (3.412)	Loss 1.610	Prec@1 62.8557	Prec@5 83.4035
Train: [48][2400/10010]	Time 0.589 (1414.008)	Data 0.001 (3.583)	Loss 1.610	Prec@1 62.8361	Prec@5 83.4219
Train: [48][2600/10010]	Time 0.589 (1531.437)	Data 0.001 (3.754)	Loss 1.611	Prec@1 62.7953	Prec@5 83.4150
Train: [48][2800/10010]	Time 0.589 (1648.466)	Data 0.001 (3.930)	Loss 1.612	Prec@1 62.7792	Prec@5 83.3812
Train: [48][3000/10010]	Time 0.588 (1765.523)	Data 0.001 (4.097)	Loss 1.613	Prec@1 62.7624	Prec@5 83.3764
Train: [48][3200/10010]	Time 0.588 (1883.287)	Data 0.001 (4.250)	Loss 1.613	Prec@1 62.7433	Prec@5 83.3760
Train: [48][3400/10010]	Time 0.588 (2001.187)	Data 0.001 (4.419)	Loss 1.613	Prec@1 62.7515	Prec@5 83.3776
Train: [48][3600/10010]	Time 0.588 (2118.606)	Data 0.001 (4.590)	Loss 1.613	Prec@1 62.7480	Prec@5 83.3692
Train: [48][3800/10010]	Time 0.588 (2236.329)	Data 0.001 (4.761)	Loss 1.615	Prec@1 62.7226	Prec@5 83.3370
Train: [48][4000/10010]	Time 0.588 (2353.669)	Data 0.001 (4.934)	Loss 1.616	Prec@1 62.6886	Prec@5 83.3249
Train: [48][4200/10010]	Time 0.588 (2470.997)	Data 0.001 (5.085)	Loss 1.616	Prec@1 62.6958	Prec@5 83.3256
Train: [48][4400/10010]	Time 0.588 (2587.722)	Data 0.001 (5.252)	Loss 1.617	Prec@1 62.6779	Prec@5 83.3159
Train: [48][4600/10010]	Time 0.588 (2704.916)	Data 0.001 (5.407)	Loss 1.617	Prec@1 62.6847	Prec@5 83.3007
Train: [48][4800/10010]	Time 0.588 (2822.485)	Data 0.001 (5.566)	Loss 1.618	Prec@1 62.6871	Prec@5 83.2899
Train: [48][5000/10010]	Time 0.588 (2939.951)	Data 0.001 (5.727)	Loss 1.619	Prec@1 62.6795	Prec@5 83.2777
Train: [48][5200/10010]	Time 0.588 (3057.812)	Data 0.001 (5.884)	Loss 1.619	Prec@1 62.6795	Prec@5 83.2688
Train: [48][5400/10010]	Time 0.588 (3175.083)	Data 0.001 (6.052)	Loss 1.620	Prec@1 62.6587	Prec@5 83.2619
Train: [48][5600/10010]	Time 0.588 (3292.183)	Data 0.001 (6.202)	Loss 1.620	Prec@1 62.6501	Prec@5 83.2586
Train: [48][5800/10010]	Time 0.588 (3409.745)	Data 0.001 (6.381)	Loss 1.621	Prec@1 62.6213	Prec@5 83.2497
Train: [48][6000/10010]	Time 0.588 (3527.236)	Data 0.001 (6.543)	Loss 1.621	Prec@1 62.6084	Prec@5 83.2452
Train: [48][6200/10010]	Time 0.588 (3644.649)	Data 0.001 (6.713)	Loss 1.622	Prec@1 62.5860	Prec@5 83.2325
Train: [48][6400/10010]	Time 0.588 (3762.079)	Data 0.001 (6.891)	Loss 1.623	Prec@1 62.5769	Prec@5 83.2248
Train: [48][6600/10010]	Time 0.588 (3879.162)	Data 0.001 (7.056)	Loss 1.623	Prec@1 62.5563	Prec@5 83.2179
Train: [48][6800/10010]	Time 0.588 (3996.937)	Data 0.001 (7.213)	Loss 1.623	Prec@1 62.5605	Prec@5 83.2248
Train: [48][7000/10010]	Time 0.588 (4114.532)	Data 0.001 (7.374)	Loss 1.623	Prec@1 62.5480	Prec@5 83.2174
Train: [48][7200/10010]	Time 0.588 (4232.100)	Data 0.001 (7.540)	Loss 1.624	Prec@1 62.5436	Prec@5 83.2097
Train: [48][7400/10010]	Time 0.588 (4349.004)	Data 0.001 (7.708)	Loss 1.624	Prec@1 62.5362	Prec@5 83.2079
Train: [48][7600/10010]	Time 0.588 (4465.962)	Data 0.001 (7.880)	Loss 1.625	Prec@1 62.5143	Prec@5 83.1990
Train: [48][7800/10010]	Time 0.588 (4583.425)	Data 0.001 (8.039)	Loss 1.625	Prec@1 62.5067	Prec@5 83.1965
Train: [48][8000/10010]	Time 0.587 (4700.383)	Data 0.001 (8.197)	Loss 1.626	Prec@1 62.5085	Prec@5 83.1936
Train: [48][8200/10010]	Time 0.587 (4817.807)	Data 0.001 (8.375)	Loss 1.626	Prec@1 62.5126	Prec@5 83.1976
Train: [48][8400/10010]	Time 0.587 (4935.420)	Data 0.001 (8.545)	Loss 1.626	Prec@1 62.4943	Prec@5 83.1855
Train: [48][8600/10010]	Time 0.588 (5053.550)	Data 0.001 (8.705)	Loss 1.627	Prec@1 62.4768	Prec@5 83.1862
Train: [48][8800/10010]	Time 0.588 (5171.302)	Data 0.001 (8.881)	Loss 1.627	Prec@1 62.4642	Prec@5 83.1770
Train: [48][9000/10010]	Time 0.588 (5288.654)	Data 0.001 (9.062)	Loss 1.628	Prec@1 62.4515	Prec@5 83.1633
Train: [48][9200/10010]	Time 0.587 (5404.322)	Data 0.001 (9.197)	Loss 1.629	Prec@1 62.4408	Prec@5 83.1535
Train: [48][9400/10010]	Time 0.587 (5520.312)	Data 0.001 (9.368)	Loss 1.629	Prec@1 62.4314	Prec@5 83.1436
Train: [48][9600/10010]	Time 0.587 (5636.739)	Data 0.001 (9.527)	Loss 1.629	Prec@1 62.4379	Prec@5 83.1469
Train: [48][9800/10010]	Time 0.587 (5753.514)	Data 0.001 (9.688)	Loss 1.629	Prec@1 62.4274	Prec@5 83.1436
Train: [48][10000/10010]	Time 0.587 (5870.074)	Data 0.001 (9.831)	Loss 1.629	Prec@1 62.4220	Prec@5 83.1400
Train: [48]	Time 5870.636	Data 9.831	Loss 1.629	Prec@1 62.4213	Prec@5 83.1391	
Val: [48]	Time 88.692	Data 1.472	Loss 1.335	Prec@1 67.8600	Prec@5 88.2880	
Best Prec@1: [67.968]	
Starting epoch number: 49 Learning rate: 0.010000000000000002
Train: [49][0/10010]	Time 2.066 (2.066)	Data 1.423 (1.423)	Loss 1.777	Prec@1 60.9375	Prec@5 81.2500
Train: [49][200/10010]	Time 0.593 (119.237)	Data 0.008 (1.568)	Loss 1.602	Prec@1 63.3201	Prec@5 83.4227
Train: [49][400/10010]	Time 0.591 (236.872)	Data 0.004 (1.730)	Loss 1.603	Prec@1 63.0611	Prec@5 83.5256
Train: [49][600/10010]	Time 0.590 (354.430)	Data 0.003 (1.910)	Loss 1.602	Prec@1 63.0525	Prec@5 83.5847
Train: [49][800/10010]	Time 0.589 (471.674)	Data 0.003 (2.088)	Loss 1.599	Prec@1 63.0989	Prec@5 83.6279
Train: [49][1000/10010]	Time 0.588 (588.949)	Data 0.002 (2.261)	Loss 1.600	Prec@1 63.1291	Prec@5 83.5844
Train: [49][1200/10010]	Time 0.588 (705.697)	Data 0.002 (2.418)	Loss 1.602	Prec@1 63.0523	Prec@5 83.5684
Train: [49][1400/10010]	Time 0.587 (822.469)	Data 0.002 (2.582)	Loss 1.602	Prec@1 63.0303	Prec@5 83.5430
Train: [49][1600/10010]	Time 0.587 (939.331)	Data 0.002 (2.747)	Loss 1.605	Prec@1 62.9470	Prec@5 83.4722
Train: [49][1800/10010]	Time 0.587 (1056.607)	Data 0.002 (2.910)	Loss 1.605	Prec@1 62.9646	Prec@5 83.4554
Train: [49][2000/10010]	Time 0.587 (1174.001)	Data 0.002 (3.073)	Loss 1.604	Prec@1 62.9291	Prec@5 83.4509
Train: [49][2200/10010]	Time 0.587 (1290.918)	Data 0.001 (3.239)	Loss 1.605	Prec@1 62.9423	Prec@5 83.4014
Train: [49][2400/10010]	Time 0.586 (1408.125)	Data 0.001 (3.405)	Loss 1.603	Prec@1 62.9422	Prec@5 83.4392
Train: [49][2600/10010]	Time 0.586 (1525.305)	Data 0.001 (3.579)	Loss 1.603	Prec@1 62.9295	Prec@5 83.4484
Train: [49][2800/10010]	Time 0.586 (1642.673)	Data 0.001 (3.757)	Loss 1.605	Prec@1 62.8908	Prec@5 83.4225
Train: [49][3000/10010]	Time 0.587 (1760.218)	Data 0.001 (3.932)	Loss 1.606	Prec@1 62.8910	Prec@5 83.4003
Train: [49][3200/10010]	Time 0.586 (1877.092)	Data 0.001 (4.099)	Loss 1.607	Prec@1 62.8544	Prec@5 83.3878
Train: [49][3400/10010]	Time 0.586 (1994.085)	Data 0.001 (4.282)	Loss 1.607	Prec@1 62.8476	Prec@5 83.3843
Train: [49][3600/10010]	Time 0.586 (2110.837)	Data 0.001 (4.469)	Loss 1.608	Prec@1 62.8224	Prec@5 83.3705
Train: [49][3800/10010]	Time 0.586 (2228.252)	Data 0.001 (4.648)	Loss 1.609	Prec@1 62.8044	Prec@5 83.3529
Train: [49][4000/10010]	Time 0.586 (2345.214)	Data 0.001 (4.823)	Loss 1.609	Prec@1 62.7814	Prec@5 83.3544
Train: [49][4200/10010]	Time 0.586 (2462.421)	Data 0.001 (4.990)	Loss 1.610	Prec@1 62.7602	Prec@5 83.3446
Train: [49][4400/10010]	Time 0.586 (2578.974)	Data 0.001 (5.174)	Loss 1.610	Prec@1 62.7482	Prec@5 83.3484
Train: [49][4600/10010]	Time 0.586 (2696.168)	Data 0.001 (5.355)	Loss 1.611	Prec@1 62.7355	Prec@5 83.3414
Train: [49][4800/10010]	Time 0.586 (2813.190)	Data 0.001 (5.536)	Loss 1.612	Prec@1 62.7330	Prec@5 83.3322
Train: [49][5000/10010]	Time 0.586 (2930.462)	Data 0.001 (5.718)	Loss 1.612	Prec@1 62.7120	Prec@5 83.3322
Train: [49][5200/10010]	Time 0.586 (3047.750)	Data 0.001 (5.925)	Loss 1.614	Prec@1 62.6759	Prec@5 83.3020
Train: [49][5400/10010]	Time 0.586 (3165.080)	Data 0.001 (6.100)	Loss 1.615	Prec@1 62.6523	Prec@5 83.2942
Train: [49][5600/10010]	Time 0.586 (3280.788)	Data 0.001 (6.274)	Loss 1.616	Prec@1 62.6385	Prec@5 83.2890
Train: [49][5800/10010]	Time 0.586 (3397.480)	Data 0.001 (6.454)	Loss 1.617	Prec@1 62.6442	Prec@5 83.2789
Train: [49][6000/10010]	Time 0.585 (3513.479)	Data 0.001 (6.616)	Loss 1.617	Prec@1 62.6403	Prec@5 83.2700
Train: [49][6200/10010]	Time 0.585 (3630.145)	Data 0.001 (6.796)	Loss 1.617	Prec@1 62.6380	Prec@5 83.2664
Train: [49][6400/10010]	Time 0.585 (3746.299)	Data 0.001 (6.973)	Loss 1.618	Prec@1 62.6289	Prec@5 83.2512
Train: [49][6600/10010]	Time 0.585 (3862.516)	Data 0.001 (7.138)	Loss 1.618	Prec@1 62.6339	Prec@5 83.2472
Train: [49][6800/10010]	Time 0.585 (3978.742)	Data 0.001 (7.298)	Loss 1.618	Prec@1 62.6342	Prec@5 83.2463
Train: [49][7000/10010]	Time 0.585 (4094.509)	Data 0.001 (7.492)	Loss 1.618	Prec@1 62.6203	Prec@5 83.2397
Train: [49][7200/10010]	Time 0.585 (4210.794)	Data 0.001 (7.693)	Loss 1.619	Prec@1 62.6053	Prec@5 83.2306
Train: [49][7400/10010]	Time 0.585 (4327.160)	Data 0.001 (7.887)	Loss 1.619	Prec@1 62.5895	Prec@5 83.2249
Train: [49][7600/10010]	Time 0.585 (4442.940)	Data 0.001 (8.064)	Loss 1.620	Prec@1 62.5782	Prec@5 83.2258
Train: [49][7800/10010]	Time 0.584 (4558.914)	Data 0.001 (8.263)	Loss 1.620	Prec@1 62.5772	Prec@5 83.2248
Train: [49][8000/10010]	Time 0.584 (4674.777)	Data 0.001 (8.439)	Loss 1.620	Prec@1 62.5816	Prec@5 83.2204
Train: [49][8200/10010]	Time 0.584 (4790.751)	Data 0.001 (8.643)	Loss 1.621	Prec@1 62.5682	Prec@5 83.2009
Train: [49][8400/10010]	Time 0.584 (4907.216)	Data 0.001 (8.833)	Loss 1.621	Prec@1 62.5635	Prec@5 83.1932
Train: [49][8600/10010]	Time 0.584 (5023.345)	Data 0.001 (8.999)	Loss 1.621	Prec@1 62.5522	Prec@5 83.1925
Train: [49][8800/10010]	Time 0.584 (5139.032)	Data 0.001 (9.158)	Loss 1.622	Prec@1 62.5386	Prec@5 83.1909
Train: [49][9000/10010]	Time 0.584 (5254.827)	Data 0.001 (9.311)	Loss 1.623	Prec@1 62.5234	Prec@5 83.1789
Train: [49][9200/10010]	Time 0.584 (5370.577)	Data 0.001 (9.469)	Loss 1.623	Prec@1 62.5175	Prec@5 83.1844
Train: [49][9400/10010]	Time 0.584 (5487.034)	Data 0.001 (9.637)	Loss 1.623	Prec@1 62.5137	Prec@5 83.1762
Train: [49][9600/10010]	Time 0.584 (5603.018)	Data 0.001 (9.811)	Loss 1.624	Prec@1 62.5073	Prec@5 83.1701
Train: [49][9800/10010]	Time 0.583 (5718.865)	Data 0.001 (9.961)	Loss 1.624	Prec@1 62.5071	Prec@5 83.1680
Train: [49][10000/10010]	Time 0.583 (5834.830)	Data 0.001 (10.109)	Loss 1.624	Prec@1 62.5033	Prec@5 83.1640
Train: [49]	Time 5835.397	Data 10.109	Loss 1.624	Prec@1 62.5027	Prec@5 83.1642	
Val: [49]	Time 88.345	Data 1.548	Loss 1.353	Prec@1 67.3240	Prec@5 88.1860	
Best Prec@1: [67.968]	
Starting epoch number: 50 Learning rate: 0.010000000000000002
Train: [50][0/10010]	Time 2.429 (2.429)	Data 1.642 (1.642)	Loss 1.800	Prec@1 60.9375	Prec@5 78.9062
Train: [50][200/10010]	Time 0.597 (119.943)	Data 0.009 (1.803)	Loss 1.578	Prec@1 63.3629	Prec@5 83.6443
Train: [50][400/10010]	Time 0.592 (237.544)	Data 0.005 (1.959)	Loss 1.587	Prec@1 63.2170	Prec@5 83.5723
Train: [50][600/10010]	Time 0.591 (355.006)	Data 0.004 (2.125)	Loss 1.591	Prec@1 63.2696	Prec@5 83.6041
Train: [50][800/10010]	Time 0.590 (472.574)	Data 0.003 (2.295)	Loss 1.591	Prec@1 63.3281	Prec@5 83.6250
Train: [50][1000/10010]	Time 0.589 (589.912)	Data 0.002 (2.471)	Loss 1.590	Prec@1 63.3117	Prec@5 83.5805
Train: [50][1200/10010]	Time 0.589 (707.453)	Data 0.002 (2.633)	Loss 1.593	Prec@1 63.2760	Prec@5 83.5625
Train: [50][1400/10010]	Time 0.588 (824.424)	Data 0.002 (2.797)	Loss 1.594	Prec@1 63.2182	Prec@5 83.5731
Train: [50][1600/10010]	Time 0.588 (942.032)	Data 0.002 (2.944)	Loss 1.598	Prec@1 63.1500	Prec@5 83.5435
Train: [50][1800/10010]	Time 0.588 (1059.186)	Data 0.002 (3.087)	Loss 1.599	Prec@1 63.0943	Prec@5 83.5378
Train: [50][2000/10010]	Time 0.588 (1176.454)	Data 0.002 (3.261)	Loss 1.598	Prec@1 63.1056	Prec@5 83.5235
Train: [50][2200/10010]	Time 0.588 (1293.772)	Data 0.002 (3.420)	Loss 1.598	Prec@1 63.0544	Prec@5 83.5441
Train: [50][2400/10010]	Time 0.588 (1411.127)	Data 0.001 (3.578)	Loss 1.599	Prec@1 63.0515	Prec@5 83.5209
Train: [50][2600/10010]	Time 0.588 (1528.746)	Data 0.001 (3.750)	Loss 1.601	Prec@1 63.0037	Prec@5 83.4976
Train: [50][2800/10010]	Time 0.588 (1645.959)	Data 0.001 (3.918)	Loss 1.602	Prec@1 62.9711	Prec@5 83.4585
Train: [50][3000/10010]	Time 0.588 (1763.280)	Data 0.001 (4.076)	Loss 1.603	Prec@1 62.9334	Prec@5 83.4571
Train: [50][3200/10010]	Time 0.587 (1880.062)	Data 0.001 (4.241)	Loss 1.605	Prec@1 62.9061	Prec@5 83.4468
Train: [50][3400/10010]	Time 0.587 (1997.447)	Data 0.001 (4.408)	Loss 1.605	Prec@1 62.9116	Prec@5 83.4607
Train: [50][3600/10010]	Time 0.587 (2114.754)	Data 0.001 (4.572)	Loss 1.605	Prec@1 62.9189	Prec@5 83.4638
Train: [50][3800/10010]	Time 0.587 (2231.670)	Data 0.001 (4.735)	Loss 1.606	Prec@1 62.8829	Prec@5 83.4421
Train: [50][4000/10010]	Time 0.587 (2348.822)	Data 0.001 (4.921)	Loss 1.607	Prec@1 62.8632	Prec@5 83.4309
Train: [50][4200/10010]	Time 0.587 (2466.166)	Data 0.001 (5.091)	Loss 1.609	Prec@1 62.8240	Prec@5 83.4165
Train: [50][4400/10010]	Time 0.587 (2584.110)	Data 0.001 (5.261)	Loss 1.610	Prec@1 62.7993	Prec@5 83.3994
Train: [50][4600/10010]	Time 0.587 (2701.916)	Data 0.001 (5.418)	Loss 1.609	Prec@1 62.8155	Prec@5 83.4155
Train: [50][4800/10010]	Time 0.587 (2819.372)	Data 0.001 (5.582)	Loss 1.610	Prec@1 62.8012	Prec@5 83.3982
Train: [50][5000/10010]	Time 0.587 (2936.865)	Data 0.001 (5.752)	Loss 1.610	Prec@1 62.7895	Prec@5 83.3993
Train: [50][5200/10010]	Time 0.587 (3054.436)	Data 0.001 (5.932)	Loss 1.611	Prec@1 62.7741	Prec@5 83.3983
Train: [50][5400/10010]	Time 0.587 (3171.899)	Data 0.001 (6.104)	Loss 1.612	Prec@1 62.7586	Prec@5 83.3873
Train: [50][5600/10010]	Time 0.587 (3289.157)	Data 0.001 (6.264)	Loss 1.612	Prec@1 62.7713	Prec@5 83.3893
Train: [50][5800/10010]	Time 0.587 (3407.167)	Data 0.001 (6.437)	Loss 1.612	Prec@1 62.7563	Prec@5 83.3752
Train: [50][6000/10010]	Time 0.587 (3523.745)	Data 0.001 (6.595)	Loss 1.613	Prec@1 62.7484	Prec@5 83.3594
Train: [50][6200/10010]	Time 0.587 (3640.465)	Data 0.001 (6.766)	Loss 1.614	Prec@1 62.7229	Prec@5 83.3372
Train: [50][6400/10010]	Time 0.587 (3756.646)	Data 0.001 (6.928)	Loss 1.615	Prec@1 62.7015	Prec@5 83.3189
Train: [50][6600/10010]	Time 0.587 (3872.722)	Data 0.001 (7.084)	Loss 1.616	Prec@1 62.6909	Prec@5 83.3105
Train: [50][6800/10010]	Time 0.586 (3988.599)	Data 0.001 (7.228)	Loss 1.617	Prec@1 62.6775	Prec@5 83.3074
Train: [50][7000/10010]	Time 0.586 (4104.820)	Data 0.001 (7.378)	Loss 1.617	Prec@1 62.6660	Prec@5 83.3075
Train: [50][7200/10010]	Time 0.586 (4221.497)	Data 0.001 (7.526)	Loss 1.616	Prec@1 62.6771	Prec@5 83.3094
Train: [50][7400/10010]	Time 0.586 (4337.826)	Data 0.001 (7.678)	Loss 1.617	Prec@1 62.6626	Prec@5 83.3020
Train: [50][7600/10010]	Time 0.586 (4454.640)	Data 0.001 (7.840)	Loss 1.617	Prec@1 62.6579	Prec@5 83.3076
Train: [50][7800/10010]	Time 0.586 (4570.968)	Data 0.001 (8.022)	Loss 1.617	Prec@1 62.6466	Prec@5 83.2957
Train: [50][8000/10010]	Time 0.586 (4687.550)	Data 0.001 (8.191)	Loss 1.618	Prec@1 62.6359	Prec@5 83.2941
Train: [50][8200/10010]	Time 0.586 (4804.394)	Data 0.001 (8.351)	Loss 1.618	Prec@1 62.6376	Prec@5 83.2979
Train: [50][8400/10010]	Time 0.586 (4921.045)	Data 0.001 (8.503)	Loss 1.618	Prec@1 62.6407	Prec@5 83.3038
Train: [50][8600/10010]	Time 0.586 (5037.332)	Data 0.001 (8.656)	Loss 1.617	Prec@1 62.6393	Prec@5 83.3093
Train: [50][8800/10010]	Time 0.586 (5153.765)	Data 0.001 (8.811)	Loss 1.618	Prec@1 62.6353	Prec@5 83.3045
Train: [50][9000/10010]	Time 0.586 (5270.257)	Data 0.001 (8.979)	Loss 1.617	Prec@1 62.6292	Prec@5 83.3101
Train: [50][9200/10010]	Time 0.585 (5386.891)	Data 0.001 (9.155)	Loss 1.618	Prec@1 62.6118	Prec@5 83.3011
Train: [50][9400/10010]	Time 0.585 (5503.207)	Data 0.001 (9.309)	Loss 1.619	Prec@1 62.6032	Prec@5 83.2914
Train: [50][9600/10010]	Time 0.585 (5619.722)	Data 0.001 (9.484)	Loss 1.619	Prec@1 62.5854	Prec@5 83.2796
Train: [50][9800/10010]	Time 0.585 (5736.265)	Data 0.001 (9.666)	Loss 1.620	Prec@1 62.5794	Prec@5 83.2700
Train: [50][10000/10010]	Time 0.585 (5852.380)	Data 0.001 (9.824)	Loss 1.620	Prec@1 62.5777	Prec@5 83.2695
Train: [50]	Time 5852.942	Data 9.824	Loss 1.620	Prec@1 62.5785	Prec@5 83.2698	
Val: [50]	Time 87.667	Data 1.484	Loss 1.330	Prec@1 67.6840	Prec@5 88.2600	
Best Prec@1: [67.968]	
Starting epoch number: 51 Learning rate: 0.010000000000000002
Train: [51][0/10010]	Time 2.228 (2.228)	Data 1.465 (1.465)	Loss 1.714	Prec@1 59.3750	Prec@5 79.6875
Train: [51][200/10010]	Time 0.592 (118.907)	Data 0.008 (1.607)	Loss 1.571	Prec@1 63.6116	Prec@5 83.9902
Train: [51][400/10010]	Time 0.590 (236.453)	Data 0.004 (1.756)	Loss 1.591	Prec@1 63.3806	Prec@5 83.5762
Train: [51][600/10010]	Time 0.589 (354.017)	Data 0.003 (1.910)	Loss 1.589	Prec@1 63.3410	Prec@5 83.6509
Train: [51][800/10010]	Time 0.588 (471.325)	Data 0.003 (2.055)	Loss 1.587	Prec@1 63.3144	Prec@5 83.6357
Train: [51][1000/10010]	Time 0.588 (588.465)	Data 0.002 (2.213)	Loss 1.585	Prec@1 63.3492	Prec@5 83.6780
Train: [51][1200/10010]	Time 0.588 (705.667)	Data 0.002 (2.368)	Loss 1.586	Prec@1 63.3014	Prec@5 83.6634
Train: [51][1400/10010]	Time 0.587 (822.856)	Data 0.002 (2.523)	Loss 1.589	Prec@1 63.2104	Prec@5 83.5988
Train: [51][1600/10010]	Time 0.587 (939.946)	Data 0.002 (2.672)	Loss 1.593	Prec@1 63.1524	Prec@5 83.5254
Train: [51][1800/10010]	Time 0.587 (1057.095)	Data 0.002 (2.829)	Loss 1.593	Prec@1 63.1737	Prec@5 83.5183
Train: [51][2000/10010]	Time 0.587 (1174.144)	Data 0.001 (2.992)	Loss 1.596	Prec@1 63.1235	Prec@5 83.4825
Train: [51][2200/10010]	Time 0.587 (1291.400)	Data 0.001 (3.155)	Loss 1.595	Prec@1 63.1457	Prec@5 83.5071
Train: [51][2400/10010]	Time 0.587 (1408.708)	Data 0.001 (3.304)	Loss 1.596	Prec@1 63.1189	Prec@5 83.5147
Train: [51][2600/10010]	Time 0.587 (1526.240)	Data 0.001 (3.452)	Loss 1.595	Prec@1 63.1170	Prec@5 83.5066
Train: [51][2800/10010]	Time 0.587 (1643.855)	Data 0.001 (3.611)	Loss 1.596	Prec@1 63.0966	Prec@5 83.5106
Train: [51][3000/10010]	Time 0.587 (1761.318)	Data 0.001 (3.779)	Loss 1.596	Prec@1 63.0985	Prec@5 83.5190
Train: [51][3200/10010]	Time 0.587 (1878.629)	Data 0.001 (3.933)	Loss 1.597	Prec@1 63.0694	Prec@5 83.5054
Train: [51][3400/10010]	Time 0.587 (1996.373)	Data 0.001 (4.091)	Loss 1.599	Prec@1 63.0598	Prec@5 83.4927
Train: [51][3600/10010]	Time 0.587 (2113.051)	Data 0.001 (4.233)	Loss 1.600	Prec@1 63.0463	Prec@5 83.4879
Train: [51][3800/10010]	Time 0.587 (2230.066)	Data 0.001 (4.389)	Loss 1.600	Prec@1 63.0270	Prec@5 83.4819
Train: [51][4000/10010]	Time 0.587 (2346.831)	Data 0.001 (4.539)	Loss 1.601	Prec@1 63.0128	Prec@5 83.4860
Train: [51][4200/10010]	Time 0.587 (2464.136)	Data 0.001 (4.707)	Loss 1.600	Prec@1 62.9980	Prec@5 83.4924
Train: [51][4400/10010]	Time 0.587 (2581.301)	Data 0.001 (4.885)	Loss 1.601	Prec@1 62.9820	Prec@5 83.4768
Train: [51][4600/10010]	Time 0.586 (2698.355)	Data 0.001 (5.048)	Loss 1.602	Prec@1 62.9535	Prec@5 83.4759
Train: [51][4800/10010]	Time 0.587 (2816.034)	Data 0.001 (5.212)	Loss 1.602	Prec@1 62.9566	Prec@5 83.4657
Train: [51][5000/10010]	Time 0.587 (2933.262)	Data 0.001 (5.364)	Loss 1.603	Prec@1 62.9360	Prec@5 83.4475
Train: [51][5200/10010]	Time 0.586 (3050.156)	Data 0.001 (5.505)	Loss 1.604	Prec@1 62.9311	Prec@5 83.4500
Train: [51][5400/10010]	Time 0.586 (3167.386)	Data 0.001 (5.665)	Loss 1.606	Prec@1 62.8923	Prec@5 83.4205
Train: [51][5600/10010]	Time 0.586 (3284.515)	Data 0.001 (5.834)	Loss 1.606	Prec@1 62.8883	Prec@5 83.4107
Train: [51][5800/10010]	Time 0.586 (3401.370)	Data 0.001 (5.979)	Loss 1.607	Prec@1 62.8690	Prec@5 83.3954
Train: [51][6000/10010]	Time 0.586 (3518.572)	Data 0.001 (6.148)	Loss 1.606	Prec@1 62.8734	Prec@5 83.4007
Train: [51][6200/10010]	Time 0.586 (3635.694)	Data 0.001 (6.305)	Loss 1.606	Prec@1 62.8659	Prec@5 83.4093
Train: [51][6400/10010]	Time 0.586 (3753.117)	Data 0.001 (6.464)	Loss 1.606	Prec@1 62.8839	Prec@5 83.4171
Train: [51][6600/10010]	Time 0.586 (3870.168)	Data 0.001 (6.621)	Loss 1.607	Prec@1 62.8488	Prec@5 83.3974
Train: [51][6800/10010]	Time 0.586 (3987.645)	Data 0.001 (6.793)	Loss 1.608	Prec@1 62.8396	Prec@5 83.3870
Train: [51][7000/10010]	Time 0.586 (4104.912)	Data 0.001 (6.955)	Loss 1.609	Prec@1 62.8170	Prec@5 83.3749
Train: [51][7200/10010]	Time 0.586 (4222.491)	Data 0.001 (7.113)	Loss 1.610	Prec@1 62.7988	Prec@5 83.3584
Train: [51][7400/10010]	Time 0.586 (4339.768)	Data 0.001 (7.261)	Loss 1.610	Prec@1 62.7839	Prec@5 83.3518
Train: [51][7600/10010]	Time 0.586 (4456.717)	Data 0.001 (7.422)	Loss 1.611	Prec@1 62.7757	Prec@5 83.3428
Train: [51][7800/10010]	Time 0.586 (4574.272)	Data 0.001 (7.581)	Loss 1.611	Prec@1 62.7681	Prec@5 83.3375
Train: [51][8000/10010]	Time 0.586 (4691.595)	Data 0.001 (7.754)	Loss 1.611	Prec@1 62.7653	Prec@5 83.3350
Train: [51][8200/10010]	Time 0.586 (4808.843)	Data 0.001 (7.903)	Loss 1.612	Prec@1 62.7549	Prec@5 83.3308
Train: [51][8400/10010]	Time 0.586 (4926.078)	Data 0.001 (8.059)	Loss 1.612	Prec@1 62.7484	Prec@5 83.3258
Train: [51][8600/10010]	Time 0.586 (5043.271)	Data 0.001 (8.228)	Loss 1.613	Prec@1 62.7305	Prec@5 83.3175
Train: [51][8800/10010]	Time 0.586 (5160.631)	Data 0.001 (8.402)	Loss 1.614	Prec@1 62.7159	Prec@5 83.3060
Train: [51][9000/10010]	Time 0.586 (5277.865)	Data 0.001 (8.562)	Loss 1.615	Prec@1 62.7059	Prec@5 83.2909
Train: [51][9200/10010]	Time 0.586 (5395.236)	Data 0.001 (8.739)	Loss 1.615	Prec@1 62.6905	Prec@5 83.2869
Train: [51][9400/10010]	Time 0.586 (5512.137)	Data 0.001 (8.916)	Loss 1.615	Prec@1 62.6898	Prec@5 83.2899
Train: [51][9600/10010]	Time 0.586 (5629.807)	Data 0.001 (9.096)	Loss 1.615	Prec@1 62.6876	Prec@5 83.2834
Train: [51][9800/10010]	Time 0.586 (5747.155)	Data 0.001 (9.288)	Loss 1.615	Prec@1 62.6841	Prec@5 83.2816
Train: [51][10000/10010]	Time 0.586 (5864.417)	Data 0.001 (9.438)	Loss 1.616	Prec@1 62.6768	Prec@5 83.2801
Train: [51]	Time 5864.977	Data 9.439	Loss 1.616	Prec@1 62.6760	Prec@5 83.2801	
Val: [51]	Time 88.243	Data 1.671	Loss 1.327	Prec@1 67.7820	Prec@5 88.3480	
Best Prec@1: [67.968]	
Starting epoch number: 52 Learning rate: 0.010000000000000002
Train: [52][0/10010]	Time 2.205 (2.205)	Data 1.469 (1.469)	Loss 1.678	Prec@1 58.5938	Prec@5 85.1562
Train: [52][200/10010]	Time 0.591 (118.742)	Data 0.008 (1.609)	Loss 1.582	Prec@1 63.5145	Prec@5 83.8347
Train: [52][400/10010]	Time 0.588 (235.911)	Data 0.004 (1.751)	Loss 1.581	Prec@1 63.5501	Prec@5 83.8022
Train: [52][600/10010]	Time 0.587 (353.070)	Data 0.003 (1.903)	Loss 1.584	Prec@1 63.5243	Prec@5 83.7718
Train: [52][800/10010]	Time 0.587 (470.132)	Data 0.003 (2.041)	Loss 1.582	Prec@1 63.5300	Prec@5 83.7878
Train: [52][1000/10010]	Time 0.587 (587.341)	Data 0.002 (2.196)	Loss 1.581	Prec@1 63.5138	Prec@5 83.8326
Train: [52][1200/10010]	Time 0.586 (704.127)	Data 0.002 (2.357)	Loss 1.582	Prec@1 63.4504	Prec@5 83.8162
Train: [52][1400/10010]	Time 0.586 (821.222)	Data 0.002 (2.521)	Loss 1.583	Prec@1 63.4000	Prec@5 83.7638
Train: [52][1600/10010]	Time 0.586 (938.075)	Data 0.002 (2.687)	Loss 1.584	Prec@1 63.4013	Prec@5 83.7480
Train: [52][1800/10010]	Time 0.586 (1055.329)	Data 0.002 (2.833)	Loss 1.585	Prec@1 63.3762	Prec@5 83.7087
Train: [52][2000/10010]	Time 0.586 (1172.472)	Data 0.001 (2.975)	Loss 1.585	Prec@1 63.3562	Prec@5 83.7085
Train: [52][2200/10010]	Time 0.586 (1289.434)	Data 0.001 (3.122)	Loss 1.586	Prec@1 63.3224	Prec@5 83.6814
Train: [52][2400/10010]	Time 0.586 (1406.332)	Data 0.001 (3.268)	Loss 1.587	Prec@1 63.2884	Prec@5 83.6621
Train: [52][2600/10010]	Time 0.586 (1523.191)	Data 0.001 (3.417)	Loss 1.588	Prec@1 63.2647	Prec@5 83.6496
Train: [52][2800/10010]	Time 0.586 (1640.232)	Data 0.001 (3.555)	Loss 1.590	Prec@1 63.2283	Prec@5 83.6406
Train: [52][3000/10010]	Time 0.586 (1757.206)	Data 0.001 (3.696)	Loss 1.591	Prec@1 63.1813	Prec@5 83.6323
Train: [52][3200/10010]	Time 0.585 (1874.098)	Data 0.001 (3.839)	Loss 1.592	Prec@1 63.1482	Prec@5 83.6233
Train: [52][3400/10010]	Time 0.585 (1990.886)	Data 0.001 (3.992)	Loss 1.595	Prec@1 63.0819	Prec@5 83.6045
Train: [52][3600/10010]	Time 0.585 (2107.659)	Data 0.001 (4.133)	Loss 1.595	Prec@1 63.0652	Prec@5 83.6050
Train: [52][3800/10010]	Time 0.585 (2224.779)	Data 0.001 (4.280)	Loss 1.595	Prec@1 63.0582	Prec@5 83.6108
Train: [52][4000/10010]	Time 0.585 (2341.735)	Data 0.001 (4.428)	Loss 1.596	Prec@1 63.0405	Prec@5 83.6027
Train: [52][4200/10010]	Time 0.585 (2459.027)	Data 0.001 (4.582)	Loss 1.596	Prec@1 63.0428	Prec@5 83.5943
Train: [52][4400/10010]	Time 0.585 (2576.200)	Data 0.001 (4.752)	Loss 1.596	Prec@1 63.0512	Prec@5 83.5945
Train: [52][4600/10010]	Time 0.585 (2692.776)	Data 0.001 (4.918)	Loss 1.596	Prec@1 63.0425	Prec@5 83.5898
Train: [52][4800/10010]	Time 0.585 (2810.087)	Data 0.001 (5.083)	Loss 1.597	Prec@1 63.0329	Prec@5 83.5820
Train: [52][5000/10010]	Time 0.585 (2927.124)	Data 0.001 (5.240)	Loss 1.597	Prec@1 63.0343	Prec@5 83.5764
Train: [52][5200/10010]	Time 0.585 (3043.942)	Data 0.001 (5.382)	Loss 1.598	Prec@1 63.0187	Prec@5 83.5658
Train: [52][5400/10010]	Time 0.585 (3161.040)	Data 0.001 (5.548)	Loss 1.598	Prec@1 63.0150	Prec@5 83.5806
Train: [52][5600/10010]	Time 0.585 (3277.936)	Data 0.001 (5.714)	Loss 1.600	Prec@1 62.9666	Prec@5 83.5534
Train: [52][5800/10010]	Time 0.585 (3394.924)	Data 0.001 (5.878)	Loss 1.600	Prec@1 62.9572	Prec@5 83.5453
Train: [52][6000/10010]	Time 0.585 (3512.121)	Data 0.001 (6.043)	Loss 1.600	Prec@1 62.9420	Prec@5 83.5451
Train: [52][6200/10010]	Time 0.585 (3628.986)	Data 0.001 (6.201)	Loss 1.601	Prec@1 62.9194	Prec@5 83.5372
Train: [52][6400/10010]	Time 0.585 (3746.104)	Data 0.001 (6.362)	Loss 1.602	Prec@1 62.9127	Prec@5 83.5327
Train: [52][6600/10010]	Time 0.585 (3863.221)	Data 0.001 (6.538)	Loss 1.602	Prec@1 62.9010	Prec@5 83.5141
Train: [52][6800/10010]	Time 0.585 (3980.153)	Data 0.001 (6.697)	Loss 1.603	Prec@1 62.8846	Prec@5 83.4943
Train: [52][7000/10010]	Time 0.585 (4096.756)	Data 0.001 (6.852)	Loss 1.603	Prec@1 62.8705	Prec@5 83.5080
Train: [52][7200/10010]	Time 0.585 (4213.690)	Data 0.001 (7.016)	Loss 1.603	Prec@1 62.8682	Prec@5 83.5037
Train: [52][7400/10010]	Time 0.585 (4330.850)	Data 0.001 (7.169)	Loss 1.604	Prec@1 62.8644	Prec@5 83.5030
Train: [52][7600/10010]	Time 0.585 (4447.762)	Data 0.001 (7.346)	Loss 1.604	Prec@1 62.8485	Prec@5 83.4935
Train: [52][7800/10010]	Time 0.585 (4564.929)	Data 0.001 (7.503)	Loss 1.605	Prec@1 62.8330	Prec@5 83.4743
Train: [52][8000/10010]	Time 0.585 (4681.744)	Data 0.001 (7.660)	Loss 1.606	Prec@1 62.8125	Prec@5 83.4633
Train: [52][8200/10010]	Time 0.585 (4798.651)	Data 0.001 (7.828)	Loss 1.607	Prec@1 62.7939	Prec@5 83.4534
Train: [52][8400/10010]	Time 0.585 (4915.749)	Data 0.001 (7.980)	Loss 1.607	Prec@1 62.7855	Prec@5 83.4505
Train: [52][8600/10010]	Time 0.585 (5032.514)	Data 0.001 (8.139)	Loss 1.607	Prec@1 62.7844	Prec@5 83.4548
Train: [52][8800/10010]	Time 0.585 (5149.491)	Data 0.001 (8.306)	Loss 1.608	Prec@1 62.7757	Prec@5 83.4482
Train: [52][9000/10010]	Time 0.585 (5266.418)	Data 0.001 (8.471)	Loss 1.608	Prec@1 62.7711	Prec@5 83.4420
Train: [52][9200/10010]	Time 0.585 (5383.399)	Data 0.001 (8.620)	Loss 1.609	Prec@1 62.7595	Prec@5 83.4369
Train: [52][9400/10010]	Time 0.585 (5500.691)	Data 0.001 (8.775)	Loss 1.609	Prec@1 62.7486	Prec@5 83.4317
Train: [52][9600/10010]	Time 0.585 (5617.700)	Data 0.001 (8.927)	Loss 1.610	Prec@1 62.7462	Prec@5 83.4315
Train: [52][9800/10010]	Time 0.585 (5734.658)	Data 0.001 (9.093)	Loss 1.610	Prec@1 62.7424	Prec@5 83.4189
Train: [52][10000/10010]	Time 0.585 (5851.441)	Data 0.001 (9.238)	Loss 1.611	Prec@1 62.7276	Prec@5 83.4087
Train: [52]	Time 5852.002	Data 9.238	Loss 1.611	Prec@1 62.7278	Prec@5 83.4088	
Val: [52]	Time 87.644	Data 1.645	Loss 1.323	Prec@1 68.0660	Prec@5 88.3280	
Best Prec@1: [68.066]	
Starting epoch number: 53 Learning rate: 0.010000000000000002
Train: [53][0/10010]	Time 2.931 (2.931)	Data 2.179 (2.179)	Loss 1.675	Prec@1 58.5938	Prec@5 81.2500
Train: [53][200/10010]	Time 0.596 (119.729)	Data 0.012 (2.331)	Loss 1.569	Prec@1 63.4056	Prec@5 84.0485
Train: [53][400/10010]	Time 0.588 (235.764)	Data 0.006 (2.480)	Loss 1.568	Prec@1 63.5579	Prec@5 84.0204
Train: [53][600/10010]	Time 0.586 (351.953)	Data 0.004 (2.638)	Loss 1.566	Prec@1 63.6452	Prec@5 83.9980
Train: [53][800/10010]	Time 0.584 (467.739)	Data 0.003 (2.789)	Loss 1.572	Prec@1 63.5183	Prec@5 83.9605
Train: [53][1000/10010]	Time 0.583 (583.981)	Data 0.003 (2.951)	Loss 1.576	Prec@1 63.4233	Prec@5 83.9215
Train: [53][1200/10010]	Time 0.583 (699.864)	Data 0.003 (3.118)	Loss 1.578	Prec@1 63.3541	Prec@5 83.9040
Train: [53][1400/10010]	Time 0.582 (815.934)	Data 0.002 (3.298)	Loss 1.581	Prec@1 63.3342	Prec@5 83.8865
Train: [53][1600/10010]	Time 0.582 (931.518)	Data 0.002 (3.457)	Loss 1.580	Prec@1 63.3759	Prec@5 83.8817
Train: [53][1800/10010]	Time 0.582 (1047.478)	Data 0.002 (3.603)	Loss 1.581	Prec@1 63.3702	Prec@5 83.8575
Train: [53][2000/10010]	Time 0.582 (1164.079)	Data 0.002 (3.780)	Loss 1.580	Prec@1 63.3835	Prec@5 83.8460
Train: [53][2200/10010]	Time 0.582 (1281.253)	Data 0.002 (3.941)	Loss 1.582	Prec@1 63.3256	Prec@5 83.8046
Train: [53][2400/10010]	Time 0.583 (1398.952)	Data 0.002 (4.121)	Loss 1.583	Prec@1 63.3050	Prec@5 83.8101
Train: [53][2600/10010]	Time 0.583 (1516.313)	Data 0.002 (4.286)	Loss 1.583	Prec@1 63.3020	Prec@5 83.8052
Train: [53][2800/10010]	Time 0.583 (1633.639)	Data 0.002 (4.460)	Loss 1.586	Prec@1 63.2453	Prec@5 83.7762
Train: [53][3000/10010]	Time 0.583 (1750.592)	Data 0.002 (4.646)	Loss 1.588	Prec@1 63.2190	Prec@5 83.7419
Train: [53][3200/10010]	Time 0.583 (1867.687)	Data 0.002 (4.823)	Loss 1.589	Prec@1 63.1902	Prec@5 83.7236
Train: [53][3400/10010]	Time 0.584 (1985.183)	Data 0.001 (4.987)	Loss 1.590	Prec@1 63.1641	Prec@5 83.7217
Train: [53][3600/10010]	Time 0.584 (2101.531)	Data 0.001 (5.145)	Loss 1.590	Prec@1 63.1619	Prec@5 83.7183
Train: [53][3800/10010]	Time 0.583 (2217.704)	Data 0.001 (5.330)	Loss 1.592	Prec@1 63.1423	Prec@5 83.7000
Train: [53][4000/10010]	Time 0.583 (2334.145)	Data 0.001 (5.502)	Loss 1.592	Prec@1 63.1254	Prec@5 83.6814
Train: [53][4200/10010]	Time 0.583 (2450.376)	Data 0.001 (5.673)	Loss 1.592	Prec@1 63.1215	Prec@5 83.6856
Train: [53][4400/10010]	Time 0.583 (2566.795)	Data 0.001 (5.841)	Loss 1.593	Prec@1 63.1121	Prec@5 83.6795
Train: [53][4600/10010]	Time 0.583 (2683.335)	Data 0.001 (6.009)	Loss 1.593	Prec@1 63.0935	Prec@5 83.6773
Train: [53][4800/10010]	Time 0.583 (2799.750)	Data 0.001 (6.177)	Loss 1.595	Prec@1 63.0609	Prec@5 83.6655
Train: [53][5000/10010]	Time 0.583 (2916.205)	Data 0.001 (6.354)	Loss 1.595	Prec@1 63.0563	Prec@5 83.6565
Train: [53][5200/10010]	Time 0.583 (3032.648)	Data 0.001 (6.554)	Loss 1.596	Prec@1 63.0453	Prec@5 83.6447
Train: [53][5400/10010]	Time 0.583 (3149.212)	Data 0.001 (6.730)	Loss 1.596	Prec@1 63.0233	Prec@5 83.6452
Train: [53][5600/10010]	Time 0.583 (3265.302)	Data 0.001 (6.904)	Loss 1.597	Prec@1 63.0091	Prec@5 83.6350
Train: [53][5800/10010]	Time 0.583 (3381.643)	Data 0.001 (7.082)	Loss 1.598	Prec@1 62.9937	Prec@5 83.6157
Train: [53][6000/10010]	Time 0.583 (3498.200)	Data 0.001 (7.267)	Loss 1.599	Prec@1 62.9637	Prec@5 83.5961
Train: [53][6200/10010]	Time 0.583 (3614.745)	Data 0.001 (7.452)	Loss 1.600	Prec@1 62.9447	Prec@5 83.5784
Train: [53][6400/10010]	Time 0.583 (3731.592)	Data 0.001 (7.647)	Loss 1.601	Prec@1 62.9267	Prec@5 83.5710
Train: [53][6600/10010]	Time 0.583 (3848.640)	Data 0.001 (7.854)	Loss 1.601	Prec@1 62.9278	Prec@5 83.5676
Train: [53][6800/10010]	Time 0.583 (3965.404)	Data 0.001 (8.055)	Loss 1.602	Prec@1 62.9099	Prec@5 83.5477
Train: [53][7000/10010]	Time 0.583 (4082.465)	Data 0.001 (8.217)	Loss 1.602	Prec@1 62.9007	Prec@5 83.5467
Train: [53][7200/10010]	Time 0.583 (4199.081)	Data 0.001 (8.400)	Loss 1.603	Prec@1 62.8965	Prec@5 83.5397
Train: [53][7400/10010]	Time 0.583 (4315.984)	Data 0.001 (8.570)	Loss 1.603	Prec@1 62.8940	Prec@5 83.5282
Train: [53][7600/10010]	Time 0.583 (4432.411)	Data 0.001 (8.742)	Loss 1.603	Prec@1 62.8870	Prec@5 83.5304
Train: [53][7800/10010]	Time 0.583 (4548.415)	Data 0.001 (8.898)	Loss 1.603	Prec@1 62.8864	Prec@5 83.5295
Train: [53][8000/10010]	Time 0.583 (4665.035)	Data 0.001 (9.043)	Loss 1.603	Prec@1 62.8833	Prec@5 83.5221
Train: [53][8200/10010]	Time 0.583 (4781.324)	Data 0.001 (9.201)	Loss 1.603	Prec@1 62.8860	Prec@5 83.5244
Train: [53][8400/10010]	Time 0.583 (4897.608)	Data 0.001 (9.360)	Loss 1.603	Prec@1 62.8906	Prec@5 83.5159
Train: [53][8600/10010]	Time 0.583 (5014.177)	Data 0.001 (9.501)	Loss 1.604	Prec@1 62.8702	Prec@5 83.5053
Train: [53][8800/10010]	Time 0.583 (5130.700)	Data 0.001 (9.653)	Loss 1.605	Prec@1 62.8510	Prec@5 83.4951
Train: [53][9000/10010]	Time 0.583 (5246.983)	Data 0.001 (9.832)	Loss 1.605	Prec@1 62.8513	Prec@5 83.4881
Train: [53][9200/10010]	Time 0.583 (5363.583)	Data 0.001 (10.015)	Loss 1.606	Prec@1 62.8459	Prec@5 83.4847
Train: [53][9400/10010]	Time 0.583 (5480.111)	Data 0.001 (10.194)	Loss 1.606	Prec@1 62.8352	Prec@5 83.4768
Train: [53][9600/10010]	Time 0.583 (5596.623)	Data 0.001 (10.374)	Loss 1.607	Prec@1 62.8198	Prec@5 83.4609
Train: [53][9800/10010]	Time 0.583 (5713.027)	Data 0.001 (10.538)	Loss 1.608	Prec@1 62.8069	Prec@5 83.4527
Train: [53][10000/10010]	Time 0.583 (5829.653)	Data 0.001 (10.680)	Loss 1.608	Prec@1 62.8045	Prec@5 83.4465
Train: [53]	Time 5830.216	Data 10.680	Loss 1.608	Prec@1 62.8048	Prec@5 83.4464	
Val: [53]	Time 87.495	Data 1.547	Loss 1.334	Prec@1 68.0460	Prec@5 88.4620	
Best Prec@1: [68.066]	
Starting epoch number: 54 Learning rate: 0.010000000000000002
Train: [54][0/10010]	Time 2.189 (2.189)	Data 1.591 (1.591)	Loss 1.476	Prec@1 64.0625	Prec@5 84.3750
Train: [54][200/10010]	Time 0.591 (118.876)	Data 0.009 (1.726)	Loss 1.584	Prec@1 63.3007	Prec@5 84.0407
Train: [54][400/10010]	Time 0.588 (235.852)	Data 0.005 (1.871)	Loss 1.574	Prec@1 63.5871	Prec@5 84.0243
Train: [54][600/10010]	Time 0.588 (353.104)	Data 0.003 (2.011)	Loss 1.572	Prec@1 63.5464	Prec@5 84.0357
Train: [54][800/10010]	Time 0.587 (470.030)	Data 0.003 (2.153)	Loss 1.573	Prec@1 63.5456	Prec@5 84.0453
Train: [54][1000/10010]	Time 0.587 (587.248)	Data 0.002 (2.296)	Loss 1.571	Prec@1 63.6449	Prec@5 84.0558
Train: [54][1200/10010]	Time 0.587 (704.770)	Data 0.002 (2.446)	Loss 1.570	Prec@1 63.6878	Prec@5 84.0068
Train: [54][1400/10010]	Time 0.587 (821.942)	Data 0.002 (2.598)	Loss 1.571	Prec@1 63.5863	Prec@5 83.9478
Train: [54][1600/10010]	Time 0.587 (939.481)	Data 0.002 (2.757)	Loss 1.574	Prec@1 63.5213	Prec@5 83.8909
Train: [54][1800/10010]	Time 0.587 (1057.163)	Data 0.002 (2.905)	Loss 1.576	Prec@1 63.4786	Prec@5 83.8584
Train: [54][2000/10010]	Time 0.587 (1174.813)	Data 0.002 (3.071)	Loss 1.579	Prec@1 63.4253	Prec@5 83.8421
Train: [54][2200/10010]	Time 0.587 (1292.226)	Data 0.001 (3.247)	Loss 1.582	Prec@1 63.3473	Prec@5 83.7876
Train: [54][2400/10010]	Time 0.587 (1409.602)	Data 0.001 (3.401)	Loss 1.584	Prec@1 63.3050	Prec@5 83.7519
Train: [54][2600/10010]	Time 0.587 (1526.832)	Data 0.001 (3.534)	Loss 1.584	Prec@1 63.2722	Prec@5 83.7340
Train: [54][2800/10010]	Time 0.587 (1644.256)	Data 0.001 (3.687)	Loss 1.585	Prec@1 63.2383	Prec@5 83.7285
Train: [54][3000/10010]	Time 0.587 (1761.343)	Data 0.001 (3.832)	Loss 1.587	Prec@1 63.2099	Prec@5 83.7138
Train: [54][3200/10010]	Time 0.587 (1878.706)	Data 0.001 (3.983)	Loss 1.589	Prec@1 63.1521	Prec@5 83.6941
Train: [54][3400/10010]	Time 0.587 (1995.871)	Data 0.001 (4.134)	Loss 1.590	Prec@1 63.1248	Prec@5 83.6976
Train: [54][3600/10010]	Time 0.587 (2113.224)	Data 0.001 (4.283)	Loss 1.591	Prec@1 63.0886	Prec@5 83.6920
Train: [54][3800/10010]	Time 0.587 (2230.982)	Data 0.001 (4.427)	Loss 1.592	Prec@1 63.0572	Prec@5 83.6760
Train: [54][4000/10010]	Time 0.587 (2348.477)	Data 0.001 (4.584)	Loss 1.593	Prec@1 63.0436	Prec@5 83.6625
Train: [54][4200/10010]	Time 0.587 (2465.975)	Data 0.001 (4.769)	Loss 1.594	Prec@1 63.0289	Prec@5 83.6464
Train: [54][4400/10010]	Time 0.587 (2583.081)	Data 0.001 (4.917)	Loss 1.594	Prec@1 63.0439	Prec@5 83.6440
Train: [54][4600/10010]	Time 0.587 (2700.332)	Data 0.001 (5.061)	Loss 1.594	Prec@1 63.0281	Prec@5 83.6466
Train: [54][4800/10010]	Time 0.587 (2817.509)	Data 0.001 (5.205)	Loss 1.594	Prec@1 63.0357	Prec@5 83.6411
Train: [54][5000/10010]	Time 0.587 (2935.377)	Data 0.001 (5.362)	Loss 1.595	Prec@1 63.0277	Prec@5 83.6217
Train: [54][5200/10010]	Time 0.587 (3052.791)	Data 0.001 (5.517)	Loss 1.596	Prec@1 63.0148	Prec@5 83.6083
Train: [54][5400/10010]	Time 0.587 (3170.310)	Data 0.001 (5.686)	Loss 1.596	Prec@1 63.0116	Prec@5 83.6029
Train: [54][5600/10010]	Time 0.587 (3287.667)	Data 0.001 (5.839)	Loss 1.597	Prec@1 62.9854	Prec@5 83.5926
Train: [54][5800/10010]	Time 0.587 (3404.889)	Data 0.001 (5.996)	Loss 1.597	Prec@1 62.9992	Prec@5 83.5849
Train: [54][6000/10010]	Time 0.587 (3522.111)	Data 0.001 (6.142)	Loss 1.598	Prec@1 62.9886	Prec@5 83.5771
Train: [54][6200/10010]	Time 0.587 (3639.404)	Data 0.001 (6.296)	Loss 1.598	Prec@1 62.9868	Prec@5 83.5620
Train: [54][6400/10010]	Time 0.587 (3757.090)	Data 0.001 (6.448)	Loss 1.599	Prec@1 62.9563	Prec@5 83.5595
Train: [54][6600/10010]	Time 0.587 (3874.669)	Data 0.001 (6.600)	Loss 1.600	Prec@1 62.9398	Prec@5 83.5510
Train: [54][6800/10010]	Time 0.587 (3992.126)	Data 0.001 (6.764)	Loss 1.599	Prec@1 62.9554	Prec@5 83.5534
Train: [54][7000/10010]	Time 0.587 (4109.236)	Data 0.001 (6.925)	Loss 1.600	Prec@1 62.9494	Prec@5 83.5463
Train: [54][7200/10010]	Time 0.587 (4226.328)	Data 0.001 (7.085)	Loss 1.600	Prec@1 62.9536	Prec@5 83.5417
Train: [54][7400/10010]	Time 0.587 (4343.977)	Data 0.001 (7.247)	Loss 1.600	Prec@1 62.9534	Prec@5 83.5461
Train: [54][7600/10010]	Time 0.587 (4461.179)	Data 0.001 (7.387)	Loss 1.601	Prec@1 62.9401	Prec@5 83.5400
Train: [54][7800/10010]	Time 0.587 (4578.542)	Data 0.001 (7.540)	Loss 1.601	Prec@1 62.9345	Prec@5 83.5340
Train: [54][8000/10010]	Time 0.587 (4695.905)	Data 0.001 (7.706)	Loss 1.602	Prec@1 62.9290	Prec@5 83.5237
Train: [54][8200/10010]	Time 0.587 (4813.279)	Data 0.001 (7.869)	Loss 1.602	Prec@1 62.9354	Prec@5 83.5225
Train: [54][8400/10010]	Time 0.587 (4930.714)	Data 0.001 (8.019)	Loss 1.602	Prec@1 62.9308	Prec@5 83.5203
Train: [54][8600/10010]	Time 0.587 (5048.130)	Data 0.001 (8.173)	Loss 1.602	Prec@1 62.9287	Prec@5 83.5184
Train: [54][8800/10010]	Time 0.587 (5165.462)	Data 0.001 (8.330)	Loss 1.602	Prec@1 62.9280	Prec@5 83.5205
Train: [54][9000/10010]	Time 0.587 (5282.786)	Data 0.001 (8.498)	Loss 1.602	Prec@1 62.9246	Prec@5 83.5202
Train: [54][9200/10010]	Time 0.587 (5400.416)	Data 0.001 (8.648)	Loss 1.602	Prec@1 62.9157	Prec@5 83.5111
Train: [54][9400/10010]	Time 0.587 (5517.531)	Data 0.001 (8.801)	Loss 1.603	Prec@1 62.9117	Prec@5 83.5074
Train: [54][9600/10010]	Time 0.587 (5634.679)	Data 0.001 (8.944)	Loss 1.603	Prec@1 62.9053	Prec@5 83.4988
Train: [54][9800/10010]	Time 0.587 (5751.725)	Data 0.001 (9.088)	Loss 1.604	Prec@1 62.9027	Prec@5 83.4993
Train: [54][10000/10010]	Time 0.587 (5868.588)	Data 0.001 (9.230)	Loss 1.603	Prec@1 62.9082	Prec@5 83.5029
Train: [54]	Time 5869.154	Data 9.231	Loss 1.604	Prec@1 62.9079	Prec@5 83.5025	
Val: [54]	Time 87.366	Data 1.679	Loss 1.325	Prec@1 67.8140	Prec@5 88.5400	
Best Prec@1: [68.066]	
Starting epoch number: 55 Learning rate: 0.010000000000000002
Train: [55][0/10010]	Time 2.201 (2.201)	Data 1.597 (1.597)	Loss 1.672	Prec@1 66.4062	Prec@5 84.3750
Train: [55][200/10010]	Time 0.591 (118.874)	Data 0.009 (1.728)	Loss 1.564	Prec@1 63.3473	Prec@5 84.1962
Train: [55][400/10010]	Time 0.588 (235.668)	Data 0.005 (1.866)	Loss 1.557	Prec@1 63.5540	Prec@5 84.2951
Train: [55][600/10010]	Time 0.587 (352.766)	Data 0.003 (2.011)	Loss 1.562	Prec@1 63.5607	Prec@5 84.2281
Train: [55][800/10010]	Time 0.587 (470.130)	Data 0.003 (2.175)	Loss 1.561	Prec@1 63.5183	Prec@5 84.2882
Train: [55][1000/10010]	Time 0.587 (587.237)	Data 0.002 (2.323)	Loss 1.565	Prec@1 63.4982	Prec@5 84.2033
Train: [55][1200/10010]	Time 0.587 (704.543)	Data 0.002 (2.474)	Loss 1.570	Prec@1 63.4426	Prec@5 84.0784
Train: [55][1400/10010]	Time 0.587 (821.901)	Data 0.002 (2.623)	Loss 1.571	Prec@1 63.4418	Prec@5 84.0800
Train: [55][1600/10010]	Time 0.587 (939.438)	Data 0.002 (2.787)	Loss 1.571	Prec@1 63.4647	Prec@5 84.0456
Train: [55][1800/10010]	Time 0.587 (1056.834)	Data 0.002 (2.944)	Loss 1.575	Prec@1 63.3971	Prec@5 83.9620
Train: [55][2000/10010]	Time 0.587 (1174.172)	Data 0.002 (3.114)	Loss 1.575	Prec@1 63.4148	Prec@5 83.9596
Train: [55][2200/10010]	Time 0.587 (1291.504)	Data 0.001 (3.278)	Loss 1.576	Prec@1 63.3796	Prec@5 83.9430
Train: [55][2400/10010]	Time 0.587 (1408.972)	Data 0.001 (3.454)	Loss 1.577	Prec@1 63.3896	Prec@5 83.9282
Train: [55][2600/10010]	Time 0.587 (1526.280)	Data 0.001 (3.630)	Loss 1.577	Prec@1 63.4020	Prec@5 83.9199
Train: [55][2800/10010]	Time 0.587 (1643.514)	Data 0.001 (3.795)	Loss 1.580	Prec@1 63.3298	Prec@5 83.8509
Train: [55][3000/10010]	Time 0.587 (1760.851)	Data 0.001 (3.950)	Loss 1.581	Prec@1 63.2987	Prec@5 83.8187
Train: [55][3200/10010]	Time 0.587 (1878.476)	Data 0.001 (4.108)	Loss 1.582	Prec@1 63.2798	Prec@5 83.7980
Train: [55][3400/10010]	Time 0.587 (1995.620)	Data 0.001 (4.270)	Loss 1.583	Prec@1 63.2654	Prec@5 83.7690
Train: [55][3600/10010]	Time 0.587 (2113.069)	Data 0.001 (4.445)	Loss 1.584	Prec@1 63.2461	Prec@5 83.7712
Train: [55][3800/10010]	Time 0.587 (2230.521)	Data 0.001 (4.611)	Loss 1.585	Prec@1 63.2383	Prec@5 83.7516
Train: [55][4000/10010]	Time 0.587 (2348.193)	Data 0.001 (4.778)	Loss 1.585	Prec@1 63.2420	Prec@5 83.7380
Train: [55][4200/10010]	Time 0.587 (2466.080)	Data 0.001 (4.939)	Loss 1.586	Prec@1 63.2188	Prec@5 83.7288
Train: [55][4400/10010]	Time 0.587 (2583.312)	Data 0.001 (5.099)	Loss 1.586	Prec@1 63.2161	Prec@5 83.7310
Train: [55][4600/10010]	Time 0.587 (2700.720)	Data 0.001 (5.250)	Loss 1.587	Prec@1 63.2014	Prec@5 83.7148
Train: [55][4800/10010]	Time 0.587 (2818.032)	Data 0.001 (5.391)	Loss 1.588	Prec@1 63.1896	Prec@5 83.7093
Train: [55][5000/10010]	Time 0.587 (2935.718)	Data 0.001 (5.543)	Loss 1.590	Prec@1 63.1700	Prec@5 83.6925
Train: [55][5200/10010]	Time 0.587 (3052.979)	Data 0.001 (5.695)	Loss 1.590	Prec@1 63.1719	Prec@5 83.6974
Train: [55][5400/10010]	Time 0.587 (3170.279)	Data 0.001 (5.837)	Loss 1.590	Prec@1 63.1524	Prec@5 83.6951
Train: [55][5600/10010]	Time 0.587 (3287.610)	Data 0.001 (5.998)	Loss 1.590	Prec@1 63.1528	Prec@5 83.6847
Train: [55][5800/10010]	Time 0.587 (3405.142)	Data 0.001 (6.150)	Loss 1.591	Prec@1 63.1400	Prec@5 83.6638
Train: [55][6000/10010]	Time 0.587 (3522.209)	Data 0.001 (6.314)	Loss 1.593	Prec@1 63.1220	Prec@5 83.6435
Train: [55][6200/10010]	Time 0.587 (3639.589)	Data 0.001 (6.487)	Loss 1.593	Prec@1 63.1239	Prec@5 83.6367
Train: [55][6400/10010]	Time 0.587 (3756.725)	Data 0.001 (6.642)	Loss 1.594	Prec@1 63.0991	Prec@5 83.6210
Train: [55][6600/10010]	Time 0.587 (3874.281)	Data 0.001 (6.791)	Loss 1.594	Prec@1 63.0841	Prec@5 83.6133
Train: [55][6800/10010]	Time 0.587 (3991.919)	Data 0.001 (6.947)	Loss 1.595	Prec@1 63.0705	Prec@5 83.6008
Train: [55][7000/10010]	Time 0.587 (4109.374)	Data 0.001 (7.095)	Loss 1.595	Prec@1 63.0649	Prec@5 83.5990
Train: [55][7200/10010]	Time 0.587 (4226.596)	Data 0.001 (7.253)	Loss 1.596	Prec@1 63.0450	Prec@5 83.5857
Train: [55][7400/10010]	Time 0.587 (4343.924)	Data 0.001 (7.422)	Loss 1.596	Prec@1 63.0432	Prec@5 83.5831
Train: [55][7600/10010]	Time 0.587 (4461.089)	Data 0.001 (7.570)	Loss 1.596	Prec@1 63.0380	Prec@5 83.5729
Train: [55][7800/10010]	Time 0.587 (4578.255)	Data 0.001 (7.731)	Loss 1.596	Prec@1 63.0463	Prec@5 83.5753
Train: [55][8000/10010]	Time 0.587 (4695.924)	Data 0.001 (7.890)	Loss 1.597	Prec@1 63.0273	Prec@5 83.5717
Train: [55][8200/10010]	Time 0.587 (4813.363)	Data 0.001 (8.055)	Loss 1.597	Prec@1 63.0218	Prec@5 83.5673
Train: [55][8400/10010]	Time 0.587 (4930.642)	Data 0.001 (8.215)	Loss 1.597	Prec@1 63.0240	Prec@5 83.5653
Train: [55][8600/10010]	Time 0.587 (5047.968)	Data 0.001 (8.361)	Loss 1.598	Prec@1 63.0127	Prec@5 83.5527
Train: [55][8800/10010]	Time 0.587 (5165.555)	Data 0.001 (8.509)	Loss 1.598	Prec@1 63.0068	Prec@5 83.5517
Train: [55][9000/10010]	Time 0.587 (5283.064)	Data 0.001 (8.679)	Loss 1.599	Prec@1 62.9866	Prec@5 83.5431
Train: [55][9200/10010]	Time 0.587 (5400.534)	Data 0.001 (8.829)	Loss 1.599	Prec@1 62.9757	Prec@5 83.5347
Train: [55][9400/10010]	Time 0.587 (5517.949)	Data 0.001 (8.983)	Loss 1.599	Prec@1 62.9730	Prec@5 83.5333
Train: [55][9600/10010]	Time 0.587 (5635.591)	Data 0.001 (9.130)	Loss 1.600	Prec@1 62.9710	Prec@5 83.5320
Train: [55][9800/10010]	Time 0.587 (5753.028)	Data 0.001 (9.295)	Loss 1.600	Prec@1 62.9575	Prec@5 83.5188
Train: [55][10000/10010]	Time 0.587 (5870.761)	Data 0.001 (9.438)	Loss 1.601	Prec@1 62.9397	Prec@5 83.5077
Train: [55]	Time 5871.317	Data 9.439	Loss 1.601	Prec@1 62.9394	Prec@5 83.5075	
Val: [55]	Time 87.976	Data 1.559	Loss 1.339	Prec@1 67.4580	Prec@5 88.2480	
Best Prec@1: [68.066]	
Starting epoch number: 56 Learning rate: 0.010000000000000002
Train: [56][0/10010]	Time 1.899 (1.899)	Data 1.268 (1.268)	Loss 1.431	Prec@1 66.4062	Prec@5 85.1562
Train: [56][200/10010]	Time 0.590 (118.651)	Data 0.007 (1.402)	Loss 1.578	Prec@1 63.6660	Prec@5 83.8308
Train: [56][400/10010]	Time 0.589 (236.103)	Data 0.004 (1.546)	Loss 1.571	Prec@1 63.6222	Prec@5 83.9561
Train: [56][600/10010]	Time 0.589 (353.753)	Data 0.003 (1.697)	Loss 1.572	Prec@1 63.5815	Prec@5 83.8654
Train: [56][800/10010]	Time 0.588 (471.125)	Data 0.002 (1.846)	Loss 1.574	Prec@1 63.5036	Prec@5 83.8269
Train: [56][1000/10010]	Time 0.588 (588.267)	Data 0.002 (2.003)	Loss 1.575	Prec@1 63.4366	Prec@5 83.8209
Train: [56][1200/10010]	Time 0.587 (705.400)	Data 0.002 (2.170)	Loss 1.575	Prec@1 63.4673	Prec@5 83.8240
Train: [56][1400/10010]	Time 0.587 (822.468)	Data 0.002 (2.315)	Loss 1.577	Prec@1 63.4274	Prec@5 83.8001
Train: [56][1600/10010]	Time 0.587 (939.690)	Data 0.002 (2.478)	Loss 1.578	Prec@1 63.3881	Prec@5 83.8085
Train: [56][1800/10010]	Time 0.587 (1057.031)	Data 0.001 (2.643)	Loss 1.580	Prec@1 63.3962	Prec@5 83.8011
Train: [56][2000/10010]	Time 0.587 (1174.524)	Data 0.001 (2.800)	Loss 1.582	Prec@1 63.3340	Prec@5 83.7745
Train: [56][2200/10010]	Time 0.587 (1292.194)	Data 0.001 (2.972)	Loss 1.583	Prec@1 63.3050	Prec@5 83.7673
Train: [56][2400/10010]	Time 0.587 (1409.722)	Data 0.001 (3.129)	Loss 1.584	Prec@1 63.2910	Prec@5 83.7769
Train: [56][2600/10010]	Time 0.587 (1526.563)	Data 0.001 (3.295)	Loss 1.584	Prec@1 63.2873	Prec@5 83.7812
Train: [56][2800/10010]	Time 0.587 (1643.748)	Data 0.001 (3.452)	Loss 1.585	Prec@1 63.2614	Prec@5 83.7597
Train: [56][3000/10010]	Time 0.587 (1761.057)	Data 0.001 (3.594)	Loss 1.587	Prec@1 63.2300	Prec@5 83.7278
Train: [56][3200/10010]	Time 0.587 (1878.199)	Data 0.001 (3.743)	Loss 1.587	Prec@1 63.2261	Prec@5 83.7280
Train: [56][3400/10010]	Time 0.587 (1995.170)	Data 0.001 (3.906)	Loss 1.588	Prec@1 63.2321	Prec@5 83.7077
Train: [56][3600/10010]	Time 0.587 (2112.536)	Data 0.001 (4.068)	Loss 1.587	Prec@1 63.2322	Prec@5 83.7142
Train: [56][3800/10010]	Time 0.587 (2229.798)	Data 0.001 (4.239)	Loss 1.586	Prec@1 63.2397	Prec@5 83.7173
Train: [56][4000/10010]	Time 0.587 (2347.030)	Data 0.001 (4.411)	Loss 1.587	Prec@1 63.2477	Prec@5 83.7060
Train: [56][4200/10010]	Time 0.587 (2464.449)	Data 0.001 (4.563)	Loss 1.587	Prec@1 63.2318	Prec@5 83.6919
Train: [56][4400/10010]	Time 0.587 (2581.903)	Data 0.001 (4.726)	Loss 1.587	Prec@1 63.2417	Prec@5 83.6951
Train: [56][4600/10010]	Time 0.587 (2699.211)	Data 0.001 (4.885)	Loss 1.587	Prec@1 63.2313	Prec@5 83.6983
Train: [56][4800/10010]	Time 0.587 (2816.395)	Data 0.001 (5.051)	Loss 1.588	Prec@1 63.2134	Prec@5 83.6881
Train: [56][5000/10010]	Time 0.587 (2933.676)	Data 0.001 (5.213)	Loss 1.587	Prec@1 63.2234	Prec@5 83.6853
Train: [56][5200/10010]	Time 0.587 (3050.726)	Data 0.001 (5.377)	Loss 1.588	Prec@1 63.2155	Prec@5 83.6822
Train: [56][5400/10010]	Time 0.587 (3167.996)	Data 0.001 (5.549)	Loss 1.589	Prec@1 63.2007	Prec@5 83.6609
Train: [56][5600/10010]	Time 0.587 (3285.474)	Data 0.001 (5.714)	Loss 1.590	Prec@1 63.1942	Prec@5 83.6461
Train: [56][5800/10010]	Time 0.587 (3402.668)	Data 0.001 (5.878)	Loss 1.590	Prec@1 63.1898	Prec@5 83.6460
Train: [56][6000/10010]	Time 0.587 (3519.952)	Data 0.001 (6.035)	Loss 1.591	Prec@1 63.1758	Prec@5 83.6362
Train: [56][6200/10010]	Time 0.587 (3637.473)	Data 0.001 (6.198)	Loss 1.590	Prec@1 63.1706	Prec@5 83.6370
Train: [56][6400/10010]	Time 0.587 (3754.808)	Data 0.001 (6.352)	Loss 1.591	Prec@1 63.1640	Prec@5 83.6244
Train: [56][6600/10010]	Time 0.587 (3871.929)	Data 0.001 (6.493)	Loss 1.591	Prec@1 63.1669	Prec@5 83.6271
Train: [56][6800/10010]	Time 0.587 (3989.568)	Data 0.001 (6.657)	Loss 1.591	Prec@1 63.1586	Prec@5 83.6206
Train: [56][7000/10010]	Time 0.587 (4106.684)	Data 0.001 (6.800)	Loss 1.591	Prec@1 63.1611	Prec@5 83.6245
Train: [56][7200/10010]	Time 0.587 (4224.226)	Data 0.001 (6.939)	Loss 1.592	Prec@1 63.1444	Prec@5 83.6117
Train: [56][7400/10010]	Time 0.587 (4341.933)	Data 0.001 (7.088)	Loss 1.593	Prec@1 63.1303	Prec@5 83.6048
Train: [56][7600/10010]	Time 0.587 (4459.176)	Data 0.001 (7.234)	Loss 1.594	Prec@1 63.1182	Prec@5 83.6035
Train: [56][7800/10010]	Time 0.587 (4576.273)	Data 0.001 (7.391)	Loss 1.594	Prec@1 63.1064	Prec@5 83.5892
Train: [56][8000/10010]	Time 0.587 (4693.712)	Data 0.001 (7.546)	Loss 1.595	Prec@1 63.0895	Prec@5 83.5831
Train: [56][8200/10010]	Time 0.587 (4810.994)	Data 0.001 (7.706)	Loss 1.596	Prec@1 63.0854	Prec@5 83.5765
Train: [56][8400/10010]	Time 0.587 (4927.963)	Data 0.001 (7.854)	Loss 1.596	Prec@1 63.0714	Prec@5 83.5696
Train: [56][8600/10010]	Time 0.587 (5045.330)	Data 0.001 (8.004)	Loss 1.597	Prec@1 63.0665	Prec@5 83.5609
Train: [56][8800/10010]	Time 0.587 (5162.933)	Data 0.001 (8.154)	Loss 1.597	Prec@1 63.0552	Prec@5 83.5544
Train: [56][9000/10010]	Time 0.587 (5280.416)	Data 0.001 (8.307)	Loss 1.598	Prec@1 63.0469	Prec@5 83.5440
Train: [56][9200/10010]	Time 0.587 (5397.618)	Data 0.001 (8.445)	Loss 1.599	Prec@1 63.0296	Prec@5 83.5324
Train: [56][9400/10010]	Time 0.587 (5515.314)	Data 0.001 (8.596)	Loss 1.598	Prec@1 63.0214	Prec@5 83.5379
Train: [56][9600/10010]	Time 0.587 (5632.575)	Data 0.001 (8.742)	Loss 1.599	Prec@1 63.0160	Prec@5 83.5377
Train: [56][9800/10010]	Time 0.587 (5750.226)	Data 0.001 (8.904)	Loss 1.600	Prec@1 63.0021	Prec@5 83.5246
Train: [56][10000/10010]	Time 0.587 (5867.482)	Data 0.001 (9.075)	Loss 1.600	Prec@1 62.9986	Prec@5 83.5192
Train: [56]	Time 5868.045	Data 9.075	Loss 1.600	Prec@1 62.9983	Prec@5 83.5189	
Val: [56]	Time 86.982	Data 1.559	Loss 1.323	Prec@1 67.8340	Prec@5 88.3020	
Best Prec@1: [68.066]	
Starting epoch number: 57 Learning rate: 0.010000000000000002
Train: [57][0/10010]	Time 2.312 (2.312)	Data 1.687 (1.687)	Loss 1.397	Prec@1 71.0938	Prec@5 85.9375
Train: [57][200/10010]	Time 0.596 (119.775)	Data 0.009 (1.833)	Loss 1.564	Prec@1 63.9964	Prec@5 83.8697
Train: [57][400/10010]	Time 0.592 (237.527)	Data 0.005 (1.990)	Loss 1.565	Prec@1 63.8248	Prec@5 83.9230
Train: [57][600/10010]	Time 0.591 (355.124)	Data 0.004 (2.162)	Loss 1.561	Prec@1 63.7401	Prec@5 84.0227
Train: [57][800/10010]	Time 0.590 (472.419)	Data 0.003 (2.312)	Loss 1.560	Prec@1 63.7514	Prec@5 84.1078
Train: [57][1000/10010]	Time 0.589 (589.802)	Data 0.002 (2.479)	Loss 1.557	Prec@1 63.8034	Prec@5 84.0893
Train: [57][1200/10010]	Time 0.589 (707.396)	Data 0.002 (2.643)	Loss 1.556	Prec@1 63.8264	Prec@5 84.1337
Train: [57][1400/10010]	Time 0.589 (825.304)	Data 0.002 (2.797)	Loss 1.558	Prec@1 63.7954	Prec@5 84.0906
Train: [57][1600/10010]	Time 0.589 (942.845)	Data 0.002 (2.943)	Loss 1.560	Prec@1 63.7473	Prec@5 84.0451
Train: [57][1800/10010]	Time 0.589 (1060.222)	Data 0.002 (3.100)	Loss 1.561	Prec@1 63.7346	Prec@5 84.0184
Train: [57][2000/10010]	Time 0.589 (1177.657)	Data 0.002 (3.270)	Loss 1.559	Prec@1 63.7626	Prec@5 84.0627
Train: [57][2200/10010]	Time 0.588 (1295.277)	Data 0.002 (3.446)	Loss 1.562	Prec@1 63.7246	Prec@5 84.0250
Train: [57][2400/10010]	Time 0.588 (1412.666)	Data 0.001 (3.591)	Loss 1.563	Prec@1 63.6916	Prec@5 83.9972
Train: [57][2600/10010]	Time 0.588 (1530.415)	Data 0.001 (3.756)	Loss 1.565	Prec@1 63.6660	Prec@5 83.9767
Train: [57][2800/10010]	Time 0.588 (1648.328)	Data 0.001 (3.907)	Loss 1.565	Prec@1 63.6720	Prec@5 83.9834
Train: [57][3000/10010]	Time 0.588 (1765.926)	Data 0.001 (4.070)	Loss 1.567	Prec@1 63.6389	Prec@5 83.9455
Train: [57][3200/10010]	Time 0.588 (1883.008)	Data 0.001 (4.244)	Loss 1.568	Prec@1 63.6298	Prec@5 83.9386
Train: [57][3400/10010]	Time 0.588 (2000.594)	Data 0.001 (4.402)	Loss 1.569	Prec@1 63.5849	Prec@5 83.9275
Train: [57][3600/10010]	Time 0.588 (2118.135)	Data 0.001 (4.561)	Loss 1.570	Prec@1 63.5572	Prec@5 83.9200
Train: [57][3800/10010]	Time 0.588 (2235.490)	Data 0.001 (4.718)	Loss 1.571	Prec@1 63.5213	Prec@5 83.9175
Train: [57][4000/10010]	Time 0.588 (2352.839)	Data 0.001 (4.878)	Loss 1.573	Prec@1 63.4781	Prec@5 83.9073
Train: [57][4200/10010]	Time 0.588 (2470.313)	Data 0.001 (5.032)	Loss 1.575	Prec@1 63.4596	Prec@5 83.8694
Train: [57][4400/10010]	Time 0.588 (2587.986)	Data 0.001 (5.191)	Loss 1.575	Prec@1 63.4346	Prec@5 83.8511
Train: [57][4600/10010]	Time 0.588 (2705.304)	Data 0.001 (5.343)	Loss 1.576	Prec@1 63.4210	Prec@5 83.8430
Train: [57][4800/10010]	Time 0.588 (2822.631)	Data 0.001 (5.499)	Loss 1.578	Prec@1 63.3786	Prec@5 83.8307
Train: [57][5000/10010]	Time 0.588 (2940.564)	Data 0.001 (5.666)	Loss 1.579	Prec@1 63.3619	Prec@5 83.8189
Train: [57][5200/10010]	Time 0.588 (3058.380)	Data 0.001 (5.825)	Loss 1.578	Prec@1 63.3703	Prec@5 83.8273
Train: [57][5400/10010]	Time 0.588 (3175.787)	Data 0.001 (5.982)	Loss 1.579	Prec@1 63.3602	Prec@5 83.8243
Train: [57][5600/10010]	Time 0.588 (3293.095)	Data 0.001 (6.164)	Loss 1.579	Prec@1 63.3594	Prec@5 83.8119
Train: [57][5800/10010]	Time 0.588 (3410.422)	Data 0.001 (6.312)	Loss 1.580	Prec@1 63.3342	Prec@5 83.7982
Train: [57][6000/10010]	Time 0.588 (3528.346)	Data 0.001 (6.499)	Loss 1.581	Prec@1 63.3134	Prec@5 83.7962
Train: [57][6200/10010]	Time 0.588 (3645.792)	Data 0.001 (6.668)	Loss 1.581	Prec@1 63.2923	Prec@5 83.7832
Train: [57][6400/10010]	Time 0.588 (3763.522)	Data 0.001 (6.845)	Loss 1.582	Prec@1 63.2773	Prec@5 83.7768
Train: [57][6600/10010]	Time 0.588 (3881.190)	Data 0.001 (7.008)	Loss 1.583	Prec@1 63.2594	Prec@5 83.7682
Train: [57][6800/10010]	Time 0.588 (3998.721)	Data 0.001 (7.187)	Loss 1.584	Prec@1 63.2528	Prec@5 83.7591
Train: [57][7000/10010]	Time 0.588 (4115.835)	Data 0.001 (7.336)	Loss 1.585	Prec@1 63.2319	Prec@5 83.7429
Train: [57][7200/10010]	Time 0.588 (4233.749)	Data 0.001 (7.498)	Loss 1.585	Prec@1 63.2188	Prec@5 83.7325
Train: [57][7400/10010]	Time 0.588 (4351.093)	Data 0.001 (7.680)	Loss 1.586	Prec@1 63.1792	Prec@5 83.7156
Train: [57][7600/10010]	Time 0.588 (4468.176)	Data 0.001 (7.834)	Loss 1.587	Prec@1 63.1709	Prec@5 83.7074
Train: [57][7800/10010]	Time 0.588 (4585.412)	Data 0.001 (7.995)	Loss 1.588	Prec@1 63.1626	Prec@5 83.6925
Train: [57][8000/10010]	Time 0.588 (4702.711)	Data 0.001 (8.175)	Loss 1.588	Prec@1 63.1581	Prec@5 83.6860
Train: [57][8200/10010]	Time 0.588 (4820.562)	Data 0.001 (8.337)	Loss 1.589	Prec@1 63.1513	Prec@5 83.6832
Train: [57][8400/10010]	Time 0.588 (4937.928)	Data 0.001 (8.490)	Loss 1.589	Prec@1 63.1451	Prec@5 83.6764
Train: [57][8600/10010]	Time 0.588 (5055.629)	Data 0.001 (8.643)	Loss 1.590	Prec@1 63.1372	Prec@5 83.6691
Train: [57][8800/10010]	Time 0.588 (5173.003)	Data 0.001 (8.793)	Loss 1.591	Prec@1 63.1094	Prec@5 83.6484
Train: [57][9000/10010]	Time 0.588 (5290.806)	Data 0.001 (8.968)	Loss 1.591	Prec@1 63.1195	Prec@5 83.6548
Train: [57][9200/10010]	Time 0.588 (5408.254)	Data 0.001 (9.144)	Loss 1.591	Prec@1 63.1037	Prec@5 83.6424
Train: [57][9400/10010]	Time 0.588 (5525.886)	Data 0.001 (9.312)	Loss 1.592	Prec@1 63.0816	Prec@5 83.6379
Train: [57][9600/10010]	Time 0.588 (5643.830)	Data 0.001 (9.498)	Loss 1.593	Prec@1 63.0615	Prec@5 83.6224
Train: [57][9800/10010]	Time 0.588 (5761.753)	Data 0.001 (9.668)	Loss 1.593	Prec@1 63.0596	Prec@5 83.6181
Train: [57][10000/10010]	Time 0.588 (5879.470)	Data 0.001 (9.846)	Loss 1.593	Prec@1 63.0542	Prec@5 83.6191
Train: [57]	Time 5880.033	Data 9.846	Loss 1.593	Prec@1 63.0549	Prec@5 83.6193	
Val: [57]	Time 88.918	Data 1.498	Loss 1.297	Prec@1 68.4100	Prec@5 88.8580	
Best Prec@1: [68.410]	
Starting epoch number: 58 Learning rate: 0.010000000000000002
Train: [58][0/10010]	Time 2.102 (2.102)	Data 1.501 (1.501)	Loss 1.683	Prec@1 68.7500	Prec@5 79.6875
Train: [58][200/10010]	Time 0.592 (119.065)	Data 0.008 (1.643)	Loss 1.554	Prec@1 64.1597	Prec@5 84.1340
Train: [58][400/10010]	Time 0.589 (236.030)	Data 0.004 (1.779)	Loss 1.556	Prec@1 64.0333	Prec@5 84.1315
Train: [58][600/10010]	Time 0.588 (353.385)	Data 0.003 (1.919)	Loss 1.561	Prec@1 63.9377	Prec@5 84.1033
Train: [58][800/10010]	Time 0.588 (470.920)	Data 0.003 (2.079)	Loss 1.561	Prec@1 63.8684	Prec@5 84.1468
Train: [58][1000/10010]	Time 0.587 (587.860)	Data 0.002 (2.215)	Loss 1.563	Prec@1 63.7542	Prec@5 84.1198
Train: [58][1200/10010]	Time 0.587 (705.169)	Data 0.002 (2.353)	Loss 1.560	Prec@1 63.7984	Prec@5 84.1434
Train: [58][1400/10010]	Time 0.587 (822.408)	Data 0.002 (2.502)	Loss 1.561	Prec@1 63.7491	Prec@5 84.0945
Train: [58][1600/10010]	Time 0.587 (939.428)	Data 0.002 (2.653)	Loss 1.561	Prec@1 63.7287	Prec@5 84.1100
Train: [58][1800/10010]	Time 0.587 (1056.609)	Data 0.002 (2.807)	Loss 1.563	Prec@1 63.7094	Prec@5 84.0939
Train: [58][2000/10010]	Time 0.587 (1173.845)	Data 0.001 (2.947)	Loss 1.564	Prec@1 63.7033	Prec@5 84.0759
Train: [58][2200/10010]	Time 0.587 (1291.082)	Data 0.001 (3.104)	Loss 1.565	Prec@1 63.7150	Prec@5 84.0431
Train: [58][2400/10010]	Time 0.587 (1408.372)	Data 0.001 (3.252)	Loss 1.567	Prec@1 63.6815	Prec@5 84.0047
Train: [58][2600/10010]	Time 0.586 (1525.247)	Data 0.001 (3.415)	Loss 1.569	Prec@1 63.6360	Prec@5 83.9932
Train: [58][2800/10010]	Time 0.586 (1642.302)	Data 0.001 (3.580)	Loss 1.569	Prec@1 63.6249	Prec@5 83.9820
Train: [58][3000/10010]	Time 0.586 (1759.220)	Data 0.001 (3.735)	Loss 1.570	Prec@1 63.6009	Prec@5 83.9632
Train: [58][3200/10010]	Time 0.586 (1876.056)	Data 0.001 (3.897)	Loss 1.570	Prec@1 63.6046	Prec@5 83.9611
Train: [58][3400/10010]	Time 0.586 (1993.337)	Data 0.001 (4.064)	Loss 1.571	Prec@1 63.5753	Prec@5 83.9498
Train: [58][3600/10010]	Time 0.586 (2110.798)	Data 0.001 (4.230)	Loss 1.572	Prec@1 63.5505	Prec@5 83.9279
Train: [58][3800/10010]	Time 0.586 (2227.751)	Data 0.001 (4.409)	Loss 1.573	Prec@1 63.5345	Prec@5 83.9023
Train: [58][4000/10010]	Time 0.586 (2345.015)	Data 0.001 (4.583)	Loss 1.573	Prec@1 63.5392	Prec@5 83.9105
Train: [58][4200/10010]	Time 0.586 (2462.203)	Data 0.001 (4.749)	Loss 1.575	Prec@1 63.5098	Prec@5 83.8796
Train: [58][4400/10010]	Time 0.586 (2579.599)	Data 0.001 (4.917)	Loss 1.576	Prec@1 63.4984	Prec@5 83.8607
Train: [58][4600/10010]	Time 0.586 (2696.511)	Data 0.001 (5.071)	Loss 1.576	Prec@1 63.4809	Prec@5 83.8653
Train: [58][4800/10010]	Time 0.586 (2813.387)	Data 0.001 (5.237)	Loss 1.577	Prec@1 63.4614	Prec@5 83.8512
Train: [58][5000/10010]	Time 0.586 (2930.541)	Data 0.001 (5.410)	Loss 1.578	Prec@1 63.4418	Prec@5 83.8376
Train: [58][5200/10010]	Time 0.586 (3047.478)	Data 0.001 (5.553)	Loss 1.579	Prec@1 63.4241	Prec@5 83.8206
Train: [58][5400/10010]	Time 0.586 (3164.767)	Data 0.001 (5.704)	Loss 1.580	Prec@1 63.4091	Prec@5 83.8103
Train: [58][5600/10010]	Time 0.586 (3281.830)	Data 0.001 (5.847)	Loss 1.580	Prec@1 63.4085	Prec@5 83.7999
Train: [58][5800/10010]	Time 0.586 (3398.769)	Data 0.001 (5.990)	Loss 1.581	Prec@1 63.4054	Prec@5 83.7885
Train: [58][6000/10010]	Time 0.586 (3515.735)	Data 0.001 (6.126)	Loss 1.581	Prec@1 63.3782	Prec@5 83.7778
Train: [58][6200/10010]	Time 0.586 (3632.972)	Data 0.001 (6.267)	Loss 1.581	Prec@1 63.3727	Prec@5 83.7815
Train: [58][6400/10010]	Time 0.586 (3750.163)	Data 0.001 (6.419)	Loss 1.582	Prec@1 63.3561	Prec@5 83.7717
Train: [58][6600/10010]	Time 0.586 (3867.014)	Data 0.001 (6.574)	Loss 1.583	Prec@1 63.3305	Prec@5 83.7664
Train: [58][6800/10010]	Time 0.586 (3984.272)	Data 0.001 (6.731)	Loss 1.583	Prec@1 63.3117	Prec@5 83.7580
Train: [58][7000/10010]	Time 0.586 (4101.233)	Data 0.001 (6.883)	Loss 1.584	Prec@1 63.2945	Prec@5 83.7470
Train: [58][7200/10010]	Time 0.586 (4218.359)	Data 0.001 (7.042)	Loss 1.585	Prec@1 63.2676	Prec@5 83.7411
Train: [58][7400/10010]	Time 0.586 (4335.534)	Data 0.001 (7.205)	Loss 1.584	Prec@1 63.2744	Prec@5 83.7489
Train: [58][7600/10010]	Time 0.586 (4452.674)	Data 0.001 (7.377)	Loss 1.586	Prec@1 63.2497	Prec@5 83.7303
Train: [58][7800/10010]	Time 0.586 (4569.742)	Data 0.001 (7.535)	Loss 1.586	Prec@1 63.2457	Prec@5 83.7170
Train: [58][8000/10010]	Time 0.586 (4686.706)	Data 0.001 (7.701)	Loss 1.587	Prec@1 63.2294	Prec@5 83.7106
Train: [58][8200/10010]	Time 0.586 (4803.520)	Data 0.001 (7.850)	Loss 1.587	Prec@1 63.2182	Prec@5 83.7079
Train: [58][8400/10010]	Time 0.586 (4920.647)	Data 0.001 (7.999)	Loss 1.588	Prec@1 63.1965	Prec@5 83.7032
Train: [58][8600/10010]	Time 0.586 (5037.662)	Data 0.001 (8.156)	Loss 1.588	Prec@1 63.1844	Prec@5 83.6956
Train: [58][8800/10010]	Time 0.586 (5155.087)	Data 0.001 (8.302)	Loss 1.588	Prec@1 63.1826	Prec@5 83.6928
Train: [58][9000/10010]	Time 0.586 (5272.265)	Data 0.001 (8.452)	Loss 1.589	Prec@1 63.1712	Prec@5 83.6837
Train: [58][9200/10010]	Time 0.586 (5389.284)	Data 0.001 (8.587)	Loss 1.590	Prec@1 63.1632	Prec@5 83.6773
Train: [58][9400/10010]	Time 0.586 (5506.318)	Data 0.001 (8.739)	Loss 1.590	Prec@1 63.1559	Prec@5 83.6729
Train: [58][9600/10010]	Time 0.586 (5623.176)	Data 0.001 (8.916)	Loss 1.590	Prec@1 63.1440	Prec@5 83.6654
Train: [58][9800/10010]	Time 0.586 (5740.208)	Data 0.001 (9.073)	Loss 1.590	Prec@1 63.1331	Prec@5 83.6648
Train: [58][10000/10010]	Time 0.586 (5857.322)	Data 0.001 (9.233)	Loss 1.591	Prec@1 63.1192	Prec@5 83.6572
Train: [58]	Time 5857.878	Data 9.233	Loss 1.591	Prec@1 63.1189	Prec@5 83.6567	
Val: [58]	Time 87.595	Data 1.615	Loss 1.300	Prec@1 68.4580	Prec@5 88.7060	
Best Prec@1: [68.458]	
Starting epoch number: 59 Learning rate: 0.010000000000000002
Train: [59][0/10010]	Time 2.384 (2.384)	Data 1.673 (1.673)	Loss 1.586	Prec@1 64.0625	Prec@5 84.3750
Train: [59][200/10010]	Time 0.594 (119.435)	Data 0.009 (1.820)	Loss 1.571	Prec@1 63.6583	Prec@5 83.8503
Train: [59][400/10010]	Time 0.590 (236.595)	Data 0.005 (1.965)	Loss 1.566	Prec@1 63.7800	Prec@5 84.0613
Train: [59][600/10010]	Time 0.588 (353.659)	Data 0.004 (2.120)	Loss 1.568	Prec@1 63.6686	Prec@5 84.0565
Train: [59][800/10010]	Time 0.588 (471.113)	Data 0.003 (2.280)	Loss 1.569	Prec@1 63.5787	Prec@5 84.0366
Train: [59][1000/10010]	Time 0.588 (588.441)	Data 0.002 (2.412)	Loss 1.565	Prec@1 63.6567	Prec@5 84.1276
Train: [59][1200/10010]	Time 0.588 (705.590)	Data 0.002 (2.553)	Loss 1.564	Prec@1 63.6722	Prec@5 84.1454
Train: [59][1400/10010]	Time 0.587 (822.526)	Data 0.002 (2.702)	Loss 1.563	Prec@1 63.6716	Prec@5 84.1369
Train: [59][1600/10010]	Time 0.587 (939.695)	Data 0.002 (2.848)	Loss 1.564	Prec@1 63.6794	Prec@5 84.0983
Train: [59][1800/10010]	Time 0.587 (1056.637)	Data 0.002 (3.008)	Loss 1.563	Prec@1 63.6552	Prec@5 84.0961
Train: [59][2000/10010]	Time 0.587 (1173.646)	Data 0.002 (3.168)	Loss 1.562	Prec@1 63.6928	Prec@5 84.0896
Train: [59][2200/10010]	Time 0.586 (1290.408)	Data 0.002 (3.345)	Loss 1.563	Prec@1 63.6887	Prec@5 84.0811
Train: [59][2400/10010]	Time 0.586 (1407.480)	Data 0.001 (3.516)	Loss 1.566	Prec@1 63.6262	Prec@5 84.0545
Train: [59][2600/10010]	Time 0.586 (1524.939)	Data 0.001 (3.655)	Loss 1.569	Prec@1 63.5942	Prec@5 84.0182
Train: [59][2800/10010]	Time 0.586 (1642.064)	Data 0.001 (3.808)	Loss 1.573	Prec@1 63.5264	Prec@5 83.9460
Train: [59][3000/10010]	Time 0.586 (1759.140)	Data 0.001 (3.960)	Loss 1.573	Prec@1 63.5202	Prec@5 83.9533
Train: [59][3200/10010]	Time 0.586 (1876.338)	Data 0.001 (4.104)	Loss 1.572	Prec@1 63.5263	Prec@5 83.9659
Train: [59][3400/10010]	Time 0.586 (1993.339)	Data 0.001 (4.240)	Loss 1.573	Prec@1 63.5374	Prec@5 83.9505
Train: [59][3600/10010]	Time 0.586 (2110.699)	Data 0.001 (4.383)	Loss 1.575	Prec@1 63.5132	Prec@5 83.9253
Train: [59][3800/10010]	Time 0.586 (2228.004)	Data 0.001 (4.546)	Loss 1.575	Prec@1 63.5197	Prec@5 83.9171
Train: [59][4000/10010]	Time 0.586 (2344.940)	Data 0.001 (4.689)	Loss 1.574	Prec@1 63.5329	Prec@5 83.9259
Train: [59][4200/10010]	Time 0.586 (2461.966)	Data 0.001 (4.837)	Loss 1.577	Prec@1 63.4808	Prec@5 83.8963
Train: [59][4400/10010]	Time 0.586 (2579.070)	Data 0.001 (4.984)	Loss 1.577	Prec@1 63.4609	Prec@5 83.9017
Train: [59][4600/10010]	Time 0.586 (2696.372)	Data 0.001 (5.126)	Loss 1.576	Prec@1 63.4694	Prec@5 83.9036
Train: [59][4800/10010]	Time 0.586 (2813.268)	Data 0.001 (5.289)	Loss 1.576	Prec@1 63.4637	Prec@5 83.8967
Train: [59][5000/10010]	Time 0.586 (2930.551)	Data 0.001 (5.461)	Loss 1.578	Prec@1 63.4340	Prec@5 83.8624
Train: [59][5200/10010]	Time 0.586 (3047.896)	Data 0.001 (5.629)	Loss 1.578	Prec@1 63.4297	Prec@5 83.8625
Train: [59][5400/10010]	Time 0.586 (3165.321)	Data 0.001 (5.773)	Loss 1.578	Prec@1 63.4162	Prec@5 83.8467
Train: [59][5600/10010]	Time 0.586 (3282.681)	Data 0.001 (5.923)	Loss 1.580	Prec@1 63.3900	Prec@5 83.8179
Train: [59][5800/10010]	Time 0.586 (3399.812)	Data 0.001 (6.061)	Loss 1.581	Prec@1 63.3763	Prec@5 83.8013
Train: [59][6000/10010]	Time 0.586 (3516.650)	Data 0.001 (6.217)	Loss 1.582	Prec@1 63.3564	Prec@5 83.7989
Train: [59][6200/10010]	Time 0.586 (3633.850)	Data 0.001 (6.357)	Loss 1.582	Prec@1 63.3310	Prec@5 83.7873
Train: [59][6400/10010]	Time 0.586 (3751.173)	Data 0.001 (6.503)	Loss 1.583	Prec@1 63.3094	Prec@5 83.7680
Train: [59][6600/10010]	Time 0.586 (3868.815)	Data 0.001 (6.650)	Loss 1.584	Prec@1 63.3008	Prec@5 83.7562
Train: [59][6800/10010]	Time 0.586 (3986.725)	Data 0.001 (6.802)	Loss 1.584	Prec@1 63.2794	Prec@5 83.7433
Train: [59][7000/10010]	Time 0.586 (4103.824)	Data 0.001 (6.962)	Loss 1.585	Prec@1 63.2754	Prec@5 83.7390
Train: [59][7200/10010]	Time 0.586 (4221.285)	Data 0.001 (7.112)	Loss 1.584	Prec@1 63.2832	Prec@5 83.7400
Train: [59][7400/10010]	Time 0.586 (4338.459)	Data 0.001 (7.276)	Loss 1.584	Prec@1 63.2777	Prec@5 83.7432
Train: [59][7600/10010]	Time 0.586 (4455.675)	Data 0.001 (7.429)	Loss 1.585	Prec@1 63.2644	Prec@5 83.7348
Train: [59][7800/10010]	Time 0.586 (4572.532)	Data 0.001 (7.583)	Loss 1.585	Prec@1 63.2515	Prec@5 83.7272
Train: [59][8000/10010]	Time 0.586 (4689.552)	Data 0.001 (7.734)	Loss 1.585	Prec@1 63.2482	Prec@5 83.7303
Train: [59][8200/10010]	Time 0.586 (4806.655)	Data 0.001 (7.882)	Loss 1.586	Prec@1 63.2417	Prec@5 83.7258
Train: [59][8400/10010]	Time 0.586 (4923.647)	Data 0.001 (8.044)	Loss 1.586	Prec@1 63.2314	Prec@5 83.7249
Train: [59][8600/10010]	Time 0.586 (5041.056)	Data 0.001 (8.210)	Loss 1.587	Prec@1 63.2154	Prec@5 83.7165
Train: [59][8800/10010]	Time 0.586 (5158.307)	Data 0.001 (8.360)	Loss 1.588	Prec@1 63.1946	Prec@5 83.7001
Train: [59][9000/10010]	Time 0.586 (5275.522)	Data 0.001 (8.525)	Loss 1.588	Prec@1 63.1955	Prec@5 83.6988
Train: [59][9200/10010]	Time 0.586 (5392.711)	Data 0.001 (8.693)	Loss 1.589	Prec@1 63.1805	Prec@5 83.6866
Train: [59][9400/10010]	Time 0.586 (5509.732)	Data 0.001 (8.846)	Loss 1.589	Prec@1 63.1786	Prec@5 83.6825
Train: [59][9600/10010]	Time 0.586 (5626.956)	Data 0.001 (8.998)	Loss 1.589	Prec@1 63.1709	Prec@5 83.6669
Train: [59][9800/10010]	Time 0.586 (5744.059)	Data 0.001 (9.163)	Loss 1.590	Prec@1 63.1649	Prec@5 83.6582
Train: [59][10000/10010]	Time 0.586 (5861.241)	Data 0.001 (9.297)	Loss 1.590	Prec@1 63.1476	Prec@5 83.6510
Train: [59]	Time 5861.892	Data 9.297	Loss 1.590	Prec@1 63.1474	Prec@5 83.6512	
Val: [59]	Time 87.790	Data 1.554	Loss 1.295	Prec@1 68.4200	Prec@5 88.8780	
Best Prec@1: [68.458]	
Starting epoch number: 60 Learning rate: 0.0010000000000000002
Train: [60][0/10010]	Time 1.988 (1.988)	Data 1.322 (1.322)	Loss 1.212	Prec@1 67.1875	Prec@5 89.8438
Train: [60][200/10010]	Time 0.592 (118.949)	Data 0.007 (1.463)	Loss 1.494	Prec@1 65.2713	Prec@5 85.1057
Train: [60][400/10010]	Time 0.588 (235.980)	Data 0.004 (1.607)	Loss 1.475	Prec@1 65.6815	Prec@5 85.3900
Train: [60][600/10010]	Time 0.587 (352.861)	Data 0.003 (1.756)	Loss 1.463	Prec@1 65.9721	Prec@5 85.4630
Train: [60][800/10010]	Time 0.587 (469.910)	Data 0.002 (1.898)	Loss 1.454	Prec@1 66.2463	Prec@5 85.5591
Train: [60][1000/10010]	Time 0.586 (586.732)	Data 0.002 (2.046)	Loss 1.441	Prec@1 66.5249	Prec@5 85.7346
Train: [60][1200/10010]	Time 0.586 (703.700)	Data 0.002 (2.186)	Loss 1.438	Prec@1 66.5903	Prec@5 85.7573
Train: [60][1400/10010]	Time 0.586 (820.830)	Data 0.002 (2.341)	Loss 1.432	Prec@1 66.7431	Prec@5 85.8460
Train: [60][1600/10010]	Time 0.586 (938.229)	Data 0.002 (2.492)	Loss 1.427	Prec@1 66.8708	Prec@5 85.8819
Train: [60][1800/10010]	Time 0.586 (1055.245)	Data 0.001 (2.622)	Loss 1.424	Prec@1 66.9454	Prec@5 85.9271
Train: [60][2000/10010]	Time 0.586 (1172.164)	Data 0.001 (2.760)	Loss 1.417	Prec@1 67.1141	Prec@5 85.9972
Train: [60][2200/10010]	Time 0.586 (1288.957)	Data 0.001 (2.913)	Loss 1.413	Prec@1 67.1864	Prec@5 86.0536
Train: [60][2400/10010]	Time 0.585 (1405.753)	Data 0.001 (3.055)	Loss 1.410	Prec@1 67.2461	Prec@5 86.0768
Train: [60][2600/10010]	Time 0.585 (1522.508)	Data 0.001 (3.211)	Loss 1.409	Prec@1 67.2932	Prec@5 86.1051
Train: [60][2800/10010]	Time 0.585 (1639.455)	Data 0.001 (3.371)	Loss 1.405	Prec@1 67.3236	Prec@5 86.1587
Train: [60][3000/10010]	Time 0.585 (1756.105)	Data 0.001 (3.520)	Loss 1.402	Prec@1 67.3713	Prec@5 86.2010
Train: [60][3200/10010]	Time 0.585 (1872.971)	Data 0.001 (3.667)	Loss 1.400	Prec@1 67.4355	Prec@5 86.2318
Train: [60][3400/10010]	Time 0.585 (1989.839)	Data 0.001 (3.833)	Loss 1.397	Prec@1 67.4905	Prec@5 86.2685
Train: [60][3600/10010]	Time 0.585 (2106.811)	Data 0.001 (3.977)	Loss 1.395	Prec@1 67.5353	Prec@5 86.2844
Train: [60][3800/10010]	Time 0.585 (2223.556)	Data 0.001 (4.133)	Loss 1.393	Prec@1 67.5616	Prec@5 86.3249
Train: [60][4000/10010]	Time 0.585 (2340.799)	Data 0.001 (4.291)	Loss 1.389	Prec@1 67.6446	Prec@5 86.3839
Train: [60][4200/10010]	Time 0.585 (2457.837)	Data 0.001 (4.457)	Loss 1.387	Prec@1 67.6887	Prec@5 86.4113
Train: [60][4400/10010]	Time 0.585 (2574.796)	Data 0.001 (4.609)	Loss 1.385	Prec@1 67.7311	Prec@5 86.4360
Train: [60][4600/10010]	Time 0.585 (2691.770)	Data 0.001 (4.759)	Loss 1.384	Prec@1 67.7385	Prec@5 86.4652
Train: [60][4800/10010]	Time 0.585 (2809.100)	Data 0.001 (4.899)	Loss 1.383	Prec@1 67.7717	Prec@5 86.4854
Train: [60][5000/10010]	Time 0.585 (2926.218)	Data 0.001 (5.038)	Loss 1.381	Prec@1 67.8024	Prec@5 86.5091
Train: [60][5200/10010]	Time 0.585 (3043.078)	Data 0.001 (5.211)	Loss 1.379	Prec@1 67.8499	Prec@5 86.5359
Train: [60][5400/10010]	Time 0.585 (3159.817)	Data 0.001 (5.377)	Loss 1.378	Prec@1 67.8815	Prec@5 86.5403
Train: [60][5600/10010]	Time 0.585 (3276.677)	Data 0.001 (5.533)	Loss 1.376	Prec@1 67.9019	Prec@5 86.5578
Train: [60][5800/10010]	Time 0.585 (3393.682)	Data 0.001 (5.695)	Loss 1.375	Prec@1 67.9184	Prec@5 86.5738
Train: [60][6000/10010]	Time 0.585 (3511.152)	Data 0.001 (5.849)	Loss 1.374	Prec@1 67.9395	Prec@5 86.5815
Train: [60][6200/10010]	Time 0.585 (3628.293)	Data 0.001 (5.997)	Loss 1.373	Prec@1 67.9565	Prec@5 86.5970
Train: [60][6400/10010]	Time 0.585 (3745.090)	Data 0.001 (6.140)	Loss 1.371	Prec@1 67.9823	Prec@5 86.6181
Train: [60][6600/10010]	Time 0.585 (3862.367)	Data 0.001 (6.292)	Loss 1.370	Prec@1 67.9990	Prec@5 86.6331
Train: [60][6800/10010]	Time 0.585 (3979.374)	Data 0.001 (6.451)	Loss 1.370	Prec@1 68.0076	Prec@5 86.6354
Train: [60][7000/10010]	Time 0.585 (4096.432)	Data 0.001 (6.609)	Loss 1.369	Prec@1 68.0270	Prec@5 86.6501
Train: [60][7200/10010]	Time 0.585 (4213.209)	Data 0.001 (6.776)	Loss 1.367	Prec@1 68.0567	Prec@5 86.6627
Train: [60][7400/10010]	Time 0.585 (4330.052)	Data 0.001 (6.953)	Loss 1.366	Prec@1 68.0886	Prec@5 86.6858
Train: [60][7600/10010]	Time 0.585 (4447.143)	Data 0.001 (7.105)	Loss 1.365	Prec@1 68.0953	Prec@5 86.6948
Train: [60][7800/10010]	Time 0.585 (4564.162)	Data 0.001 (7.256)	Loss 1.364	Prec@1 68.1266	Prec@5 86.7184
Train: [60][8000/10010]	Time 0.585 (4681.469)	Data 0.001 (7.401)	Loss 1.363	Prec@1 68.1528	Prec@5 86.7301
Train: [60][8200/10010]	Time 0.585 (4798.563)	Data 0.001 (7.558)	Loss 1.361	Prec@1 68.1859	Prec@5 86.7525
Train: [60][8400/10010]	Time 0.585 (4915.754)	Data 0.001 (7.720)	Loss 1.360	Prec@1 68.2127	Prec@5 86.7665
Train: [60][8600/10010]	Time 0.585 (5032.625)	Data 0.001 (7.874)	Loss 1.359	Prec@1 68.2274	Prec@5 86.7719
Train: [60][8800/10010]	Time 0.585 (5149.673)	Data 0.001 (8.029)	Loss 1.358	Prec@1 68.2517	Prec@5 86.7859
Train: [60][9000/10010]	Time 0.585 (5266.713)	Data 0.001 (8.181)	Loss 1.357	Prec@1 68.2783	Prec@5 86.8053
Train: [60][9200/10010]	Time 0.585 (5383.593)	Data 0.001 (8.319)	Loss 1.356	Prec@1 68.2904	Prec@5 86.8087
Train: [60][9400/10010]	Time 0.585 (5500.722)	Data 0.001 (8.454)	Loss 1.355	Prec@1 68.3112	Prec@5 86.8207
Train: [60][9600/10010]	Time 0.585 (5617.278)	Data 0.001 (8.592)	Loss 1.354	Prec@1 68.3392	Prec@5 86.8344
Train: [60][9800/10010]	Time 0.585 (5734.122)	Data 0.001 (8.729)	Loss 1.353	Prec@1 68.3514	Prec@5 86.8415
Train: [60][10000/10010]	Time 0.585 (5851.093)	Data 0.001 (8.864)	Loss 1.353	Prec@1 68.3697	Prec@5 86.8538
Train: [60]	Time 5851.661	Data 8.864	Loss 1.353	Prec@1 68.3698	Prec@5 86.8540	
Val: [60]	Time 88.583	Data 1.793	Loss 1.111	Prec@1 72.3740	Prec@5 91.0300	
Best Prec@1: [72.374]	
Starting epoch number: 61 Learning rate: 0.0010000000000000002
